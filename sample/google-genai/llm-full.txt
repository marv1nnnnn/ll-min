Contents Menu Expand Light mode Dark mode Auto light/dark, in light mode Auto light/dark, in dark mode
Hide navigation sidebar
Hide table of contents sidebar
Skip to content
Toggle site navigation sidebar
Google Gen AI SDK documentation
Toggle Light / Dark / Auto color theme
Toggle table of contents sidebar
Google Gen AI SDK documentation
  * Submodules
  * genai.client module
  * genai.batches module
  * genai.caches module
  * genai.chats module
  * genai.files module
  * genai.live module
  * genai.models module
  * genai.tunings module
  * genai.types module


Back to top
View this page
Toggle Light / Dark / Auto color theme
Toggle table of contents sidebar
# Google Gen AI SDK¶
https://github.com/googleapis/python-genai
**google-genai** is an initial Python client library for interacting with Google’s Generative AI APIs.
Google Gen AI Python SDK provides an interface for developers to integrate Google’s generative models into their Python applications. It supports the Gemini Developer API and Vertex AI APIs.
## Installation¶
## Imports¶
```
fromgoogleimport genai
fromgoogle.genaiimport types

```

## Create a client¶
Please run one of the following code blocks to create a client for different services (Gemini Developer API or Vertex AI). Feel free to switch the client and run all the examples to see how it behaves under different APIs.
```
fromgoogleimport genai

# Only run this block for Gemini Developer API
client = genai.Client(api_key='GEMINI_API_KEY')

```

```
fromgoogleimport genai

# Only run this block for Vertex AI API
client = genai.Client(
    vertexai=True, project='your-project-id', location='us-central1'
)

```

**(Optional) Using environment variables:**
You can create a client by configuring the necessary environment variables. Configuration setup instructions depends on whether you’re using the Gemini Developer API or the Gemini API in Vertex AI.
**Gemini Developer API:** Set GOOGLE_API_KEY as shown below:
```
exportGOOGLE_API_KEY='your-api-key'

```

**Gemini API in Vertex AI:** Set GOOGLE_GENAI_USE_VERTEXAI, GOOGLE_CLOUD_PROJECT and GOOGLE_CLOUD_LOCATION, as shown below:
```
exportGOOGLE_GENAI_USE_VERTEXAI=true
exportGOOGLE_CLOUD_PROJECT='your-project-id'
exportGOOGLE_CLOUD_LOCATION='us-central1'

```

```
fromgoogleimport genai

client = genai.Client()

```

### API Selection¶
By default, the SDK uses the beta API endpoints provided by Google to support preview features in the APIs. The stable API endpoints can be selected by setting the API version to v1.
To set the API version use `http_options`. For example, to set the API version to `v1` for Vertex AI:
```
fromgoogleimport genai
fromgoogle.genaiimport types

client = genai.Client(
    vertexai=True,
    project='your-project-id',
    location='us-central1',
    http_options=types.HttpOptions(api_version='v1')
)

```

To set the API version to v1alpha for the Gemini Developer API:
```
fromgoogleimport genai
fromgoogle.genaiimport types

# Only run this block for Gemini Developer API
client = genai.Client(
    api_key='GEMINI_API_KEY',
    http_options=types.HttpOptions(api_version='v1alpha')
)

```

## Types¶
Parameter types can be specified as either dictionaries(`TypedDict`) or Pydantic Models. Pydantic model types are available in the `types` module.
# Models¶
The `client.models` modules exposes model inferencing and model getters. See the ‘Create a client’ section above to initialize a client.
## Generate Content¶
### with text content¶
```
response = client.models.generate_content(
    model='gemini-2.0-flash-001', contents='Why is the sky blue?'
)
print(response.text)

```

### with uploaded file (Gemini Developer API only)¶
download the file in console.
```
!wget -q https://storage.googleapis.com/generativeai-downloads/data/a11.txt

```

python code.
```
file = client.files.upload(file='a11.txt')
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents=['Could you summarize this file?', file]
)
print(response.text)

```

### How to structure contents argument for generate_content¶
The SDK always converts the inputs to the contents argument into list[types.Content]. The following shows some common ways to provide your inputs.
#### Provide a list[types.Content]¶
This is the canonical way to provide contents, SDK will not do any conversion.
#### Provide a types.Content instance¶
```
fromgoogle.genaiimport types

contents = types.Content(
role='user',
parts=[types.Part.from_text(text='Why is the sky blue?')]
)

```

SDK converts this to
```
[
types.Content(
    role='user',
    parts=[types.Part.from_text(text='Why is the sky blue?')]
)
]

```

#### Provide a string¶
```
contents='Why is the sky blue?'

```

The SDK will assume this is a text part, and it converts this into the following:
```
[
types.UserContent(
    parts=[
    types.Part.from_text(text='Why is the sky blue?')
    ]
)
]

```

Where a types.UserContent is a subclass of types.Content, it sets the role field to be user.
#### Provide a list of string¶
The SDK assumes these are 2 text parts, it converts this into a single content, like the following:
```
[
types.UserContent(
    parts=[
    types.Part.from_text(text='Why is the sky blue?'),
    types.Part.from_text(text='Why is the cloud white?'),
    ]
)
]

```

Where a types.UserContent is a subclass of types.Content, the role field in types.UserContent is fixed to be user.
#### Provide a function call part¶
```
fromgoogle.genaiimport types

contents = types.Part.from_function_call(
name='get_weather_by_location',
args={'location': 'Boston'}
)

```

The SDK converts a function call part to a content with a model role:
```
[
types.ModelContent(
    parts=[
    types.Part.from_function_call(
        name='get_weather_by_location',
        args={'location': 'Boston'}
    )
    ]
)
]

```

Where a types.ModelContent is a subclass of types.Content, the role field in types.ModelContent is fixed to be model.
#### Provide a list of function call parts¶
```
fromgoogle.genaiimport types

contents = [
types.Part.from_function_call(
    name='get_weather_by_location',
    args={'location': 'Boston'}
),
types.Part.from_function_call(
    name='get_weather_by_location',
    args={'location': 'New York'}
),
]

```

The SDK converts a list of function call parts to the a content with a model role:
```
[
types.ModelContent(
    parts=[
    types.Part.from_function_call(
        name='get_weather_by_location',
        args={'location': 'Boston'}
    ),
    types.Part.from_function_call(
        name='get_weather_by_location',
        args={'location': 'New York'}
    )
    ]
)
]

```

Where a types.ModelContent is a subclass of types.Content, the role field in types.ModelContent is fixed to be model.
#### Provide a non function call part¶
```
fromgoogle.genaiimport types

contents = types.Part.from_uri(
file_uri: 'gs://generativeai-downloads/images/scones.jpg',
mime_type: 'image/jpeg',
)

```

The SDK converts all non function call parts into a content with a user role.
```
[
types.UserContent(parts=[
    types.Part.from_uri(
    file_uri: 'gs://generativeai-downloads/images/scones.jpg',
    mime_type: 'image/jpeg',
    )
])
]

```

#### Provide a list of non function call parts¶
```
fromgoogle.genaiimport types

contents = [
types.Part.from_text('What is this image about?'),
types.Part.from_uri(
    file_uri: 'gs://generativeai-downloads/images/scones.jpg',
    mime_type: 'image/jpeg',
)
]

```

The SDK will convert the list of parts into a content with a user role
```
[
types.UserContent(
    parts=[
    types.Part.from_text('What is this image about?'),
    types.Part.from_uri(
        file_uri: 'gs://generativeai-downloads/images/scones.jpg',
        mime_type: 'image/jpeg',
    )
    ]
)
]

```

#### Mix types in contents¶
You can also provide a list of types.ContentUnion. The SDK leaves items of types.Content as is, it groups consecutive non function call parts into a single types.UserContent, and it groups consecutive function call parts into a single types.ModelContent.
If you put a list within a list, the inner list can only contain types.PartUnion items. The SDK will convert the inner list into a single types.UserContent.
## System Instructions and Other Configs¶
The output of the model can be influenced by several optional settings available in generate_content’s config parameter. For example, increasing max_output_tokens is essential for longer model responses. To make a model more deterministic, lowering the temperature parameter reduces randomness, with values near 0 minimizing variability. Capabilities and parameter defaults for each model is shown in the [Vertex AI docs](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash) and [Gemini API docs](https://ai.google.dev/gemini-api/docs/models) respectively.
```
fromgoogle.genaiimport types

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='high',
    config=types.GenerateContentConfig(
        system_instruction='I say high, you say low',
        max_output_tokens=3,
        temperature=0.3,
    ),
)
print(response.text)

```

## Typed Config¶
All API methods support Pydantic types for parameters as well as dictionaries. You can get the type from `google.genai.types`.
```
fromgoogle.genaiimport types

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents=types.Part.from_text(text='Why is the sky blue?'),
    config=types.GenerateContentConfig(
        temperature=0,
        top_p=0.95,
        top_k=20,
        candidate_count=1,
        seed=5,
        max_output_tokens=100,
        stop_sequences=['STOP!'],
        presence_penalty=0.0,
        frequency_penalty=0.0,
    ),
)

print(response.text)

```

## List Base Models¶
To retrieve tuned models, see: List Tuned Models
```
for model in client.models.list():
    print(model)

```

```
pager = client.models.list(config={'page_size': 10})
print(pager.page_size)
print(pager[0])
pager.next_page()
print(pager[0])

```

### List Base Models (Asynchronous)¶
```
async for job in await client.aio.models.list():
    print(job)

```

```
async_pager = await client.aio.models.list(config={'page_size': 10})
print(async_pager.page_size)
print(async_pager[0])
await async_pager.next_page()
print(async_pager[0])

```

## Safety Settings¶
```
fromgoogle.genaiimport types

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='Say something bad.',
    config=types.GenerateContentConfig(
        safety_settings=[
            types.SafetySetting(
                category='HARM_CATEGORY_HATE_SPEECH',
                threshold='BLOCK_ONLY_HIGH',
            )
        ]
    ),
)
print(response.text)

```

## Function Calling¶
Automatic Python function Support:
You can pass a Python function directly and it will be automatically called and responded.
```
fromgoogle.genaiimport types

defget_current_weather(location: str) -> str:
"""Returns the current weather.

    Args:
      location: The city and state, e.g. San Francisco, CA
    """
    return 'sunny'


response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='What is the weather like in Boston?',
    config=types.GenerateContentConfig(
        tools=[get_current_weather],
    ),
)

print(response.text)

```

### Disabling automatic function calling¶
If you pass in a python function as a tool directly, and do not want automatic function calling, you can disable automatic function calling as follows:
```
fromgoogle.genaiimport types

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='What is the weather like in Boston?',
    config=types.GenerateContentConfig(
        tools=[get_current_weather],
        automatic_function_calling=types.AutomaticFunctionCallingConfig(
            disable=True
        ),
    ),
)

```

With automatic function calling disabled, you will get a list of function call parts in the response:
### Manually declare and invoke a function for function calling¶
If you don’t want to use the automatic function support, you can manually declare the function and invoke it.
The following example shows how to declare a function and pass it as a tool. Then you will receive a function call part in the response.
```
fromgoogle.genaiimport types

function = types.FunctionDeclaration(
    name='get_current_weather',
    description='Get the current weather in a given location',
    parameters=types.Schema(
        type='OBJECT',
        properties={
            'location': types.Schema(
                type='STRING',
                description='The city and state, e.g. San Francisco, CA',
            ),
        },
        required=['location'],
    ),
)

tool = types.Tool(function_declarations=[function])

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='What is the weather like in Boston?',
    config=types.GenerateContentConfig(
        tools=[tool],
    ),
)
print(response.function_calls[0])

```

After you receive the function call part from the model, you can invoke the function and get the function response. And then you can pass the function response to the model. The following example shows how to do it for a simple function invocation.
```
fromgoogle.genaiimport types

user_prompt_content = types.Content(
    role='user',
    parts=[types.Part.from_text(text='What is the weather like in Boston?')],
)
function_call_part = response.function_calls[0]
function_call_content = response.candidates[0].content


try:
    function_result = get_current_weather(
        **function_call_part.function_call.args
    )
    function_response = {'result': function_result}
except (
    Exception
) as e:  # instead of raising the exception, you can let the model handle it
    function_response = {'error': str(e)}


function_response_part = types.Part.from_function_response(
    name=function_call_part.name,
    response=function_response,
)
function_response_content = types.Content(
    role='tool', parts=[function_response_part]
)

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents=[
        user_prompt_content,
        function_call_content,
        function_response_content,
    ],
    config=types.GenerateContentConfig(
        tools=[tool],
    ),
)

print(response.text)

```

### Function calling with `ANY` tools config mode¶
If you configure function calling mode to be ANY, then the model will always return function call parts. If you also pass a python function as a tool, by default the SDK will perform automatic function calling until the remote calls exceed the maximum remote call for automatic function calling (default to 10 times).
If you’d like to disable automatic function calling in ANY mode:
```
fromgoogle.genaiimport types

defget_current_weather(location: str) -> str:
"""Returns the current weather.

    Args:
        location: The city and state, e.g. San Francisco, CA
    """
    return "sunny"

response = client.models.generate_content(
    model="gemini-2.0-flash-001",
    contents="What is the weather like in Boston?",
    config=types.GenerateContentConfig(
        tools=[get_current_weather],
        automatic_function_calling=types.AutomaticFunctionCallingConfig(
            disable=True
        ),
        tool_config=types.ToolConfig(
            function_calling_config=types.FunctionCallingConfig(mode='ANY')
        ),
    ),
)

```

If you’d like to set `x` number of automatic function call turns, you can configure the maximum remote calls to be `x + 1`. Assuming you prefer `1` turn for automatic function calling:
```
fromgoogle.genaiimport types

defget_current_weather(location: str) -> str:
"""Returns the current weather.

    Args:
        location: The city and state, e.g. San Francisco, CA
    """
    return "sunny"

response = client.models.generate_content(
    model="gemini-2.0-flash-001",
    contents="What is the weather like in Boston?",
    config=types.GenerateContentConfig(
        tools=[get_current_weather],
        automatic_function_calling=types.AutomaticFunctionCallingConfig(
            maximum_remote_calls=2
        ),
        tool_config=types.ToolConfig(
            function_calling_config=types.FunctionCallingConfig(mode='ANY')
        ),
    ),
)

```

## JSON Response Schema¶
### Pydantic Model Schema support¶
Schemas can be provided as Pydantic Models.
```
frompydanticimport BaseModel
fromgoogle.genaiimport types


classCountryInfo(BaseModel):
    name: str
    population: int
    capital: str
    continent: str
    gdp: int
    official_language: str
    total_area_sq_mi: int


response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='Give me information for the United States.',
    config=types.GenerateContentConfig(
        response_mime_type='application/json',
        response_schema=CountryInfo,
    ),
)
print(response.text)

```

```
fromgoogle.genaiimport types

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='Give me information for the United States.',
    config=types.GenerateContentConfig(
        response_mime_type='application/json',
        response_schema={
            'required': [
                'name',
                'population',
                'capital',
                'continent',
                'gdp',
                'official_language',
                'total_area_sq_mi',
            ],
            'properties': {
                'name': {'type': 'STRING'},
                'population': {'type': 'INTEGER'},
                'capital': {'type': 'STRING'},
                'continent': {'type': 'STRING'},
                'gdp': {'type': 'INTEGER'},
                'official_language': {'type': 'STRING'},
                'total_area_sq_mi': {'type': 'INTEGER'},
            },
            'type': 'OBJECT',
        },
    ),
)
print(response.text)

```

## Enum Response Schema¶
### Text Response¶
You can set response_mime_type to ‘text/x.enum’ to return one of those enum values as the response.
```
fromenumimport Enum

classInstrumentEnum(Enum):
    PERCUSSION = 'Percussion'
    STRING = 'String'
    WOODWIND = 'Woodwind'
    BRASS = 'Brass'
    KEYBOARD = 'Keyboard'

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='What instrument plays multiple notes at once?',
    config={
        'response_mime_type': 'text/x.enum',
        'response_schema': InstrumentEnum,
    },
)
print(response.text)

```

### JSON Response¶
You can also set response_mime_type to ‘application/json’, the response will be identical but in quotes.
```
classInstrumentEnum(Enum):
    PERCUSSION = 'Percussion'
    STRING = 'String'
    WOODWIND = 'Woodwind'
    BRASS = 'Brass'
    KEYBOARD = 'Keyboard'

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='What instrument plays multiple notes at once?',
    config={
        'response_mime_type': 'application/json',
        'response_schema': InstrumentEnum,
    },
)
print(response.text)

```

## Generate Content (Synchronous Streaming)¶
Generate content in a streaming format so that the model outputs streams back to you, rather than being returned as one chunk.
### Streaming for text content¶
```
for chunk in client.models.generate_content_stream(
    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'
):
    print(chunk.text, end='')

```

### Streaming for image content¶
If your image is stored in Google Cloud Storage, you can use the from_uri class method to create a Part object.
```
fromgoogle.genaiimport types

for chunk in client.models.generate_content_stream(
    model='gemini-2.0-flash-001',
    contents=[
        'What is this image about?',
        types.Part.from_uri(
            file_uri='gs://generativeai-downloads/images/scones.jpg',
            mime_type='image/jpeg',
        ),
    ],
):
    print(chunk.text, end='')

```

If your image is stored in your local file system, you can read it in as bytes data and use the `from_bytes` class method to create a `Part` object.
```
fromgoogle.genaiimport types

YOUR_IMAGE_PATH = 'your_image_path'
YOUR_IMAGE_MIME_TYPE = 'your_image_mime_type'
with open(YOUR_IMAGE_PATH, 'rb') as f:
    image_bytes = f.read()

for chunk in client.models.generate_content_stream(
    model='gemini-2.0-flash-001',
    contents=[
        'What is this image about?',
        types.Part.from_bytes(data=image_bytes, mime_type=YOUR_IMAGE_MIME_TYPE),
    ],
):
    print(chunk.text, end='')

```

## Generate Content (Asynchronous Non-Streaming)¶
`client.aio` exposes all the analogous async methods that are available on `client`. Note that it applies to all the modules.
For example, `client.aio.models.generate_content` is the `async` version of `client.models.generate_content`
```
response = await client.aio.models.generate_content(
    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'
)

print(response.text)

```

## Generate Content (Asynchronous Streaming)¶
```
async for chunk in await client.aio.models.generate_content_stream(
    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'
):
    print(chunk.text, end='')

```

## Count Tokens and Compute Tokens¶
```
response = client.models.count_tokens(
    model='gemini-2.0-flash-001',
    contents='why is the sky blue?',
)
print(response)

```

### Compute Tokens¶
Compute tokens is only supported in Vertex AI.
```
response = client.models.compute_tokens(
    model='gemini-2.0-flash-001',
    contents='why is the sky blue?',
)
print(response)

```

### Count Tokens (Asynchronous)¶
```
response = await client.aio.models.count_tokens(
    model='gemini-2.0-flash-001',
    contents='why is the sky blue?',
)
print(response)

```

## Embed Content¶
```
response = client.models.embed_content(
    model='text-embedding-004',
    contents='why is the sky blue?',
)
print(response)

```

```
fromgoogle.genaiimport types

# multiple contents with config
response = client.models.embed_content(
    model='text-embedding-004',
    contents=['why is the sky blue?', 'What is your age?'],
    config=types.EmbedContentConfig(output_dimensionality=10),
)

print(response)

```

## Imagen¶
### Generate Image¶
Support for generate image in Gemini Developer API is behind an allowlist
```
fromgoogle.genaiimport types

# Generate Image
response1 = client.models.generate_images(
    model='imagen-3.0-generate-002',
    prompt='An umbrella in the foreground, and a rainy night sky in the background',
    config=types.GenerateImagesConfig(
        number_of_images=1,
        include_rai_reason=True,
        output_mime_type='image/jpeg',
    ),
)
response1.generated_images[0].image.show()

```

Upscale image is only supported in Vertex AI.
```
fromgoogle.genaiimport types

# Upscale the generated image from above
response2 = client.models.upscale_image(
    model='imagen-3.0-generate-002',
    image=response1.generated_images[0].image,
    upscale_factor='x2',
    config=types.UpscaleImageConfig(
        include_rai_reason=True,
        output_mime_type='image/jpeg',
    ),
)
response2.generated_images[0].image.show()

```

### Edit Image¶
Edit image uses a separate model from generate and upscale.
Edit image is only supported in Vertex AI.
```
# Edit the generated image from above
fromgoogle.genaiimport types
fromgoogle.genai.typesimport RawReferenceImage, MaskReferenceImage

raw_ref_image = RawReferenceImage(
    reference_id=1,
    reference_image=response1.generated_images[0].image,
)

# Model computes a mask of the background
mask_ref_image = MaskReferenceImage(
    reference_id=2,
    config=types.MaskReferenceConfig(
        mask_mode='MASK_MODE_BACKGROUND',
        mask_dilation=0,
    ),
)

response3 = client.models.edit_image(
    model='imagen-3.0-capability-001',
    prompt='Sunlight and clear sky',
    reference_images=[raw_ref_image, mask_ref_image],
    config=types.EditImageConfig(
        edit_mode='EDIT_MODE_INPAINT_INSERTION',
        number_of_images=1,
        include_rai_reason=True,
        output_mime_type='image/jpeg',
    ),
)
response3.generated_images[0].image.show()

```

## Veo¶
### Generate Videos¶
Support for generate videos in Vertex and Gemini Developer API is behind an allowlist
```
fromgoogle.genaiimport types

# Create operation
operation = client.models.generate_videos(
    model='veo-2.0-generate-001',
    prompt='A neon hologram of a cat driving at top speed',
    config=types.GenerateVideosConfig(
        number_of_videos=1,
        fps=24,
        duration_seconds=5,
        enhance_prompt=True,
    ),
)

# Poll operation
while not operation.done:
    time.sleep(20)
    operation = client.operations.get(operation)

video = operation.result.generated_videos[0].video
video.show()

```

# Chats¶
Create a chat session to start a multi-turn conversations with the model. Then, use chat.send_message function multiple times within the same chat session so that it can reflect on its previous responses (i.e., engage in an ongoing conversation). See the ‘Create a client’ section above to initialize a client.
## Send Message (Synchronous Non-Streaming)¶
```
chat = client.chats.create(model='gemini-2.0-flash-001')
response = chat.send_message('tell me a story')
print(response.text)
response = chat.send_message('summarize the story you told me in 1 sentence')
print(response.text)

```

## Send Message (Synchronous Streaming)¶
```
chat = client.chats.create(model='gemini-2.0-flash-001')
for chunk in chat.send_message_stream('tell me a story'):
    print(chunk.text, end='')  # end='' is optional, for demo purposes.

```

## Send Message (Asynchronous Non-Streaming)¶
```
chat = client.aio.chats.create(model='gemini-2.0-flash-001')
response = await chat.send_message('tell me a story')
print(response.text)

```

## Send Message (Asynchronous Streaming)¶
```
chat = client.aio.chats.create(model='gemini-2.0-flash-001')
async for chunk in await chat.send_message_stream('tell me a story'):
    print(chunk.text, end='') # end='' is optional, for demo purposes.

```

# Files¶
Files are only supported in Gemini Developer API. See the ‘Create a client’ section above to initialize a client.
```
gsutil cp gs://cloud-samples-data/generative-ai/pdf/2312.11805v3.pdf .
gsutil cp gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf .

```

## Upload¶
```
file1 = client.files.upload(file='2312.11805v3.pdf')
file2 = client.files.upload(file='2403.05530.pdf')

print(file1)
print(file2)

```

## Get¶
```
file1 = client.files.upload(file='2312.11805v3.pdf')
file_info = client.files.get(name=file1.name)

```

## Delete¶
```
file3 = client.files.upload(file='2312.11805v3.pdf')

client.files.delete(name=file3.name)

```

# Caches¶ 

`client.caches` contains the control plane APIs for cached content.
    
See the ‘Create a client’ section above to initialize a client.
## Create¶
```
fromgoogle.genaiimport types

if client.vertexai:
    file_uris = [
        'gs://cloud-samples-data/generative-ai/pdf/2312.11805v3.pdf',
        'gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf',
    ]
else:
    file_uris = [file1.uri, file2.uri]

cached_content = client.caches.create(
    model='gemini-2.0-flash-001',
    config=types.CreateCachedContentConfig(
        contents=[
            types.Content(
                role='user',
                parts=[
                    types.Part.from_uri(
                        file_uri=file_uris[0], mime_type='application/pdf'
                    ),
                    types.Part.from_uri(
                        file_uri=file_uris[1],
                        mime_type='application/pdf',
                    ),
                ],
            )
        ],
        system_instruction='What is the sum of the two pdfs?',
        display_name='test cache',
        ttl='3600s',
    ),
)

```

## Get¶
```
cached_content = client.caches.get(name=cached_content.name)

```

## Generate Content with Caches¶
```
fromgoogle.genaiimport types

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='Summarize the pdfs',
    config=types.GenerateContentConfig(
        cached_content=cached_content.name,
    ),
)
print(response.text)

```

# Tunings¶
`client.tunings` contains tuning job APIs and supports supervised fine tuning through `tune`. See the ‘Create a client’ section above to initialize a client.
## Tune¶
  * Vertex AI supports tuning from GCS source
  * Gemini Developer API supports tuning from inline examples


```
fromgoogle.genaiimport types

if client.vertexai:
    model = 'gemini-2.0-flash-001'
    training_dataset = types.TuningDataset(
        gcs_uri='gs://cloud-samples-data/ai-platform/generative_ai/gemini-1_5/text/sft_train_data.jsonl',
    )
else:
    model = 'models/gemini-2.0-flash-001'
    training_dataset = types.TuningDataset(
        examples=[
            types.TuningExample(
                text_input=f'Input text {i}',
                output=f'Output text {i}',
            )
            for i in range(5)
        ],
    )

```

```
fromgoogle.genaiimport types

tuning_job = client.tunings.tune(
    base_model=model,
    training_dataset=training_dataset,
    config=types.CreateTuningJobConfig(
        epoch_count=1, tuned_model_display_name='test_dataset_examples model'
    ),
)
print(tuning_job)

```

## Get Tuning Job¶
```
tuning_job = client.tunings.get(name=tuning_job.name)
print(tuning_job)

```

```
importtime

running_states = set(
    [
        'JOB_STATE_PENDING',
        'JOB_STATE_RUNNING',
    ]
)

while tuning_job.state in running_states:
    print(tuning_job.state)
    tuning_job = client.tunings.get(name=tuning_job.name)
    time.sleep(10)

```

## Use Tuned Model¶
```
response = client.models.generate_content(
    model=tuning_job.tuned_model.endpoint,
    contents='why is the sky blue?',
)

print(response.text)

```

## Get Tuned Model¶
```
tuned_model = client.models.get(model=tuning_job.tuned_model.model)
print(tuned_model)

```

## Update Tuned Model¶
```
fromgoogle.genaiimport types

tuned_model = client.models.update(
    model=tuning_job.tuned_model.model,
    config=types.UpdateModelConfig(
        display_name='my tuned model', description='my tuned model description'
    ),
)
print(tuned_model)

```

## List Tuned Models¶
To retrieve base models, see: List Base Models
```
for model in client.models.list(config={'page_size': 10, 'query_base': False}}):
    print(model)

```

```
pager = client.models.list(config={'page_size': 10, 'query_base': False}})
print(pager.page_size)
print(pager[0])
pager.next_page()
print(pager[0])

```

### List Tuned Models (Asynchronous)¶
```
async for job in await client.aio.models.list(config={'page_size': 10, 'query_base': False}}):
    print(job)

```

```
async_pager = await client.aio.models.list(config={'page_size': 10, 'query_base': False}})
print(async_pager.page_size)
print(async_pager[0])
await async_pager.next_page()
print(async_pager[0])

```

## Update Tuned Model¶
```
model = pager[0]

model = client.models.update(
    model=model.name,
    config=types.UpdateModelConfig(
        display_name='my tuned model', description='my tuned model description'
    ),
)

print(model)

```

## List Tuning Jobs¶
```
for job in client.tunings.list(config={'page_size': 10}):
    print(job)

```

```
pager = client.tunings.list(config={'page_size': 10})
print(pager.page_size)
print(pager[0])
pager.next_page()
print(pager[0])

```

List Tuning Jobs (Asynchronous):
```
async for job in await client.aio.tunings.list(config={'page_size': 10}):
    print(job)

```

```
async_pager = await client.aio.tunings.list(config={'page_size': 10})
print(async_pager.page_size)
print(async_pager[0])
await async_pager.next_page()
print(async_pager[0])

```

# Batch Prediction¶
Only supported in Vertex AI. See the ‘Create a client’ section above to initialize a client.
## Create¶
```
# Specify model and source file only, destination and job display name will be auto-populated
job = client.batches.create(
    model='gemini-2.0-flash-001',
    src='bq://my-project.my-dataset.my-table',
)

job

```

```
# Get a job by name
job = client.batches.get(name=job.name)

job.state

```

```
completed_states = set(
    [
        'JOB_STATE_SUCCEEDED',
        'JOB_STATE_FAILED',
        'JOB_STATE_CANCELLED',
        'JOB_STATE_PAUSED',
    ]
)

while job.state not in completed_states:
    print(job.state)
    job = client.batches.get(name=job.name)
    time.sleep(30)

job

```

## List¶
```
fromgoogle.genaiimport types

for job in client.batches.list(config=types.ListBatchJobsConfig(page_size=10)):
    print(job)

```

### List Batch Jobs with Pager¶
```
fromgoogle.genaiimport types

pager = client.batches.list(config=types.ListBatchJobsConfig(page_size=10))
print(pager.page_size)
print(pager[0])
pager.next_page()
print(pager[0])

```

### List Batch Jobs (Asynchronous)¶
```
fromgoogle.genaiimport types

async for job in await client.aio.batches.list(
    config=types.ListBatchJobsConfig(page_size=10)
):
    print(job)

```

### List Batch Jobs with Pager (Asynchronous)¶
```
fromgoogle.genaiimport types

async_pager = await client.aio.batches.list(
    config=types.ListBatchJobsConfig(page_size=10)
)
print(async_pager.page_size)
print(async_pager[0])
await async_pager.next_page()
print(async_pager[0])

```

## Delete¶
```
# Delete the job resource
delete_job = client.batches.delete(name=job.name)

delete_job

```

# Error Handling¶
To handle errors raised by the model, the SDK provides this [APIError](https://github.com/googleapis/python-genai/blob/main/google/genai/errors.py) class.
```
try:
    client.models.generate_content(
        model="invalid-model-name",
        contents="What is your name?",
    )
except errors.APIError as e:
    print(e.code) # 404
    print(e.message)

```

# Reference¶
  * Submodules
  * genai.client module
    * `AsyncClient`
      * `AsyncClient.batches`
      * `AsyncClient.caches`
      * `AsyncClient.chats`
      * `AsyncClient.files`
      * `AsyncClient.live`
      * `AsyncClient.models`
      * `AsyncClient.operations`
      * `AsyncClient.tunings`
    * `Client`
      * `Client.api_key`
      * `Client.vertexai`
      * `Client.credentials`
      * `Client.project`
      * `Client.location`
      * `Client.debug_config`
      * `Client.http_options`
      * `Client.aio`
      * `Client.batches`
      * `Client.caches`
      * `Client.chats`
      * `Client.files`
      * `Client.models`
      * `Client.operations`
      * `Client.tunings`
      * `Client.vertexai`
    * `DebugConfig`
      * `DebugConfig.client_mode`
      * `DebugConfig.replay_id`
      * `DebugConfig.replays_directory`
  * genai.batches module
    * `AsyncBatches`
      * `AsyncBatches.cancel()`
      * `AsyncBatches.create()`
      * `AsyncBatches.delete()`
      * `AsyncBatches.get()`
      * `AsyncBatches.list()`
    * `Batches`
      * `Batches.cancel()`
      * `Batches.create()`
      * `Batches.delete()`
      * `Batches.get()`
      * `Batches.list()`
  * genai.caches module
    * `AsyncCaches`
      * `AsyncCaches.create()`
      * `AsyncCaches.delete()`
      * `AsyncCaches.get()`
      * `AsyncCaches.list()`
      * `AsyncCaches.update()`
    * `Caches`
      * `Caches.create()`
      * `Caches.delete()`
      * `Caches.get()`
      * `Caches.list()`
      * `Caches.update()`
  * genai.chats module
    * `AsyncChat`
      * `AsyncChat.send_message()`
      * `AsyncChat.send_message_stream()`
    * `AsyncChats`
      * `AsyncChats.create()`
    * `Chat`
      * `Chat.send_message()`
      * `Chat.send_message_stream()`
    * `Chats`
      * `Chats.create()`
  * genai.files module
    * `AsyncFiles`
      * `AsyncFiles.delete()`
      * `AsyncFiles.download()`
      * `AsyncFiles.get()`
      * `AsyncFiles.list()`
      * `AsyncFiles.upload()`
    * `Files`
      * `Files.delete()`
      * `Files.download()`
      * `Files.get()`
      * `Files.list()`
      * `Files.upload()`
  * genai.live module
    * `AsyncLive`
      * `AsyncLive.connect()`
    * `AsyncSession`
      * `AsyncSession.close()`
      * `AsyncSession.receive()`
      * `AsyncSession.send()`
      * `AsyncSession.send_client_content()`
      * `AsyncSession.send_realtime_input()`
      * `AsyncSession.send_tool_response()`
      * `AsyncSession.start_stream()`
  * genai.models module
    * `AsyncModels`
      * `AsyncModels.compute_tokens()`
      * `AsyncModels.count_tokens()`
      * `AsyncModels.delete()`
      * `AsyncModels.edit_image()`
      * `AsyncModels.embed_content()`
      * `AsyncModels.generate_content()`
      * `AsyncModels.generate_content_stream()`
      * `AsyncModels.generate_images()`
      * `AsyncModels.generate_videos()`
      * `AsyncModels.get()`
      * `AsyncModels.list()`
      * `AsyncModels.update()`
      * `AsyncModels.upscale_image()`
    * `Models`
      * `Models.compute_tokens()`
      * `Models.count_tokens()`
      * `Models.delete()`
      * `Models.edit_image()`
      * `Models.embed_content()`
      * `Models.generate_content()`
      * `Models.generate_content_stream()`
      * `Models.generate_images()`
      * `Models.generate_videos()`
      * `Models.get()`
      * `Models.list()`
      * `Models.update()`
      * `Models.upscale_image()`
  * genai.tunings module
    * `AsyncTunings`
      * `AsyncTunings.get()`
      * `AsyncTunings.list()`
      * `AsyncTunings.tune()`
    * `Tunings`
      * `Tunings.get()`
      * `Tunings.list()`
      * `Tunings.tune()`
  * genai.types module
    * `ActivityEnd`
    * `ActivityEndDict`
    * `ActivityHandling`
      * `ActivityHandling.ACTIVITY_HANDLING_UNSPECIFIED`
      * `ActivityHandling.NO_INTERRUPTION`
      * `ActivityHandling.START_OF_ACTIVITY_INTERRUPTS`
    * `ActivityStart`
    * `ActivityStartDict`
    * `AdapterSize`
      * `AdapterSize.ADAPTER_SIZE_EIGHT`
      * `AdapterSize.ADAPTER_SIZE_FOUR`
      * `AdapterSize.ADAPTER_SIZE_ONE`
      * `AdapterSize.ADAPTER_SIZE_SIXTEEN`
      * `AdapterSize.ADAPTER_SIZE_THIRTY_TWO`
      * `AdapterSize.ADAPTER_SIZE_TWO`
      * `AdapterSize.ADAPTER_SIZE_UNSPECIFIED`
    * `ApiKeyConfig`
      * `ApiKeyConfig.api_key_string`
    * `ApiKeyConfigDict`
      * `ApiKeyConfigDict.api_key_string`
    * `AudioTranscriptionConfig`
    * `AudioTranscriptionConfigDict`
    * `AuthConfig`
      * `AuthConfig.api_key_config`
      * `AuthConfig.auth_type`
      * `AuthConfig.google_service_account_config`
      * `AuthConfig.http_basic_auth_config`
      * `AuthConfig.oauth_config`
      * `AuthConfig.oidc_config`
    * `AuthConfigDict`
      * `AuthConfigDict.api_key_config`
      * `AuthConfigDict.auth_type`
      * `AuthConfigDict.google_service_account_config`
      * `AuthConfigDict.http_basic_auth_config`
      * `AuthConfigDict.oauth_config`
      * `AuthConfigDict.oidc_config`
    * `AuthConfigGoogleServiceAccountConfig`
      * `AuthConfigGoogleServiceAccountConfig.service_account`
    * `AuthConfigGoogleServiceAccountConfigDict`
      * `AuthConfigGoogleServiceAccountConfigDict.service_account`
    * `AuthConfigHttpBasicAuthConfig`
      * `AuthConfigHttpBasicAuthConfig.credential_secret`
    * `AuthConfigHttpBasicAuthConfigDict`
      * `AuthConfigHttpBasicAuthConfigDict.credential_secret`
    * `AuthConfigOauthConfig`
      * `AuthConfigOauthConfig.access_token`
      * `AuthConfigOauthConfig.service_account`
    * `AuthConfigOauthConfigDict`
      * `AuthConfigOauthConfigDict.access_token`
      * `AuthConfigOauthConfigDict.service_account`
    * `AuthConfigOidcConfig`
      * `AuthConfigOidcConfig.id_token`
      * `AuthConfigOidcConfig.service_account`
    * `AuthConfigOidcConfigDict`
      * `AuthConfigOidcConfigDict.id_token`
      * `AuthConfigOidcConfigDict.service_account`
    * `AuthType`
      * `AuthType.API_KEY_AUTH`
      * `AuthType.AUTH_TYPE_UNSPECIFIED`
      * `AuthType.GOOGLE_SERVICE_ACCOUNT_AUTH`
      * `AuthType.HTTP_BASIC_AUTH`
      * `AuthType.NO_AUTH`
      * `AuthType.OAUTH`
      * `AuthType.OIDC_AUTH`
    * `AutomaticActivityDetection`
      * `AutomaticActivityDetection.disabled`
      * `AutomaticActivityDetection.end_of_speech_sensitivity`
      * `AutomaticActivityDetection.prefix_padding_ms`
      * `AutomaticActivityDetection.silence_duration_ms`
      * `AutomaticActivityDetection.start_of_speech_sensitivity`
    * `AutomaticActivityDetectionDict`
      * `AutomaticActivityDetectionDict.disabled`
      * `AutomaticActivityDetectionDict.end_of_speech_sensitivity`
      * `AutomaticActivityDetectionDict.prefix_padding_ms`
      * `AutomaticActivityDetectionDict.silence_duration_ms`
      * `AutomaticActivityDetectionDict.start_of_speech_sensitivity`
    * `AutomaticFunctionCallingConfig`
      * `AutomaticFunctionCallingConfig.disable`
      * `AutomaticFunctionCallingConfig.ignore_call_history`
      * `AutomaticFunctionCallingConfig.maximum_remote_calls`
    * `AutomaticFunctionCallingConfigDict`
      * `AutomaticFunctionCallingConfigDict.disable`
      * `AutomaticFunctionCallingConfigDict.ignore_call_history`
      * `AutomaticFunctionCallingConfigDict.maximum_remote_calls`
    * `BatchJob`
      * `BatchJob.create_time`
      * `BatchJob.dest`
      * `BatchJob.display_name`
      * `BatchJob.end_time`
      * `BatchJob.error`
      * `BatchJob.model`
      * `BatchJob.name`
      * `BatchJob.src`
      * `BatchJob.start_time`
      * `BatchJob.state`
      * `BatchJob.update_time`
    * `BatchJobDestination`
      * `BatchJobDestination.bigquery_uri`
      * `BatchJobDestination.format`
      * `BatchJobDestination.gcs_uri`
    * `BatchJobDestinationDict`
      * `BatchJobDestinationDict.bigquery_uri`
      * `BatchJobDestinationDict.format`
      * `BatchJobDestinationDict.gcs_uri`
    * `BatchJobDict`
      * `BatchJobDict.create_time`
      * `BatchJobDict.dest`
      * `BatchJobDict.display_name`
      * `BatchJobDict.end_time`
      * `BatchJobDict.error`
      * `BatchJobDict.model`
      * `BatchJobDict.name`
      * `BatchJobDict.src`
      * `BatchJobDict.start_time`
      * `BatchJobDict.state`
      * `BatchJobDict.update_time`
    * `BatchJobSource`
      * `BatchJobSource.bigquery_uri`
      * `BatchJobSource.format`
      * `BatchJobSource.gcs_uri`
    * `BatchJobSourceDict`
      * `BatchJobSourceDict.bigquery_uri`
      * `BatchJobSourceDict.format`
      * `BatchJobSourceDict.gcs_uri`
    * `Blob`
      * `Blob.data`
      * `Blob.display_name`
      * `Blob.mime_type`
    * `BlobDict`
      * `BlobDict.data`
      * `BlobDict.display_name`
      * `BlobDict.mime_type`
    * `BlockedReason`
      * `BlockedReason.BLOCKED_REASON_UNSPECIFIED`
      * `BlockedReason.BLOCKLIST`
      * `BlockedReason.OTHER`
      * `BlockedReason.PROHIBITED_CONTENT`
      * `BlockedReason.SAFETY`
    * `CachedContent`
      * `CachedContent.create_time`
      * `CachedContent.display_name`
      * `CachedContent.expire_time`
      * `CachedContent.model`
      * `CachedContent.name`
      * `CachedContent.update_time`
      * `CachedContent.usage_metadata`
    * `CachedContentDict`
      * `CachedContentDict.create_time`
      * `CachedContentDict.display_name`
      * `CachedContentDict.expire_time`
      * `CachedContentDict.model`
      * `CachedContentDict.name`
      * `CachedContentDict.update_time`
      * `CachedContentDict.usage_metadata`
    * `CachedContentUsageMetadata`
      * `CachedContentUsageMetadata.audio_duration_seconds`
      * `CachedContentUsageMetadata.image_count`
      * `CachedContentUsageMetadata.text_count`
      * `CachedContentUsageMetadata.total_token_count`
      * `CachedContentUsageMetadata.video_duration_seconds`
    * `CachedContentUsageMetadataDict`
      * `CachedContentUsageMetadataDict.audio_duration_seconds`
      * `CachedContentUsageMetadataDict.image_count`
      * `CachedContentUsageMetadataDict.text_count`
      * `CachedContentUsageMetadataDict.total_token_count`
      * `CachedContentUsageMetadataDict.video_duration_seconds`
    * `CancelBatchJobConfig`
      * `CancelBatchJobConfig.http_options`
    * `CancelBatchJobConfigDict`
      * `CancelBatchJobConfigDict.http_options`
    * `Candidate`
      * `Candidate.avg_logprobs`
      * `Candidate.citation_metadata`
      * `Candidate.content`
      * `Candidate.finish_message`
      * `Candidate.finish_reason`
      * `Candidate.grounding_metadata`
      * `Candidate.index`
      * `Candidate.logprobs_result`
      * `Candidate.safety_ratings`
      * `Candidate.token_count`
    * `CandidateDict`
      * `CandidateDict.avg_logprobs`
      * `CandidateDict.citation_metadata`
      * `CandidateDict.content`
      * `CandidateDict.finish_message`
      * `CandidateDict.finish_reason`
      * `CandidateDict.grounding_metadata`
      * `CandidateDict.index`
      * `CandidateDict.logprobs_result`
      * `CandidateDict.safety_ratings`
      * `CandidateDict.token_count`
    * `Checkpoint`
      * `Checkpoint.checkpoint_id`
      * `Checkpoint.epoch`
      * `Checkpoint.step`
    * `CheckpointDict`
      * `CheckpointDict.checkpoint_id`
      * `CheckpointDict.epoch`
      * `CheckpointDict.step`
    * `Citation`
      * `Citation.end_index`
      * `Citation.license`
      * `Citation.publication_date`
      * `Citation.start_index`
      * `Citation.title`
      * `Citation.uri`
    * `CitationDict`
      * `CitationDict.end_index`
      * `CitationDict.license`
      * `CitationDict.publication_date`
      * `CitationDict.start_index`
      * `CitationDict.title`
      * `CitationDict.uri`
    * `CitationMetadata`
      * `CitationMetadata.citations`
    * `CitationMetadataDict`
      * `CitationMetadataDict.citations`
    * `CodeExecutionResult`
      * `CodeExecutionResult.outcome`
      * `CodeExecutionResult.output`
    * `CodeExecutionResultDict`
      * `CodeExecutionResultDict.outcome`
      * `CodeExecutionResultDict.output`
    * `ComputeTokensConfig`
      * `ComputeTokensConfig.http_options`
    * `ComputeTokensConfigDict`
      * `ComputeTokensConfigDict.http_options`
    * `ComputeTokensResponse`
      * `ComputeTokensResponse.tokens_info`
    * `ComputeTokensResponseDict`
      * `ComputeTokensResponseDict.tokens_info`
    * `Content`
      * `Content.parts`
      * `Content.role`
    * `ContentDict`
      * `ContentDict.parts`
      * `ContentDict.role`
    * `ContentEmbedding`
      * `ContentEmbedding.statistics`
      * `ContentEmbedding.values`
    * `ContentEmbeddingDict`
      * `ContentEmbeddingDict.statistics`
    * `ContentEmbeddingStatistics`
      * `ContentEmbeddingStatistics.token_count`
      * `ContentEmbeddingStatistics.truncated`
    * `ContentEmbeddingStatisticsDict`
      * `ContentEmbeddingStatisticsDict.token_count`
      * `ContentEmbeddingStatisticsDict.truncated`
    * `ContextWindowCompressionConfig`
      * `ContextWindowCompressionConfig.sliding_window`
      * `ContextWindowCompressionConfig.trigger_tokens`
    * `ContextWindowCompressionConfigDict`
      * `ContextWindowCompressionConfigDict.sliding_window`
      * `ContextWindowCompressionConfigDict.trigger_tokens`
    * `ControlReferenceConfig`
      * `ControlReferenceConfig.control_type`
      * `ControlReferenceConfig.enable_control_image_computation`
    * `ControlReferenceConfigDict`
      * `ControlReferenceConfigDict.control_type`
      * `ControlReferenceConfigDict.enable_control_image_computation`
    * `ControlReferenceImage`
      * `ControlReferenceImage.config`
      * `ControlReferenceImage.control_image_config`
      * `ControlReferenceImage.reference_id`
      * `ControlReferenceImage.reference_image`
      * `ControlReferenceImage.reference_type`
    * `ControlReferenceImageDict`
      * `ControlReferenceImageDict.config`
      * `ControlReferenceImageDict.reference_id`
      * `ControlReferenceImageDict.reference_image`
      * `ControlReferenceImageDict.reference_type`
    * `ControlReferenceType`
      * `ControlReferenceType.CONTROL_TYPE_CANNY`
      * `ControlReferenceType.CONTROL_TYPE_DEFAULT`
      * `ControlReferenceType.CONTROL_TYPE_FACE_MESH`
      * `ControlReferenceType.CONTROL_TYPE_SCRIBBLE`
    * `CountTokensConfig`
      * `CountTokensConfig.generation_config`
      * `CountTokensConfig.http_options`
      * `CountTokensConfig.system_instruction`
      * `CountTokensConfig.tools`
    * `CountTokensConfigDict`
      * `CountTokensConfigDict.generation_config`
      * `CountTokensConfigDict.http_options`
      * `CountTokensConfigDict.system_instruction`
      * `CountTokensConfigDict.tools`
    * `CountTokensResponse`
      * `CountTokensResponse.cached_content_token_count`
      * `CountTokensResponse.total_tokens`
    * `CountTokensResponseDict`
      * `CountTokensResponseDict.cached_content_token_count`
      * `CountTokensResponseDict.total_tokens`
    * `CreateBatchJobConfig`
      * `CreateBatchJobConfig.dest`
      * `CreateBatchJobConfig.display_name`
      * `CreateBatchJobConfig.http_options`
    * `CreateBatchJobConfigDict`
      * `CreateBatchJobConfigDict.dest`
      * `CreateBatchJobConfigDict.display_name`
      * `CreateBatchJobConfigDict.http_options`
    * `CreateCachedContentConfig`
      * `CreateCachedContentConfig.contents`
      * `CreateCachedContentConfig.display_name`
      * `CreateCachedContentConfig.expire_time`
      * `CreateCachedContentConfig.http_options`
      * `CreateCachedContentConfig.system_instruction`
      * `CreateCachedContentConfig.tool_config`
      * `CreateCachedContentConfig.tools`
      * `CreateCachedContentConfig.ttl`
    * `CreateCachedContentConfigDict`
      * `CreateCachedContentConfigDict.contents`
      * `CreateCachedContentConfigDict.display_name`
      * `CreateCachedContentConfigDict.expire_time`
      * `CreateCachedContentConfigDict.http_options`
      * `CreateCachedContentConfigDict.system_instruction`
      * `CreateCachedContentConfigDict.tool_config`
      * `CreateCachedContentConfigDict.tools`
      * `CreateCachedContentConfigDict.ttl`
    * `CreateFileConfig`
      * `CreateFileConfig.http_options`
    * `CreateFileConfigDict`
      * `CreateFileConfigDict.http_options`
    * `CreateFileResponse`
      * `CreateFileResponse.http_headers`
    * `CreateFileResponseDict`
      * `CreateFileResponseDict.http_headers`
    * `CreateTuningJobConfig`
      * `CreateTuningJobConfig.adapter_size`
      * `CreateTuningJobConfig.batch_size`
      * `CreateTuningJobConfig.description`
      * `CreateTuningJobConfig.epoch_count`
      * `CreateTuningJobConfig.export_last_checkpoint_only`
      * `CreateTuningJobConfig.http_options`
      * `CreateTuningJobConfig.learning_rate`
      * `CreateTuningJobConfig.learning_rate_multiplier`
      * `CreateTuningJobConfig.tuned_model_display_name`
      * `CreateTuningJobConfig.validation_dataset`
    * `CreateTuningJobConfigDict`
      * `CreateTuningJobConfigDict.adapter_size`
      * `CreateTuningJobConfigDict.batch_size`
      * `CreateTuningJobConfigDict.description`
      * `CreateTuningJobConfigDict.epoch_count`
      * `CreateTuningJobConfigDict.export_last_checkpoint_only`
      * `CreateTuningJobConfigDict.http_options`
      * `CreateTuningJobConfigDict.learning_rate`
      * `CreateTuningJobConfigDict.learning_rate_multiplier`
      * `CreateTuningJobConfigDict.tuned_model_display_name`
      * `CreateTuningJobConfigDict.validation_dataset`
    * `DatasetDistribution`
      * `DatasetDistribution.buckets`
      * `DatasetDistribution.max`
      * `DatasetDistribution.mean`
      * `DatasetDistribution.median`
      * `DatasetDistribution.min`
      * `DatasetDistribution.p5`
      * `DatasetDistribution.p95`
      * `DatasetDistribution.sum`
    * `DatasetDistributionDict`
      * `DatasetDistributionDict.buckets`
      * `DatasetDistributionDict.max`
      * `DatasetDistributionDict.mean`
      * `DatasetDistributionDict.median`
      * `DatasetDistributionDict.min`
      * `DatasetDistributionDict.p5`
      * `DatasetDistributionDict.p95`
      * `DatasetDistributionDict.sum`
    * `DatasetDistributionDistributionBucket`
      * `DatasetDistributionDistributionBucket.count`
      * `DatasetDistributionDistributionBucket.left`
      * `DatasetDistributionDistributionBucket.right`
    * `DatasetDistributionDistributionBucketDict`
      * `DatasetDistributionDistributionBucketDict.count`
      * `DatasetDistributionDistributionBucketDict.left`
      * `DatasetDistributionDistributionBucketDict.right`
    * `DatasetStats`
      * `DatasetStats.total_billable_character_count`
      * `DatasetStats.total_tuning_character_count`
      * `DatasetStats.tuning_dataset_example_count`
      * `DatasetStats.tuning_step_count`
      * `DatasetStats.user_dataset_examples`
      * `DatasetStats.user_input_token_distribution`
      * `DatasetStats.user_message_per_example_distribution`
      * `DatasetStats.user_output_token_distribution`
    * `DatasetStatsDict`
      * `DatasetStatsDict.total_billable_character_count`
      * `DatasetStatsDict.total_tuning_character_count`
      * `DatasetStatsDict.tuning_dataset_example_count`
      * `DatasetStatsDict.tuning_step_count`
      * `DatasetStatsDict.user_dataset_examples`
      * `DatasetStatsDict.user_input_token_distribution`
      * `DatasetStatsDict.user_message_per_example_distribution`
      * `DatasetStatsDict.user_output_token_distribution`
    * `DeleteBatchJobConfig`
      * `DeleteBatchJobConfig.http_options`
    * `DeleteBatchJobConfigDict`
      * `DeleteBatchJobConfigDict.http_options`
    * `DeleteCachedContentConfig`
      * `DeleteCachedContentConfig.http_options`
    * `DeleteCachedContentConfigDict`
      * `DeleteCachedContentConfigDict.http_options`
    * `DeleteCachedContentResponse`
    * `DeleteCachedContentResponseDict`
    * `DeleteFileConfig`
      * `DeleteFileConfig.http_options`
    * `DeleteFileConfigDict`
      * `DeleteFileConfigDict.http_options`
    * `DeleteFileResponse`
    * `DeleteFileResponseDict`
    * `DeleteModelConfig`
      * `DeleteModelConfig.http_options`
    * `DeleteModelConfigDict`
      * `DeleteModelConfigDict.http_options`
    * `DeleteModelResponse`
    * `DeleteModelResponseDict`
    * `DeleteResourceJob`
      * `DeleteResourceJob.done`
      * `DeleteResourceJob.error`
      * `DeleteResourceJob.name`
    * `DeleteResourceJobDict`
      * `DeleteResourceJobDict.done`
      * `DeleteResourceJobDict.error`
      * `DeleteResourceJobDict.name`
    * `DistillationDataStats`
      * `DistillationDataStats.training_dataset_stats`
    * `DistillationDataStatsDict`
      * `DistillationDataStatsDict.training_dataset_stats`
    * `DistillationHyperParameters`
      * `DistillationHyperParameters.adapter_size`
      * `DistillationHyperParameters.epoch_count`
      * `DistillationHyperParameters.learning_rate_multiplier`
    * `DistillationHyperParametersDict`
      * `DistillationHyperParametersDict.adapter_size`
      * `DistillationHyperParametersDict.epoch_count`
      * `DistillationHyperParametersDict.learning_rate_multiplier`
    * `DistillationSpec`
      * `DistillationSpec.base_teacher_model`
      * `DistillationSpec.hyper_parameters`
      * `DistillationSpec.pipeline_root_directory`
      * `DistillationSpec.student_model`
      * `DistillationSpec.training_dataset_uri`
      * `DistillationSpec.tuned_teacher_model_source`
      * `DistillationSpec.validation_dataset_uri`
    * `DistillationSpecDict`
      * `DistillationSpecDict.base_teacher_model`
      * `DistillationSpecDict.hyper_parameters`
      * `DistillationSpecDict.pipeline_root_directory`
      * `DistillationSpecDict.student_model`
      * `DistillationSpecDict.training_dataset_uri`
      * `DistillationSpecDict.tuned_teacher_model_source`
      * `DistillationSpecDict.validation_dataset_uri`
    * `DownloadFileConfig`
      * `DownloadFileConfig.http_options`
    * `DownloadFileConfigDict`
      * `DownloadFileConfigDict.http_options`
    * `DynamicRetrievalConfig`
      * `DynamicRetrievalConfig.dynamic_threshold`
      * `DynamicRetrievalConfig.mode`
    * `DynamicRetrievalConfigDict`
      * `DynamicRetrievalConfigDict.dynamic_threshold`
      * `DynamicRetrievalConfigDict.mode`
    * `DynamicRetrievalConfigMode`
      * `DynamicRetrievalConfigMode.MODE_DYNAMIC`
      * `DynamicRetrievalConfigMode.MODE_UNSPECIFIED`
    * `EditImageConfig`
      * `EditImageConfig.aspect_ratio`
      * `EditImageConfig.base_steps`
      * `EditImageConfig.edit_mode`
      * `EditImageConfig.guidance_scale`
      * `EditImageConfig.http_options`
      * `EditImageConfig.include_rai_reason`
      * `EditImageConfig.include_safety_attributes`
      * `EditImageConfig.language`
      * `EditImageConfig.negative_prompt`
      * `EditImageConfig.number_of_images`
      * `EditImageConfig.output_compression_quality`
      * `EditImageConfig.output_gcs_uri`
      * `EditImageConfig.output_mime_type`
      * `EditImageConfig.person_generation`
      * `EditImageConfig.safety_filter_level`
      * `EditImageConfig.seed`
    * `EditImageConfigDict`
      * `EditImageConfigDict.aspect_ratio`
      * `EditImageConfigDict.base_steps`
      * `EditImageConfigDict.edit_mode`
      * `EditImageConfigDict.guidance_scale`
      * `EditImageConfigDict.http_options`
      * `EditImageConfigDict.include_rai_reason`
      * `EditImageConfigDict.include_safety_attributes`
      * `EditImageConfigDict.language`
      * `EditImageConfigDict.negative_prompt`
      * `EditImageConfigDict.number_of_images`
      * `EditImageConfigDict.output_compression_quality`
      * `EditImageConfigDict.output_gcs_uri`
      * `EditImageConfigDict.output_mime_type`
      * `EditImageConfigDict.person_generation`
      * `EditImageConfigDict.safety_filter_level`
      * `EditImageConfigDict.seed`
    * `EditImageResponse`
      * `EditImageResponse.generated_images`
    * `EditImageResponseDict`
      * `EditImageResponseDict.generated_images`
    * `EditMode`
      * `EditMode.EDIT_MODE_BGSWAP`
      * `EditMode.EDIT_MODE_CONTROLLED_EDITING`
      * `EditMode.EDIT_MODE_DEFAULT`
      * `EditMode.EDIT_MODE_INPAINT_INSERTION`
      * `EditMode.EDIT_MODE_INPAINT_REMOVAL`
      * `EditMode.EDIT_MODE_OUTPAINT`
      * `EditMode.EDIT_MODE_PRODUCT_IMAGE`
      * `EditMode.EDIT_MODE_STYLE`
    * `EmbedContentConfig`
      * `EmbedContentConfig.auto_truncate`
      * `EmbedContentConfig.http_options`
      * `EmbedContentConfig.mime_type`
      * `EmbedContentConfig.output_dimensionality`
      * `EmbedContentConfig.task_type`
      * `EmbedContentConfig.title`
    * `EmbedContentConfigDict`
      * `EmbedContentConfigDict.auto_truncate`
      * `EmbedContentConfigDict.http_options`
      * `EmbedContentConfigDict.mime_type`
      * `EmbedContentConfigDict.output_dimensionality`
      * `EmbedContentConfigDict.task_type`
      * `EmbedContentConfigDict.title`
    * `EmbedContentMetadata`
      * `EmbedContentMetadata.billable_character_count`
    * `EmbedContentMetadataDict`
      * `EmbedContentMetadataDict.billable_character_count`
    * `EmbedContentResponse`
      * `EmbedContentResponse.embeddings`
      * `EmbedContentResponse.metadata`
    * `EmbedContentResponseDict`
      * `EmbedContentResponseDict.embeddings`
      * `EmbedContentResponseDict.metadata`
    * `EncryptionSpec`
      * `EncryptionSpec.kms_key_name`
    * `EncryptionSpecDict`
      * `EncryptionSpecDict.kms_key_name`
    * `EndSensitivity`
      * `EndSensitivity.END_SENSITIVITY_HIGH`
      * `EndSensitivity.END_SENSITIVITY_LOW`
      * `EndSensitivity.END_SENSITIVITY_UNSPECIFIED`
    * `Endpoint`
      * `Endpoint.deployed_model_id`
      * `Endpoint.name`
    * `EndpointDict`
      * `EndpointDict.deployed_model_id`
      * `EndpointDict.name`
    * `EnterpriseWebSearch`
    * `EnterpriseWebSearchDict`
    * `ExecutableCode`
      * `ExecutableCode.code`
      * `ExecutableCode.language`
    * `ExecutableCodeDict`
      * `ExecutableCodeDict.code`
      * `ExecutableCodeDict.language`
    * `FeatureSelectionPreference`
      * `FeatureSelectionPreference.BALANCED`
      * `FeatureSelectionPreference.FEATURE_SELECTION_PREFERENCE_UNSPECIFIED`
      * `FeatureSelectionPreference.PRIORITIZE_COST`
      * `FeatureSelectionPreference.PRIORITIZE_QUALITY`
    * `FetchPredictOperationConfig`
      * `FetchPredictOperationConfig.http_options`
    * `FetchPredictOperationConfigDict`
      * `FetchPredictOperationConfigDict.http_options`
    * `File`
      * `File.create_time`
      * `File.display_name`
      * `File.download_uri`
      * `File.error`
      * `File.expiration_time`
      * `File.mime_type`
      * `File.name`
      * `File.sha256_hash`
      * `File.size_bytes`
      * `File.source`
      * `File.state`
      * `File.update_time`
      * `File.uri`
      * `File.video_metadata`
    * `FileData`
      * `FileData.file_uri`
      * `FileData.mime_type`
    * `FileDataDict`
      * `FileDataDict.file_uri`
      * `FileDataDict.mime_type`
    * `FileDict`
      * `FileDict.create_time`
      * `FileDict.display_name`
      * `FileDict.download_uri`
      * `FileDict.error`
      * `FileDict.expiration_time`
      * `FileDict.mime_type`
      * `FileDict.name`
      * `FileDict.sha256_hash`
      * `FileDict.size_bytes`
      * `FileDict.source`
      * `FileDict.state`
      * `FileDict.update_time`
      * `FileDict.uri`
      * `FileDict.video_metadata`
    * `FileSource`
      * `FileSource.GENERATED`
      * `FileSource.SOURCE_UNSPECIFIED`
      * `FileSource.UPLOADED`
    * `FileState`
      * `FileState.ACTIVE`
      * `FileState.FAILED`
      * `FileState.PROCESSING`
      * `FileState.STATE_UNSPECIFIED`
    * `FileStatus`
      * `FileStatus.code`
      * `FileStatus.details`
      * `FileStatus.message`
    * `FileStatusDict`
      * `FileStatusDict.code`
      * `FileStatusDict.details`
      * `FileStatusDict.message`
    * `FinishReason`
      * `FinishReason.BLOCKLIST`
      * `FinishReason.FINISH_REASON_UNSPECIFIED`
      * `FinishReason.IMAGE_SAFETY`
      * `FinishReason.LANGUAGE`
      * `FinishReason.MALFORMED_FUNCTION_CALL`
      * `FinishReason.MAX_TOKENS`
      * `FinishReason.OTHER`
      * `FinishReason.PROHIBITED_CONTENT`
      * `FinishReason.RECITATION`
      * `FinishReason.SAFETY`
      * `FinishReason.SPII`
      * `FinishReason.STOP`
    * `FunctionCall`
      * `FunctionCall.args`
      * `FunctionCall.id`
      * `FunctionCall.name`
    * `FunctionCallDict`
      * `FunctionCallDict.args`
      * `FunctionCallDict.id`
      * `FunctionCallDict.name`
    * `FunctionCallingConfig`
      * `FunctionCallingConfig.allowed_function_names`
      * `FunctionCallingConfig.mode`
    * `FunctionCallingConfigDict`
      * `FunctionCallingConfigDict.allowed_function_names`
      * `FunctionCallingConfigDict.mode`
    * `FunctionCallingConfigMode`
      * `FunctionCallingConfigMode.ANY`
      * `FunctionCallingConfigMode.AUTO`
      * `FunctionCallingConfigMode.MODE_UNSPECIFIED`
      * `FunctionCallingConfigMode.NONE`
    * `FunctionDeclaration`
      * `FunctionDeclaration.description`
      * `FunctionDeclaration.name`
      * `FunctionDeclaration.parameters`
      * `FunctionDeclaration.response`
      * `FunctionDeclaration.from_callable()`
      * `FunctionDeclaration.from_callable_with_api_option()`
    * `FunctionDeclarationDict`
      * `FunctionDeclarationDict.description`
      * `FunctionDeclarationDict.name`
      * `FunctionDeclarationDict.parameters`
      * `FunctionDeclarationDict.response`
    * `FunctionResponse`
      * `FunctionResponse.id`
      * `FunctionResponse.name`
      * `FunctionResponse.response`
    * `FunctionResponseDict`
      * `FunctionResponseDict.id`
      * `FunctionResponseDict.name`
      * `FunctionResponseDict.response`
    * `GenerateContentConfig`
      * `GenerateContentConfig.audio_timestamp`
      * `GenerateContentConfig.automatic_function_calling`
      * `GenerateContentConfig.cached_content`
      * `GenerateContentConfig.candidate_count`
      * `GenerateContentConfig.frequency_penalty`
      * `GenerateContentConfig.http_options`
      * `GenerateContentConfig.labels`
      * `GenerateContentConfig.logprobs`
      * `GenerateContentConfig.max_output_tokens`
      * `GenerateContentConfig.media_resolution`
      * `GenerateContentConfig.model_selection_config`
      * `GenerateContentConfig.presence_penalty`
      * `GenerateContentConfig.response_logprobs`
      * `GenerateContentConfig.response_mime_type`
      * `GenerateContentConfig.response_modalities`
      * `GenerateContentConfig.response_schema`
      * `GenerateContentConfig.routing_config`
      * `GenerateContentConfig.safety_settings`
      * `GenerateContentConfig.seed`
      * `GenerateContentConfig.speech_config`
      * `GenerateContentConfig.stop_sequences`
      * `GenerateContentConfig.system_instruction`
      * `GenerateContentConfig.temperature`
      * `GenerateContentConfig.thinking_config`
      * `GenerateContentConfig.tool_config`
      * `GenerateContentConfig.tools`
      * `GenerateContentConfig.top_k`
      * `GenerateContentConfig.top_p`
    * `GenerateContentConfigDict`
      * `GenerateContentConfigDict.audio_timestamp`
      * `GenerateContentConfigDict.automatic_function_calling`
      * `GenerateContentConfigDict.cached_content`
      * `GenerateContentConfigDict.candidate_count`
      * `GenerateContentConfigDict.frequency_penalty`
      * `GenerateContentConfigDict.http_options`
      * `GenerateContentConfigDict.labels`
      * `GenerateContentConfigDict.logprobs`
      * `GenerateContentConfigDict.max_output_tokens`
      * `GenerateContentConfigDict.media_resolution`
      * `GenerateContentConfigDict.model_selection_config`
      * `GenerateContentConfigDict.presence_penalty`
      * `GenerateContentConfigDict.response_logprobs`
      * `GenerateContentConfigDict.response_mime_type`
      * `GenerateContentConfigDict.response_modalities`
      * `GenerateContentConfigDict.response_schema`
      * `GenerateContentConfigDict.routing_config`
      * `GenerateContentConfigDict.safety_settings`
      * `GenerateContentConfigDict.seed`
      * `GenerateContentConfigDict.speech_config`
      * `GenerateContentConfigDict.stop_sequences`
      * `GenerateContentConfigDict.system_instruction`
      * `GenerateContentConfigDict.temperature`
      * `GenerateContentConfigDict.thinking_config`
      * `GenerateContentConfigDict.tool_config`
      * `GenerateContentConfigDict.tools`
      * `GenerateContentConfigDict.top_k`
      * `GenerateContentConfigDict.top_p`
    * `GenerateContentResponse`
      * `GenerateContentResponse.automatic_function_calling_history`
      * `GenerateContentResponse.candidates`
      * `GenerateContentResponse.create_time`
      * `GenerateContentResponse.model_version`
      * `GenerateContentResponse.parsed`
      * `GenerateContentResponse.prompt_feedback`
      * `GenerateContentResponse.response_id`
      * `GenerateContentResponse.usage_metadata`
      * `GenerateContentResponse.code_execution_result`
      * `GenerateContentResponse.executable_code`
      * `GenerateContentResponse.function_calls`
      * `GenerateContentResponse.text`
    * `GenerateContentResponseDict`
      * `GenerateContentResponseDict.candidates`
      * `GenerateContentResponseDict.create_time`
      * `GenerateContentResponseDict.model_version`
      * `GenerateContentResponseDict.prompt_feedback`
      * `GenerateContentResponseDict.response_id`
      * `GenerateContentResponseDict.usage_metadata`
    * `GenerateContentResponsePromptFeedback`
      * `GenerateContentResponsePromptFeedback.block_reason`
      * `GenerateContentResponsePromptFeedback.block_reason_message`
      * `GenerateContentResponsePromptFeedback.safety_ratings`
    * `GenerateContentResponsePromptFeedbackDict`
      * `GenerateContentResponsePromptFeedbackDict.block_reason`
      * `GenerateContentResponsePromptFeedbackDict.block_reason_message`
      * `GenerateContentResponsePromptFeedbackDict.safety_ratings`
    * `GenerateContentResponseUsageMetadata`
      * `GenerateContentResponseUsageMetadata.cache_tokens_details`
      * `GenerateContentResponseUsageMetadata.cached_content_token_count`
      * `GenerateContentResponseUsageMetadata.candidates_token_count`
      * `GenerateContentResponseUsageMetadata.candidates_tokens_details`
      * `GenerateContentResponseUsageMetadata.prompt_token_count`
      * `GenerateContentResponseUsageMetadata.prompt_tokens_details`
      * `GenerateContentResponseUsageMetadata.thoughts_token_count`
      * `GenerateContentResponseUsageMetadata.tool_use_prompt_token_count`
      * `GenerateContentResponseUsageMetadata.tool_use_prompt_tokens_details`
      * `GenerateContentResponseUsageMetadata.total_token_count`
      * `GenerateContentResponseUsageMetadata.traffic_type`
    * `GenerateContentResponseUsageMetadataDict`
      * `GenerateContentResponseUsageMetadataDict.cache_tokens_details`
      * `GenerateContentResponseUsageMetadataDict.cached_content_token_count`
      * `GenerateContentResponseUsageMetadataDict.candidates_token_count`
      * `GenerateContentResponseUsageMetadataDict.candidates_tokens_details`
      * `GenerateContentResponseUsageMetadataDict.prompt_token_count`
      * `GenerateContentResponseUsageMetadataDict.prompt_tokens_details`
      * `GenerateContentResponseUsageMetadataDict.thoughts_token_count`
      * `GenerateContentResponseUsageMetadataDict.tool_use_prompt_token_count`
      * `GenerateContentResponseUsageMetadataDict.tool_use_prompt_tokens_details`
      * `GenerateContentResponseUsageMetadataDict.total_token_count`
      * `GenerateContentResponseUsageMetadataDict.traffic_type`
    * `GenerateImagesConfig`
      * `GenerateImagesConfig.add_watermark`
      * `GenerateImagesConfig.aspect_ratio`
      * `GenerateImagesConfig.enhance_prompt`
      * `GenerateImagesConfig.guidance_scale`
      * `GenerateImagesConfig.http_options`
      * `GenerateImagesConfig.include_rai_reason`
      * `GenerateImagesConfig.include_safety_attributes`
      * `GenerateImagesConfig.language`
      * `GenerateImagesConfig.negative_prompt`
      * `GenerateImagesConfig.number_of_images`
      * `GenerateImagesConfig.output_compression_quality`
      * `GenerateImagesConfig.output_gcs_uri`
      * `GenerateImagesConfig.output_mime_type`
      * `GenerateImagesConfig.person_generation`
      * `GenerateImagesConfig.safety_filter_level`
      * `GenerateImagesConfig.seed`
    * `GenerateImagesConfigDict`
      * `GenerateImagesConfigDict.add_watermark`
      * `GenerateImagesConfigDict.aspect_ratio`
      * `GenerateImagesConfigDict.enhance_prompt`
      * `GenerateImagesConfigDict.guidance_scale`
      * `GenerateImagesConfigDict.http_options`
      * `GenerateImagesConfigDict.include_rai_reason`
      * `GenerateImagesConfigDict.include_safety_attributes`
      * `GenerateImagesConfigDict.language`
      * `GenerateImagesConfigDict.negative_prompt`
      * `GenerateImagesConfigDict.number_of_images`
      * `GenerateImagesConfigDict.output_compression_quality`
      * `GenerateImagesConfigDict.output_gcs_uri`
      * `GenerateImagesConfigDict.output_mime_type`
      * `GenerateImagesConfigDict.person_generation`
      * `GenerateImagesConfigDict.safety_filter_level`
      * `GenerateImagesConfigDict.seed`
    * `GenerateImagesResponse`
      * `GenerateImagesResponse.generated_images`
      * `GenerateImagesResponse.positive_prompt_safety_attributes`
    * `GenerateImagesResponseDict`
      * `GenerateImagesResponseDict.generated_images`
      * `GenerateImagesResponseDict.positive_prompt_safety_attributes`
    * `GenerateVideosConfig`
      * `GenerateVideosConfig.aspect_ratio`
      * `GenerateVideosConfig.duration_seconds`
      * `GenerateVideosConfig.enhance_prompt`
      * `GenerateVideosConfig.fps`
      * `GenerateVideosConfig.http_options`
      * `GenerateVideosConfig.negative_prompt`
      * `GenerateVideosConfig.number_of_videos`
      * `GenerateVideosConfig.output_gcs_uri`
      * `GenerateVideosConfig.person_generation`
      * `GenerateVideosConfig.pubsub_topic`
      * `GenerateVideosConfig.resolution`
      * `GenerateVideosConfig.seed`
    * `GenerateVideosConfigDict`
      * `GenerateVideosConfigDict.aspect_ratio`
      * `GenerateVideosConfigDict.duration_seconds`
      * `GenerateVideosConfigDict.enhance_prompt`
      * `GenerateVideosConfigDict.fps`
      * `GenerateVideosConfigDict.http_options`
      * `GenerateVideosConfigDict.negative_prompt`
      * `GenerateVideosConfigDict.number_of_videos`
      * `GenerateVideosConfigDict.output_gcs_uri`
      * `GenerateVideosConfigDict.person_generation`
      * `GenerateVideosConfigDict.pubsub_topic`
      * `GenerateVideosConfigDict.resolution`
      * `GenerateVideosConfigDict.seed`
    * `GenerateVideosOperation`
      * `GenerateVideosOperation.done`
      * `GenerateVideosOperation.error`
      * `GenerateVideosOperation.metadata`
      * `GenerateVideosOperation.name`
      * `GenerateVideosOperation.response`
      * `GenerateVideosOperation.result`
    * `GenerateVideosOperationDict`
      * `GenerateVideosOperationDict.done`
      * `GenerateVideosOperationDict.error`
      * `GenerateVideosOperationDict.metadata`
      * `GenerateVideosOperationDict.name`
      * `GenerateVideosOperationDict.response`
      * `GenerateVideosOperationDict.result`
    * `GenerateVideosResponse`
      * `GenerateVideosResponse.generated_videos`
      * `GenerateVideosResponse.rai_media_filtered_count`
      * `GenerateVideosResponse.rai_media_filtered_reasons`
    * `GenerateVideosResponseDict`
      * `GenerateVideosResponseDict.generated_videos`
      * `GenerateVideosResponseDict.rai_media_filtered_count`
      * `GenerateVideosResponseDict.rai_media_filtered_reasons`
    * `GeneratedImage`
      * `GeneratedImage.enhanced_prompt`
      * `GeneratedImage.image`
      * `GeneratedImage.rai_filtered_reason`
      * `GeneratedImage.safety_attributes`
    * `GeneratedImageDict`
      * `GeneratedImageDict.enhanced_prompt`
      * `GeneratedImageDict.image`
      * `GeneratedImageDict.rai_filtered_reason`
      * `GeneratedImageDict.safety_attributes`
    * `GeneratedVideo`
      * `GeneratedVideo.video`
    * `GeneratedVideoDict`
      * `GeneratedVideoDict.video`
    * `GenerationConfig`
      * `GenerationConfig.audio_timestamp`
      * `GenerationConfig.candidate_count`
      * `GenerationConfig.frequency_penalty`
      * `GenerationConfig.logprobs`
      * `GenerationConfig.max_output_tokens`
      * `GenerationConfig.media_resolution`
      * `GenerationConfig.presence_penalty`
      * `GenerationConfig.response_logprobs`
      * `GenerationConfig.response_mime_type`
      * `GenerationConfig.response_schema`
      * `GenerationConfig.routing_config`
      * `GenerationConfig.seed`
      * `GenerationConfig.stop_sequences`
      * `GenerationConfig.temperature`
      * `GenerationConfig.top_k`
      * `GenerationConfig.top_p`
    * `GenerationConfigDict`
      * `GenerationConfigDict.audio_timestamp`
      * `GenerationConfigDict.candidate_count`
      * `GenerationConfigDict.frequency_penalty`
      * `GenerationConfigDict.logprobs`
      * `GenerationConfigDict.max_output_tokens`
      * `GenerationConfigDict.media_resolution`
      * `GenerationConfigDict.presence_penalty`
      * `GenerationConfigDict.response_logprobs`
      * `GenerationConfigDict.response_mime_type`
      * `GenerationConfigDict.response_schema`
      * `GenerationConfigDict.routing_config`
      * `GenerationConfigDict.seed`
      * `GenerationConfigDict.stop_sequences`
      * `GenerationConfigDict.temperature`
      * `GenerationConfigDict.top_k`
      * `GenerationConfigDict.top_p`
    * `GenerationConfigRoutingConfig`
      * `GenerationConfigRoutingConfig.auto_mode`
      * `GenerationConfigRoutingConfig.manual_mode`
    * `GenerationConfigRoutingConfigAutoRoutingMode`
      * `GenerationConfigRoutingConfigAutoRoutingMode.model_routing_preference`
    * `GenerationConfigRoutingConfigAutoRoutingModeDict`
      * `GenerationConfigRoutingConfigAutoRoutingModeDict.model_routing_preference`
    * `GenerationConfigRoutingConfigDict`
      * `GenerationConfigRoutingConfigDict.auto_mode`
      * `GenerationConfigRoutingConfigDict.manual_mode`
    * `GenerationConfigRoutingConfigManualRoutingMode`
      * `GenerationConfigRoutingConfigManualRoutingMode.model_name`
    * `GenerationConfigRoutingConfigManualRoutingModeDict`
      * `GenerationConfigRoutingConfigManualRoutingModeDict.model_name`
    * `GetBatchJobConfig`
      * `GetBatchJobConfig.http_options`
    * `GetBatchJobConfigDict`
      * `GetBatchJobConfigDict.http_options`
    * `GetCachedContentConfig`
      * `GetCachedContentConfig.http_options`
    * `GetCachedContentConfigDict`
      * `GetCachedContentConfigDict.http_options`
    * `GetFileConfig`
      * `GetFileConfig.http_options`
    * `GetFileConfigDict`
      * `GetFileConfigDict.http_options`
    * `GetModelConfig`
      * `GetModelConfig.http_options`
    * `GetModelConfigDict`
      * `GetModelConfigDict.http_options`
    * `GetOperationConfig`
      * `GetOperationConfig.http_options`
    * `GetOperationConfigDict`
      * `GetOperationConfigDict.http_options`
    * `GetTuningJobConfig`
      * `GetTuningJobConfig.http_options`
    * `GetTuningJobConfigDict`
      * `GetTuningJobConfigDict.http_options`
    * `GoogleMaps`
      * `GoogleMaps.auth_config`
    * `GoogleMapsDict`
      * `GoogleMapsDict.auth_config`
    * `GoogleRpcStatus`
      * `GoogleRpcStatus.code`
      * `GoogleRpcStatus.details`
      * `GoogleRpcStatus.message`
    * `GoogleRpcStatusDict`
      * `GoogleRpcStatusDict.code`
      * `GoogleRpcStatusDict.details`
      * `GoogleRpcStatusDict.message`
    * `GoogleSearch`
    * `GoogleSearchDict`
    * `GoogleSearchRetrieval`
      * `GoogleSearchRetrieval.dynamic_retrieval_config`
    * `GoogleSearchRetrievalDict`
      * `GoogleSearchRetrievalDict.dynamic_retrieval_config`
    * `GoogleTypeDate`
      * `GoogleTypeDate.day`
      * `GoogleTypeDate.month`
      * `GoogleTypeDate.year`
    * `GoogleTypeDateDict`
      * `GoogleTypeDateDict.day`
      * `GoogleTypeDateDict.month`
      * `GoogleTypeDateDict.year`
    * `GroundingChunk`
      * `GroundingChunk.retrieved_context`
      * `GroundingChunk.web`
    * `GroundingChunkDict`
      * `GroundingChunkDict.retrieved_context`
      * `GroundingChunkDict.web`
    * `GroundingChunkRetrievedContext`
      * `GroundingChunkRetrievedContext.text`
      * `GroundingChunkRetrievedContext.title`
      * `GroundingChunkRetrievedContext.uri`
    * `GroundingChunkRetrievedContextDict`
      * `GroundingChunkRetrievedContextDict.text`
      * `GroundingChunkRetrievedContextDict.title`
      * `GroundingChunkRetrievedContextDict.uri`
    * `GroundingChunkWeb`
      * `GroundingChunkWeb.domain`
      * `GroundingChunkWeb.title`
      * `GroundingChunkWeb.uri`
    * `GroundingChunkWebDict`
      * `GroundingChunkWebDict.domain`
      * `GroundingChunkWebDict.title`
      * `GroundingChunkWebDict.uri`
    * `GroundingMetadata`
      * `GroundingMetadata.grounding_chunks`
      * `GroundingMetadata.grounding_supports`
      * `GroundingMetadata.retrieval_metadata`
      * `GroundingMetadata.retrieval_queries`
      * `GroundingMetadata.search_entry_point`
      * `GroundingMetadata.web_search_queries`
    * `GroundingMetadataDict`
      * `GroundingMetadataDict.grounding_chunks`
      * `GroundingMetadataDict.grounding_supports`
      * `GroundingMetadataDict.retrieval_metadata`
      * `GroundingMetadataDict.retrieval_queries`
      * `GroundingMetadataDict.search_entry_point`
      * `GroundingMetadataDict.web_search_queries`
    * `GroundingSupport`
      * `GroundingSupport.confidence_scores`
      * `GroundingSupport.grounding_chunk_indices`
      * `GroundingSupport.segment`
    * `GroundingSupportDict`
      * `GroundingSupportDict.confidence_scores`
      * `GroundingSupportDict.grounding_chunk_indices`
      * `GroundingSupportDict.segment`
    * `HarmBlockMethod`
      * `HarmBlockMethod.HARM_BLOCK_METHOD_UNSPECIFIED`
      * `HarmBlockMethod.PROBABILITY`
      * `HarmBlockMethod.SEVERITY`
    * `HarmBlockThreshold`
      * `HarmBlockThreshold.BLOCK_LOW_AND_ABOVE`
      * `HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE`
      * `HarmBlockThreshold.BLOCK_NONE`
      * `HarmBlockThreshold.BLOCK_ONLY_HIGH`
      * `HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED`
      * `HarmBlockThreshold.OFF`
    * `HarmCategory`
      * `HarmCategory.HARM_CATEGORY_CIVIC_INTEGRITY`
      * `HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT`
      * `HarmCategory.HARM_CATEGORY_HARASSMENT`
      * `HarmCategory.HARM_CATEGORY_HATE_SPEECH`
      * `HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT`
      * `HarmCategory.HARM_CATEGORY_UNSPECIFIED`
    * `HarmProbability`
      * `HarmProbability.HARM_PROBABILITY_UNSPECIFIED`
      * `HarmProbability.HIGH`
      * `HarmProbability.LOW`
      * `HarmProbability.MEDIUM`
      * `HarmProbability.NEGLIGIBLE`
    * `HarmSeverity`
      * `HarmSeverity.HARM_SEVERITY_HIGH`
      * `HarmSeverity.HARM_SEVERITY_LOW`
      * `HarmSeverity.HARM_SEVERITY_MEDIUM`
      * `HarmSeverity.HARM_SEVERITY_NEGLIGIBLE`
      * `HarmSeverity.HARM_SEVERITY_UNSPECIFIED`
    * `HttpOptions`
      * `HttpOptions.api_version`
      * `HttpOptions.async_client_args`
      * `HttpOptions.base_url`
      * `HttpOptions.client_args`
      * `HttpOptions.headers`
      * `HttpOptions.timeout`
    * `HttpOptionsDict`
      * `HttpOptionsDict.api_version`
      * `HttpOptionsDict.async_client_args`
      * `HttpOptionsDict.base_url`
      * `HttpOptionsDict.client_args`
      * `HttpOptionsDict.headers`
      * `HttpOptionsDict.timeout`
    * `Image`
      * `Image.gcs_uri`
      * `Image.image_bytes`
      * `Image.mime_type`
      * `Image.from_file()`
      * `Image.model_post_init()`
      * `Image.save()`
      * `Image.show()`
    * `ImageDict`
      * `ImageDict.gcs_uri`
      * `ImageDict.image_bytes`
      * `ImageDict.mime_type`
    * `ImagePromptLanguage`
      * `ImagePromptLanguage.auto`
      * `ImagePromptLanguage.en`
      * `ImagePromptLanguage.hi`
      * `ImagePromptLanguage.ja`
      * `ImagePromptLanguage.ko`
    * `JSONSchema`
      * `JSONSchema.any_of`
      * `JSONSchema.default`
      * `JSONSchema.description`
      * `JSONSchema.enum`
      * `JSONSchema.format`
      * `JSONSchema.items`
      * `JSONSchema.max_items`
      * `JSONSchema.max_length`
      * `JSONSchema.max_properties`
      * `JSONSchema.maximum`
      * `JSONSchema.min_items`
      * `JSONSchema.min_length`
      * `JSONSchema.min_properties`
      * `JSONSchema.minimum`
      * `JSONSchema.pattern`
      * `JSONSchema.properties`
      * `JSONSchema.required`
      * `JSONSchema.title`
      * `JSONSchema.type`
    * `JSONSchemaType`
      * `JSONSchemaType.ARRAY`
      * `JSONSchemaType.BOOLEAN`
      * `JSONSchemaType.INTEGER`
      * `JSONSchemaType.NULL`
      * `JSONSchemaType.NUMBER`
      * `JSONSchemaType.OBJECT`
      * `JSONSchemaType.STRING`
    * `JobError`
      * `JobError.code`
      * `JobError.details`
      * `JobError.message`
    * `JobErrorDict`
      * `JobErrorDict.code`
      * `JobErrorDict.details`
      * `JobErrorDict.message`
    * `JobState`
      * `JobState.JOB_STATE_CANCELLED`
      * `JobState.JOB_STATE_CANCELLING`
      * `JobState.JOB_STATE_EXPIRED`
      * `JobState.JOB_STATE_FAILED`
      * `JobState.JOB_STATE_PARTIALLY_SUCCEEDED`
      * `JobState.JOB_STATE_PAUSED`
      * `JobState.JOB_STATE_PENDING`
      * `JobState.JOB_STATE_QUEUED`
      * `JobState.JOB_STATE_RUNNING`
      * `JobState.JOB_STATE_SUCCEEDED`
      * `JobState.JOB_STATE_UNSPECIFIED`
      * `JobState.JOB_STATE_UPDATING`
    * `Language`
      * `Language.LANGUAGE_UNSPECIFIED`
      * `Language.PYTHON`
    * `LatLng`
      * `LatLng.latitude`
      * `LatLng.longitude`
    * `LatLngDict`
      * `LatLngDict.latitude`
      * `LatLngDict.longitude`
    * `ListBatchJobsConfig`
      * `ListBatchJobsConfig.filter`
      * `ListBatchJobsConfig.http_options`
      * `ListBatchJobsConfig.page_size`
      * `ListBatchJobsConfig.page_token`
    * `ListBatchJobsConfigDict`
      * `ListBatchJobsConfigDict.filter`
      * `ListBatchJobsConfigDict.http_options`
      * `ListBatchJobsConfigDict.page_size`
      * `ListBatchJobsConfigDict.page_token`
    * `ListBatchJobsResponse`
      * `ListBatchJobsResponse.batch_jobs`
      * `ListBatchJobsResponse.next_page_token`
    * `ListBatchJobsResponseDict`
      * `ListBatchJobsResponseDict.batch_jobs`
      * `ListBatchJobsResponseDict.next_page_token`
    * `ListCachedContentsConfig`
      * `ListCachedContentsConfig.http_options`
      * `ListCachedContentsConfig.page_size`
      * `ListCachedContentsConfig.page_token`
    * `ListCachedContentsConfigDict`
      * `ListCachedContentsConfigDict.http_options`
      * `ListCachedContentsConfigDict.page_size`
      * `ListCachedContentsConfigDict.page_token`
    * `ListCachedContentsResponse`
      * `ListCachedContentsResponse.cached_contents`
      * `ListCachedContentsResponse.next_page_token`
    * `ListCachedContentsResponseDict`
      * `ListCachedContentsResponseDict.cached_contents`
      * `ListCachedContentsResponseDict.next_page_token`
    * `ListFilesConfig`
      * `ListFilesConfig.http_options`
      * `ListFilesConfig.page_size`
      * `ListFilesConfig.page_token`
    * `ListFilesConfigDict`
      * `ListFilesConfigDict.http_options`
      * `ListFilesConfigDict.page_size`
      * `ListFilesConfigDict.page_token`
    * `ListFilesResponse`
      * `ListFilesResponse.files`
      * `ListFilesResponse.next_page_token`
    * `ListFilesResponseDict`
      * `ListFilesResponseDict.files`
      * `ListFilesResponseDict.next_page_token`
    * `ListModelsConfig`
      * `ListModelsConfig.filter`
      * `ListModelsConfig.http_options`
      * `ListModelsConfig.page_size`
      * `ListModelsConfig.page_token`
      * `ListModelsConfig.query_base`
    * `ListModelsConfigDict`
      * `ListModelsConfigDict.filter`
      * `ListModelsConfigDict.http_options`
      * `ListModelsConfigDict.page_size`
      * `ListModelsConfigDict.page_token`
      * `ListModelsConfigDict.query_base`
    * `ListModelsResponse`
      * `ListModelsResponse.models`
      * `ListModelsResponse.next_page_token`
    * `ListModelsResponseDict`
      * `ListModelsResponseDict.models`
      * `ListModelsResponseDict.next_page_token`
    * `ListTuningJobsConfig`
      * `ListTuningJobsConfig.filter`
      * `ListTuningJobsConfig.http_options`
      * `ListTuningJobsConfig.page_size`
      * `ListTuningJobsConfig.page_token`
    * `ListTuningJobsConfigDict`
      * `ListTuningJobsConfigDict.filter`
      * `ListTuningJobsConfigDict.http_options`
      * `ListTuningJobsConfigDict.page_size`
      * `ListTuningJobsConfigDict.page_token`
    * `ListTuningJobsResponse`
      * `ListTuningJobsResponse.next_page_token`
      * `ListTuningJobsResponse.tuning_jobs`
    * `ListTuningJobsResponseDict`
      * `ListTuningJobsResponseDict.next_page_token`
      * `ListTuningJobsResponseDict.tuning_jobs`
    * `LiveClientContent`
      * `LiveClientContent.turn_complete`
      * `LiveClientContent.turns`
    * `LiveClientContentDict`
      * `LiveClientContentDict.turn_complete`
      * `LiveClientContentDict.turns`
    * `LiveClientMessage`
      * `LiveClientMessage.client_content`
      * `LiveClientMessage.realtime_input`
      * `LiveClientMessage.setup`
      * `LiveClientMessage.tool_response`
    * `LiveClientMessageDict`
      * `LiveClientMessageDict.client_content`
      * `LiveClientMessageDict.realtime_input`
      * `LiveClientMessageDict.setup`
      * `LiveClientMessageDict.tool_response`
    * `LiveClientRealtimeInput`
      * `LiveClientRealtimeInput.activity_end`
      * `LiveClientRealtimeInput.activity_start`
      * `LiveClientRealtimeInput.audio`
      * `LiveClientRealtimeInput.audio_stream_end`
      * `LiveClientRealtimeInput.media_chunks`
      * `LiveClientRealtimeInput.text`
      * `LiveClientRealtimeInput.video`
    * `LiveClientRealtimeInputDict`
      * `LiveClientRealtimeInputDict.activity_end`
      * `LiveClientRealtimeInputDict.activity_start`
      * `LiveClientRealtimeInputDict.audio`
      * `LiveClientRealtimeInputDict.audio_stream_end`
      * `LiveClientRealtimeInputDict.media_chunks`
      * `LiveClientRealtimeInputDict.text`
      * `LiveClientRealtimeInputDict.video`
    * `LiveClientSetup`
      * `LiveClientSetup.context_window_compression`
      * `LiveClientSetup.generation_config`
      * `LiveClientSetup.input_audio_transcription`
      * `LiveClientSetup.model`
      * `LiveClientSetup.output_audio_transcription`
      * `LiveClientSetup.session_resumption`
      * `LiveClientSetup.system_instruction`
      * `LiveClientSetup.tools`
    * `LiveClientSetupDict`
      * `LiveClientSetupDict.context_window_compression`
      * `LiveClientSetupDict.generation_config`
      * `LiveClientSetupDict.input_audio_transcription`
      * `LiveClientSetupDict.model`
      * `LiveClientSetupDict.output_audio_transcription`
      * `LiveClientSetupDict.session_resumption`
      * `LiveClientSetupDict.system_instruction`
      * `LiveClientSetupDict.tools`
    * `LiveClientToolResponse`
      * `LiveClientToolResponse.function_responses`
    * `LiveClientToolResponseDict`
      * `LiveClientToolResponseDict.function_responses`
    * `LiveConnectConfig`
      * `LiveConnectConfig.context_window_compression`
      * `LiveConnectConfig.generation_config`
      * `LiveConnectConfig.input_audio_transcription`
      * `LiveConnectConfig.max_output_tokens`
      * `LiveConnectConfig.media_resolution`
      * `LiveConnectConfig.output_audio_transcription`
      * `LiveConnectConfig.realtime_input_config`
      * `LiveConnectConfig.response_modalities`
      * `LiveConnectConfig.seed`
      * `LiveConnectConfig.session_resumption`
      * `LiveConnectConfig.speech_config`
      * `LiveConnectConfig.system_instruction`
      * `LiveConnectConfig.temperature`
      * `LiveConnectConfig.tools`
      * `LiveConnectConfig.top_k`
      * `LiveConnectConfig.top_p`
    * `LiveConnectConfigDict`
      * `LiveConnectConfigDict.context_window_compression`
      * `LiveConnectConfigDict.generation_config`
      * `LiveConnectConfigDict.input_audio_transcription`
      * `LiveConnectConfigDict.max_output_tokens`
      * `LiveConnectConfigDict.media_resolution`
      * `LiveConnectConfigDict.output_audio_transcription`
      * `LiveConnectConfigDict.realtime_input_config`
      * `LiveConnectConfigDict.response_modalities`
      * `LiveConnectConfigDict.seed`
      * `LiveConnectConfigDict.session_resumption`
      * `LiveConnectConfigDict.speech_config`
      * `LiveConnectConfigDict.system_instruction`
      * `LiveConnectConfigDict.temperature`
      * `LiveConnectConfigDict.tools`
      * `LiveConnectConfigDict.top_k`
      * `LiveConnectConfigDict.top_p`
    * `LiveConnectParameters`
      * `LiveConnectParameters.config`
      * `LiveConnectParameters.model`
    * `LiveConnectParametersDict`
      * `LiveConnectParametersDict.config`
      * `LiveConnectParametersDict.model`
    * `LiveSendRealtimeInputParameters`
      * `LiveSendRealtimeInputParameters.activity_end`
      * `LiveSendRealtimeInputParameters.activity_start`
      * `LiveSendRealtimeInputParameters.audio`
      * `LiveSendRealtimeInputParameters.audio_stream_end`
      * `LiveSendRealtimeInputParameters.media`
      * `LiveSendRealtimeInputParameters.text`
      * `LiveSendRealtimeInputParameters.video`
    * `LiveSendRealtimeInputParametersDict`
      * `LiveSendRealtimeInputParametersDict.activity_end`
      * `LiveSendRealtimeInputParametersDict.activity_start`
      * `LiveSendRealtimeInputParametersDict.audio`
      * `LiveSendRealtimeInputParametersDict.audio_stream_end`
      * `LiveSendRealtimeInputParametersDict.media`
      * `LiveSendRealtimeInputParametersDict.text`
      * `LiveSendRealtimeInputParametersDict.video`
    * `LiveServerContent`
      * `LiveServerContent.generation_complete`
      * `LiveServerContent.grounding_metadata`
      * `LiveServerContent.input_transcription`
      * `LiveServerContent.interrupted`
      * `LiveServerContent.model_turn`
      * `LiveServerContent.output_transcription`
      * `LiveServerContent.turn_complete`
    * `LiveServerContentDict`
      * `LiveServerContentDict.generation_complete`
      * `LiveServerContentDict.grounding_metadata`
      * `LiveServerContentDict.input_transcription`
      * `LiveServerContentDict.interrupted`
      * `LiveServerContentDict.model_turn`
      * `LiveServerContentDict.output_transcription`
      * `LiveServerContentDict.turn_complete`
    * `LiveServerGoAway`
      * `LiveServerGoAway.time_left`
    * `LiveServerGoAwayDict`
      * `LiveServerGoAwayDict.time_left`
    * `LiveServerMessage`
      * `LiveServerMessage.go_away`
      * `LiveServerMessage.server_content`
      * `LiveServerMessage.session_resumption_update`
      * `LiveServerMessage.setup_complete`
      * `LiveServerMessage.tool_call`
      * `LiveServerMessage.tool_call_cancellation`
      * `LiveServerMessage.usage_metadata`
      * `LiveServerMessage.data`
      * `LiveServerMessage.text`
    * `LiveServerMessageDict`
      * `LiveServerMessageDict.go_away`
      * `LiveServerMessageDict.server_content`
      * `LiveServerMessageDict.session_resumption_update`
      * `LiveServerMessageDict.setup_complete`
      * `LiveServerMessageDict.tool_call`
      * `LiveServerMessageDict.tool_call_cancellation`
      * `LiveServerMessageDict.usage_metadata`
    * `LiveServerSessionResumptionUpdate`
      * `LiveServerSessionResumptionUpdate.last_consumed_client_message_index`
      * `LiveServerSessionResumptionUpdate.new_handle`
      * `LiveServerSessionResumptionUpdate.resumable`
    * `LiveServerSessionResumptionUpdateDict`
      * `LiveServerSessionResumptionUpdateDict.last_consumed_client_message_index`
      * `LiveServerSessionResumptionUpdateDict.new_handle`
      * `LiveServerSessionResumptionUpdateDict.resumable`
    * `LiveServerSetupComplete`
    * `LiveServerSetupCompleteDict`
    * `LiveServerToolCall`
      * `LiveServerToolCall.function_calls`
    * `LiveServerToolCallCancellation`
      * `LiveServerToolCallCancellation.ids`
    * `LiveServerToolCallCancellationDict`
      * `LiveServerToolCallCancellationDict.ids`
    * `LiveServerToolCallDict`
      * `LiveServerToolCallDict.function_calls`
    * `LogprobsResult`
      * `LogprobsResult.chosen_candidates`
      * `LogprobsResult.top_candidates`
    * `LogprobsResultCandidate`
      * `LogprobsResultCandidate.log_probability`
      * `LogprobsResultCandidate.token`
      * `LogprobsResultCandidate.token_id`
    * `LogprobsResultCandidateDict`
      * `LogprobsResultCandidateDict.log_probability`
      * `LogprobsResultCandidateDict.token`
      * `LogprobsResultCandidateDict.token_id`
    * `LogprobsResultDict`
      * `LogprobsResultDict.chosen_candidates`
      * `LogprobsResultDict.top_candidates`
    * `LogprobsResultTopCandidates`
      * `LogprobsResultTopCandidates.candidates`
    * `LogprobsResultTopCandidatesDict`
      * `LogprobsResultTopCandidatesDict.candidates`
    * `MaskReferenceConfig`
      * `MaskReferenceConfig.mask_dilation`
      * `MaskReferenceConfig.mask_mode`
      * `MaskReferenceConfig.segmentation_classes`
    * `MaskReferenceConfigDict`
      * `MaskReferenceConfigDict.mask_dilation`
      * `MaskReferenceConfigDict.mask_mode`
      * `MaskReferenceConfigDict.segmentation_classes`
    * `MaskReferenceImage`
      * `MaskReferenceImage.config`
      * `MaskReferenceImage.mask_image_config`
      * `MaskReferenceImage.reference_id`
      * `MaskReferenceImage.reference_image`
      * `MaskReferenceImage.reference_type`
    * `MaskReferenceImageDict`
      * `MaskReferenceImageDict.config`
      * `MaskReferenceImageDict.reference_id`
      * `MaskReferenceImageDict.reference_image`
      * `MaskReferenceImageDict.reference_type`
    * `MaskReferenceMode`
      * `MaskReferenceMode.MASK_MODE_BACKGROUND`
      * `MaskReferenceMode.MASK_MODE_DEFAULT`
      * `MaskReferenceMode.MASK_MODE_FOREGROUND`
      * `MaskReferenceMode.MASK_MODE_SEMANTIC`
      * `MaskReferenceMode.MASK_MODE_USER_PROVIDED`
    * `MediaModality`
      * `MediaModality.AUDIO`
      * `MediaModality.DOCUMENT`
      * `MediaModality.IMAGE`
      * `MediaModality.MODALITY_UNSPECIFIED`
      * `MediaModality.TEXT`
      * `MediaModality.VIDEO`
    * `MediaResolution`
      * `MediaResolution.MEDIA_RESOLUTION_HIGH`
      * `MediaResolution.MEDIA_RESOLUTION_LOW`
      * `MediaResolution.MEDIA_RESOLUTION_MEDIUM`
      * `MediaResolution.MEDIA_RESOLUTION_UNSPECIFIED`
    * `Modality`
      * `Modality.AUDIO`
      * `Modality.IMAGE`
      * `Modality.MODALITY_UNSPECIFIED`
      * `Modality.TEXT`
    * `ModalityTokenCount`
      * `ModalityTokenCount.modality`
      * `ModalityTokenCount.token_count`
    * `ModalityTokenCountDict`
      * `ModalityTokenCountDict.modality`
      * `ModalityTokenCountDict.token_count`
    * `Mode`
      * `Mode.MODE_DYNAMIC`
      * `Mode.MODE_UNSPECIFIED`
    * `Model`
      * `Model.checkpoints`
      * `Model.default_checkpoint_id`
      * `Model.description`
      * `Model.display_name`
      * `Model.endpoints`
      * `Model.input_token_limit`
      * `Model.labels`
      * `Model.name`
      * `Model.output_token_limit`
      * `Model.supported_actions`
      * `Model.tuned_model_info`
      * `Model.version`
    * `ModelContent`
      * `ModelContent.parts`
      * `ModelContent.role`
    * `ModelDict`
      * `ModelDict.checkpoints`
      * `ModelDict.default_checkpoint_id`
      * `ModelDict.description`
      * `ModelDict.display_name`
      * `ModelDict.endpoints`
      * `ModelDict.input_token_limit`
      * `ModelDict.labels`
      * `ModelDict.name`
      * `ModelDict.output_token_limit`
      * `ModelDict.supported_actions`
      * `ModelDict.tuned_model_info`
      * `ModelDict.version`
    * `ModelSelectionConfig`
      * `ModelSelectionConfig.feature_selection_preference`
    * `ModelSelectionConfigDict`
      * `ModelSelectionConfigDict.feature_selection_preference`
    * `Operation`
      * `Operation.done`
      * `Operation.error`
      * `Operation.metadata`
      * `Operation.name`
    * `OperationDict`
      * `OperationDict.done`
      * `OperationDict.error`
      * `OperationDict.metadata`
      * `OperationDict.name`
    * `Outcome`
      * `Outcome.OUTCOME_DEADLINE_EXCEEDED`
      * `Outcome.OUTCOME_FAILED`
      * `Outcome.OUTCOME_OK`
      * `Outcome.OUTCOME_UNSPECIFIED`
    * `Part`
      * `Part.code_execution_result`
      * `Part.executable_code`
      * `Part.file_data`
      * `Part.function_call`
      * `Part.function_response`
      * `Part.inline_data`
      * `Part.text`
      * `Part.thought`
      * `Part.video_metadata`
      * `Part.from_bytes()`
      * `Part.from_code_execution_result()`
      * `Part.from_executable_code()`
      * `Part.from_function_call()`
      * `Part.from_function_response()`
      * `Part.from_text()`
      * `Part.from_uri()`
    * `PartDict`
      * `PartDict.code_execution_result`
      * `PartDict.executable_code`
      * `PartDict.file_data`
      * `PartDict.function_call`
      * `PartDict.function_response`
      * `PartDict.inline_data`
      * `PartDict.text`
      * `PartDict.thought`
      * `PartDict.video_metadata`
    * `PartnerModelTuningSpec`
      * `PartnerModelTuningSpec.hyper_parameters`
      * `PartnerModelTuningSpec.training_dataset_uri`
      * `PartnerModelTuningSpec.validation_dataset_uri`
    * `PartnerModelTuningSpecDict`
      * `PartnerModelTuningSpecDict.hyper_parameters`
      * `PartnerModelTuningSpecDict.training_dataset_uri`
      * `PartnerModelTuningSpecDict.validation_dataset_uri`
    * `PersonGeneration`
      * `PersonGeneration.ALLOW_ADULT`
      * `PersonGeneration.ALLOW_ALL`
      * `PersonGeneration.DONT_ALLOW`
    * `PrebuiltVoiceConfig`
      * `PrebuiltVoiceConfig.voice_name`
    * `PrebuiltVoiceConfigDict`
      * `PrebuiltVoiceConfigDict.voice_name`
    * `RagRetrievalConfig`
      * `RagRetrievalConfig.filter`
      * `RagRetrievalConfig.hybrid_search`
      * `RagRetrievalConfig.ranking`
      * `RagRetrievalConfig.top_k`
    * `RagRetrievalConfigDict`
      * `RagRetrievalConfigDict.filter`
      * `RagRetrievalConfigDict.hybrid_search`
      * `RagRetrievalConfigDict.ranking`
      * `RagRetrievalConfigDict.top_k`
    * `RagRetrievalConfigFilter`
      * `RagRetrievalConfigFilter.metadata_filter`
      * `RagRetrievalConfigFilter.vector_distance_threshold`
      * `RagRetrievalConfigFilter.vector_similarity_threshold`
    * `RagRetrievalConfigFilterDict`
      * `RagRetrievalConfigFilterDict.metadata_filter`
      * `RagRetrievalConfigFilterDict.vector_distance_threshold`
      * `RagRetrievalConfigFilterDict.vector_similarity_threshold`
    * `RagRetrievalConfigHybridSearch`
      * `RagRetrievalConfigHybridSearch.alpha`
    * `RagRetrievalConfigHybridSearchDict`
      * `RagRetrievalConfigHybridSearchDict.alpha`
    * `RagRetrievalConfigRanking`
      * `RagRetrievalConfigRanking.llm_ranker`
      * `RagRetrievalConfigRanking.rank_service`
    * `RagRetrievalConfigRankingDict`
      * `RagRetrievalConfigRankingDict.llm_ranker`
      * `RagRetrievalConfigRankingDict.rank_service`
    * `RagRetrievalConfigRankingLlmRanker`
      * `RagRetrievalConfigRankingLlmRanker.model_name`
    * `RagRetrievalConfigRankingLlmRankerDict`
      * `RagRetrievalConfigRankingLlmRankerDict.model_name`
    * `RagRetrievalConfigRankingRankService`
      * `RagRetrievalConfigRankingRankService.model_name`
    * `RagRetrievalConfigRankingRankServiceDict`
      * `RagRetrievalConfigRankingRankServiceDict.model_name`
    * `RawReferenceImage`
      * `RawReferenceImage.reference_id`
      * `RawReferenceImage.reference_image`
      * `RawReferenceImage.reference_type`
    * `RawReferenceImageDict`
      * `RawReferenceImageDict.reference_id`
      * `RawReferenceImageDict.reference_image`
      * `RawReferenceImageDict.reference_type`
    * `RealtimeInputConfig`
      * `RealtimeInputConfig.activity_handling`
      * `RealtimeInputConfig.automatic_activity_detection`
      * `RealtimeInputConfig.turn_coverage`
    * `RealtimeInputConfigDict`
      * `RealtimeInputConfigDict.activity_handling`
      * `RealtimeInputConfigDict.automatic_activity_detection`
      * `RealtimeInputConfigDict.turn_coverage`
    * `ReplayFile`
      * `ReplayFile.interactions`
      * `ReplayFile.replay_id`
    * `ReplayFileDict`
      * `ReplayFileDict.interactions`
      * `ReplayFileDict.replay_id`
    * `ReplayInteraction`
      * `ReplayInteraction.request`
      * `ReplayInteraction.response`
    * `ReplayInteractionDict`
      * `ReplayInteractionDict.request`
      * `ReplayInteractionDict.response`
    * `ReplayRequest`
      * `ReplayRequest.body_segments`
      * `ReplayRequest.headers`
      * `ReplayRequest.method`
      * `ReplayRequest.url`
    * `ReplayRequestDict`
      * `ReplayRequestDict.body_segments`
      * `ReplayRequestDict.headers`
      * `ReplayRequestDict.method`
      * `ReplayRequestDict.url`
    * `ReplayResponse`
      * `ReplayResponse.body_segments`
      * `ReplayResponse.headers`
      * `ReplayResponse.sdk_response_segments`
      * `ReplayResponse.status_code`
    * `ReplayResponseDict`
      * `ReplayResponseDict.body_segments`
      * `ReplayResponseDict.headers`
      * `ReplayResponseDict.sdk_response_segments`
      * `ReplayResponseDict.status_code`
    * `Retrieval`
      * `Retrieval.disable_attribution`
      * `Retrieval.vertex_ai_search`
      * `Retrieval.vertex_rag_store`
    * `RetrievalConfig`
      * `RetrievalConfig.lat_lng`
    * `RetrievalConfigDict`
      * `RetrievalConfigDict.lat_lng`
    * `RetrievalDict`
      * `RetrievalDict.disable_attribution`
      * `RetrievalDict.vertex_ai_search`
      * `RetrievalDict.vertex_rag_store`
    * `RetrievalMetadata`
      * `RetrievalMetadata.google_search_dynamic_retrieval_score`
    * `RetrievalMetadataDict`
      * `RetrievalMetadataDict.google_search_dynamic_retrieval_score`
    * `SafetyAttributes`
      * `SafetyAttributes.categories`
      * `SafetyAttributes.content_type`
      * `SafetyAttributes.scores`
    * `SafetyAttributesDict`
      * `SafetyAttributesDict.categories`
      * `SafetyAttributesDict.content_type`
      * `SafetyAttributesDict.scores`
    * `SafetyFilterLevel`
      * `SafetyFilterLevel.BLOCK_LOW_AND_ABOVE`
      * `SafetyFilterLevel.BLOCK_MEDIUM_AND_ABOVE`
      * `SafetyFilterLevel.BLOCK_NONE`
      * `SafetyFilterLevel.BLOCK_ONLY_HIGH`
    * `SafetyRating`
      * `SafetyRating.blocked`
      * `SafetyRating.category`
      * `SafetyRating.probability`
      * `SafetyRating.probability_score`
      * `SafetyRating.severity`
      * `SafetyRating.severity_score`
    * `SafetyRatingDict`
      * `SafetyRatingDict.blocked`
      * `SafetyRatingDict.category`
      * `SafetyRatingDict.probability`
      * `SafetyRatingDict.probability_score`
      * `SafetyRatingDict.severity`
      * `SafetyRatingDict.severity_score`
    * `SafetySetting`
      * `SafetySetting.category`
      * `SafetySetting.method`
      * `SafetySetting.threshold`
    * `SafetySettingDict`
      * `SafetySettingDict.category`
      * `SafetySettingDict.method`
      * `SafetySettingDict.threshold`
    * `Schema`
      * `Schema.any_of`
      * `Schema.default`
      * `Schema.description`
      * `Schema.enum`
      * `Schema.example`
      * `Schema.format`
      * `Schema.items`
      * `Schema.max_items`
      * `Schema.max_length`
      * `Schema.max_properties`
      * `Schema.maximum`
      * `Schema.min_items`
      * `Schema.min_length`
      * `Schema.min_properties`
      * `Schema.minimum`
      * `Schema.nullable`
      * `Schema.pattern`
      * `Schema.properties`
      * `Schema.property_ordering`
      * `Schema.required`
      * `Schema.title`
      * `Schema.type`
      * `Schema.from_json_schema()`
      * `Schema.json_schema`
    * `SchemaDict`
      * `SchemaDict.any_of`
      * `SchemaDict.default`
      * `SchemaDict.description`
      * `SchemaDict.enum`
      * `SchemaDict.example`
      * `SchemaDict.format`
      * `SchemaDict.max_items`
      * `SchemaDict.max_length`
      * `SchemaDict.max_properties`
      * `SchemaDict.maximum`
      * `SchemaDict.min_items`
      * `SchemaDict.min_length`
      * `SchemaDict.min_properties`
      * `SchemaDict.minimum`
      * `SchemaDict.nullable`
      * `SchemaDict.pattern`
      * `SchemaDict.properties`
      * `SchemaDict.property_ordering`
      * `SchemaDict.required`
      * `SchemaDict.title`
      * `SchemaDict.type`
    * `SearchEntryPoint`
      * `SearchEntryPoint.rendered_content`
      * `SearchEntryPoint.sdk_blob`
    * `SearchEntryPointDict`
      * `SearchEntryPointDict.rendered_content`
      * `SearchEntryPointDict.sdk_blob`
    * `Segment`
      * `Segment.end_index`
      * `Segment.part_index`
      * `Segment.start_index`
      * `Segment.text`
    * `SegmentDict`
      * `SegmentDict.end_index`
      * `SegmentDict.part_index`
      * `SegmentDict.start_index`
      * `SegmentDict.text`
    * `SessionResumptionConfig`
      * `SessionResumptionConfig.handle`
      * `SessionResumptionConfig.transparent`
    * `SessionResumptionConfigDict`
      * `SessionResumptionConfigDict.handle`
      * `SessionResumptionConfigDict.transparent`
    * `SlidingWindow`
      * `SlidingWindow.target_tokens`
    * `SlidingWindowDict`
      * `SlidingWindowDict.target_tokens`
    * `SpeechConfig`
      * `SpeechConfig.language_code`
      * `SpeechConfig.voice_config`
    * `SpeechConfigDict`
      * `SpeechConfigDict.language_code`
      * `SpeechConfigDict.voice_config`
    * `StartSensitivity`
      * `StartSensitivity.START_SENSITIVITY_HIGH`
      * `StartSensitivity.START_SENSITIVITY_LOW`
      * `StartSensitivity.START_SENSITIVITY_UNSPECIFIED`
    * `StyleReferenceConfig`
      * `StyleReferenceConfig.style_description`
    * `StyleReferenceConfigDict`
      * `StyleReferenceConfigDict.style_description`
    * `StyleReferenceImage`
      * `StyleReferenceImage.config`
      * `StyleReferenceImage.reference_id`
      * `StyleReferenceImage.reference_image`
      * `StyleReferenceImage.reference_type`
      * `StyleReferenceImage.style_image_config`
    * `StyleReferenceImageDict`
      * `StyleReferenceImageDict.config`
      * `StyleReferenceImageDict.reference_id`
      * `StyleReferenceImageDict.reference_image`
      * `StyleReferenceImageDict.reference_type`
    * `SubjectReferenceConfig`
      * `SubjectReferenceConfig.subject_description`
      * `SubjectReferenceConfig.subject_type`
    * `SubjectReferenceConfigDict`
      * `SubjectReferenceConfigDict.subject_description`
      * `SubjectReferenceConfigDict.subject_type`
    * `SubjectReferenceImage`
      * `SubjectReferenceImage.config`
      * `SubjectReferenceImage.reference_id`
      * `SubjectReferenceImage.reference_image`
      * `SubjectReferenceImage.reference_type`
      * `SubjectReferenceImage.subject_image_config`
    * `SubjectReferenceImageDict`
      * `SubjectReferenceImageDict.config`
      * `SubjectReferenceImageDict.reference_id`
      * `SubjectReferenceImageDict.reference_image`
      * `SubjectReferenceImageDict.reference_type`
    * `SubjectReferenceType`
      * `SubjectReferenceType.SUBJECT_TYPE_ANIMAL`
      * `SubjectReferenceType.SUBJECT_TYPE_DEFAULT`
      * `SubjectReferenceType.SUBJECT_TYPE_PERSON`
      * `SubjectReferenceType.SUBJECT_TYPE_PRODUCT`
    * `SupervisedHyperParameters`
      * `SupervisedHyperParameters.adapter_size`
      * `SupervisedHyperParameters.epoch_count`
      * `SupervisedHyperParameters.learning_rate_multiplier`
    * `SupervisedHyperParametersDict`
      * `SupervisedHyperParametersDict.adapter_size`
      * `SupervisedHyperParametersDict.epoch_count`
      * `SupervisedHyperParametersDict.learning_rate_multiplier`
    * `SupervisedTuningDataStats`
      * `SupervisedTuningDataStats.total_billable_character_count`
      * `SupervisedTuningDataStats.total_billable_token_count`
      * `SupervisedTuningDataStats.total_truncated_example_count`
      * `SupervisedTuningDataStats.total_tuning_character_count`
      * `SupervisedTuningDataStats.truncated_example_indices`
      * `SupervisedTuningDataStats.tuning_dataset_example_count`
      * `SupervisedTuningDataStats.tuning_step_count`
      * `SupervisedTuningDataStats.user_dataset_examples`
      * `SupervisedTuningDataStats.user_input_token_distribution`
      * `SupervisedTuningDataStats.user_message_per_example_distribution`
      * `SupervisedTuningDataStats.user_output_token_distribution`
    * `SupervisedTuningDataStatsDict`
      * `SupervisedTuningDataStatsDict.total_billable_character_count`
      * `SupervisedTuningDataStatsDict.total_billable_token_count`
      * `SupervisedTuningDataStatsDict.total_truncated_example_count`
      * `SupervisedTuningDataStatsDict.total_tuning_character_count`
      * `SupervisedTuningDataStatsDict.truncated_example_indices`
      * `SupervisedTuningDataStatsDict.tuning_dataset_example_count`
      * `SupervisedTuningDataStatsDict.tuning_step_count`
      * `SupervisedTuningDataStatsDict.user_dataset_examples`
      * `SupervisedTuningDataStatsDict.user_input_token_distribution`
      * `SupervisedTuningDataStatsDict.user_message_per_example_distribution`
      * `SupervisedTuningDataStatsDict.user_output_token_distribution`
    * `SupervisedTuningDatasetDistribution`
      * `SupervisedTuningDatasetDistribution.billable_sum`
      * `SupervisedTuningDatasetDistribution.buckets`
      * `SupervisedTuningDatasetDistribution.max`
      * `SupervisedTuningDatasetDistribution.mean`
      * `SupervisedTuningDatasetDistribution.median`
      * `SupervisedTuningDatasetDistribution.min`
      * `SupervisedTuningDatasetDistribution.p5`
      * `SupervisedTuningDatasetDistribution.p95`
      * `SupervisedTuningDatasetDistribution.sum`
    * `SupervisedTuningDatasetDistributionDatasetBucket`
      * `SupervisedTuningDatasetDistributionDatasetBucket.count`
      * `SupervisedTuningDatasetDistributionDatasetBucket.left`
      * `SupervisedTuningDatasetDistributionDatasetBucket.right`
    * `SupervisedTuningDatasetDistributionDatasetBucketDict`
      * `SupervisedTuningDatasetDistributionDatasetBucketDict.count`
      * `SupervisedTuningDatasetDistributionDatasetBucketDict.left`
      * `SupervisedTuningDatasetDistributionDatasetBucketDict.right`
    * `SupervisedTuningDatasetDistributionDict`
      * `SupervisedTuningDatasetDistributionDict.billable_sum`
      * `SupervisedTuningDatasetDistributionDict.buckets`
      * `SupervisedTuningDatasetDistributionDict.max`
      * `SupervisedTuningDatasetDistributionDict.mean`
      * `SupervisedTuningDatasetDistributionDict.median`
      * `SupervisedTuningDatasetDistributionDict.min`
      * `SupervisedTuningDatasetDistributionDict.p5`
      * `SupervisedTuningDatasetDistributionDict.p95`
      * `SupervisedTuningDatasetDistributionDict.sum`
    * `SupervisedTuningSpec`
      * `SupervisedTuningSpec.export_last_checkpoint_only`
      * `SupervisedTuningSpec.hyper_parameters`
      * `SupervisedTuningSpec.training_dataset_uri`
      * `SupervisedTuningSpec.validation_dataset_uri`
    * `SupervisedTuningSpecDict`
      * `SupervisedTuningSpecDict.export_last_checkpoint_only`
      * `SupervisedTuningSpecDict.hyper_parameters`
      * `SupervisedTuningSpecDict.training_dataset_uri`
      * `SupervisedTuningSpecDict.validation_dataset_uri`
    * `TestTableFile`
      * `TestTableFile.comment`
      * `TestTableFile.parameter_names`
      * `TestTableFile.test_method`
      * `TestTableFile.test_table`
    * `TestTableFileDict`
      * `TestTableFileDict.comment`
      * `TestTableFileDict.parameter_names`
      * `TestTableFileDict.test_method`
      * `TestTableFileDict.test_table`
    * `TestTableItem`
      * `TestTableItem.exception_if_mldev`
      * `TestTableItem.exception_if_vertex`
      * `TestTableItem.has_union`
      * `TestTableItem.ignore_keys`
      * `TestTableItem.name`
      * `TestTableItem.override_replay_id`
      * `TestTableItem.parameters`
      * `TestTableItem.skip_in_api_mode`
    * `TestTableItemDict`
      * `TestTableItemDict.exception_if_mldev`
      * `TestTableItemDict.exception_if_vertex`
      * `TestTableItemDict.has_union`
      * `TestTableItemDict.ignore_keys`
      * `TestTableItemDict.name`
      * `TestTableItemDict.override_replay_id`
      * `TestTableItemDict.parameters`
      * `TestTableItemDict.skip_in_api_mode`
    * `ThinkingConfig`
      * `ThinkingConfig.include_thoughts`
      * `ThinkingConfig.thinking_budget`
    * `ThinkingConfigDict`
      * `ThinkingConfigDict.include_thoughts`
      * `ThinkingConfigDict.thinking_budget`
    * `TokensInfo`
      * `TokensInfo.role`
      * `TokensInfo.token_ids`
      * `TokensInfo.tokens`
    * `TokensInfoDict`
      * `TokensInfoDict.role`
      * `TokensInfoDict.token_ids`
      * `TokensInfoDict.tokens`
    * `Tool`
      * `Tool.code_execution`
      * `Tool.enterprise_web_search`
      * `Tool.function_declarations`
      * `Tool.google_maps`
      * `Tool.google_search`
      * `Tool.google_search_retrieval`
      * `Tool.retrieval`
    * `ToolCodeExecution`
    * `ToolCodeExecutionDict`
    * `ToolConfig`
      * `ToolConfig.function_calling_config`
      * `ToolConfig.retrieval_config`
    * `ToolConfigDict`
      * `ToolConfigDict.function_calling_config`
      * `ToolConfigDict.retrieval_config`
    * `ToolDict`
      * `ToolDict.code_execution`
      * `ToolDict.enterprise_web_search`
      * `ToolDict.function_declarations`
      * `ToolDict.google_maps`
      * `ToolDict.google_search`
      * `ToolDict.google_search_retrieval`
      * `ToolDict.retrieval`
    * `TrafficType`
      * `TrafficType.ON_DEMAND`
      * `TrafficType.PROVISIONED_THROUGHPUT`
      * `TrafficType.TRAFFIC_TYPE_UNSPECIFIED`
    * `Transcription`
      * `Transcription.finished`
      * `Transcription.text`
    * `TranscriptionDict`
      * `TranscriptionDict.finished`
      * `TranscriptionDict.text`
    * `TunedModel`
      * `TunedModel.checkpoints`
      * `TunedModel.endpoint`
      * `TunedModel.model`
    * `TunedModelCheckpoint`
      * `TunedModelCheckpoint.checkpoint_id`
      * `TunedModelCheckpoint.endpoint`
      * `TunedModelCheckpoint.epoch`
      * `TunedModelCheckpoint.step`
    * `TunedModelCheckpointDict`
      * `TunedModelCheckpointDict.checkpoint_id`
      * `TunedModelCheckpointDict.endpoint`
      * `TunedModelCheckpointDict.epoch`
      * `TunedModelCheckpointDict.step`
    * `TunedModelDict`
      * `TunedModelDict.checkpoints`
      * `TunedModelDict.endpoint`
      * `TunedModelDict.model`
    * `TunedModelInfo`
      * `TunedModelInfo.base_model`
      * `TunedModelInfo.create_time`
      * `TunedModelInfo.update_time`
    * `TunedModelInfoDict`
      * `TunedModelInfoDict.base_model`
      * `TunedModelInfoDict.create_time`
      * `TunedModelInfoDict.update_time`
    * `TuningDataStats`
      * `TuningDataStats.distillation_data_stats`
      * `TuningDataStats.supervised_tuning_data_stats`
    * `TuningDataStatsDict`
      * `TuningDataStatsDict.distillation_data_stats`
      * `TuningDataStatsDict.supervised_tuning_data_stats`
    * `TuningDataset`
      * `TuningDataset.examples`
      * `TuningDataset.gcs_uri`
    * `TuningDatasetDict`
      * `TuningDatasetDict.examples`
      * `TuningDatasetDict.gcs_uri`
    * `TuningExample`
      * `TuningExample.output`
      * `TuningExample.text_input`
    * `TuningExampleDict`
      * `TuningExampleDict.output`
      * `TuningExampleDict.text_input`
    * `TuningJob`
      * `TuningJob.base_model`
      * `TuningJob.create_time`
      * `TuningJob.description`
      * `TuningJob.distillation_spec`
      * `TuningJob.encryption_spec`
      * `TuningJob.end_time`
      * `TuningJob.error`
      * `TuningJob.experiment`
      * `TuningJob.labels`
      * `TuningJob.name`
      * `TuningJob.partner_model_tuning_spec`
      * `TuningJob.pipeline_job`
      * `TuningJob.start_time`
      * `TuningJob.state`
      * `TuningJob.supervised_tuning_spec`
      * `TuningJob.tuned_model`
      * `TuningJob.tuned_model_display_name`
      * `TuningJob.tuning_data_stats`
      * `TuningJob.update_time`
      * `TuningJob.has_ended`
      * `TuningJob.has_succeeded`
    * `TuningJobDict`
      * `TuningJobDict.base_model`
      * `TuningJobDict.create_time`
      * `TuningJobDict.description`
      * `TuningJobDict.distillation_spec`
      * `TuningJobDict.encryption_spec`
      * `TuningJobDict.end_time`
      * `TuningJobDict.error`
      * `TuningJobDict.experiment`
      * `TuningJobDict.labels`
      * `TuningJobDict.name`
      * `TuningJobDict.partner_model_tuning_spec`
      * `TuningJobDict.pipeline_job`
      * `TuningJobDict.start_time`
      * `TuningJobDict.state`
      * `TuningJobDict.supervised_tuning_spec`
      * `TuningJobDict.tuned_model`
      * `TuningJobDict.tuned_model_display_name`
      * `TuningJobDict.tuning_data_stats`
      * `TuningJobDict.update_time`
    * `TuningValidationDataset`
      * `TuningValidationDataset.gcs_uri`
    * `TuningValidationDatasetDict`
      * `TuningValidationDatasetDict.gcs_uri`
    * `TurnCoverage`
      * `TurnCoverage.TURN_COVERAGE_UNSPECIFIED`
      * `TurnCoverage.TURN_INCLUDES_ALL_INPUT`
      * `TurnCoverage.TURN_INCLUDES_ONLY_ACTIVITY`
    * `Type`
      * `Type.ARRAY`
      * `Type.BOOLEAN`
      * `Type.INTEGER`
      * `Type.NUMBER`
      * `Type.OBJECT`
      * `Type.STRING`
      * `Type.TYPE_UNSPECIFIED`
    * `UpdateCachedContentConfig`
      * `UpdateCachedContentConfig.expire_time`
      * `UpdateCachedContentConfig.http_options`
      * `UpdateCachedContentConfig.ttl`
    * `UpdateCachedContentConfigDict`
      * `UpdateCachedContentConfigDict.expire_time`
      * `UpdateCachedContentConfigDict.http_options`
      * `UpdateCachedContentConfigDict.ttl`
    * `UpdateModelConfig`
      * `UpdateModelConfig.default_checkpoint_id`
      * `UpdateModelConfig.description`
      * `UpdateModelConfig.display_name`
      * `UpdateModelConfig.http_options`
    * `UpdateModelConfigDict`
      * `UpdateModelConfigDict.default_checkpoint_id`
      * `UpdateModelConfigDict.description`
      * `UpdateModelConfigDict.display_name`
      * `UpdateModelConfigDict.http_options`
    * `UploadFileConfig`
      * `UploadFileConfig.display_name`
      * `UploadFileConfig.http_options`
      * `UploadFileConfig.mime_type`
      * `UploadFileConfig.name`
    * `UploadFileConfigDict`
      * `UploadFileConfigDict.display_name`
      * `UploadFileConfigDict.http_options`
      * `UploadFileConfigDict.mime_type`
      * `UploadFileConfigDict.name`
    * `UpscaleImageConfig`
      * `UpscaleImageConfig.http_options`
      * `UpscaleImageConfig.include_rai_reason`
      * `UpscaleImageConfig.output_compression_quality`
      * `UpscaleImageConfig.output_mime_type`
    * `UpscaleImageConfigDict`
      * `UpscaleImageConfigDict.http_options`
      * `UpscaleImageConfigDict.include_rai_reason`
      * `UpscaleImageConfigDict.output_compression_quality`
      * `UpscaleImageConfigDict.output_mime_type`
    * `UpscaleImageParameters`
      * `UpscaleImageParameters.config`
      * `UpscaleImageParameters.image`
      * `UpscaleImageParameters.model`
      * `UpscaleImageParameters.upscale_factor`
    * `UpscaleImageParametersDict`
      * `UpscaleImageParametersDict.config`
      * `UpscaleImageParametersDict.image`
      * `UpscaleImageParametersDict.model`
      * `UpscaleImageParametersDict.upscale_factor`
    * `UpscaleImageResponse`
      * `UpscaleImageResponse.generated_images`
    * `UpscaleImageResponseDict`
      * `UpscaleImageResponseDict.generated_images`
    * `UsageMetadata`
      * `UsageMetadata.cache_tokens_details`
      * `UsageMetadata.cached_content_token_count`
      * `UsageMetadata.prompt_token_count`
      * `UsageMetadata.prompt_tokens_details`
      * `UsageMetadata.response_token_count`
      * `UsageMetadata.response_tokens_details`
      * `UsageMetadata.thoughts_token_count`
      * `UsageMetadata.tool_use_prompt_token_count`
      * `UsageMetadata.tool_use_prompt_tokens_details`
      * `UsageMetadata.total_token_count`
      * `UsageMetadata.traffic_type`
    * `UsageMetadataDict`
      * `UsageMetadataDict.cache_tokens_details`
      * `UsageMetadataDict.cached_content_token_count`
      * `UsageMetadataDict.prompt_token_count`
      * `UsageMetadataDict.prompt_tokens_details`
      * `UsageMetadataDict.response_token_count`
      * `UsageMetadataDict.response_tokens_details`
      * `UsageMetadataDict.thoughts_token_count`
      * `UsageMetadataDict.tool_use_prompt_token_count`
      * `UsageMetadataDict.tool_use_prompt_tokens_details`
      * `UsageMetadataDict.total_token_count`
      * `UsageMetadataDict.traffic_type`
    * `UserContent`
      * `UserContent.parts`
      * `UserContent.role`
    * `VertexAISearch`
      * `VertexAISearch.datastore`
      * `VertexAISearch.engine`
    * `VertexAISearchDict`
      * `VertexAISearchDict.datastore`
      * `VertexAISearchDict.engine`
    * `VertexRagStore`
      * `VertexRagStore.rag_corpora`
      * `VertexRagStore.rag_resources`
      * `VertexRagStore.rag_retrieval_config`
      * `VertexRagStore.similarity_top_k`
      * `VertexRagStore.vector_distance_threshold`
    * `VertexRagStoreDict`
      * `VertexRagStoreDict.rag_corpora`
      * `VertexRagStoreDict.rag_resources`
      * `VertexRagStoreDict.rag_retrieval_config`
      * `VertexRagStoreDict.similarity_top_k`
      * `VertexRagStoreDict.vector_distance_threshold`
    * `VertexRagStoreRagResource`
      * `VertexRagStoreRagResource.rag_corpus`
      * `VertexRagStoreRagResource.rag_file_ids`
    * `VertexRagStoreRagResourceDict`
      * `VertexRagStoreRagResourceDict.rag_corpus`
      * `VertexRagStoreRagResourceDict.rag_file_ids`
    * `Video`
      * `Video.mime_type`
      * `Video.uri`
      * `Video.video_bytes`
      * `Video.save()`
      * `Video.show()`
    * `VideoDict`
      * `VideoDict.mime_type`
      * `VideoDict.uri`
      * `VideoDict.video_bytes`
    * `VideoMetadata`
      * `VideoMetadata.end_offset`
      * `VideoMetadata.start_offset`
    * `VideoMetadataDict`
      * `VideoMetadataDict.end_offset`
      * `VideoMetadataDict.start_offset`
    * `VoiceConfig`
      * `VoiceConfig.prebuilt_voice_config`
    * `VoiceConfigDict`
      * `VoiceConfigDict.prebuilt_voice_config`


Next
Submodules
Copyright © 2024, Google 
Made with Sphinx and @pradyunsg's Furo
On this page 
  * Google Gen AI SDK
    * Installation
    * Imports
    * Create a client
      * API Selection
    * Types
  * Models
    * Generate Content
      * with text content
      * with uploaded file (Gemini Developer API only)
      * How to structure contents argument for generate_content
        * Provide a list[types.Content]
        * Provide a types.Content instance
        * Provide a string
        * Provide a list of string
        * Provide a function call part
        * Provide a list of function call parts
        * Provide a non function call part
        * Provide a list of non function call parts
        * Mix types in contents
    * System Instructions and Other Configs
    * Typed Config
    * List Base Models
      * List Base Models (Asynchronous)
    * Safety Settings
    * Function Calling
      * Disabling automatic function calling
      * Manually declare and invoke a function for function calling
      * Function calling with `ANY` tools config mode
    * JSON Response Schema
      * Pydantic Model Schema support
    * Enum Response Schema
      * Text Response
      * JSON Response
    * Generate Content (Synchronous Streaming)
      * Streaming for text content
      * Streaming for image content
    * Generate Content (Asynchronous Non-Streaming)
    * Generate Content (Asynchronous Streaming)
    * Count Tokens and Compute Tokens
      * Compute Tokens
      * Count Tokens (Asynchronous)
    * Embed Content
    * Imagen
      * Generate Image
      * Edit Image
    * Veo
      * Generate Videos
  * Chats
    * Send Message (Synchronous Non-Streaming)
    * Send Message (Synchronous Streaming)
    * Send Message (Asynchronous Non-Streaming)
    * Send Message (Asynchronous Streaming)
  * Files
    * Upload
    * Get
    * Delete
  * Caches
    * Create
    * Get
    * Generate Content with Caches
  * Tunings
    * Tune
    * Get Tuning Job
    * Use Tuned Model
    * Get Tuned Model
    * Update Tuned Model
    * List Tuned Models
      * List Tuned Models (Asynchronous)
    * Update Tuned Model
    * List Tuning Jobs
  * Batch Prediction
    * Create
    * List
      * List Batch Jobs with Pager
      * List Batch Jobs (Asynchronous)
      * List Batch Jobs with Pager (Asynchronous)
    * Delete
  * Error Handling
  * Reference




---

```
Google Gen AI SDK
=================

|pypi|

`<https://github.com/googleapis/python-genai>`_

.. |pypi| image:: https://img.shields.io/pypi/v/google-genai.svg
   :target: https://pypi.org/project/google-genai/

:strong:`google-genai` is an initial Python client library for interacting with
Google's Generative AI APIs.

Google Gen AI Python SDK provides an interface for developers to integrate Google's generative models into their Python applications. It supports the `Gemini Developer API <https://ai.google.dev/gemini-api/docs>`_ and `Vertex AI <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/overview>`_ APIs.

Installation
------------

.. code:: shell

    pip install google-genai

Imports
-------

.. code:: python

    from google import genai
    from google.genai import types

Create a client
---------------

Please run one of the following code blocks to create a client for
different services (`Gemini Developer API <https://ai.google.dev/gemini-api/docs>`_ or `Vertex AI <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/overview>`_). Feel free to switch the client and
run all the examples to see how it behaves under different APIs.

.. code:: python

    from google import genai

    # Only run this block for Gemini Developer API
    client = genai.Client(api_key='GEMINI_API_KEY')

.. code:: python

    from google import genai

    # Only run this block for Vertex AI API
    client = genai.Client(
        vertexai=True, project='your-project-id', location='us-central1'
    )


**(Optional) Using environment variables:**

You can create a client by configuring the necessary environment variables.
Configuration setup instructions depends on whether you're using the Gemini
Developer API or the Gemini API in Vertex AI.

**Gemini Developer API:** Set `GOOGLE_API_KEY` as shown below:

.. code:: bash

    export GOOGLE_API_KEY='your-api-key'


**Gemini API in Vertex AI:** Set `GOOGLE_GENAI_USE_VERTEXAI`, `GOOGLE_CLOUD_PROJECT`
and `GOOGLE_CLOUD_LOCATION`, as shown below:

.. code:: bash

    export GOOGLE_GENAI_USE_VERTEXAI=true
    export GOOGLE_CLOUD_PROJECT='your-project-id'
    export GOOGLE_CLOUD_LOCATION='us-central1'


.. code:: python

    from google import genai

    client = genai.Client()


API Selection
^^^^^^^^^^^^^

By default, the SDK uses the beta API endpoints provided by Google to support preview features in the APIs. The stable API endpoints can be selected by setting the API version to `v1`.

To set the API version use ``http_options``. For example, to set the API version to ``v1`` for Vertex AI:

.. code:: python

    from google import genai
    from google.genai import types

    client = genai.Client(
        vertexai=True,
        project='your-project-id',
        location='us-central1',
        http_options=types.HttpOptions(api_version='v1')
    )

To set the API version to `v1alpha` for the Gemini Developer API:

.. code:: python

    from google import genai
    from google.genai import types

    # Only run this block for Gemini Developer API
    client = genai.Client(
        api_key='GEMINI_API_KEY',
        http_options=types.HttpOptions(api_version='v1alpha')
    )


Types
-----

Parameter types can be specified as either dictionaries(``TypedDict``) or `Pydantic Models <https://pydantic.readthedocs.io/en/stable/model.html>`_.
Pydantic model types are available in the ``types`` module.

Models
======

The ``client.models`` modules exposes model inferencing and model
getters. See the 'Create a client' section above to initialize a client.

Generate Content
----------------

with text content
^^^^^^^^^^^^^^^^^

.. code:: python

    response = client.models.generate_content(
        model='gemini-2.0-flash-001', contents='Why is the sky blue?'
    )
    print(response.text)

with uploaded file (Gemini Developer API only)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

download the file in console.

.. code:: console

    !wget -q https://storage.googleapis.com/generativeai-downloads/data/a11.txt

python code.

.. code:: python

    file = client.files.upload(file='a11.txt')
    response = client.models.generate_content(
        model='gemini-2.0-flash-001',
        contents=['Could you summarize this file?', file]
    )
    print(response.text)


How to structure `contents` argument for `generate_content`
^^^^^^^^^^^^^^^^^^^^^^^^^^^
The SDK always converts the inputs to the `contents` argument into
`list[types.Content]`.
The following shows some common ways to provide your inputs.

Provide a `list[types.Content]`
""""""""""""""""""""""""""""""
This is the canonical way to provide contents, SDK will not do any conversion.

Provide a `types.Content` instance
""""""""""""""""""""""""""""""

.. code:: python

    from google.genai import types

    contents = types.Content(
    role='user',
    parts=[types.Part.from_text(text='Why is the sky blue?')]
    )

SDK converts this to

.. code:: python

    [
    types.Content(
        role='user',
        parts=[types.Part.from_text(text='Why is the sky blue?')]
    )
    ]

Provide a string
""""""""""""""""""

.. code:: python

    contents='Why is the sky blue?'

The SDK will assume this is a text part, and it converts this into the following:

.. code:: python

    [
    types.UserContent(
        parts=[
        types.Part.from_text(text='Why is the sky blue?')
        ]
    )
    ]

Where a `types.UserContent` is a subclass of `types.Content`, it sets the
`role` field to be `user`.

Provide a list of string
""""""""""""""""""""""""

.. code:: python
    contents=['Why is the sky blue?', 'Why is the cloud white?']

The SDK assumes these are 2 text parts, it converts this into a single content,
like the following:

.. code:: python

    [
    types.UserContent(
        parts=[
        types.Part.from_text(text='Why is the sky blue?'),
        types.Part.from_text(text='Why is the cloud white?'),
        ]
    )
    ]

Where a `types.UserContent` is a subclass of `types.Content`, the
`role` field in `types.UserContent` is fixed to be `user`.

Provide a function call part
""""""""""""""""""""""""""

.. code:: python

    from google.genai import types

    contents = types.Part.from_function_call(
    name='get_weather_by_location',
    args={'location': 'Boston'}
    )

The SDK converts a function call part to a content with a `model` role:

.. code:: python

    [
    types.ModelContent(
        parts=[
        types.Part.from_function_call(
            name='get_weather_by_location',
            args={'location': 'Boston'}
        )
        ]
    )
    ]

Where a `types.ModelContent` is a subclass of `types.Content`, the
`role` field in `types.ModelContent` is fixed to be `model`.

Provide a list of function call parts
""""""""""""""""""""""""""""""

.. code:: python

    from google.genai import types

    contents = [
    types.Part.from_function_call(
        name='get_weather_by_location',
        args={'location': 'Boston'}
    ),
    types.Part.from_function_call(
        name='get_weather_by_location',
        args={'location': 'New York'}
    ),
    ]

The SDK converts a list of function call parts to the a content with a `model` role:

.. code:: python

    [
    types.ModelContent(
        parts=[
        types.Part.from_function_call(
            name='get_weather_by_location',
            args={'location': 'Boston'}
        ),
        types.Part.from_function_call(
            name='get_weather_by_location',
            args={'location': 'New York'}
        )
        ]
    )
    ]

Where a `types.ModelContent` is a subclass of `types.Content`, the
`role` field in `types.ModelContent` is fixed to be `model`.

Provide a non function call part
""""""""""""""""""""""""

.. code:: python

    from google.genai import types

    contents = types.Part.from_uri(
    file_uri: 'gs://generativeai-downloads/images/scones.jpg',
    mime_type: 'image/jpeg',
    )

The SDK converts all non function call parts into a content with a `user` role.

.. code:: python

    [
    types.UserContent(parts=[
        types.Part.from_uri(
        file_uri: 'gs://generativeai-downloads/images/scones.jpg',
        mime_type: 'image/jpeg',
        )
    ])
    ]

Provide a list of non function call parts
""""""""""""""""""""

.. code:: python

    from google.genai import types

    contents = [
    types.Part.from_text('What is this image about?'),
    types.Part.from_uri(
        file_uri: 'gs://generativeai-downloads/images/scones.jpg',
        mime_type: 'image/jpeg',
    )
    ]

The SDK will convert the list of parts into a content with a `user` role

.. code:: python

    [
    types.UserContent(
        parts=[
        types.Part.from_text('What is this image about?'),
        types.Part.from_uri(
            file_uri: 'gs://generativeai-downloads/images/scones.jpg',
            mime_type: 'image/jpeg',
        )
        ]
    )
    ]

Mix types in contents
""""""""""""""""""""""""""
You can also provide a list of `types.ContentUnion`. The SDK leaves items of
`types.Content` as is, it groups consecutive non function call parts into a
single `types.UserContent`, and it groups consecutive function call parts into
a single `types.ModelContent`.

If you put a list within a list, the inner list can only contain
`types.PartUnion` items. The SDK will convert the inner list into a single
`types.UserContent`.


System Instructions and Other Configs
-------------------------------------

The output of the model can be influenced by several optional settings
available in generate_content's config parameter. For example, increasing
`max_output_tokens` is essential for longer model responses. To make a model more
deterministic, lowering the `temperature` parameter reduces randomness, with
values near 0 minimizing variability. Capabilities and parameter defaults for
each model is shown in the
[Vertex AI docs](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash)
and [Gemini API docs](https://ai.google.dev/gemini-api/docs/models) respectively.

.. code:: python

    from google.genai import types

    response = client.models.generate_content(
        model='gemini-2.0-flash-001',
        contents='high',
        config=types.GenerateContentConfig(
            system_instruction='I say high, you say low',
            max_output_tokens=3,
            temperature=0.3,
        ),
    )
    print(response.text)

Typed Config
------------

All API methods support Pydantic types for parameters as well as
dictionaries. You can get the type from ``google.genai.types``.

.. code:: python

    from google.genai import types

    response = client.models.generate_content(
        model='gemini-2.0-flash-001',
        contents=types.Part.from_text(text='Why is the sky blue?'),
        config=types.GenerateContentConfig(
            temperature=0,
            top_p=0.95,
            top_k=20,
            candidate_count=1,
            seed=5,
            max_output_tokens=100,
            stop_sequences=['STOP!'],
            presence_penalty=0.0,
            frequency_penalty=0.0,
        ),
    )

    print(response.text)

List Base Models
----------------

To retrieve tuned models, see: :ref:`List Tuned Models`

.. code:: python

    for model in client.models.list():
        print(model)

.. code:: python

    pager = client.models.list(config={'page_size': 10})
    print(pager.page_size)
    print(pager[0])
    pager.next_page()
    print(pager[0])

List Base Models (Asynchronous)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. code:: python

    async for job in await client.aio.models.list():
        print(job)

.. code:: python

    async_pager = await client.aio.models.list(config={'page_size': 10})
    print(async_pager.page_size)
    print(async_pager[0])
    await async_pager.next_page()
    print(async_pager[0])

Safety Settings
---------------

.. code:: python

    from google.genai import types

    response = client.models.generate_content(
        model='gemini-2.0-flash-001',
        contents='Say something bad.',
        config=types.GenerateContentConfig(
            safety_settings=[
                types.SafetySetting(
                    category='HARM_CATEGORY_HATE_SPEECH',
                    threshold='BLOCK_ONLY_HIGH',
                )
            ]
        ),
    )
    print(response.text)

Function Calling
----------------

Automatic Python function Support:

You can pass a Python function directly and it will be automatically
called and responded.

.. code:: python

    from google.genai import types

    def get_current_weather(location: str) -> str:
        """Returns the current weather.

        Args:
          location: The city and state, e.g. San Francisco, CA
        """
        return 'sunny'


    response = client.models.generate_content(
        model='gemini-2.0-flash-001',
        contents='What is the weather like in Boston?',
        config=types.GenerateContentConfig(
            tools=[get_current_weather],
        ),
    )

    print(response.text)

Disabling automatic function calling
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

If you pass in a python function as a tool directly, and do not want
automatic function calling, you can disable automatic function calling
as follows:

.. code:: python

    from google.genai import types

    response = client.models.generate_content(
        model='gemini-2.0-flash-001',
        contents='What is the weather like in Boston?',
        config=types.GenerateContentConfig(
            tools=[get_current_weather],
            automatic_function_calling=types.AutomaticFunctionCallingConfig(
                disable=True
            ),
        ),
    )

With automatic function calling disabled, you will get a list of function call
parts in the response:

.. code:: python
    function_calls: Optional[List[types.FunctionCall]] = response.function_calls


Manually declare and invoke a function for function calling
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

If you don't want to use the automatic function support, you can manually
declare the function and invoke it.

The following example shows how to declare a function and pass it as a tool.
Then you will receive a function call part in the response.

.. code:: python

    from google.genai import types

    function = types.FunctionDeclaration(
        name='get_current_weather',
        description='Get the current weather in a given location',
        parameters=types.Schema(
            type='OBJECT',
            properties={
                'location': types.Schema(
                    type='STRING',
                    description='The city and state, e.g. San Francisco, CA',
                ),
            },
            required=['location'],
        ),
    )

    tool = types.Tool(function_declarations=[function])

    response = client.models.generate_content(
        model='gemini-2.0-flash-001',
        contents='What is the weather like in Boston?',
        config=types.GenerateContentConfig(
            tools=[tool],
        ),
    )
    print(response.function_calls[0])

After you receive the function call part from the model, you can invoke the function
and get the function response. And then you can pass the function response to
the model.
The following example shows how to do it for a simple function invocation.

.. code:: python

    from google.genai import types

    user_prompt_content = types.Content(
        role='user',
        parts=[types.Part.from_text(text='What is the weather like in Boston?')],
    )
    function_call_part = response.function_calls[0]
    function_call_content = response.candidates[0].content


    try:
        function_result = get_current_weather(
            **function_call_part.function_call.args
        )
        function_response = {'result': function_result}
    except (
        Exception
    ) as e:  # instead of raising the exception, you can let the model handle it
        function_response = {'error': str(e)}


    function_response_part = types.Part.from_function_response(
        name=function_call_part.name,
        response=function_response,
    )
    function_response_content = types.Content(
        role='tool', parts=[function_response_part]
    )

    response = client.models.generate_content(
        model='gemini-2.0-flash-001',
        contents=[
            user_prompt_content,
            function_call_content,
            function_response_content,
        ],
        config=types.GenerateContentConfig(
            tools=[tool],
        ),
    )

    print(response.text)


Function calling with ``ANY`` tools config mode
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

If you configure function calling mode to be `ANY`, then the model will always
return function call parts. If you also pass a python function as a tool, by
default the SDK will perform automatic function calling until the remote calls
exceed the maximum remote call for automatic function calling (default to 10 times).

If you'd like to disable automatic function calling in `ANY` mode:

.. code-block:: python

    from google.genai import types

    def get_current_weather(location: str) -> str:
        """Returns the current weather.

        Args:
            location: The city and state, e.g. San Francisco, CA
        """
        return "sunny"

    response = client.models.generate_content(
        model="gemini-2.0-flash-001",
        contents="What is the weather like in Boston?",
        config=types.GenerateContentConfig(
            tools=[get_current_weather],
            automatic_function_calling=types.AutomaticFunctionCallingConfig(
                disable=True
            ),
            tool_config=types.ToolConfig(
                function_calling_config=types.FunctionCallingConfig(mode='ANY')
            ),
        ),
    )

If you'd like to set ``x`` number of automatic function call turns, you can
configure the maximum remote calls to be ``x + 1``.
Assuming you prefer ``1`` turn for automatic function calling:

.. code-block:: python

    from google.genai import types

    def get_current_weather(location: str) -> str:
        """Returns the current weather.

        Args:
            location: The city and state, e.g. San Francisco, CA
        """
        return "sunny"

    response = client.models.generate_content(
        model="gemini-2.0-flash-001",
        contents="What is the weather like in Boston?",
        config=types.GenerateContentConfig(
            tools=[get_current_weather],
            automatic_function_calling=types.AutomaticFunctionCallingConfig(
                maximum_remote_calls=2
            ),
            tool_config=types.ToolConfig(
                function_calling_config=types.FunctionCallingConfig(mode='ANY')
            ),
        ),
    )

JSON Response Schema
--------------------

Pydantic Model Schema support
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Schemas can be provided as Pydantic Models.

.. code:: python

    from pydantic import BaseModel
    from google.genai import types


    class CountryInfo(BaseModel):
        name: str
        population: int
        capital: str
        continent: str
        gdp: int
        official_language: str
        total_area_sq_mi: int


    response = client.models.generate_content(
        model='gemini-2.0-flash-001',
        contents='Give me information for the United States.',
        config=types.GenerateContentConfig(
            response_mime_type='application/json',
            response_schema=CountryInfo,
        ),
    )
    print(response.text)

.. code:: python

    from google.genai import types

    response = client.models.generate_content(
        model='gemini-2.0-flash-001',
        contents='Give me information for the United States.',
        config=types.GenerateContentConfig(
            response_mime_type='application/json',
            response_schema={
                'required': [
                    'name',
                    'population',
                    'capital',
                    'continent',
                    'gdp',
                    'official_language',
                    'total_area_sq_mi',
                ],
                'properties': {
                    'name': {'type': 'STRING'},
                    'population': {'type': 'INTEGER'},
                    'capital': {'type': 'STRING'},
                    'continent': {'type': 'STRING'},
                    'gdp': {'type': 'INTEGER'},
                    'official_language': {'type': 'STRING'},
                    'total_area_sq_mi': {'type': 'INTEGER'},
                },
                'type': 'OBJECT',
            },
        ),
    )
    print(response.text)

Enum Response Schema
--------------------

Text Response
^^^^^^^^^^^^^^

You can set response_mime_type to 'text/x.enum' to return one of those enum 
values as the response.

.. code:: python

    from enum import Enum

    class InstrumentEnum(Enum):
        PERCUSSION = 'Percussion'
        STRING = 'String'
        WOODWIND = 'Woodwind'
        BRASS = 'Brass'
        KEYBOARD = 'Keyboard'

    response = client.models.generate_content(
        model='gemini-2.0-flash-001',
        contents='What instrument plays multiple notes at once?',
        config={
            'response_mime_type': 'text/x.enum',
            'response_schema': InstrumentEnum,
        },
    )
    print(response.text)

JSON Response
^^^^^^^^^^^^^^

You can also set response_mime_type to 'application/json', the response will be 
identical but in quotes.

.. code:: python

    class InstrumentEnum(Enum):
        PERCUSSION = 'Percussion'
        STRING = 'String'
        WOODWIND = 'Woodwind'
        BRASS = 'Brass'
        KEYBOARD = 'Keyboard'

    response = client.models.generate_content(
        model='gemini-2.0-flash-001',
        contents='What instrument plays multiple notes at once?',
        config={
            'response_mime_type': 'application/json',
            'response_schema': InstrumentEnum,
        },
    )
    print(response.text)

Generate Content (Synchronous Streaming)
---------

Generate content in a streaming format so that the model outputs streams back
to you, rather than being returned as one chunk.

Streaming for text content
^^^^^^^^^^^^^^^^^^^^^^^^^^

.. code:: python

    for chunk in client.models.generate_content_stream(
        model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'
    ):
        print(chunk.text, end='')

Streaming for image content
^^^^^^^^^^^^^^^^^^^^^^^^^^^

If your image is stored in `Google Cloud Storage <https://cloud.google.com/storage>`_, you can use the `from_uri` class method to create a `Part` object.

.. code:: python

    from google.genai import types

    for chunk in client.models.generate_content_stream(
        model='gemini-2.0-flash-001',
        contents=[
            'What is this image about?',
            types.Part.from_uri(
                file_uri='gs://generativeai-downloads/images/scones.jpg',
                mime_type='image/jpeg',
            ),
        ],
    ):
        print(chunk.text, end='')


If your image is stored in your local file system, you can read it in as bytes
data and use the ``from_bytes`` class method to create a ``Part`` object.

.. code:: python

    from google.genai import types

    YOUR_IMAGE_PATH = 'your_image_path'
    YOUR_IMAGE_MIME_TYPE = 'your_image_mime_type'
    with open(YOUR_IMAGE_PATH, 'rb') as f:
        image_bytes = f.read()

    for chunk in client.models.generate_content_stream(
        model='gemini-2.0-flash-001',
        contents=[
            'What is this image about?',
            types.Part.from_bytes(data=image_bytes, mime_type=YOUR_IMAGE_MIME_TYPE),
        ],
    ):
        print(chunk.text, end='')

Generate Content (Asynchronous Non-Streaming)
---------------------------------------------

``client.aio`` exposes all the analogous `async methods <https://docs.python.org/3/library/asyncio.html>`_ that are available on ``client``.
Note that it applies to all the modules.

For example, ``client.aio.models.generate_content`` is the ``async`` version of ``client.models.generate_content``

.. code:: python

    response = await client.aio.models.generate_content(
        model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'
    )

    print(response.text)

Generate Content (Asynchronous Streaming)
-----------------------------------------

.. code:: python

    async for chunk in await client.aio.models.generate_content_stream(
        model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'
    ):
        print(chunk.text, end='')

Count Tokens and Compute Tokens
-------------------------------

.. code:: python

    response = client.models.count_tokens(
        model='gemini-2.0-flash-001',
        contents='why is the sky blue?',
    )
    print(response)

Compute Tokens
^^^^^^^^^^^^^^

Compute tokens is only supported in Vertex AI.

.. code:: python

    response = client.models.compute_tokens(
        model='gemini-2.0-flash-001',
        contents='why is the sky blue?',
    )
    print(response)

Count Tokens (Asynchronous)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. code:: python

    response = await client.aio.models.count_tokens(
        model='gemini-2.0-flash-001',
        contents='why is the sky blue?',
    )
    print(response)

Embed Content
-------------

.. code:: python

    response = client.models.embed_content(
        model='text-embedding-004',
        contents='why is the sky blue?',
    )
    print(response)

.. code:: python

    from google.genai import types

    # multiple contents with config
    response = client.models.embed_content(
        model='text-embedding-004',
        contents=['why is the sky blue?', 'What is your age?'],
        config=types.EmbedContentConfig(output_dimensionality=10),
    )

    print(response)

Imagen
------

Generate Image
^^^^^^^^^^^^^^^

Support for generate image in Gemini Developer API is behind an allowlist

.. code:: python

    from google.genai import types

    # Generate Image
    response1 = client.models.generate_images(
        model='imagen-3.0-generate-002',
        prompt='An umbrella in the foreground, and a rainy night sky in the background',
        config=types.GenerateImagesConfig(
            number_of_images=1,
            include_rai_reason=True,
            output_mime_type='image/jpeg',
        ),
    )
    response1.generated_images[0].image.show()

Upscale Image
~~~~~~~~~~~~~

Upscale image is only supported in Vertex AI.

.. code:: python

    from google.genai import types

    # Upscale the generated image from above
    response2 = client.models.upscale_image(
        model='imagen-3.0-generate-002',
        image=response1.generated_images[0].image,
        upscale_factor='x2',
        config=types.UpscaleImageConfig(
            include_rai_reason=True,
            output_mime_type='image/jpeg',
        ),
    )
    response2.generated_images[0].image.show()

Edit Image
^^^^^^^^^^^

Edit image uses a separate model from generate and upscale.

Edit image is only supported in Vertex AI.

.. code:: python

    # Edit the generated image from above
    from google.genai import types
    from google.genai.types import RawReferenceImage, MaskReferenceImage

    raw_ref_image = RawReferenceImage(
        reference_id=1,
        reference_image=response1.generated_images[0].image,
    )

    # Model computes a mask of the background
    mask_ref_image = MaskReferenceImage(
        reference_id=2,
        config=types.MaskReferenceConfig(
            mask_mode='MASK_MODE_BACKGROUND',
            mask_dilation=0,
        ),
    )

    response3 = client.models.edit_image(
        model='imagen-3.0-capability-001',
        prompt='Sunlight and clear sky',
        reference_images=[raw_ref_image, mask_ref_image],
        config=types.EditImageConfig(
            edit_mode='EDIT_MODE_INPAINT_INSERTION',
            number_of_images=1,
            include_rai_reason=True,
            output_mime_type='image/jpeg',
        ),
    )
    response3.generated_images[0].image.show()

Veo
------

Generate Videos
^^^^^^^^^^^^^^^

Support for generate videos in Vertex and Gemini Developer API is behind an allowlist

.. code:: python

    from google.genai import types

    # Create operation
    operation = client.models.generate_videos(
        model='veo-2.0-generate-001',
        prompt='A neon hologram of a cat driving at top speed',
        config=types.GenerateVideosConfig(
            number_of_videos=1,
            fps=24,
            duration_seconds=5,
            enhance_prompt=True,
        ),
    )

    # Poll operation
    while not operation.done:
        time.sleep(20)
        operation = client.operations.get(operation)

    video = operation.result.generated_videos[0].video
    video.show()

Chats
=====

Create a chat session to start a multi-turn conversations with the model. Then,
use `chat.send_message` function multiple times within the same chat session so
that it can reflect on its previous responses (i.e., engage in an ongoing
conversation). See the 'Create a client' section above to initialize a client.

Send Message (Synchronous Non-Streaming)
------------

.. code:: python

    chat = client.chats.create(model='gemini-2.0-flash-001')
    response = chat.send_message('tell me a story')
    print(response.text)
    response = chat.send_message('summarize the story you told me in 1 sentence')
    print(response.text)

Send Message (Synchronous Streaming)
------------------------------------

.. code:: python

    chat = client.chats.create(model='gemini-2.0-flash-001')
    for chunk in chat.send_message_stream('tell me a story'):
        print(chunk.text, end='')  # end='' is optional, for demo purposes.

Send Message (Asynchronous Non-Streaming)
-----------------------------------------

.. code:: python

    chat = client.aio.chats.create(model='gemini-2.0-flash-001')
    response = await chat.send_message('tell me a story')
    print(response.text)

Send Message (Asynchronous Streaming)
-------------------------------------

.. code:: python

    chat = client.aio.chats.create(model='gemini-2.0-flash-001')
    async for chunk in await chat.send_message_stream('tell me a story'):
        print(chunk.text, end='') # end='' is optional, for demo purposes.

Files
======================

Files are only supported in Gemini Developer API.  See the 'Create a client'
section above to initialize a client.

.. code:: console

    gsutil cp gs://cloud-samples-data/generative-ai/pdf/2312.11805v3.pdf .
    gsutil cp gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf .

Upload
------

.. code:: python

    file1 = client.files.upload(file='2312.11805v3.pdf')
    file2 = client.files.upload(file='2403.05530.pdf')

    print(file1)
    print(file2)

Get
---

.. code:: python

    file1 = client.files.upload(file='2312.11805v3.pdf')
    file_info = client.files.get(name=file1.name)


Delete
------

.. code:: python

    file3 = client.files.upload(file='2312.11805v3.pdf')

    client.files.delete(name=file3.name)

Caches
======

``client.caches`` contains the control plane APIs for cached content.
 See the 'Create a client' section above to initialize a client.

Create
------

.. code:: python

    from google.genai import types

    if client.vertexai:
        file_uris = [
            'gs://cloud-samples-data/generative-ai/pdf/2312.11805v3.pdf',
            'gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf',
        ]
    else:
        file_uris = [file1.uri, file2.uri]

    cached_content = client.caches.create(
        model='gemini-2.0-flash-001',
        config=types.CreateCachedContentConfig(
            contents=[
                types.Content(
                    role='user',
                    parts=[
                        types.Part.from_uri(
                            file_uri=file_uris[0], mime_type='application/pdf'
                        ),
                        types.Part.from_uri(
                            file_uri=file_uris[1],
                            mime_type='application/pdf',
                        ),
                    ],
                )
            ],
            system_instruction='What is the sum of the two pdfs?',
            display_name='test cache',
            ttl='3600s',
        ),
    )

Get
---

.. code:: python

    cached_content = client.caches.get(name=cached_content.name)

Generate Content with Caches
-----------------------------

.. code:: python

    from google.genai import types

    response = client.models.generate_content(
        model='gemini-2.0-flash-001',
        contents='Summarize the pdfs',
        config=types.GenerateContentConfig(
            cached_content=cached_content.name,
        ),
    )
    print(response.text)

Tunings
=======

``client.tunings`` contains tuning job APIs and supports supervised fine
tuning through ``tune``. See the 'Create a client' section above to initialize a
client.

Tune
----

-   Vertex AI supports tuning from GCS source
-   Gemini Developer API supports tuning from inline examples

.. code:: python

    from google.genai import types

    if client.vertexai:
        model = 'gemini-2.0-flash-001'
        training_dataset = types.TuningDataset(
            gcs_uri='gs://cloud-samples-data/ai-platform/generative_ai/gemini-1_5/text/sft_train_data.jsonl',
        )
    else:
        model = 'models/gemini-2.0-flash-001'
        training_dataset = types.TuningDataset(
            examples=[
                types.TuningExample(
                    text_input=f'Input text {i}',
                    output=f'Output text {i}',
                )
                for i in range(5)
            ],
        )

.. code:: python

    from google.genai import types

    tuning_job = client.tunings.tune(
        base_model=model,
        training_dataset=training_dataset,
        config=types.CreateTuningJobConfig(
            epoch_count=1, tuned_model_display_name='test_dataset_examples model'
        ),
    )
    print(tuning_job)

Get Tuning Job
--------------

.. code:: python

    tuning_job = client.tunings.get(name=tuning_job.name)
    print(tuning_job)

.. code:: python

    import time

    running_states = set(
        [
            'JOB_STATE_PENDING',
            'JOB_STATE_RUNNING',
        ]
    )

    while tuning_job.state in running_states:
        print(tuning_job.state)
        tuning_job = client.tunings.get(name=tuning_job.name)
        time.sleep(10)

Use Tuned Model
---------------

.. code:: python

    response = client.models.generate_content(
        model=tuning_job.tuned_model.endpoint,
        contents='why is the sky blue?',
    )

    print(response.text)

Get Tuned Model
---------------

.. code:: python

    tuned_model = client.models.get(model=tuning_job.tuned_model.model)
    print(tuned_model)

Update Tuned Model
---------------

.. code:: python

    from google.genai import types

    tuned_model = client.models.update(
        model=tuning_job.tuned_model.model,
        config=types.UpdateModelConfig(
            display_name='my tuned model', description='my tuned model description'
        ),
    )
    print(tuned_model)

List Tuned Models
-----------------

To retrieve base models, see: :ref:`List Base Models`

.. code:: python

    for model in client.models.list(config={'page_size': 10, 'query_base': False}}):
        print(model)

.. code:: python

    pager = client.models.list(config={'page_size': 10, 'query_base': False}})
    print(pager.page_size)
    print(pager[0])
    pager.next_page()
    print(pager[0])

List Tuned Models (Asynchronous)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. code:: python

    async for job in await client.aio.models.list(config={'page_size': 10, 'query_base': False}}):
        print(job)

.. code:: python

    async_pager = await client.aio.models.list(config={'page_size': 10, 'query_base': False}})
    print(async_pager.page_size)
    print(async_pager[0])
    await async_pager.next_page()
    print(async_pager[0])

Update Tuned Model
------------------

.. code:: python

    model = pager[0]

    model = client.models.update(
        model=model.name,
        config=types.UpdateModelConfig(
            display_name='my tuned model', description='my tuned model description'
        ),
    )

    print(model)


List Tuning Jobs
----------------

.. code:: python

    for job in client.tunings.list(config={'page_size': 10}):
        print(job)

.. code:: python

    pager = client.tunings.list(config={'page_size': 10})
    print(pager.page_size)
    print(pager[0])
    pager.next_page()
    print(pager[0])

List Tuning Jobs (Asynchronous):

.. code:: python

    async for job in await client.aio.tunings.list(config={'page_size': 10}):
        print(job)

.. code:: python

    async_pager = await client.aio.tunings.list(config={'page_size': 10})
    print(async_pager.page_size)
    print(async_pager[0])
    await async_pager.next_page()
    print(async_pager[0])

Batch Prediction
================

Only supported in Vertex AI. See the 'Create a client' section above to
initialize a client.

Create
------

.. code:: python

    # Specify model and source file only, destination and job display name will be auto-populated
    job = client.batches.create(
        model='gemini-2.0-flash-001',
        src='bq://my-project.my-dataset.my-table',
    )

    job

.. code:: python

    # Get a job by name
    job = client.batches.get(name=job.name)

    job.state

.. code:: python

    completed_states = set(
        [
            'JOB_STATE_SUCCEEDED',
            'JOB_STATE_FAILED',
            'JOB_STATE_CANCELLED',
            'JOB_STATE_PAUSED',
        ]
    )

    while job.state not in completed_states:
        print(job.state)
        job = client.batches.get(name=job.name)
        time.sleep(30)

    job

List
----

.. code:: python

    from google.genai import types

    for job in client.batches.list(config=types.ListBatchJobsConfig(page_size=10)):
        print(job)

List Batch Jobs with Pager
^^^^^^^^^^^^^^^^^^^^^^^^^

.. code:: python

    from google.genai import types

    pager = client.batches.list(config=types.ListBatchJobsConfig(page_size=10))
    print(pager.page_size)
    print(pager[0])
    pager.next_page()
    print(pager[0])

List Batch Jobs (Asynchronous)
^^^^^^^^^^^^^^^^^^^^^^^^^

.. code:: python

    from google.genai import types

    async for job in await client.aio.batches.list(
        config=types.ListBatchJobsConfig(page_size=10)
    ):
        print(job)

List Batch Jobs with Pager (Asynchronous)
^^^^^^^^^^^^^^^^^^^^^^^^^

.. code:: python

    from google.genai import types

    async_pager = await client.aio.batches.list(
        config=types.ListBatchJobsConfig(page_size=10)
    )
    print(async_pager.page_size)
    print(async_pager[0])
    await async_pager.next_page()
    print(async_pager[0])

Delete
------

.. code:: python

    # Delete the job resource
    delete_job = client.batches.delete(name=job.name)

    delete_job

Error Handling
==============

To handle errors raised by the model, the SDK provides this [APIError](https://github.com/googleapis/python-genai/blob/main/google/genai/errors.py) class.

.. code:: python

    try:
        client.models.generate_content(
            model="invalid-model-name",
            contents="What is your name?",
        )
    except errors.APIError as e:
        print(e.code) # 404
        print(e.message)

Reference
=========
.. toctree::
   :maxdepth: 4

   genai

```



---

Contents Menu Expand Light mode Dark mode Auto light/dark, in light mode Auto light/dark, in dark mode
Hide navigation sidebar
Hide table of contents sidebar
Skip to content
Toggle site navigation sidebar
Google Gen AI SDK documentation
Toggle Light / Dark / Auto color theme
Toggle table of contents sidebar
Google Gen AI SDK documentation
  * Submodules
  * genai.client module
  * genai.batches module
  * genai.caches module
  * genai.chats module
  * genai.files module
  * genai.live module
  * genai.models module
  * genai.tunings module
  * genai.types module


Back to top
View this page
Toggle Light / Dark / Auto color theme
Toggle table of contents sidebar
# Submodules¶
# genai.client module¶ 

_class_ genai.client.AsyncClient(_api_client_)¶ 
    
Bases: `object`
Client for making asynchronous (non-blocking) requests. 

_property_ batches _: AsyncBatches_¶ 


_property_ caches _: AsyncCaches_¶ 


_property_ chats _: AsyncChats_¶ 


_property_ files _: AsyncFiles_¶ 


_property_ live _: AsyncLive_¶ 


_property_ models _: AsyncModels_¶ 


_property_ operations _: AsyncOperations_¶ 


_property_ tunings _: AsyncTunings_¶ 


_class_ genai.client.Client(_*_ , _vertexai =None_, _api_key =None_, _credentials =None_, _project =None_, _location =None_, _debug_config =None_, _http_options =None_)¶ 
    
Bases: `object`
Client for making synchronous requests.
Use this client to make a request to the Gemini Developer API or Vertex AI API and then wait for the response.
To initialize the client, provide the required arguments either directly or by using environment variables. Gemini API users and Vertex AI users in express mode can provide API key by providing input argument api_key=”your-api-key” or by defining GOOGLE_API_KEY=”your-api-key” as an environment variable
Vertex AI API users can provide inputs argument as vertexai=True, project=”your-project-id”, location=”us-central1” or by defining GOOGLE_GENAI_USE_VERTEXAI=true, GOOGLE_CLOUD_PROJECT and GOOGLE_CLOUD_LOCATION environment variables. 

api_key¶ 
    
The API key to use for authentication. Applies to the Gemini Developer API only. 

vertexai¶ 
    
Indicates whether the client should use the Vertex AI API endpoints. Defaults to False (uses Gemini Developer API endpoints). Applies to the Vertex AI API only. 

credentials¶ 
    
The credentials to use for authentication when calling the Vertex AI APIs. Credentials can be obtained from environment variables and default credentials. For more information, see Set up Application Default Credentials. Applies to the Vertex AI API only. 

project¶ 
    
The Google Cloud project ID to use for quota. Can be obtained from environment variables (for example, `GOOGLE_CLOUD_PROJECT`). Applies to the Vertex AI API only. Find your Google Cloud project ID. 

location¶ 
    
The location to send API requests to (for example, `us-central1`). Can be obtained from environment variables. Applies to the Vertex AI API only. 

debug_config¶ 
    
Config settings that control network behavior of the client. This is typically used when running test code. 

http_options¶ 
    
Http options to use for the client. These options will be applied to all requests made by the client. Example usage: client = genai.Client(http_options=types.HttpOptions(api_version=’v1’)).
Usage for the Gemini Developer API:
```
fromgoogleimport genai

client = genai.Client(api_key='my-api-key')

```

Usage for the Vertex AI API:
```
fromgoogleimport genai

client = genai.Client(
    vertexai=True, project='my-project-id', location='us-central1'
)

```

Initializes the client. 

Parameters: 
    
  * **vertexai** (_bool_) – Indicates whether the client should use the Vertex AI API endpoints. Defaults to False (uses Gemini Developer API endpoints). Applies to the Vertex AI API only.
  * **api_key** (_str_) – 
The API key to use for authentication. Applies to the Gemini Developer API only.
  * **credentials** (_google.auth.credentials.Credentials_) – 
The credentials to use for authentication when calling the Vertex AI APIs. Credentials can be obtained from environment variables and default credentials. For more information, see Set up Application Default Credentials. Applies to the Vertex AI API only.
  * **project** (_str_) – 
The Google Cloud project ID to use for quota. Can be obtained from environment variables (for example, `GOOGLE_CLOUD_PROJECT`). Applies to the Vertex AI API only.
  * **location** (_str_) – 
The location to send API requests to (for example, `us-central1`). Can be obtained from environment variables. Applies to the Vertex AI API only.
  * **debug_config** (_DebugConfig_) – Config settings that control network behavior of the client. This is typically used when running test code.
  * **http_options** (_Union_ _[__HttpOptions_ _,__HttpOptionsDict_ _]_) – Http options to use for the client.



_property_ aio _: AsyncClient_¶ 


_property_ batches _: Batches_¶ 


_property_ caches _: Caches_¶ 


_property_ chats _: Chats_¶ 


_property_ files _: Files_¶ 


_property_ models _: Models_¶ 


_property_ operations _: Operations_¶ 


_property_ tunings _: Tunings_¶ 


_property_ vertexai _: bool_¶ 
    
Returns whether the client is using the Vertex AI API. 

_pydantic model_genai.client.DebugConfig¶ 
    
Bases: `BaseModel`
Configuration options that change client network behavior when testing.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"DebugConfig",
"description":"Configuration options that change client network behavior when testing.",
"type":"object",
"properties":{
"client_mode":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"title":"Client Mode"
},
"replays_directory":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"title":"Replays Directory"
},
"replay_id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"title":"Replay Id"
}
}
}

```


Fields: 
    
  * `client_mode (str | None)`
  * `replay_id (str | None)`
  * `replays_directory (str | None)`



_field_ client_mode _:`Optional`[`str`]__[Optional]_¶ 


_field_ replay_id _:`Optional`[`str`]__[Optional]_¶ 


_field_ replays_directory _:`Optional`[`str`]__[Optional]_¶ 

# genai.batches module¶ 

_class_ genai.batches.AsyncBatches(_api_client__)¶ 
    
Bases: `BaseModule` 

_async_ cancel(_*_ , _name_ , _config =None_)¶ 
    
Cancels a batch job.
Only available for batch jobs that are running or pending. 

Return type: 
    
`None` 

Parameters: 
    
**name** (_str_) – 
A fully-qualified BatchJob resource name or ID. Example: “projects/…/locations/…/batchPredictionJobs/123456789” or
> ”123456789” when project and location are initialized in the client.
Usage:
```
await client.aio.batches.cancel(name='123456789')

```


_async_ create(_*_ , _model_ , _src_ , _config =None_)¶ 
    
Creates a batch job asynchronously. 

Return type: 
    
`BatchJob` 

Parameters: 
    
  * **model** (_str_) – The model to use for the batch job.
  * **src** (_str_) – The source of the batch job. Currently supports GCS URI(-s) or BigQuery URI. Example: “gs://path/to/input/data” or “bq://projectId.bqDatasetId.bqTableId”.
  * **config** (_CreateBatchJobConfig_) – Optional configuration for the batch job.



Returns: 
    
A BatchJob object that contains details about the batch job.
Usage:
```
batch_job = await client.aio.batches.create(
    model="gemini-2.0-flash-001",
    src="gs://path/to/input/data",
)

```


_async_ delete(_*_ , _name_ , _config =None_)¶ 
    
Deletes a batch job. 

Return type: 
    
`DeleteResourceJob` 

Parameters: 
    
**name** (_str_) – 
A fully-qualified BatchJob resource name or ID. Example: “projects/…/locations/…/batchPredictionJobs/456” or “456”
> when project and location are initialized in the client. 

Returns: 
    
A DeleteResourceJob object that shows the status of the deletion.
Usage:
```
await client.aio.batches.delete(name='123456789')

```


_async_ get(_*_ , _name_ , _config =None_)¶ 
    
Gets a batch job. 

Return type: 
    
`BatchJob` 

Parameters: 
    
**name** (_str_) – 
A fully-qualified BatchJob resource name or ID. Example: “projects/…/locations/…/batchPredictionJobs/456” or “456”
> when project and location are initialized in the client. 

Returns: 
    
A BatchJob object that contains details about the batch job.
Usage:
```
batch_job = await client.aio.batches.get(name='123456789')
print(f"Batch job: {batch_job.name}, state {batch_job.state}")

```


_async_ list(_*_ , _config =None_)¶ 
    
Lists batch jobs asynchronously. 

Return type: 
    
`AsyncPager`[`BatchJob`] 

Parameters: 
    
**config** (_ListBatchJobsConfig_) – Optional configuration for the list request. 

Returns: 
    
A Pager object that contains one page of batch jobs. When iterating over the pager, it automatically fetches the next page if there are more.
Usage:
```
batch_jobs = await client.aio.batches.list(config={'page_size': 5})
print(f"current page: {batch_jobs.page}")
await batch_jobs_pager.next_page()
print(f"next page: {batch_jobs_pager.page}")

```


_class_ genai.batches.Batches(_api_client__)¶ 
    
Bases: `BaseModule` 

cancel(_*_ , _name_ , _config =None_)¶ 
    
Cancels a batch job.
Only available for batch jobs that are running or pending. 

Return type: 
    
`None` 

Parameters: 
    
**name** (_str_) – 
A fully-qualified BatchJob resource name or ID. Example: “projects/…/locations/…/batchPredictionJobs/123456789” or
> ”123456789” when project and location are initialized in the client.
Usage:
```
client.batches.cancel(name='123456789')

```


create(_*_ , _model_ , _src_ , _config =None_)¶ 
    
Creates a batch job. 

Return type: 
    
`BatchJob` 

Parameters: 
    
  * **model** (_str_) – The model to use for the batch job.
  * **src** (_str_) – The source of the batch job. Currently supports GCS URI(-s) or BigQuery URI. Example: “gs://path/to/input/data” or “bq://projectId.bqDatasetId.bqTableId”.
  * **config** (_CreateBatchJobConfig_) – Optional configuration for the batch job.



Returns: 
    
A BatchJob object that contains details about the batch job.
Usage:
```
batch_job = client.batches.create(
    model="gemini-2.0-flash-001",
    src="gs://path/to/input/data",
)
print(batch_job.state)

```


delete(_*_ , _name_ , _config =None_)¶ 
    
Deletes a batch job. 

Return type: 
    
`DeleteResourceJob` 

Parameters: 
    
**name** (_str_) – 
A fully-qualified BatchJob resource name or ID. Example: “projects/…/locations/…/batchPredictionJobs/456” or “456”
> when project and location are initialized in the client. 

Returns: 
    
A DeleteResourceJob object that shows the status of the deletion.
Usage:
```
client.batches.delete(name='123456789')

```


get(_*_ , _name_ , _config =None_)¶ 
    
Gets a batch job. 

Return type: 
    
`BatchJob` 

Parameters: 
    
**name** (_str_) – 
A fully-qualified BatchJob resource name or ID. Example: “projects/…/locations/…/batchPredictionJobs/456” or “456”
> when project and location are initialized in the client. 

Returns: 
    
A BatchJob object that contains details about the batch job.
Usage:
```
batch_job = client.batches.get(name='123456789')
print(f"Batch job: {batch_job.name}, state {batch_job.state}")

```


list(_*_ , _config =None_)¶ 
    
Lists batch jobs. 

Return type: 
    
`Pager`[`BatchJob`] 

Parameters: 
    
**config** (_ListBatchJobsConfig_) – Optional configuration for the list request. 

Returns: 
    
A Pager object that contains one page of batch jobs. When iterating over the pager, it automatically fetches the next page if there are more.
Usage:
```
batch_jobs = client.batches.list(config={"page_size": 10})
for batch_job in batch_jobs:
  print(f"Batch job: {batch_job.name}, state {batch_job.state}")

```

# genai.caches module¶ 

_class_ genai.caches.AsyncCaches(_api_client__)¶ 
    
Bases: `BaseModule` 

_async_ create(_*_ , _model_ , _config =None_)¶ 
    
Creates a cached contents resource.
Usage:
```
contents = ... // Initialize the content to cache.
response = await client.aio.caches.create(
    model= ... // The publisher model id
    contents=contents,
    config={
        'display_name': 'test cache',
        'system_instruction': 'What is the sum of the two pdfs?',
        'ttl': '86400s',
    },
)

```


Return type: 
    
`CachedContent` 

_async_ delete(_*_ , _name_ , _config =None_)¶ 
    
Deletes cached content.
Usage:
```
await client.aio.caches.delete(name= ... ) // The server-generated
resource name.

```


Return type: 
    
`DeleteCachedContentResponse` 

_async_ get(_*_ , _name_ , _config =None_)¶ 
    
Gets cached content configurations.
```
await client.aio.caches.get(name= ... ) // The server-generated resource
name.

```


Return type: 
    
`CachedContent` 

_async_ list(_*_ , _config =None_)¶ 
     

Return type: 
    
`AsyncPager`[`CachedContent`] 

_async_ update(_*_ , _name_ , _config =None_)¶ 
    
Updates cached content configurations.
```
response = await client.aio.caches.update(
    name= ... // The server-generated resource name.
    config={
        'ttl': '7600s',
    },
)

```


Return type: 
    
`CachedContent` 

_class_ genai.caches.Caches(_api_client__)¶ 
    
Bases: `BaseModule` 

create(_*_ , _model_ , _config =None_)¶ 
    
Creates a cached contents resource.
Usage:
```
contents = ... // Initialize the content to cache.
response = client.caches.create(
    model= ... // The publisher model id
    contents=contents,
    config={
        'display_name': 'test cache',
        'system_instruction': 'What is the sum of the two pdfs?',
        'ttl': '86400s',
    },
)

```


Return type: 
    
`CachedContent` 

delete(_*_ , _name_ , _config =None_)¶ 
    
Deletes cached content.
Usage:
```
client.caches.delete(name= ... ) // The server-generated resource name.

```


Return type: 
    
`DeleteCachedContentResponse` 

get(_*_ , _name_ , _config =None_)¶ 
    
Gets cached content configurations.
```
client.caches.get(name= ... ) // The server-generated resource name.

```


Return type: 
    
`CachedContent` 

list(_*_ , _config =None_)¶ 
     

Return type: 
    
`Pager`[`CachedContent`] 

update(_*_ , _name_ , _config =None_)¶ 
    
Updates cached content configurations.
```
response = client.caches.update(
    name= ... // The server-generated resource name.
    config={
        'ttl': '7600s',
    },
)

```


Return type: 
    
`CachedContent`
# genai.chats module¶ 

_class_ genai.chats.AsyncChat(_*_ , _modules_ , _model_ , _config =None_, _history_)¶ 
    
Bases: `_BaseChat`
Async chat session. 

_async_ send_message(_message_ , _config =None_)¶ 
    
Sends the conversation history with the additional message and returns model’s response. 

Return type: 
    
`GenerateContentResponse` 

Parameters: 
    
  * **message** – The message to send to the model.
  * **config** – Optional config to override the default Chat config for this request.



Returns: 
    
The model’s response.
Usage:
```
chat = client.aio.chats.create(model='gemini-2.0-flash')
response = await chat.send_message('tell me a story')

```


_async_ send_message_stream(_message_ , _config =None_)¶ 
    
Sends the conversation history with the additional message and yields the model’s response in chunks. 

Return type: 
    
`AsyncIterator`[`GenerateContentResponse`] 

Parameters: 
    
  * **message** – The message to send to the model.
  * **config** – Optional config to override the default Chat config for this request.



Yields: 
    
The model’s response in chunks.
Usage: 

_class_ genai.chats.AsyncChats(_modules_)¶ 
    
Bases: `object`
A util class to create async chat sessions. 

create(_*_ , _model_ , _config =None_, _history =None_)¶ 
    
Creates a new chat session. 

Return type: 
    
`AsyncChat` 

Parameters: 
    
  * **model** – The model to use for the chat.
  * **config** – The configuration to use for the generate content request.
  * **history** – The history to use for the chat.



Returns: 
    
A new chat session. 

_class_ genai.chats.Chat(_*_ , _modules_ , _model_ , _config =None_, _history_)¶ 
    
Bases: `_BaseChat`
Chat session. 

send_message(_message_ , _config =None_)¶ 
    
Sends the conversation history with the additional message and returns the model’s response. 

Return type: 
    
`GenerateContentResponse` 

Parameters: 
    
  * **message** – The message to send to the model.
  * **config** – Optional config to override the default Chat config for this request.



Returns: 
    
The model’s response.
Usage:
```
chat = client.chats.create(model='gemini-2.0-flash')
response = chat.send_message('tell me a story')

```


send_message_stream(_message_ , _config =None_)¶ 
    
Sends the conversation history with the additional message and yields the model’s response in chunks. 

Return type: 
    
`Iterator`[`GenerateContentResponse`] 

Parameters: 
    
  * **message** – The message to send to the model.
  * **config** – Optional config to override the default Chat config for this request.



Yields: 
    
The model’s response in chunks.
Usage:
```
chat = client.chats.create(model='gemini-2.0-flash')
for chunk in chat.send_message_stream('tell me a story'):
  print(chunk.text)

```


_class_ genai.chats.Chats(_modules_)¶ 
    
Bases: `object`
A util class to create chat sessions. 

create(_*_ , _model_ , _config =None_, _history =None_)¶ 
    
Creates a new chat session. 

Return type: 
    
`Chat` 

Parameters: 
    
  * **model** – The model to use for the chat.
  * **config** – The configuration to use for the generate content request.
  * **history** – The history to use for the chat.



Returns: 
    
A new chat session.
# genai.files module¶ 

_class_ genai.files.AsyncFiles(_api_client__)¶ 
    
Bases: `BaseModule` 

_async_ delete(_*_ , _name_ , _config =None_)¶ 
    
Deletes a remotely stored file. 

Return type: 
    
`DeleteFileResponse` 

Parameters: 
    
  * **name** (_str_) – The name identifier for the file to delete.
  * **config** (_DeleteFileConfig_) – Optional, configuration for the delete method.



Returns: 
    
The response for the delete method 

Return type: 
    
DeleteFileResponse
Usage:
```
await client.aio.files.delete(name='files/...')

```


_async_ download(_*_ , _file_ , _config =None_)¶ 
    
Downloads a file’s data from the file service.
The Vertex-AI implementation of the API foes not include the file service.
Files created by upload can’t be downloaded. You can tell which files are downloadable by checking the download_uri property. 

Return type: 
    
`bytes` 

Parameters: 
    
  * **File** (_str_) – A file name, uri, or file object. Identifying which file to download.
  * **config** (_DownloadFileConfigOrDict_) – Optional, configuration for the get method.



Returns: 
    
The file data as bytes. 

Return type: 
    
File
Usage:
```
for file client.files.list():
  if file.download_uri is not None:
    break
else:
  raise ValueError('No files found with a `download_uri`.')
data = client.files.download(file=file)
# data = client.files.download(file=file.name)
# data = client.files.download(file=file.uri)

```


_async_ get(_*_ , _name_ , _config =None_)¶ 
    
Retrieves the file information from the service. 

Return type: 
    
`File` 

Parameters: 
    
  * **name** (_str_) – The name identifier for the file to retrieve.
  * **config** (_GetFileConfig_) – Optional, configuration for the get method.



Returns: 
    
The file information. 

Return type: 
    
File
Usage:
```
file = await client.aio.files.get(name='files/...')
print(file.uri)

```


_async_ list(_*_ , _config =None_)¶ 
     

Return type: 
    
`AsyncPager`[`File`] 

_async_ upload(_*_ , _file_ , _config =None_)¶ 
    
Calls the API to upload a file asynchronously using a supported file service. 

Return type: 
    
`File` 

Parameters: 
    
  * **file** – A path to the file or an IOBase object to be uploaded. If it’s an IOBase object, it must be opened in blocking (the default) mode and binary mode. In other words, do not use non-blocking mode or text mode. The given stream must be seekable, that is, it must be able to call seek() on ‘path’.
  * **config** – Optional parameters to set diplay_name, mime_type, and name.



_class_ genai.files.Files(_api_client__)¶ 
    
Bases: `BaseModule` 

delete(_*_ , _name_ , _config =None_)¶ 
    
Deletes a remotely stored file. 

Return type: 
    
`DeleteFileResponse` 

Parameters: 
    
  * **name** (_str_) – The name identifier for the file to delete.
  * **config** (_DeleteFileConfig_) – Optional, configuration for the delete method.



Returns: 
    
The response for the delete method 

Return type: 
    
DeleteFileResponse
Usage:
```
client.files.delete(name='files/...')

```


download(_*_ , _file_ , _config =None_)¶ 
    
Downloads a file’s data from storage.
Files created by upload can’t be downloaded. You can tell which files are downloadable by checking the source or download_uri property.
Note: This method returns the data as bytes. For Video and GeneratedVideo objects there is an additional side effect, that it also sets the video_bytes property on the Video object. 

Return type: 
    
`bytes` 

Parameters: 
    
  * **file** (_str_) – A file name, uri, or file object. Identifying which file to download.
  * **config** (_DownloadFileConfigOrDict_) – Optional, configuration for the get method.



Returns: 
    
The file data as bytes. 

Return type: 
    
File
Usage:
```
for file client.files.list():
  if file.download_uri is not None:
    break
else:
  raise ValueError('No files found with a `download_uri`.')
data = client.files.download(file=file)
# data = client.files.download(file=file.name)
# data = client.files.download(file=file.download_uri)

video = types.Video(uri=file.uri)
video_bytes = client.files.download(file=video)
video.video_bytes

```


get(_*_ , _name_ , _config =None_)¶ 
    
Retrieves the file information from the service. 

Return type: 
    
`File` 

Parameters: 
    
  * **name** (_str_) – The name identifier for the file to retrieve.
  * **config** (_GetFileConfig_) – Optional, configuration for the get method.



Returns: 
    
The file information. 

Return type: 
    
File
Usage:
```
file = client.files.get(name='files/...')
print(file.uri)

```


list(_*_ , _config =None_)¶ 
     

Return type: 
    
`Pager`[`File`] 

upload(_*_ , _file_ , _config =None_)¶ 
    
Calls the API to upload a file using a supported file service. 

Return type: 
    
`File` 

Parameters: 
    
  * **file** – A path to the file or an IOBase object to be uploaded. If it’s an IOBase object, it must be opened in blocking (the default) mode and binary mode. In other words, do not use non-blocking mode or text mode. The given stream must be seekable, that is, it must be able to call seek() on ‘path’.
  * **config** – Optional parameters to set diplay_name, mime_type, and name.


# genai.live module¶
[Preview] Live API client. 

_class_ genai.live.AsyncLive(_api_client__)¶ 
    
Bases: `BaseModule`
[Preview] AsyncLive. 

connect(_*_ , _model_ , _config =None_)¶ 
    
[Preview] Connect to the live server.
Note: the live API is currently in preview.
Usage:
```
client = genai.Client(api_key=API_KEY)
config = {}
async with client.aio.live.connect(model='...', config=config) as session:
  await session.send(input='Hello world!', end_of_turn=True)
  async for message in session.receive():
    print(message)

```


Return type: 
    
`AsyncIterator`[`AsyncSession`] 

_class_ genai.live.AsyncSession(_api_client_ , _websocket_)¶ 
    
Bases: `object`
[Preview] AsyncSession. 

_async_ close()¶ 
     

Return type: 
    
`None` 

_async_ receive()¶ 
    
Receive model responses from the server.
The method will yield the model responses from the server. The returned responses will represent a complete model turn. When the returned message is function call, user must call send with the function response to continue the turn. 

Return type: 
    
`AsyncIterator`[`LiveServerMessage`] 

Yields: 
    
The model responses from the server.
Example usage:
```
client = genai.Client(api_key=API_KEY)

async with client.aio.live.connect(model='...') as session:
  await session.send(input='Hello world!', end_of_turn=True)
  async for message in session.receive():
    print(message)

```


_async_ send(_*_ , _input =None_, _end_of_turn =False_)¶ 
    
[Deprecated] Send input to the model.
> **Warning** : This method is deprecated and will be removed in a future version (not before Q3 2025). Please use one of the more specific methods: send_client_content, send_realtime_input, or send_tool_response instead.
The method will send the input request to the server. 

Return type: 
    
`None` 

Parameters: 
    
  * **input** – The input request to the model.
  * **end_of_turn** – Whether the input is the last message in a turn.


Example usage:
```
client = genai.Client(api_key=API_KEY)

async with client.aio.live.connect(model='...') as session:
  await session.send(input='Hello world!', end_of_turn=True)
  async for message in session.receive():
    print(message)

```


_async_ send_client_content(_*_ , _turns =None_, _turn_complete =True_)¶ 
    
Send non-realtime, turn based content to the model.
There are two ways to send messages to the live API: send_client_content and send_realtime_input.
send_client_content messages are added to the model context **in order**. Having a conversation using send_client_content messages is roughly equivalent to using the Chat.send_message_stream method, except that the state of the chat history is stored on the API server.
Because of send_client_content’s order guarantee, the model cannot respond as quickly to send_client_content messages as to send_realtime_input messages. This makes the biggest difference when sending objects that have significant preprocessing time (typically images).
The send_client_content message sends a list of Content objects, which has more options than the media:Blob sent by send_realtime_input.
The main use-cases for send_client_content over send_realtime_input are: :rtype: `None`
  * Prefilling a conversation context (including sending anything that can’t be represented as a realtime message), before starting a realtime conversation.
  * Conducting a non-realtime conversation, similar to client.chat, using the live api.



Caution: Interleaving send_client_content and send_realtime_input 
    
in the same conversation is not recommended and can lead to unexpected results. 

Parameters: 
    
  * **turns** – A Content object or list of Content objects (or equivalent dicts).
  * **turn_complete** – if true (the default) the model will reply immediately. If false, the model will wait for you to send additional client_content, and will not return until you send turn_complete=True.


Example: ``` import google.genai from google.genai import types import os 

if os.environ.get(‘GOOGLE_GENAI_USE_VERTEXAI’):
    
MODEL_NAME = ‘gemini-2.0-flash-live-preview-04-09’ 

else:
    
MODEL_NAME = ‘gemini-2.0-flash-live-001’;
client = genai.Client() async with client.aio.live.connect(
> model=MODEL_NAME, config={“response_modalities”: [“TEXT”]} 

) as session:
     

await session.send_client_content(
     

turns=types.Content(
    
role=’user’, parts=[types.Part(text=”Hello world!”)])) 

async for msg in session.receive():
     

if msg.text:
    
print(msg.text)
``` 

_async_ send_realtime_input(_*_ , _media =None_, _audio =None_, _audio_stream_end =None_, _video =None_, _text =None_, _activity_start =None_, _activity_end =None_)¶ 
    
Send realtime input to the model, only send one argument per call.
Use send_realtime_input for realtime audio chunks and video frames(images).
With send_realtime_input the api will respond to audio automatically based on voice activity detection (VAD).
send_realtime_input is optimized for responsivness at the expense of deterministic ordering. Audio and video tokens are added to the context when they become available. 

Return type: 
    
`None` 

Parameters: 
    
**media** – A Blob-like object, the realtime media to send.
Example: ``` from pathlib import Path
from google import genai from google.genai import types
import PIL.Image
import os 

if os.environ.get(‘GOOGLE_GENAI_USE_VERTEXAI’):
    
MODEL_NAME = ‘gemini-2.0-flash-live-preview-04-09’ 

else:
    
MODEL_NAME = ‘gemini-2.0-flash-live-001’;
client = genai.Client() 

async with client.aio.live.connect(
    
model=MODEL_NAME, config={“response_modalities”: [“TEXT”]}, 

) as session:
     

await session.send_realtime_input(
    
media=PIL.Image.open(‘image.jpg’))
audio_bytes = Path(‘audio.pcm’).read_bytes() await session.send_realtime_input(
> media=types.Blob(data=audio_bytes, mime_type=’audio/pcm;rate=16000’)) 

async for msg in session.receive():
     

if msg.text is not None:
    
print(f’{msg.text}’)
``` 

_async_ send_tool_response(_*_ , _function_responses_)¶ 
    
Send a tool response to the session.
Use send_tool_response to reply to LiveServerToolCall messages from the server.
To set the available tools, use the config.tools argument when you connect to the session (client.live.connect). 

Return type: 
    
`None` 

Parameters: 
    
**function_responses** – A FunctionResponse-like object or list of FunctionResponse-like objects.
Example: ``` from google import genai from google.genai import types
import os 

if os.environ.get(‘GOOGLE_GENAI_USE_VERTEXAI’):
    
MODEL_NAME = ‘gemini-2.0-flash-live-preview-04-09’ 

else:
    
MODEL_NAME = ‘gemini-2.0-flash-live-001’;
client = genai.Client()
tools = [{‘function_declarations’: [{‘name’: ‘turn_on_the_lights’}]}] config = {
> “tools”: tools, “response_modalities”: [‘TEXT’]
} 

async with client.aio.live.connect(
    
model=’models/gemini-2.0-flash-live-001’, config=config 

) as session:
    
prompt = “Turn on the lights please” await session.send_client_content(
> turns={“parts”: [{‘text’: prompt}]}
) 

async for chunk in session.receive():
     

if chunk.server_content:
     

if chunk.text is not None:
    
print(chunk.text) 

elif chunk.tool_call:
    
print(chunk.tool_call) print(‘_’*80) function_response=types.FunctionResponse(
> > name=’turn_on_the_lights’, response={‘result’: ‘ok’}, id=chunk.tool_call.function_calls[0].id,
> )
print(function_response) await session.send_tool_response(
> function_responses=function_response
)
print(‘_’*80) 

_async_ start_stream(_*_ , _stream_ , _mime_type_)¶ 
    
[Deprecated] Start a live session from a data stream.
> **Warning** : This method is deprecated and will be removed in a future version (not before Q2 2025). Please use one of the more specific methods: send_client_content, send_realtime_input, or send_tool_response instead.
The interaction terminates when the input stream is complete. This method will start two async tasks. One task will be used to send the input stream to the model and the other task will be used to receive the responses from the model. 

Return type: 
    
`AsyncIterator`[`LiveServerMessage`] 

Parameters: 
    
  * **stream** – An iterator that yields the model response.
  * **mime_type** – The MIME type of the data in the stream.



Yields: 
    
The audio bytes received from the model and server response messages.
Example usage:
```
client = genai.Client(api_key=API_KEY)
config = {'response_modalities': ['AUDIO']}
async defaudio_stream():
  stream = read_audio()
  for data in stream:
    yield data
async with client.aio.live.connect(model='...', config=config) as session:
  for audio in session.start_stream(stream = audio_stream(),
  mime_type = 'audio/pcm'):
    play_audio_chunk(audio.data)

```

# genai.models module¶ 

_class_ genai.models.AsyncModels(_api_client__)¶ 
    
Bases: `BaseModule` 

_async_ compute_tokens(_*_ , _model_ , _contents_ , _config =None_)¶ 
    
Given a list of contents, returns a corresponding TokensInfo containing the
list of tokens and list of token ids. 

Return type: 
    
`ComputeTokensResponse` 

Parameters: 
    
  * **model** (_str_) – The model to use.
  * **contents** (_list_ _[__shared.Content_ _]_) – The content to compute tokens for.


Usage:
```
response = await client.aio.models.compute_tokens(
    model='gemini-2.0-flash',
    contents='What is your name?',
)
print(response)
# tokens_info=[TokensInfo(role='user', token_ids=['1841', ...],
# tokens=[b'What', b' is', b' your', b' name', b'?'])]

```


_async_ count_tokens(_*_ , _model_ , _contents_ , _config =None_)¶ 
    
Counts the number of tokens in the given content.
Multimodal input is supported for Gemini models. 

Return type: 
    
`CountTokensResponse` 

Parameters: 
    
  * **model** (_str_) – The model to use for counting tokens.
  * **contents** (_list_ _[__types.Content_ _]_) – The content to count tokens for.
  * **config** (_CountTokensConfig_) – The configuration for counting tokens.


Usage:
```
response = await client.aio.models.count_tokens(
    model='gemini-2.0-flash',
    contents='What is your name?',
)
print(response)
# total_tokens=5 cached_content_token_count=None

```


_async_ delete(_*_ , _model_ , _config =None_)¶ 
     

Return type: 
    
`DeleteModelResponse` 

_async_ edit_image(_*_ , _model_ , _prompt_ , _reference_images_ , _config =None_)¶ 
    
Edits an image based on a text description and configuration. 

Return type: 
    
`EditImageResponse` 

Parameters: 
    
  * **model** (_str_) – The model to use.
  * **prompt** (_str_) – A text description of the edit to apply to the image. reference_images (list[Union[RawReferenceImage, MaskReferenceImage, ControlReferenceImage, StyleReferenceImage, SubjectReferenceImage]): The reference images for editing.
  * **config** (_EditImageConfig_) – Configuration for editing.


Usage:
```
fromgoogle.genai.typesimport RawReferenceImage, MaskReferenceImage

raw_ref_image = RawReferenceImage(
  reference_id=1,
  reference_image=types.Image.from_file(IMAGE_FILE_PATH),
)

mask_ref_image = MaskReferenceImage(
  reference_id=2,
  config=types.MaskReferenceConfig(
      mask_mode='MASK_MODE_FOREGROUND',
      mask_dilation=0.06,
  ),
)
response = await client.aio.models.edit_image(
  model='imagen-3.0-capability-001',
  prompt='man with dog',
  reference_images=[raw_ref_image, mask_ref_image],
  config=types.EditImageConfig(
      edit_mode= "EDIT_MODE_INPAINT_INSERTION",
      number_of_images= 1,
      include_rai_reason= True,
  )
)
response.generated_images[0].image.show()
# Shows a man with a dog instead of a cat.

```


_async_ embed_content(_*_ , _model_ , _contents_ , _config =None_)¶ 
    
Calculates embeddings for the given contents. Only text is supported. 

Return type: 
    
`EmbedContentResponse` 

Parameters: 
    
  * **model** (_str_) – The model to use.
  * **contents** (_list_ _[__Content_ _]_) – The contents to embed.
  * **config** (_EmbedContentConfig_) – Optional configuration for embeddings.


Usage:
```
embeddings = await client.aio.models.embed_content(
    model= 'text-embedding-004',
    contents=[
        'What is your name?',
        'What is your favorite color?',
    ],
    config={
        'output_dimensionality': 64
    },
)

```


_async_ generate_content(_*_ , _model_ , _contents_ , _config =None_)¶ 
    
Makes an API request to generate content using a model.
Some models support multimodal input and output.
Usage:
```
fromgoogle.genaiimport types
fromgoogleimport genai

client = genai.Client(
    vertexai=True, project='my-project-id', location='us-central1'
)

response = await client.aio.models.generate_content(
    model='gemini-2.0-flash',
    contents='User input: I like bagels. Answer:',
    config=types.GenerateContentConfig(
        system_instruction=
          [
            'You are a helpful language translator.',
            'Your mission is to translate text in English to French.'
          ]
    ),
)
print(response.text)
# J'aime les bagels.

```


Return type: 
    
`GenerateContentResponse` 

_async_ generate_content_stream(_*_ , _model_ , _contents_ , _config =None_)¶ 
    
Makes an API request to generate content using a model and yields the model’s response in chunks.
For the model parameter, supported formats for Vertex AI API include: :rtype: `AsyncIterator`[`GenerateContentResponse`]
  * The Gemini model ID, for example: ‘gemini-2.0-flash’
  * The full resource name starts with ‘projects/’, for example: ‘projects/my-project-id/locations/us-central1/publishers/google/models/gemini-2.0-flash’
  * The partial resource name with ‘publishers/’, for example: ‘publishers/google/models/gemini-2.0-flash’ or ‘publishers/meta/models/llama-3.1-405b-instruct-maas’
  * / separated publisher and model name, for example: ‘google/gemini-2.0-flash’ or ‘meta/llama-3.1-405b-instruct-maas’


For the model parameter, supported formats for Gemini API include: - The Gemini model ID, for example: ‘gemini-2.0-flash’ - The model name starts with ‘models/’, for example:
> ‘models/gemini-2.0-flash’
  * For tuned models, the model name starts with ‘tunedModels/’, for example: ‘tunedModels/1234567890123456789’


Some models support multimodal input and output.
Usage:
```
fromgoogle.genaiimport types
fromgoogleimport genai

client = genai.Client(
    vertexai=True, project='my-project-id', location='us-central1'
)

async for chunk in await client.aio.models.generate_content_stream(
  model='gemini-2.0-flash',
  contents='''What is a good name for a flower shop that specializes in
    selling bouquets of dried flowers?'''
):
  print(chunk.text)
# **Elegant & Classic:**
# * The Dried Bloom
# * Everlasting Florals
# * Timeless Petals

async for chunk in awiat client.aio.models.generate_content_stream(
  model='gemini-2.0-flash',
  contents=[
    types.Part.from_text('What is shown in this image?'),
    types.Part.from_uri('gs://generativeai-downloads/images/scones.jpg',
    'image/jpeg')
  ]
):
  print(chunk.text)
# The image shows a flat lay arrangement of freshly baked blueberry
# scones.

```


_async_ generate_images(_*_ , _model_ , _prompt_ , _config =None_)¶ 
    
Generates images based on a text description and configuration. 

Return type: 
    
`GenerateImagesResponse` 

Parameters: 
    
  * **model** (_str_) – The model to use.
  * **prompt** (_str_) – A text description of the images to generate.
  * **config** (_GenerateImagesConfig_) – Configuration for generation.


Usage:
```
response = await client.aio.models.generate_images(
  model='imagen-3.0-generate-002',
  prompt='Man with a dog',
  config=types.GenerateImagesConfig(
      number_of_images= 1,
      include_rai_reason= True,
  )
)
response.generated_images[0].image.show()
# Shows a man with a dog.

```


_async_ generate_videos(_*_ , _model_ , _prompt =None_, _image =None_, _config =None_)¶ 
    
Generates videos based on a text description and configuration. 

Return type: 
    
`GenerateVideosOperation` 

Parameters: 
    
  * **model** – The model to use.
  * **instances** – A list of prompts, images and videos to generate videos from.
  * **config** – Configuration for generation.


Usage:
> ``` operation = client.models.generate_videos(
>> model=”veo-2.0-generate-001”, prompt=”A neon hologram of a cat driving at top speed”,
> ) while not operation.done:
>> time.sleep(10) operation = client.operations.get(operation)
> operation.result.generated_videos[0].video.uri ``` 

_async_ get(_*_ , _model_ , _config =None_)¶ 
     

Return type: 
    
`Model` 

_async_ list(_*_ , _config =None_)¶ 
    
Makes an API request to list the available models.
If query_base is set to True in the config or not set (default), the API will return all available base models. If set to False, it will return all tuned models. 

Return type: 
    
`AsyncPager`[`Model`] 

Parameters: 
    
**config** (_ListModelsConfigOrDict_) – Configuration for retrieving models.
Usage:
```
response = await client.aio.models.list(config={'page_size': 5})
print(response.page)
# [Model(name='projects/./locations/./models/123', display_name='my_model'

response = await client.aio.models.list(
    config={'page_size': 5, 'query_base': True}
  )
print(response.page)
# [Model(name='publishers/google/models/gemini-2.0-flash-exp' ...

```


_async_ update(_*_ , _model_ , _config =None_)¶ 
     

Return type: 
    
`Model` 

_async_ upscale_image(_*_ , _model_ , _image_ , _upscale_factor_ , _config =None_)¶ 
    
Makes an API request to upscale a provided image. 

Return type: 
    
`UpscaleImageResponse` 

Parameters: 
    
  * **model** (_str_) – The model to use.
  * **image** (_Image_) – The input image for upscaling.
  * **upscale_factor** (_str_) – The factor to upscale the image (x2 or x4).
  * **config** (_UpscaleImageConfig_) – Configuration for upscaling.


Usage:
```
fromgoogle.genai.typesimport Image

IMAGE_FILE_PATH="my-image.png"
response = await client.aio.models.upscale_image(
    model='imagen-3.0-generate-001',
    image=types.Image.from_file(IMAGE_FILE_PATH),
    upscale_factor='x2',
)
response.generated_images[0].image.show()
# Opens my-image.png which is upscaled by a factor of 2.

```


_class_ genai.models.Models(_api_client__)¶ 
    
Bases: `BaseModule` 

compute_tokens(_*_ , _model_ , _contents_ , _config =None_)¶ 
    
Given a list of contents, returns a corresponding TokensInfo containing the
list of tokens and list of token ids.
This method is not supported by the Gemini Developer API. 

Return type: 
    
`ComputeTokensResponse` 

Parameters: 
    
  * **model** (_str_) – The model to use.
  * **contents** (_list_ _[__shared.Content_ _]_) – The content to compute tokens for.


Usage:
```
response = client.models.compute_tokens(
    model='gemini-2.0-flash',
    contents='What is your name?',
)
print(response)
# tokens_info=[TokensInfo(role='user', token_ids=['1841', ...],
# tokens=[b'What', b' is', b' your', b' name', b'?'])]

```


count_tokens(_*_ , _model_ , _contents_ , _config =None_)¶ 
    
Counts the number of tokens in the given content.
Multimodal input is supported for Gemini models. 

Return type: 
    
`CountTokensResponse` 

Parameters: 
    
  * **model** (_str_) – The model to use for counting tokens.
  * **contents** (_list_ _[__types.Content_ _]_) – The content to count tokens for.
  * **config** (_CountTokensConfig_) – The configuration for counting tokens.


Usage:
```
response = client.models.count_tokens(
    model='gemini-2.0-flash',
    contents='What is your name?',
)
print(response)
# total_tokens=5 cached_content_token_count=None

```


delete(_*_ , _model_ , _config =None_)¶ 
     

Return type: 
    
`DeleteModelResponse` 

edit_image(_*_ , _model_ , _prompt_ , _reference_images_ , _config =None_)¶ 
    
Edits an image based on a text description and configuration. 

Return type: 
    
`EditImageResponse` 

Parameters: 
    
  * **model** (_str_) – The model to use.
  * **prompt** (_str_) – A text description of the edit to apply to the image. reference_images (list[Union[RawReferenceImage, MaskReferenceImage, ControlReferenceImage, StyleReferenceImage, SubjectReferenceImage]): The reference images for editing.
  * **config** (_EditImageConfig_) – Configuration for editing.


Usage:
```
fromgoogle.genai.typesimport RawReferenceImage, MaskReferenceImage

raw_ref_image = RawReferenceImage(
  reference_id=1,
  reference_image=types.Image.from_file(IMAGE_FILE_PATH),
)

mask_ref_image = MaskReferenceImage(
  reference_id=2,
  config=types.MaskReferenceConfig(
      mask_mode='MASK_MODE_FOREGROUND',
      mask_dilation=0.06,
  ),
)
response = client.models.edit_image(
  model='imagen-3.0-capability-001',
  prompt='man with dog',
  reference_images=[raw_ref_image, mask_ref_image],
  config=types.EditImageConfig(
      edit_mode= "EDIT_MODE_INPAINT_INSERTION",
      number_of_images= 1,
      include_rai_reason= True,
  )
)
response.generated_images[0].image.show()
# Shows a man with a dog instead of a cat.

```


embed_content(_*_ , _model_ , _contents_ , _config =None_)¶ 
    
Calculates embeddings for the given contents. Only text is supported. 

Return type: 
    
`EmbedContentResponse` 

Parameters: 
    
  * **model** (_str_) – The model to use.
  * **contents** (_list_ _[__Content_ _]_) – The contents to embed.
  * **config** (_EmbedContentConfig_) – Optional configuration for embeddings.


Usage:
```
embeddings = client.models.embed_content(
    model= 'text-embedding-004',
    contents=[
        'What is your name?',
        'What is your favorite color?',
    ],
    config={
        'output_dimensionality': 64
    },
)

```


generate_content(_*_ , _model_ , _contents_ , _config =None_)¶ 
    
Makes an API request to generate content using a model.
For the model parameter, supported formats for Vertex AI API include: :rtype: `GenerateContentResponse`
  * The Gemini model ID, for example: ‘gemini-2.0-flash’
  * The full resource name starts with ‘projects/’, for example: ‘projects/my-project-id/locations/us-central1/publishers/google/models/gemini-2.0-flash’
  * The partial resource name with ‘publishers/’, for example: ‘publishers/google/models/gemini-2.0-flash’ or ‘publishers/meta/models/llama-3.1-405b-instruct-maas’
  * / separated publisher and model name, for example: ‘google/gemini-2.0-flash’ or ‘meta/llama-3.1-405b-instruct-maas’


For the model parameter, supported formats for Gemini API include: - The Gemini model ID, for example: ‘gemini-2.0-flash’ - The model name starts with ‘models/’, for example:
> ‘models/gemini-2.0-flash’
  * For tuned models, the model name starts with ‘tunedModels/’, for example: ‘tunedModels/1234567890123456789’


Some models support multimodal input and output.
Usage:
```
fromgoogle.genaiimport types
fromgoogleimport genai

client = genai.Client(
    vertexai=True, project='my-project-id', location='us-central1'
)

response = client.models.generate_content(
  model='gemini-2.0-flash',
  contents='''What is a good name for a flower shop that specializes in
    selling bouquets of dried flowers?'''
)
print(response.text)
# **Elegant & Classic:**
# * The Dried Bloom
# * Everlasting Florals
# * Timeless Petals

response = client.models.generate_content(
  model='gemini-2.0-flash',
  contents=[
    types.Part.from_text('What is shown in this image?'),
    types.Part.from_uri('gs://generativeai-downloads/images/scones.jpg',
    'image/jpeg')
  ]
)
print(response.text)
# The image shows a flat lay arrangement of freshly baked blueberry
# scones.

```


generate_content_stream(_*_ , _model_ , _contents_ , _config =None_)¶ 
    
Makes an API request to generate content using a model and yields the model’s response in chunks.
For the model parameter, supported formats for Vertex AI API include: :rtype: `Iterator`[`GenerateContentResponse`]
  * The Gemini model ID, for example: ‘gemini-2.0-flash’
  * The full resource name starts with ‘projects/’, for example: ‘projects/my-project-id/locations/us-central1/publishers/google/models/gemini-2.0-flash’
  * The partial resource name with ‘publishers/’, for example: ‘publishers/google/models/gemini-2.0-flash’ or ‘publishers/meta/models/llama-3.1-405b-instruct-maas’
  * / separated publisher and model name, for example: ‘google/gemini-2.0-flash’ or ‘meta/llama-3.1-405b-instruct-maas’


For the model parameter, supported formats for Gemini API include: - The Gemini model ID, for example: ‘gemini-2.0-flash’ - The model name starts with ‘models/’, for example:
> ‘models/gemini-2.0-flash’
  * For tuned models, the model name starts with ‘tunedModels/’, for example: ‘tunedModels/1234567890123456789’


Some models support multimodal input and output.
Usage:
```
fromgoogle.genaiimport types
fromgoogleimport genai

client = genai.Client(
    vertexai=True, project='my-project-id', location='us-central1'
)

for chunk in client.models.generate_content_stream(
  model='gemini-2.0-flash',
  contents='''What is a good name for a flower shop that specializes in
    selling bouquets of dried flowers?'''
):
  print(chunk.text)
# **Elegant & Classic:**
# * The Dried Bloom
# * Everlasting Florals
# * Timeless Petals

for chunk in client.models.generate_content_stream(
  model='gemini-2.0-flash',
  contents=[
    types.Part.from_text('What is shown in this image?'),
    types.Part.from_uri('gs://generativeai-downloads/images/scones.jpg',
    'image/jpeg')
  ]
):
  print(chunk.text)
# The image shows a flat lay arrangement of freshly baked blueberry
# scones.

```


generate_images(_*_ , _model_ , _prompt_ , _config =None_)¶ 
    
Generates images based on a text description and configuration. 

Return type: 
    
`GenerateImagesResponse` 

Parameters: 
    
  * **model** (_str_) – The model to use.
  * **prompt** (_str_) – A text description of the images to generate.
  * **config** (_GenerateImagesConfig_) – Configuration for generation.


Usage:
```
response = client.models.generate_images(
  model='imagen-3.0-generate-002',
  prompt='Man with a dog',
  config=types.GenerateImagesConfig(
      number_of_images= 1,
      include_rai_reason= True,
  )
)
response.generated_images[0].image.show()
# Shows a man with a dog.

```


generate_videos(_*_ , _model_ , _prompt =None_, _image =None_, _config =None_)¶ 
    
Generates videos based on a text description and configuration. 

Return type: 
    
`GenerateVideosOperation` 

Parameters: 
    
  * **model** – The model to use.
  * **instances** – A list of prompts, images and videos to generate videos from.
  * **config** – Configuration for generation.


Usage:
> ``` operation = client.models.generate_videos(
>> model=”veo-2.0-generate-001”, prompt=”A neon hologram of a cat driving at top speed”,
> ) while not operation.done:
>> time.sleep(10) operation = client.operations.get(operation)
> operation.result.generated_videos[0].video.uri ``` 

get(_*_ , _model_ , _config =None_)¶ 
     

Return type: 
    
`Model` 

list(_*_ , _config =None_)¶ 
    
Makes an API request to list the available models.
If query_base is set to True in the config or not set (default), the API will return all available base models. If set to False, it will return all tuned models. 

Return type: 
    
`Pager`[`Model`] 

Parameters: 
    
**config** (_ListModelsConfigOrDict_) – Configuration for retrieving models.
Usage:
```
response=client.models.list(config={'page_size': 5})
print(response.page)
# [Model(name='projects/./locations/./models/123', display_name='my_model'

response=client.models.list(config={'page_size': 5, 'query_base': True})
print(response.page)
# [Model(name='publishers/google/models/gemini-2.0-flash-exp' ...

```


update(_*_ , _model_ , _config =None_)¶ 
     

Return type: 
    
`Model` 

upscale_image(_*_ , _model_ , _image_ , _upscale_factor_ , _config =None_)¶ 
    
Makes an API request to upscale a provided image. 

Return type: 
    
`UpscaleImageResponse` 

Parameters: 
    
  * **model** (_str_) – The model to use.
  * **image** (_Image_) – The input image for upscaling.
  * **upscale_factor** (_str_) – The factor to upscale the image (x2 or x4).
  * **config** (_UpscaleImageConfig_) – Configuration for upscaling.


Usage:
```
fromgoogle.genai.typesimport Image

IMAGE_FILE_PATH="my-image.png"
response=client.models.upscale_image(
    model='imagen-3.0-generate-001',
    image=types.Image.from_file(IMAGE_FILE_PATH),
    upscale_factor='x2',
)
response.generated_images[0].image.show()
# Opens my-image.png which is upscaled by a factor of 2.

```

# genai.tunings module¶ 

_class_ genai.tunings.AsyncTunings(_api_client__)¶ 
    
Bases: `BaseModule` 

_async_ get(_*_ , _name_ , _config =None_)¶ 
     

Return type: 
    
`TuningJob` 

_async_ list(_*_ , _config =None_)¶ 
     

Return type: 
    
`AsyncPager`[`TuningJob`] 

tune(_*_ , _base_model_ , _training_dataset_ , _config =None_)¶ 
     

Return type: 
    
`TuningJob` 

_class_ genai.tunings.Tunings(_api_client__)¶ 
    
Bases: `BaseModule` 

get(_*_ , _name_ , _config =None_)¶ 
     

Return type: 
    
`TuningJob` 

list(_*_ , _config =None_)¶ 
     

Return type: 
    
`Pager`[`TuningJob`] 

tune(_*_ , _base_model_ , _training_dataset_ , _config =None_)¶ 
     

Return type: 
    
`TuningJob`
# genai.types module¶ 

_pydantic model_genai.types.ActivityEnd¶ 
    
Bases: `BaseModel`
Marks the end of user activity.
This can only be sent if automatic (i.e. server-side) activity detection is disabled.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ActivityEnd",
"description":"Marks the end of user activity.\n\nThis can only be sent if automatic (i.e. server-side) activity detection is\ndisabled.",
"type":"object",
"properties":{},
"additionalProperties":false
}

```


_class_ genai.types.ActivityEndDict¶ 
    
Bases: `TypedDict`
Marks the end of user activity.
This can only be sent if automatic (i.e. server-side) activity detection is disabled. 

_class_ genai.types.ActivityHandling(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
The different ways of handling user activity. 

ACTIVITY_HANDLING_UNSPECIFIED _= 'ACTIVITY_HANDLING_UNSPECIFIED'_¶ 


NO_INTERRUPTION _= 'NO_INTERRUPTION'_¶ 


START_OF_ACTIVITY_INTERRUPTS _= 'START_OF_ACTIVITY_INTERRUPTS'_¶ 


_pydantic model_genai.types.ActivityStart¶ 
    
Bases: `BaseModel`
Marks the start of user activity.
This can only be sent if automatic (i.e. server-side) activity detection is disabled.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ActivityStart",
"description":"Marks the start of user activity.\n\nThis can only be sent if automatic (i.e. server-side) activity detection is\ndisabled.",
"type":"object",
"properties":{},
"additionalProperties":false
}

```


_class_ genai.types.ActivityStartDict¶ 
    
Bases: `TypedDict`
Marks the start of user activity.
This can only be sent if automatic (i.e. server-side) activity detection is disabled. 

_class_ genai.types.AdapterSize(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Optional. Adapter size for tuning. 

ADAPTER_SIZE_EIGHT _= 'ADAPTER_SIZE_EIGHT'_¶ 


ADAPTER_SIZE_FOUR _= 'ADAPTER_SIZE_FOUR'_¶ 


ADAPTER_SIZE_ONE _= 'ADAPTER_SIZE_ONE'_¶ 


ADAPTER_SIZE_SIXTEEN _= 'ADAPTER_SIZE_SIXTEEN'_¶ 


ADAPTER_SIZE_THIRTY_TWO _= 'ADAPTER_SIZE_THIRTY_TWO'_¶ 


ADAPTER_SIZE_TWO _= 'ADAPTER_SIZE_TWO'_¶ 


ADAPTER_SIZE_UNSPECIFIED _= 'ADAPTER_SIZE_UNSPECIFIED'_¶ 


_pydantic model_genai.types.ApiKeyConfig¶ 
    
Bases: `BaseModel`
Config for authentication with API key.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ApiKeyConfig",
"description":"Config for authentication with API key.",
"type":"object",
"properties":{
"apiKeyString":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The API key to be used in the request directly.",
"title":"Apikeystring"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `api_key_string (str | None)`



_field_ api_key_string _:`Optional`[`str`]__= None_ _(alias 'apiKeyString')_¶ 
    
The API key to be used in the request directly. 

_class_ genai.types.ApiKeyConfigDict¶ 
    
Bases: `TypedDict`
Config for authentication with API key. 

api_key_string _:`Optional`[`str`]_¶ 
    
The API key to be used in the request directly. 

_pydantic model_genai.types.AudioTranscriptionConfig¶ 
    
Bases: `BaseModel`
The audio transcription configuration in Setup.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"AudioTranscriptionConfig",
"description":"The audio transcription configuration in Setup.",
"type":"object",
"properties":{},
"additionalProperties":false
}

```


_class_ genai.types.AudioTranscriptionConfigDict¶ 
    
Bases: `TypedDict`
The audio transcription configuration in Setup. 

_pydantic model_genai.types.AuthConfig¶ 
    
Bases: `BaseModel`
Auth configuration to run the extension.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"AuthConfig",
"description":"Auth configuration to run the extension.",
"type":"object",
"properties":{
"apiKeyConfig":{
"anyOf":[
{
"$ref":"#/$defs/ApiKeyConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for API key auth."
},
"authType":{
"anyOf":[
{
"$ref":"#/$defs/AuthType"
},
{
"type":"null"
}
],
"default":null,
"description":"Type of auth scheme."
},
"googleServiceAccountConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigGoogleServiceAccountConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for Google Service Account auth."
},
"httpBasicAuthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigHttpBasicAuthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for HTTP Basic auth."
},
"oauthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOauthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user oauth."
},
"oidcConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOidcConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user OIDC auth."
}
},
"$defs":{
"ApiKeyConfig":{
"additionalProperties":false,
"description":"Config for authentication with API key.",
"properties":{
"apiKeyString":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The API key to be used in the request directly.",
"title":"Apikeystring"
}
},
"title":"ApiKeyConfig",
"type":"object"
},
"AuthConfigGoogleServiceAccountConfig":{
"additionalProperties":false,
"description":"Config for Google Service Account Authentication.",
"properties":{
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The service account that the extension execution service runs as. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified service account. - If not specified, the Vertex AI Extension Service Agent will be used to execute the Extension.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigGoogleServiceAccountConfig",
"type":"object"
},
"AuthConfigHttpBasicAuthConfig":{
"additionalProperties":false,
"description":"Config for HTTP Basic Authentication.",
"properties":{
"credentialSecret":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the SecretManager secret version resource storing the base64 encoded credentials. Format: `projects/{project}/secrets/{secrete}/versions/{version}` - If specified, the `secretmanager.versions.access` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified resource.",
"title":"Credentialsecret"
}
},
"title":"AuthConfigHttpBasicAuthConfig",
"type":"object"
},
"AuthConfigOauthConfig":{
"additionalProperties":false,
"description":"Config for user oauth.",
"properties":{
"accessToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Access token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Accesstoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate access tokens for executing the Extension. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the provided service account.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOauthConfig",
"type":"object"
},
"AuthConfigOidcConfig":{
"additionalProperties":false,
"description":"Config for user OIDC auth.",
"properties":{
"idToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"OpenID Connect formatted ID token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Idtoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate an OpenID Connect (OIDC)-compatible JWT token signed by the Google OIDC Provider (accounts.google.com) for extension endpoint (https://cloud.google.com/iam/docs/create-short-lived-credentials-direct#sa-credentials-oidc). - The audience for the token will be set to the URL in the server url defined in the OpenApi spec. - If the service account is provided, the service account should grant `iam.serviceAccounts.getOpenIdToken` permission to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOidcConfig",
"type":"object"
},
"AuthType":{
"description":"Type of auth scheme.",
"enum":[
"AUTH_TYPE_UNSPECIFIED",
"NO_AUTH",
"API_KEY_AUTH",
"HTTP_BASIC_AUTH",
"GOOGLE_SERVICE_ACCOUNT_AUTH",
"OAUTH",
"OIDC_AUTH"
],
"title":"AuthType",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `api_key_config (genai.types.ApiKeyConfig | None)`
  * `auth_type (genai.types.AuthType | None)`
  * `google_service_account_config (genai.types.AuthConfigGoogleServiceAccountConfig | None)`
  * `http_basic_auth_config (genai.types.AuthConfigHttpBasicAuthConfig | None)`
  * `oauth_config (genai.types.AuthConfigOauthConfig | None)`
  * `oidc_config (genai.types.AuthConfigOidcConfig | None)`



_field_ api_key_config _:`Optional`[`ApiKeyConfig`]__= None_ _(alias 'apiKeyConfig')_¶ 
    
Config for API key auth. 

_field_ auth_type _:`Optional`[`AuthType`]__= None_ _(alias 'authType')_¶ 
    
Type of auth scheme. 

_field_ google_service_account_config _:`Optional`[`AuthConfigGoogleServiceAccountConfig`]__= None_ _(alias 'googleServiceAccountConfig')_¶ 
    
Config for Google Service Account auth. 

_field_ http_basic_auth_config _:`Optional`[`AuthConfigHttpBasicAuthConfig`]__= None_ _(alias 'httpBasicAuthConfig')_¶ 
    
Config for HTTP Basic auth. 

_field_ oauth_config _:`Optional`[`AuthConfigOauthConfig`]__= None_ _(alias 'oauthConfig')_¶ 
    
Config for user oauth. 

_field_ oidc_config _:`Optional`[`AuthConfigOidcConfig`]__= None_ _(alias 'oidcConfig')_¶ 
    
Config for user OIDC auth. 

_class_ genai.types.AuthConfigDict¶ 
    
Bases: `TypedDict`
Auth configuration to run the extension. 

api_key_config _:`Optional`[`ApiKeyConfigDict`]_¶ 
    
Config for API key auth. 

auth_type _:`Optional`[`AuthType`]_¶ 
    
Type of auth scheme. 

google_service_account_config _:`Optional`[`AuthConfigGoogleServiceAccountConfigDict`]_¶ 
    
Config for Google Service Account auth. 

http_basic_auth_config _:`Optional`[`AuthConfigHttpBasicAuthConfigDict`]_¶ 
    
Config for HTTP Basic auth. 

oauth_config _:`Optional`[`AuthConfigOauthConfigDict`]_¶ 
    
Config for user oauth. 

oidc_config _:`Optional`[`AuthConfigOidcConfigDict`]_¶ 
    
Config for user OIDC auth. 

_pydantic model_genai.types.AuthConfigGoogleServiceAccountConfig¶ 
    
Bases: `BaseModel`
Config for Google Service Account Authentication.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"AuthConfigGoogleServiceAccountConfig",
"description":"Config for Google Service Account Authentication.",
"type":"object",
"properties":{
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The service account that the extension execution service runs as. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified service account. - If not specified, the Vertex AI Extension Service Agent will be used to execute the Extension.",
"title":"Serviceaccount"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `service_account (str | None)`



_field_ service_account _:`Optional`[`str`]__= None_ _(alias 'serviceAccount')_¶ 
    
Optional. The service account that the extension execution service runs as. - If the service account is specified, the iam.serviceAccounts.getAccessToken permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified service account. - If not specified, the Vertex AI Extension Service Agent will be used to execute the Extension. 

_class_ genai.types.AuthConfigGoogleServiceAccountConfigDict¶ 
    
Bases: `TypedDict`
Config for Google Service Account Authentication. 

service_account _:`Optional`[`str`]_¶ 
    
//cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified service account. - If not specified, the Vertex AI Extension Service Agent will be used to execute the Extension. 

Type: 
    
Optional. The service account that the extension execution service runs as. - If the service account is specified, the iam.serviceAccounts.getAccessToken permission should be granted to Vertex AI Extension Service Agent (https 

_pydantic model_genai.types.AuthConfigHttpBasicAuthConfig¶ 
    
Bases: `BaseModel`
Config for HTTP Basic Authentication.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"AuthConfigHttpBasicAuthConfig",
"description":"Config for HTTP Basic Authentication.",
"type":"object",
"properties":{
"credentialSecret":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the SecretManager secret version resource storing the base64 encoded credentials. Format: `projects/{project}/secrets/{secrete}/versions/{version}` - If specified, the `secretmanager.versions.access` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified resource.",
"title":"Credentialsecret"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `credential_secret (str | None)`



_field_ credential_secret _:`Optional`[`str`]__= None_ _(alias 'credentialSecret')_¶ 
    
Required. The name of the SecretManager secret version resource storing the base64 encoded credentials. Format: projects/{project}/secrets/{secrete}/versions/{version} - If specified, the secretmanager.versions.access permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified resource. 

_class_ genai.types.AuthConfigHttpBasicAuthConfigDict¶ 
    
Bases: `TypedDict`
Config for HTTP Basic Authentication. 

credential_secret _:`Optional`[`str`]_¶ 
    
//cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified resource. 

Type: 
    
Required. The name of the SecretManager secret version resource storing the base64 encoded credentials. Format 

Type: 
    
projects/{project}/secrets/{secrete}/versions/{version} - If specified, the secretmanager.versions.access permission should be granted to Vertex AI Extension Service Agent (https 

_pydantic model_genai.types.AuthConfigOauthConfig¶ 
    
Bases: `BaseModel`
Config for user oauth.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"AuthConfigOauthConfig",
"description":"Config for user oauth.",
"type":"object",
"properties":{
"accessToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Access token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Accesstoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate access tokens for executing the Extension. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the provided service account.",
"title":"Serviceaccount"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `access_token (str | None)`
  * `service_account (str | None)`



_field_ access_token _:`Optional`[`str`]__= None_ _(alias 'accessToken')_¶ 
    
Access token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time. 

_field_ service_account _:`Optional`[`str`]__= None_ _(alias 'serviceAccount')_¶ 
    
The service account used to generate access tokens for executing the Extension. - If the service account is specified, the iam.serviceAccounts.getAccessToken permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the provided service account. 

_class_ genai.types.AuthConfigOauthConfigDict¶ 
    
Bases: `TypedDict`
Config for user oauth. 

access_token _:`Optional`[`str`]_¶ 
    
Access token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time. 

service_account _:`Optional`[`str`]_¶ 
    
//cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the provided service account. 

Type: 
    
The service account used to generate access tokens for executing the Extension. - If the service account is specified, the iam.serviceAccounts.getAccessToken permission should be granted to Vertex AI Extension Service Agent (https 

_pydantic model_genai.types.AuthConfigOidcConfig¶ 
    
Bases: `BaseModel`
Config for user OIDC auth.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"AuthConfigOidcConfig",
"description":"Config for user OIDC auth.",
"type":"object",
"properties":{
"idToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"OpenID Connect formatted ID token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Idtoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate an OpenID Connect (OIDC)-compatible JWT token signed by the Google OIDC Provider (accounts.google.com) for extension endpoint (https://cloud.google.com/iam/docs/create-short-lived-credentials-direct#sa-credentials-oidc). - The audience for the token will be set to the URL in the server url defined in the OpenApi spec. - If the service account is provided, the service account should grant `iam.serviceAccounts.getOpenIdToken` permission to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).",
"title":"Serviceaccount"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `id_token (str | None)`
  * `service_account (str | None)`



_field_ id_token _:`Optional`[`str`]__= None_ _(alias 'idToken')_¶ 
    
OpenID Connect formatted ID token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time. 

_field_ service_account _:`Optional`[`str`]__= None_ _(alias 'serviceAccount')_¶ 
    
The service account used to generate an OpenID Connect (OIDC)-compatible JWT token signed by the Google OIDC Provider (accounts.google.com) for extension endpoint (https://cloud.google.com/iam/docs/create-short-lived-credentials-direct#sa-credentials-oidc). - The audience for the token will be set to the URL in the server url defined in the OpenApi spec. - If the service account is provided, the service account should grant iam.serviceAccounts.getOpenIdToken permission to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents). 

_class_ genai.types.AuthConfigOidcConfigDict¶ 
    
Bases: `TypedDict`
Config for user OIDC auth. 

id_token _:`Optional`[`str`]_¶ 
    
OpenID Connect formatted ID token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time. 

service_account _:`Optional`[`str`]_¶ 
    
//cloud.google.com/vertex-ai/docs/general/access-control#service-agents). 

Type: 
    
The service account used to generate an OpenID Connect (OIDC)-compatible JWT token signed by the Google OIDC Provider (accounts.google.com) for extension endpoint (https 

Type: 
    
//cloud.google.com/iam/docs/create-short-lived-credentials-direct#sa-credentials-oidc). - The audience for the token will be set to the URL in the server url defined in the OpenApi spec. - If the service account is provided, the service account should grant iam.serviceAccounts.getOpenIdToken permission to Vertex AI Extension Service Agent (https 

_class_ genai.types.AuthType(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Type of auth scheme. 

API_KEY_AUTH _= 'API_KEY_AUTH'_¶ 


AUTH_TYPE_UNSPECIFIED _= 'AUTH_TYPE_UNSPECIFIED'_¶ 


GOOGLE_SERVICE_ACCOUNT_AUTH _= 'GOOGLE_SERVICE_ACCOUNT_AUTH'_¶ 


HTTP_BASIC_AUTH _= 'HTTP_BASIC_AUTH'_¶ 


NO_AUTH _= 'NO_AUTH'_¶ 


OAUTH _= 'OAUTH'_¶ 


OIDC_AUTH _= 'OIDC_AUTH'_¶ 


_pydantic model_genai.types.AutomaticActivityDetection¶ 
    
Bases: `BaseModel`
Configures automatic detection of activity.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"AutomaticActivityDetection",
"description":"Configures automatic detection of activity.",
"type":"object",
"properties":{
"disabled":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If enabled, detected voice and text input count as activity. If disabled, the client must send activity signals.",
"title":"Disabled"
},
"startOfSpeechSensitivity":{
"anyOf":[
{
"$ref":"#/$defs/StartSensitivity"
},
{
"type":"null"
}
],
"default":null,
"description":"Determines how likely speech is to be detected."
},
"endOfSpeechSensitivity":{
"anyOf":[
{
"$ref":"#/$defs/EndSensitivity"
},
{
"type":"null"
}
],
"default":null,
"description":"Determines how likely detected speech is ended."
},
"prefixPaddingMs":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The required duration of detected speech before start-of-speech is committed. The lower this value the more sensitive the start-of-speech detection is and the shorter speech can be recognized. However, this also increases the probability of false positives.",
"title":"Prefixpaddingms"
},
"silenceDurationMs":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The required duration of detected non-speech (e.g. silence) before end-of-speech is committed. The larger this value, the longer speech gaps can be without interrupting the user's activity but this will increase the model's latency.",
"title":"Silencedurationms"
}
},
"$defs":{
"EndSensitivity":{
"description":"End of speech sensitivity.",
"enum":[
"END_SENSITIVITY_UNSPECIFIED",
"END_SENSITIVITY_HIGH",
"END_SENSITIVITY_LOW"
],
"title":"EndSensitivity",
"type":"string"
},
"StartSensitivity":{
"description":"Start of speech sensitivity.",
"enum":[
"START_SENSITIVITY_UNSPECIFIED",
"START_SENSITIVITY_HIGH",
"START_SENSITIVITY_LOW"
],
"title":"StartSensitivity",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `disabled (bool | None)`
  * `end_of_speech_sensitivity (genai.types.EndSensitivity | None)`
  * `prefix_padding_ms (int | None)`
  * `silence_duration_ms (int | None)`
  * `start_of_speech_sensitivity (genai.types.StartSensitivity | None)`



_field_ disabled _:`Optional`[`bool`]__= None_¶ 
    
If enabled, detected voice and text input count as activity. If disabled, the client must send activity signals. 

_field_ end_of_speech_sensitivity _:`Optional`[`EndSensitivity`]__= None_ _(alias 'endOfSpeechSensitivity')_¶ 
    
Determines how likely detected speech is ended. 

_field_ prefix_padding_ms _:`Optional`[`int`]__= None_ _(alias 'prefixPaddingMs')_¶ 
    
The required duration of detected speech before start-of-speech is committed. The lower this value the more sensitive the start-of-speech detection is and the shorter speech can be recognized. However, this also increases the probability of false positives. 

_field_ silence_duration_ms _:`Optional`[`int`]__= None_ _(alias 'silenceDurationMs')_¶ 
    
The required duration of detected non-speech (e.g. silence) before end-of-speech is committed. The larger this value, the longer speech gaps can be without interrupting the user’s activity but this will increase the model’s latency. 

_field_ start_of_speech_sensitivity _:`Optional`[`StartSensitivity`]__= None_ _(alias 'startOfSpeechSensitivity')_¶ 
    
Determines how likely speech is to be detected. 

_class_ genai.types.AutomaticActivityDetectionDict¶ 
    
Bases: `TypedDict`
Configures automatic detection of activity. 

disabled _:`Optional`[`bool`]_¶ 
    
If enabled, detected voice and text input count as activity. If disabled, the client must send activity signals. 

end_of_speech_sensitivity _:`Optional`[`EndSensitivity`]_¶ 
    
Determines how likely detected speech is ended. 

prefix_padding_ms _:`Optional`[`int`]_¶ 
    
The required duration of detected speech before start-of-speech is committed. The lower this value the more sensitive the start-of-speech detection is and the shorter speech can be recognized. However, this also increases the probability of false positives. 

silence_duration_ms _:`Optional`[`int`]_¶ 
    
The required duration of detected non-speech (e.g. silence) before end-of-speech is committed. The larger this value, the longer speech gaps can be without interrupting the user’s activity but this will increase the model’s latency. 

start_of_speech_sensitivity _:`Optional`[`StartSensitivity`]_¶ 
    
Determines how likely speech is to be detected. 

_pydantic model_genai.types.AutomaticFunctionCallingConfig¶ 
    
Bases: `BaseModel`
The configuration for automatic function calling.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"AutomaticFunctionCallingConfig",
"description":"The configuration for automatic function calling.",
"type":"object",
"properties":{
"disable":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Whether to disable automatic function calling.\n      If not set or set to False, will enable automatic function calling.\n      If set to True, will disable automatic function calling.\n      ",
"title":"Disable"
},
"maximumRemoteCalls":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":10,
"description":"If automatic function calling is enabled,\n      maximum number of remote calls for automatic function calling.\n      This number should be a positive integer.\n      If not set, SDK will set maximum number of remote calls to 10.\n      ",
"title":"Maximumremotecalls"
},
"ignoreCallHistory":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If automatic function calling is enabled,\n      whether to ignore call history to the response.\n      If not set, SDK will set ignore_call_history to false,\n      and will append the call history to\n      GenerateContentResponse.automatic_function_calling_history.\n      ",
"title":"Ignorecallhistory"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `disable (bool | None)`
  * `ignore_call_history (bool | None)`
  * `maximum_remote_calls (int | None)`



_field_ disable _:`Optional`[`bool`]__= None_¶ 
    
Whether to disable automatic function calling. If not set or set to False, will enable automatic function calling. If set to True, will disable automatic function calling. 

_field_ ignore_call_history _:`Optional`[`bool`]__= None_ _(alias 'ignoreCallHistory')_¶ 
    
If automatic function calling is enabled, whether to ignore call history to the response. If not set, SDK will set ignore_call_history to false, and will append the call history to GenerateContentResponse.automatic_function_calling_history. 

_field_ maximum_remote_calls _:`Optional`[`int`]__= 10_ _(alias 'maximumRemoteCalls')_¶ 
    
If automatic function calling is enabled, maximum number of remote calls for automatic function calling. This number should be a positive integer. If not set, SDK will set maximum number of remote calls to 10. 

_class_ genai.types.AutomaticFunctionCallingConfigDict¶ 
    
Bases: `TypedDict`
The configuration for automatic function calling. 

disable _:`Optional`[`bool`]_¶ 
    
Whether to disable automatic function calling. If not set or set to False, will enable automatic function calling. If set to True, will disable automatic function calling. 

ignore_call_history _:`Optional`[`bool`]_¶ 
    
If automatic function calling is enabled, whether to ignore call history to the response. If not set, SDK will set ignore_call_history to false, and will append the call history to GenerateContentResponse.automatic_function_calling_history. 

maximum_remote_calls _:`Optional`[`int`]_¶ 
    
If automatic function calling is enabled, maximum number of remote calls for automatic function calling. This number should be a positive integer. If not set, SDK will set maximum number of remote calls to 10. 

_pydantic model_genai.types.BatchJob¶ 
    
Bases: `BaseModel`
Config for batches.create return value.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"BatchJob",
"description":"Config for batches.create return value.",
"type":"object",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Resource name of the Job.",
"title":"Name"
},
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The user-defined name of this Job.",
"title":"Displayname"
},
"state":{
"anyOf":[
{
"$ref":"#/$defs/JobState"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The detailed state of the job."
},
"error":{
"anyOf":[
{
"$ref":"#/$defs/JobError"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Only populated when the job's state is JOB_STATE_FAILED or JOB_STATE_CANCELLED."
},
"createTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Time when the Job was created.",
"title":"Createtime"
},
"startTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Time when the Job for the first time entered the `JOB_STATE_RUNNING` state.",
"title":"Starttime"
},
"endTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Time when the Job entered any of the following states: `JOB_STATE_SUCCEEDED`, `JOB_STATE_FAILED`, `JOB_STATE_CANCELLED`.",
"title":"Endtime"
},
"updateTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Time when the Job was most recently updated.",
"title":"Updatetime"
},
"model":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The name of the model that produces the predictions via the BatchJob.\n      ",
"title":"Model"
},
"src":{
"anyOf":[
{
"$ref":"#/$defs/BatchJobSource"
},
{
"type":"null"
}
],
"default":null,
"description":"Configuration for the input data.\n      "
},
"dest":{
"anyOf":[
{
"$ref":"#/$defs/BatchJobDestination"
},
{
"type":"null"
}
],
"default":null,
"description":"Configuration for the output data.\n      "
}
},
"$defs":{
"BatchJobDestination":{
"additionalProperties":false,
"description":"Config for `des` parameter.",
"properties":{
"format":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Storage format of the output files. Must be one of:\n      'jsonl', 'bigquery'.\n      ",
"title":"Format"
},
"gcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The Google Cloud Storage URI to the output file.\n      ",
"title":"Gcsuri"
},
"bigqueryUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The BigQuery URI to the output table.\n      ",
"title":"Bigqueryuri"
}
},
"title":"BatchJobDestination",
"type":"object"
},
"BatchJobSource":{
"additionalProperties":false,
"description":"Config for `src` parameter.",
"properties":{
"format":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Storage format of the input files. Must be one of:\n      'jsonl', 'bigquery'.\n      ",
"title":"Format"
},
"gcsUri":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The Google Cloud Storage URIs to input files.\n      ",
"title":"Gcsuri"
},
"bigqueryUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The BigQuery URI to input table.\n      ",
"title":"Bigqueryuri"
}
},
"title":"BatchJobSource",
"type":"object"
},
"JobError":{
"additionalProperties":false,
"description":"Job error.",
"properties":{
"details":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Details"
},
"code":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The status code.",
"title":"Code"
},
"message":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the `details` field.",
"title":"Message"
}
},
"title":"JobError",
"type":"object"
},
"JobState":{
"description":"Job state.",
"enum":[
"JOB_STATE_UNSPECIFIED",
"JOB_STATE_QUEUED",
"JOB_STATE_PENDING",
"JOB_STATE_RUNNING",
"JOB_STATE_SUCCEEDED",
"JOB_STATE_FAILED",
"JOB_STATE_CANCELLING",
"JOB_STATE_CANCELLED",
"JOB_STATE_PAUSED",
"JOB_STATE_EXPIRED",
"JOB_STATE_UPDATING",
"JOB_STATE_PARTIALLY_SUCCEEDED"
],
"title":"JobState",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `create_time (datetime.datetime | None)`
  * `dest (genai.types.BatchJobDestination | None)`
  * `display_name (str | None)`
  * `end_time (datetime.datetime | None)`
  * `error (genai.types.JobError | None)`
  * `model (str | None)`
  * `name (str | None)`
  * `src (genai.types.BatchJobSource | None)`
  * `start_time (datetime.datetime | None)`
  * `state (genai.types.JobState | None)`
  * `update_time (datetime.datetime | None)`



_field_ create_time _:`Optional`[`datetime`]__= None_ _(alias 'createTime')_¶ 
    
Output only. Time when the Job was created. 

_field_ dest _:`Optional`[`BatchJobDestination`]__= None_¶ 
    
Configuration for the output data. 

_field_ display_name _:`Optional`[`str`]__= None_ _(alias 'displayName')_¶ 
    
The user-defined name of this Job. 

_field_ end_time _:`Optional`[`datetime`]__= None_ _(alias 'endTime')_¶ 
    
Output only. Time when the Job entered any of the following states: JOB_STATE_SUCCEEDED, JOB_STATE_FAILED, JOB_STATE_CANCELLED. 

_field_ error _:`Optional`[`JobError`]__= None_¶ 
    
Output only. Only populated when the job’s state is JOB_STATE_FAILED or JOB_STATE_CANCELLED. 

_field_ model _:`Optional`[`str`]__= None_¶ 
    
The name of the model that produces the predictions via the BatchJob. 

_field_ name _:`Optional`[`str`]__= None_¶ 
    
Output only. Resource name of the Job. 

_field_ src _:`Optional`[`BatchJobSource`]__= None_¶ 
    
Configuration for the input data. 

_field_ start_time _:`Optional`[`datetime`]__= None_ _(alias 'startTime')_¶ 
    
Output only. Time when the Job for the first time entered the JOB_STATE_RUNNING state. 

_field_ state _:`Optional`[`JobState`]__= None_¶ 
    
Output only. The detailed state of the job. 

_field_ update_time _:`Optional`[`datetime`]__= None_ _(alias 'updateTime')_¶ 
    
Output only. Time when the Job was most recently updated. 

_pydantic model_genai.types.BatchJobDestination¶ 
    
Bases: `BaseModel`
Config for des parameter.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"BatchJobDestination",
"description":"Config for `des` parameter.",
"type":"object",
"properties":{
"format":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Storage format of the output files. Must be one of:\n      'jsonl', 'bigquery'.\n      ",
"title":"Format"
},
"gcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The Google Cloud Storage URI to the output file.\n      ",
"title":"Gcsuri"
},
"bigqueryUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The BigQuery URI to the output table.\n      ",
"title":"Bigqueryuri"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `bigquery_uri (str | None)`
  * `format (str | None)`
  * `gcs_uri (str | None)`



_field_ bigquery_uri _:`Optional`[`str`]__= None_ _(alias 'bigqueryUri')_¶ 
    
The BigQuery URI to the output table. 

_field_ format _:`Optional`[`str`]__= None_¶ 
    
Storage format of the output files. Must be one of: ‘jsonl’, ‘bigquery’. 

_field_ gcs_uri _:`Optional`[`str`]__= None_ _(alias 'gcsUri')_¶ 
    
The Google Cloud Storage URI to the output file. 

_class_ genai.types.BatchJobDestinationDict¶ 
    
Bases: `TypedDict`
Config for des parameter. 

bigquery_uri _:`Optional`[`str`]_¶ 
    
The BigQuery URI to the output table. 

format _:`Optional`[`str`]_¶ 
    
Storage format of the output files. Must be one of: ‘jsonl’, ‘bigquery’. 

gcs_uri _:`Optional`[`str`]_¶ 
    
The Google Cloud Storage URI to the output file. 

_class_ genai.types.BatchJobDict¶ 
    
Bases: `TypedDict`
Config for batches.create return value. 

create_time _:`Optional`[`datetime`]_¶ 
    
Output only. Time when the Job was created. 

dest _:`Optional`[`BatchJobDestinationDict`]_¶ 
    
Configuration for the output data. 

display_name _:`Optional`[`str`]_¶ 
    
The user-defined name of this Job. 

end_time _:`Optional`[`datetime`]_¶ 
    
JOB_STATE_SUCCEEDED, JOB_STATE_FAILED, JOB_STATE_CANCELLED. 

Type: 
    
Output only. Time when the Job entered any of the following states 

error _:`Optional`[`JobErrorDict`]_¶ 
    
Output only. Only populated when the job’s state is JOB_STATE_FAILED or JOB_STATE_CANCELLED. 

model _:`Optional`[`str`]_¶ 
    
The name of the model that produces the predictions via the BatchJob. 

name _:`Optional`[`str`]_¶ 
    
Output only. Resource name of the Job. 

src _:`Optional`[`BatchJobSourceDict`]_¶ 
    
Configuration for the input data. 

start_time _:`Optional`[`datetime`]_¶ 
    
Output only. Time when the Job for the first time entered the JOB_STATE_RUNNING state. 

state _:`Optional`[`JobState`]_¶ 
    
Output only. The detailed state of the job. 

update_time _:`Optional`[`datetime`]_¶ 
    
Output only. Time when the Job was most recently updated. 

_pydantic model_genai.types.BatchJobSource¶ 
    
Bases: `BaseModel`
Config for src parameter.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"BatchJobSource",
"description":"Config for `src` parameter.",
"type":"object",
"properties":{
"format":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Storage format of the input files. Must be one of:\n      'jsonl', 'bigquery'.\n      ",
"title":"Format"
},
"gcsUri":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The Google Cloud Storage URIs to input files.\n      ",
"title":"Gcsuri"
},
"bigqueryUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The BigQuery URI to input table.\n      ",
"title":"Bigqueryuri"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `bigquery_uri (str | None)`
  * `format (str | None)`
  * `gcs_uri (list[str] | None)`



_field_ bigquery_uri _:`Optional`[`str`]__= None_ _(alias 'bigqueryUri')_¶ 
    
The BigQuery URI to input table. 

_field_ format _:`Optional`[`str`]__= None_¶ 
    
Storage format of the input files. Must be one of: ‘jsonl’, ‘bigquery’. 

_field_ gcs_uri _:`Optional`[`list`[`str`]]__= None_ _(alias 'gcsUri')_¶ 
    
The Google Cloud Storage URIs to input files. 

_class_ genai.types.BatchJobSourceDict¶ 
    
Bases: `TypedDict`
Config for src parameter. 

bigquery_uri _:`Optional`[`str`]_¶ 
    
The BigQuery URI to input table. 

format _:`Optional`[`str`]_¶ 
    
Storage format of the input files. Must be one of: ‘jsonl’, ‘bigquery’. 

gcs_uri _:`Optional`[`list`[`str`]]_¶ 
    
The Google Cloud Storage URIs to input files. 

_pydantic model_genai.types.Blob¶ 
    
Bases: `BaseModel`
Content blob.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"Blob",
"description":"Content blob.",
"type":"object",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `data (bytes | None)`
  * `display_name (str | None)`
  * `mime_type (str | None)`



_field_ data _:`Optional`[`bytes`]__= None_¶ 
    
Required. Raw bytes. 

_field_ display_name _:`Optional`[`str`]__= None_ _(alias 'displayName')_¶ 
    
Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls. 

_field_ mime_type _:`Optional`[`str`]__= None_ _(alias 'mimeType')_¶ 
    
Required. The IANA standard MIME type of the source data. 

_class_ genai.types.BlobDict¶ 
    
Bases: `TypedDict`
Content blob. 

data _:`Optional`[`bytes`]_¶ 
    
Required. Raw bytes. 

display_name _:`Optional`[`str`]_¶ 
    
Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls. 

mime_type _:`Optional`[`str`]_¶ 
    
Required. The IANA standard MIME type of the source data. 

_class_ genai.types.BlockedReason(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Output only. Blocked reason. 

BLOCKED_REASON_UNSPECIFIED _= 'BLOCKED_REASON_UNSPECIFIED'_¶ 


BLOCKLIST _= 'BLOCKLIST'_¶ 


OTHER _= 'OTHER'_¶ 


PROHIBITED_CONTENT _= 'PROHIBITED_CONTENT'_¶ 


SAFETY _= 'SAFETY'_¶ 


_pydantic model_genai.types.CachedContent¶ 
    
Bases: `BaseModel`
A resource used in LLM queries for users to explicitly specify what to cache.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"CachedContent",
"description":"A resource used in LLM queries for users to explicitly specify what to cache.",
"type":"object",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The server-generated resource name of the cached content.",
"title":"Name"
},
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The user-generated meaningful display name of the cached content.",
"title":"Displayname"
},
"model":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The name of the publisher model to use for cached content.",
"title":"Model"
},
"createTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Creation time of the cache entry.",
"title":"Createtime"
},
"updateTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"When the cache entry was last updated in UTC time.",
"title":"Updatetime"
},
"expireTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Expiration time of the cached content.",
"title":"Expiretime"
},
"usageMetadata":{
"anyOf":[
{
"$ref":"#/$defs/CachedContentUsageMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata on the usage of the cached content."
}
},
"$defs":{
"CachedContentUsageMetadata":{
"additionalProperties":false,
"description":"Metadata on the usage of the cached content.",
"properties":{
"audioDurationSeconds":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Duration of audio in seconds.",
"title":"Audiodurationseconds"
},
"imageCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of images.",
"title":"Imagecount"
},
"textCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of text characters.",
"title":"Textcount"
},
"totalTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Total number of tokens that the cached content consumes.",
"title":"Totaltokencount"
},
"videoDurationSeconds":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Duration of video in seconds.",
"title":"Videodurationseconds"
}
},
"title":"CachedContentUsageMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `create_time (datetime.datetime | None)`
  * `display_name (str | None)`
  * `expire_time (datetime.datetime | None)`
  * `model (str | None)`
  * `name (str | None)`
  * `update_time (datetime.datetime | None)`
  * `usage_metadata (genai.types.CachedContentUsageMetadata | None)`



_field_ create_time _:`Optional`[`datetime`]__= None_ _(alias 'createTime')_¶ 
    
Creation time of the cache entry. 

_field_ display_name _:`Optional`[`str`]__= None_ _(alias 'displayName')_¶ 
    
The user-generated meaningful display name of the cached content. 

_field_ expire_time _:`Optional`[`datetime`]__= None_ _(alias 'expireTime')_¶ 
    
Expiration time of the cached content. 

_field_ model _:`Optional`[`str`]__= None_¶ 
    
The name of the publisher model to use for cached content. 

_field_ name _:`Optional`[`str`]__= None_¶ 
    
The server-generated resource name of the cached content. 

_field_ update_time _:`Optional`[`datetime`]__= None_ _(alias 'updateTime')_¶ 
    
When the cache entry was last updated in UTC time. 

_field_ usage_metadata _:`Optional`[`CachedContentUsageMetadata`]__= None_ _(alias 'usageMetadata')_¶ 
    
Metadata on the usage of the cached content. 

_class_ genai.types.CachedContentDict¶ 
    
Bases: `TypedDict`
A resource used in LLM queries for users to explicitly specify what to cache. 

create_time _:`Optional`[`datetime`]_¶ 
    
Creation time of the cache entry. 

display_name _:`Optional`[`str`]_¶ 
    
The user-generated meaningful display name of the cached content. 

expire_time _:`Optional`[`datetime`]_¶ 
    
Expiration time of the cached content. 

model _:`Optional`[`str`]_¶ 
    
The name of the publisher model to use for cached content. 

name _:`Optional`[`str`]_¶ 
    
The server-generated resource name of the cached content. 

update_time _:`Optional`[`datetime`]_¶ 
    
When the cache entry was last updated in UTC time. 

usage_metadata _:`Optional`[`CachedContentUsageMetadataDict`]_¶ 
    
Metadata on the usage of the cached content. 

_pydantic model_genai.types.CachedContentUsageMetadata¶ 
    
Bases: `BaseModel`
Metadata on the usage of the cached content.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"CachedContentUsageMetadata",
"description":"Metadata on the usage of the cached content.",
"type":"object",
"properties":{
"audioDurationSeconds":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Duration of audio in seconds.",
"title":"Audiodurationseconds"
},
"imageCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of images.",
"title":"Imagecount"
},
"textCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of text characters.",
"title":"Textcount"
},
"totalTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Total number of tokens that the cached content consumes.",
"title":"Totaltokencount"
},
"videoDurationSeconds":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Duration of video in seconds.",
"title":"Videodurationseconds"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `audio_duration_seconds (int | None)`
  * `image_count (int | None)`
  * `text_count (int | None)`
  * `total_token_count (int | None)`
  * `video_duration_seconds (int | None)`



_field_ audio_duration_seconds _:`Optional`[`int`]__= None_ _(alias 'audioDurationSeconds')_¶ 
    
Duration of audio in seconds. 

_field_ image_count _:`Optional`[`int`]__= None_ _(alias 'imageCount')_¶ 
    
Number of images. 

_field_ text_count _:`Optional`[`int`]__= None_ _(alias 'textCount')_¶ 
    
Number of text characters. 

_field_ total_token_count _:`Optional`[`int`]__= None_ _(alias 'totalTokenCount')_¶ 
    
Total number of tokens that the cached content consumes. 

_field_ video_duration_seconds _:`Optional`[`int`]__= None_ _(alias 'videoDurationSeconds')_¶ 
    
Duration of video in seconds. 

_class_ genai.types.CachedContentUsageMetadataDict¶ 
    
Bases: `TypedDict`
Metadata on the usage of the cached content. 

audio_duration_seconds _:`Optional`[`int`]_¶ 
    
Duration of audio in seconds. 

image_count _:`Optional`[`int`]_¶ 
    
Number of images. 

text_count _:`Optional`[`int`]_¶ 
    
Number of text characters. 

total_token_count _:`Optional`[`int`]_¶ 
    
Total number of tokens that the cached content consumes. 

video_duration_seconds _:`Optional`[`int`]_¶ 
    
Duration of video in seconds. 

_pydantic model_genai.types.CancelBatchJobConfig¶ 
    
Bases: `BaseModel`
Optional parameters.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"CancelBatchJobConfig",
"description":"Optional parameters.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `http_options (genai.types.HttpOptions | None)`



_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_class_ genai.types.CancelBatchJobConfigDict¶ 
    
Bases: `TypedDict`
Optional parameters. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

_pydantic model_genai.types.Candidate¶ 
    
Bases: `BaseModel`
A response candidate generated from the model.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"Candidate",
"description":"A response candidate generated from the model.",
"type":"object",
"properties":{
"content":{
"anyOf":[
{
"$ref":"#/$defs/Content"
},
{
"type":"null"
}
],
"default":null,
"description":"Contains the multi-part content of the response.\n      "
},
"citationMetadata":{
"anyOf":[
{
"$ref":"#/$defs/CitationMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Source attribution of the generated content.\n      "
},
"finishMessage":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Describes the reason the model stopped generating tokens.\n      ",
"title":"Finishmessage"
},
"tokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens for this candidate.\n      ",
"title":"Tokencount"
},
"finishReason":{
"anyOf":[
{
"$ref":"#/$defs/FinishReason"
},
{
"type":"null"
}
],
"default":null,
"description":"The reason why the model stopped generating tokens.\n      If empty, the model has not stopped generating the tokens.\n      "
},
"avgLogprobs":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Average log probability score of the candidate.",
"title":"Avglogprobs"
},
"groundingMetadata":{
"anyOf":[
{
"$ref":"#/$defs/GroundingMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Metadata specifies sources used to ground generated content."
},
"index":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Index of the candidate.",
"title":"Index"
},
"logprobsResult":{
"anyOf":[
{
"$ref":"#/$defs/LogprobsResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Log-likelihood scores for the response tokens and top tokens"
},
"safetyRatings":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/SafetyRating"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. List of ratings for the safety of a response candidate. There is at most one rating per category.",
"title":"Safetyratings"
}
},
"$defs":{
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"Citation":{
"additionalProperties":false,
"description":"Source attributions for content.",
"properties":{
"endIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. End index into the content.",
"title":"Endindex"
},
"license":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. License of the attribution.",
"title":"License"
},
"publicationDate":{
"anyOf":[
{
"$ref":"#/$defs/GoogleTypeDate"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Publication date of the attribution."
},
"startIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Start index into the content.",
"title":"Startindex"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Title of the attribution.",
"title":"Title"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Url reference of the attribution.",
"title":"Uri"
}
},
"title":"Citation",
"type":"object"
},
"CitationMetadata":{
"additionalProperties":false,
"description":"Citation information when the model quotes another source.",
"properties":{
"citations":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Citation"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Contains citation information when the model directly quotes, at\n      length, from another source. Can include traditional websites and code\n      repositories.\n      ",
"title":"Citations"
}
},
"title":"CitationMetadata",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"Content":{
"additionalProperties":false,
"description":"Contains the multi-part content of a message.",
"properties":{
"parts":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Part"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of parts that constitute a single message. Each part may have\n      a different IANA MIME type.",
"title":"Parts"
},
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role.",
"title":"Role"
}
},
"title":"Content",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FinishReason":{
"description":"Output only. The reason why the model stopped generating tokens.\n\nIf empty, the model has not stopped generating the tokens.",
"enum":[
"FINISH_REASON_UNSPECIFIED",
"STOP",
"MAX_TOKENS",
"SAFETY",
"RECITATION",
"LANGUAGE",
"OTHER",
"BLOCKLIST",
"PROHIBITED_CONTENT",
"SPII",
"MALFORMED_FUNCTION_CALL",
"IMAGE_SAFETY"
],
"title":"FinishReason",
"type":"string"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"GoogleTypeDate":{
"additionalProperties":false,
"description":"Represents a whole or partial calendar date, such as a birthday.\n\nThe time of day and time zone are either specified elsewhere or are\ninsignificant. The date is relative to the Gregorian Calendar. This can\nrepresent one of the following: * A full date, with non-zero year, month, and\nday values. * A month and day, with a zero year (for example, an anniversary).\n* A year on its own, with a zero month and a zero day. * A year and month,\nwith a zero day (for example, a credit card expiration date). Related types: *\ngoogle.type.TimeOfDay * google.type.DateTime * google.protobuf.Timestamp",
"properties":{
"day":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.",
"title":"Day"
},
"month":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.",
"title":"Month"
},
"year":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year.",
"title":"Year"
}
},
"title":"GoogleTypeDate",
"type":"object"
},
"GroundingChunk":{
"additionalProperties":false,
"description":"Grounding chunk.",
"properties":{
"retrievedContext":{
"anyOf":[
{
"$ref":"#/$defs/GroundingChunkRetrievedContext"
},
{
"type":"null"
}
],
"default":null,
"description":"Grounding chunk from context retrieved by the retrieval tools."
},
"web":{
"anyOf":[
{
"$ref":"#/$defs/GroundingChunkWeb"
},
{
"type":"null"
}
],
"default":null,
"description":"Grounding chunk from the web."
}
},
"title":"GroundingChunk",
"type":"object"
},
"GroundingChunkRetrievedContext":{
"additionalProperties":false,
"description":"Chunk from context retrieved by the retrieval tools.",
"properties":{
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Text of the attribution.",
"title":"Text"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Title of the attribution.",
"title":"Title"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"URI reference of the attribution.",
"title":"Uri"
}
},
"title":"GroundingChunkRetrievedContext",
"type":"object"
},
"GroundingChunkWeb":{
"additionalProperties":false,
"description":"Chunk from the web.",
"properties":{
"domain":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Domain of the (original) URI.",
"title":"Domain"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Title of the chunk.",
"title":"Title"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"URI reference of the chunk.",
"title":"Uri"
}
},
"title":"GroundingChunkWeb",
"type":"object"
},
"GroundingMetadata":{
"additionalProperties":false,
"description":"Metadata returned to client when grounding is enabled.",
"properties":{
"groundingChunks":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/GroundingChunk"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of supporting references retrieved from specified grounding source.",
"title":"Groundingchunks"
},
"groundingSupports":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/GroundingSupport"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. List of grounding support.",
"title":"Groundingsupports"
},
"retrievalMetadata":{
"anyOf":[
{
"$ref":"#/$defs/RetrievalMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Output only. Retrieval metadata."
},
"retrievalQueries":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Queries executed by the retrieval tools.",
"title":"Retrievalqueries"
},
"searchEntryPoint":{
"anyOf":[
{
"$ref":"#/$defs/SearchEntryPoint"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google search entry for the following-up web searches."
},
"webSearchQueries":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Web search queries for the following-up web search.",
"title":"Websearchqueries"
}
},
"title":"GroundingMetadata",
"type":"object"
},
"GroundingSupport":{
"additionalProperties":false,
"description":"Grounding support.",
"properties":{
"confidenceScores":{
"anyOf":[
{
"items":{
"type":"number"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Confidence score of the support references. Ranges from 0 to 1. 1 is the most confident. This list must have the same size as the grounding_chunk_indices.",
"title":"Confidencescores"
},
"groundingChunkIndices":{
"anyOf":[
{
"items":{
"type":"integer"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of indices (into 'grounding_chunk') specifying the citations associated with the claim. For instance [1,3,4] means that grounding_chunk[1], grounding_chunk[3], grounding_chunk[4] are the retrieved content attributed to the claim.",
"title":"Groundingchunkindices"
},
"segment":{
"anyOf":[
{
"$ref":"#/$defs/Segment"
},
{
"type":"null"
}
],
"default":null,
"description":"Segment of the content this support belongs to."
}
},
"title":"GroundingSupport",
"type":"object"
},
"HarmCategory":{
"description":"Required. Harm category.",
"enum":[
"HARM_CATEGORY_UNSPECIFIED",
"HARM_CATEGORY_HATE_SPEECH",
"HARM_CATEGORY_DANGEROUS_CONTENT",
"HARM_CATEGORY_HARASSMENT",
"HARM_CATEGORY_SEXUALLY_EXPLICIT",
"HARM_CATEGORY_CIVIC_INTEGRITY"
],
"title":"HarmCategory",
"type":"string"
},
"HarmProbability":{
"description":"Output only. Harm probability levels in the content.",
"enum":[
"HARM_PROBABILITY_UNSPECIFIED",
"NEGLIGIBLE",
"LOW",
"MEDIUM",
"HIGH"
],
"title":"HarmProbability",
"type":"string"
},
"HarmSeverity":{
"description":"Output only. Harm severity levels in the content.",
"enum":[
"HARM_SEVERITY_UNSPECIFIED",
"HARM_SEVERITY_NEGLIGIBLE",
"HARM_SEVERITY_LOW",
"HARM_SEVERITY_MEDIUM",
"HARM_SEVERITY_HIGH"
],
"title":"HarmSeverity",
"type":"string"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"LogprobsResult":{
"additionalProperties":false,
"description":"Logprobs Result",
"properties":{
"chosenCandidates":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/LogprobsResultCandidate"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Length = total number of decoding steps. The chosen candidates may or may not be in top_candidates.",
"title":"Chosencandidates"
},
"topCandidates":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/LogprobsResultTopCandidates"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Length = total number of decoding steps.",
"title":"Topcandidates"
}
},
"title":"LogprobsResult",
"type":"object"
},
"LogprobsResultCandidate":{
"additionalProperties":false,
"description":"Candidate for the logprobs token and score.",
"properties":{
"logProbability":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"The candidate's log probability.",
"title":"Logprobability"
},
"token":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The candidate's token string value.",
"title":"Token"
},
"tokenId":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The candidate's token id value.",
"title":"Tokenid"
}
},
"title":"LogprobsResultCandidate",
"type":"object"
},
"LogprobsResultTopCandidates":{
"additionalProperties":false,
"description":"Candidates with top log probabilities at each decoding step.",
"properties":{
"candidates":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/LogprobsResultCandidate"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Sorted by log probability in descending order.",
"title":"Candidates"
}
},
"title":"LogprobsResultTopCandidates",
"type":"object"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"RetrievalMetadata":{
"additionalProperties":false,
"description":"Metadata related to retrieval in the grounding flow.",
"properties":{
"googleSearchDynamicRetrievalScore":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Score indicating how likely information from Google Search could help answer the prompt. The score is in the range `[0, 1]`, where 0 is the least likely and 1 is the most likely. This score is only populated when Google Search grounding and dynamic retrieval is enabled. It will be compared to the threshold to determine whether to trigger Google Search.",
"title":"Googlesearchdynamicretrievalscore"
}
},
"title":"RetrievalMetadata",
"type":"object"
},
"SafetyRating":{
"additionalProperties":false,
"description":"Safety rating corresponding to the generated content.",
"properties":{
"blocked":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Indicates whether the content was filtered out because of this rating.",
"title":"Blocked"
},
"category":{
"anyOf":[
{
"$ref":"#/$defs/HarmCategory"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm category."
},
"probability":{
"anyOf":[
{
"$ref":"#/$defs/HarmProbability"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm probability levels in the content."
},
"probabilityScore":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm probability score.",
"title":"Probabilityscore"
},
"severity":{
"anyOf":[
{
"$ref":"#/$defs/HarmSeverity"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm severity levels in the content."
},
"severityScore":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm severity score.",
"title":"Severityscore"
}
},
"title":"SafetyRating",
"type":"object"
},
"SearchEntryPoint":{
"additionalProperties":false,
"description":"Google search entry point.",
"properties":{
"renderedContent":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Web content snippet that can be embedded in a web page or an app webview.",
"title":"Renderedcontent"
},
"sdkBlob":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Base64 encoded JSON representing array of tuple.",
"title":"Sdkblob"
}
},
"title":"SearchEntryPoint",
"type":"object"
},
"Segment":{
"additionalProperties":false,
"description":"Segment of the content.",
"properties":{
"endIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. End index in the given Part, measured in bytes. Offset from the start of the Part, exclusive, starting at zero.",
"title":"Endindex"
},
"partIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The index of a Part object within its parent Content object.",
"title":"Partindex"
},
"startIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Start index in the given Part, measured in bytes. Offset from the start of the Part, inclusive, starting at zero.",
"title":"Startindex"
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The text corresponding to the segment from the response.",
"title":"Text"
}
},
"title":"Segment",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `avg_logprobs (float | None)`
  * `citation_metadata (genai.types.CitationMetadata | None)`
  * `content (genai.types.Content | None)`
  * `finish_message (str | None)`
  * `finish_reason (genai.types.FinishReason | None)`
  * `grounding_metadata (genai.types.GroundingMetadata | None)`
  * `index (int | None)`
  * `logprobs_result (genai.types.LogprobsResult | None)`
  * `safety_ratings (list[genai.types.SafetyRating] | None)`
  * `token_count (int | None)`



_field_ avg_logprobs _:`Optional`[`float`]__= None_ _(alias 'avgLogprobs')_¶ 
    
Output only. Average log probability score of the candidate. 

_field_ citation_metadata _:`Optional`[`CitationMetadata`]__= None_ _(alias 'citationMetadata')_¶ 
    
Source attribution of the generated content. 

_field_ content _:`Optional`[`Content`]__= None_¶ 
    
Contains the multi-part content of the response. 

_field_ finish_message _:`Optional`[`str`]__= None_ _(alias 'finishMessage')_¶ 
    
Describes the reason the model stopped generating tokens. 

_field_ finish_reason _:`Optional`[`FinishReason`]__= None_ _(alias 'finishReason')_¶ 
    
The reason why the model stopped generating tokens. If empty, the model has not stopped generating the tokens. 

_field_ grounding_metadata _:`Optional`[`GroundingMetadata`]__= None_ _(alias 'groundingMetadata')_¶ 
    
Output only. Metadata specifies sources used to ground generated content. 

_field_ index _:`Optional`[`int`]__= None_¶ 
    
Output only. Index of the candidate. 

_field_ logprobs_result _:`Optional`[`LogprobsResult`]__= None_ _(alias 'logprobsResult')_¶ 
    
Output only. Log-likelihood scores for the response tokens and top tokens 

_field_ safety_ratings _:`Optional`[`list`[`SafetyRating`]]__= None_ _(alias 'safetyRatings')_¶ 
    
Output only. List of ratings for the safety of a response candidate. There is at most one rating per category. 

_field_ token_count _:`Optional`[`int`]__= None_ _(alias 'tokenCount')_¶ 
    
Number of tokens for this candidate. 

_class_ genai.types.CandidateDict¶ 
    
Bases: `TypedDict`
A response candidate generated from the model. 

avg_logprobs _:`Optional`[`float`]_¶ 
    
Output only. Average log probability score of the candidate. 

citation_metadata _:`Optional`[`CitationMetadataDict`]_¶ 
    
Source attribution of the generated content. 

content _:`Optional`[`ContentDict`]_¶ 
    
Contains the multi-part content of the response. 

finish_message _:`Optional`[`str`]_¶ 
    
Describes the reason the model stopped generating tokens. 

finish_reason _:`Optional`[`FinishReason`]_¶ 
    
The reason why the model stopped generating tokens. If empty, the model has not stopped generating the tokens. 

grounding_metadata _:`Optional`[`GroundingMetadataDict`]_¶ 
    
Output only. Metadata specifies sources used to ground generated content. 

index _:`Optional`[`int`]_¶ 
    
Output only. Index of the candidate. 

logprobs_result _:`Optional`[`LogprobsResultDict`]_¶ 
    
Output only. Log-likelihood scores for the response tokens and top tokens 

safety_ratings _:`Optional`[`list`[`SafetyRatingDict`]]_¶ 
    
Output only. List of ratings for the safety of a response candidate. There is at most one rating per category. 

token_count _:`Optional`[`int`]_¶ 
    
Number of tokens for this candidate. 

_pydantic model_genai.types.Checkpoint¶ 
    
Bases: `BaseModel`
Describes the machine learning model version checkpoint.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"Checkpoint",
"description":"Describes the machine learning model version checkpoint.",
"type":"object",
"properties":{
"checkpointId":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The ID of the checkpoint.\n      ",
"title":"Checkpointid"
},
"epoch":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The epoch of the checkpoint.\n      ",
"title":"Epoch"
},
"step":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The step of the checkpoint.\n      ",
"title":"Step"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `checkpoint_id (str | None)`
  * `epoch (int | None)`
  * `step (int | None)`



_field_ checkpoint_id _:`Optional`[`str`]__= None_ _(alias 'checkpointId')_¶ 
    
The ID of the checkpoint. 

_field_ epoch _:`Optional`[`int`]__= None_¶ 
    
The epoch of the checkpoint. 

_field_ step _:`Optional`[`int`]__= None_¶ 
    
The step of the checkpoint. 

_class_ genai.types.CheckpointDict¶ 
    
Bases: `TypedDict`
Describes the machine learning model version checkpoint. 

checkpoint_id _:`Optional`[`str`]_¶ 
    
The ID of the checkpoint. 

epoch _:`Optional`[`int`]_¶ 
    
The epoch of the checkpoint. 

step _:`Optional`[`int`]_¶ 
    
The step of the checkpoint. 

_pydantic model_genai.types.Citation¶ 
    
Bases: `BaseModel`
Source attributions for content.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"Citation",
"description":"Source attributions for content.",
"type":"object",
"properties":{
"endIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. End index into the content.",
"title":"Endindex"
},
"license":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. License of the attribution.",
"title":"License"
},
"publicationDate":{
"anyOf":[
{
"$ref":"#/$defs/GoogleTypeDate"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Publication date of the attribution."
},
"startIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Start index into the content.",
"title":"Startindex"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Title of the attribution.",
"title":"Title"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Url reference of the attribution.",
"title":"Uri"
}
},
"$defs":{
"GoogleTypeDate":{
"additionalProperties":false,
"description":"Represents a whole or partial calendar date, such as a birthday.\n\nThe time of day and time zone are either specified elsewhere or are\ninsignificant. The date is relative to the Gregorian Calendar. This can\nrepresent one of the following: * A full date, with non-zero year, month, and\nday values. * A month and day, with a zero year (for example, an anniversary).\n* A year on its own, with a zero month and a zero day. * A year and month,\nwith a zero day (for example, a credit card expiration date). Related types: *\ngoogle.type.TimeOfDay * google.type.DateTime * google.protobuf.Timestamp",
"properties":{
"day":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.",
"title":"Day"
},
"month":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.",
"title":"Month"
},
"year":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year.",
"title":"Year"
}
},
"title":"GoogleTypeDate",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `end_index (int | None)`
  * `license (str | None)`
  * `publication_date (genai.types.GoogleTypeDate | None)`
  * `start_index (int | None)`
  * `title (str | None)`
  * `uri (str | None)`



_field_ end_index _:`Optional`[`int`]__= None_ _(alias 'endIndex')_¶ 
    
Output only. End index into the content. 

_field_ license _:`Optional`[`str`]__= None_¶ 
    
Output only. License of the attribution. 

_field_ publication_date _:`Optional`[`GoogleTypeDate`]__= None_ _(alias 'publicationDate')_¶ 
    
Output only. Publication date of the attribution. 

_field_ start_index _:`Optional`[`int`]__= None_ _(alias 'startIndex')_¶ 
    
Output only. Start index into the content. 

_field_ title _:`Optional`[`str`]__= None_¶ 
    
Output only. Title of the attribution. 

_field_ uri _:`Optional`[`str`]__= None_¶ 
    
Output only. Url reference of the attribution. 

_class_ genai.types.CitationDict¶ 
    
Bases: `TypedDict`
Source attributions for content. 

end_index _:`Optional`[`int`]_¶ 
    
Output only. End index into the content. 

license _:`Optional`[`str`]_¶ 
    
Output only. License of the attribution. 

publication_date _:`Optional`[`GoogleTypeDateDict`]_¶ 
    
Output only. Publication date of the attribution. 

start_index _:`Optional`[`int`]_¶ 
    
Output only. Start index into the content. 

title _:`Optional`[`str`]_¶ 
    
Output only. Title of the attribution. 

uri _:`Optional`[`str`]_¶ 
    
Output only. Url reference of the attribution. 

_pydantic model_genai.types.CitationMetadata¶ 
    
Bases: `BaseModel`
Citation information when the model quotes another source.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"CitationMetadata",
"description":"Citation information when the model quotes another source.",
"type":"object",
"properties":{
"citations":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Citation"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Contains citation information when the model directly quotes, at\n      length, from another source. Can include traditional websites and code\n      repositories.\n      ",
"title":"Citations"
}
},
"$defs":{
"Citation":{
"additionalProperties":false,
"description":"Source attributions for content.",
"properties":{
"endIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. End index into the content.",
"title":"Endindex"
},
"license":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. License of the attribution.",
"title":"License"
},
"publicationDate":{
"anyOf":[
{
"$ref":"#/$defs/GoogleTypeDate"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Publication date of the attribution."
},
"startIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Start index into the content.",
"title":"Startindex"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Title of the attribution.",
"title":"Title"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Url reference of the attribution.",
"title":"Uri"
}
},
"title":"Citation",
"type":"object"
},
"GoogleTypeDate":{
"additionalProperties":false,
"description":"Represents a whole or partial calendar date, such as a birthday.\n\nThe time of day and time zone are either specified elsewhere or are\ninsignificant. The date is relative to the Gregorian Calendar. This can\nrepresent one of the following: * A full date, with non-zero year, month, and\nday values. * A month and day, with a zero year (for example, an anniversary).\n* A year on its own, with a zero month and a zero day. * A year and month,\nwith a zero day (for example, a credit card expiration date). Related types: *\ngoogle.type.TimeOfDay * google.type.DateTime * google.protobuf.Timestamp",
"properties":{
"day":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.",
"title":"Day"
},
"month":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.",
"title":"Month"
},
"year":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year.",
"title":"Year"
}
},
"title":"GoogleTypeDate",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `citations (list[genai.types.Citation] | None)`



_field_ citations _:`Optional`[`list`[`Citation`]]__= None_¶ 
    
Contains citation information when the model directly quotes, at length, from another source. Can include traditional websites and code repositories. 

_class_ genai.types.CitationMetadataDict¶ 
    
Bases: `TypedDict`
Citation information when the model quotes another source. 

citations _:`Optional`[`list`[`CitationDict`]]_¶ 
    
Contains citation information when the model directly quotes, at length, from another source. Can include traditional websites and code repositories. 

_pydantic model_genai.types.CodeExecutionResult¶ 
    
Bases: `BaseModel`
Result of executing the [ExecutableCode].
Always follows a part containing the [ExecutableCode].
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"CodeExecutionResult",
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"type":"object",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"$defs":{
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `outcome (genai.types.Outcome | None)`
  * `output (str | None)`



_field_ outcome _:`Optional`[`Outcome`]__= None_¶ 
    
Required. Outcome of the code execution. 

_field_ output _:`Optional`[`str`]__= None_¶ 
    
Optional. Contains stdout when code execution is successful, stderr or other description otherwise. 

_class_ genai.types.CodeExecutionResultDict¶ 
    
Bases: `TypedDict`
Result of executing the [ExecutableCode].
Always follows a part containing the [ExecutableCode]. 

outcome _:`Optional`[`Outcome`]_¶ 
    
Required. Outcome of the code execution. 

output _:`Optional`[`str`]_¶ 
    
Optional. Contains stdout when code execution is successful, stderr or other description otherwise. 

_pydantic model_genai.types.ComputeTokensConfig¶ 
    
Bases: `BaseModel`
Optional parameters for computing tokens.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ComputeTokensConfig",
"description":"Optional parameters for computing tokens.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `http_options (genai.types.HttpOptions | None)`



_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_class_ genai.types.ComputeTokensConfigDict¶ 
    
Bases: `TypedDict`
Optional parameters for computing tokens. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

_pydantic model_genai.types.ComputeTokensResponse¶ 
    
Bases: `BaseModel`
Response for computing tokens.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ComputeTokensResponse",
"description":"Response for computing tokens.",
"type":"object",
"properties":{
"tokensInfo":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/TokensInfo"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Lists of tokens info from the input. A ComputeTokensRequest could have multiple instances with a prompt in each instance. We also need to return lists of tokens info for the request with multiple instances.",
"title":"Tokensinfo"
}
},
"$defs":{
"TokensInfo":{
"additionalProperties":false,
"description":"Tokens info with a list of tokens and the corresponding list of token ids.",
"properties":{
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Optional fields for the role from the corresponding Content.",
"title":"Role"
},
"tokenIds":{
"anyOf":[
{
"items":{
"type":"integer"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of token ids from the input.",
"title":"Tokenids"
},
"tokens":{
"anyOf":[
{
"items":{
"format":"base64url",
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of tokens from the input.",
"title":"Tokens"
}
},
"title":"TokensInfo",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `tokens_info (list[genai.types.TokensInfo] | None)`



_field_ tokens_info _:`Optional`[`list`[`TokensInfo`]]__= None_ _(alias 'tokensInfo')_¶ 
    
Lists of tokens info from the input. A ComputeTokensRequest could have multiple instances with a prompt in each instance. We also need to return lists of tokens info for the request with multiple instances. 

_class_ genai.types.ComputeTokensResponseDict¶ 
    
Bases: `TypedDict`
Response for computing tokens. 

tokens_info _:`Optional`[`list`[`TokensInfoDict`]]_¶ 
    
Lists of tokens info from the input. A ComputeTokensRequest could have multiple instances with a prompt in each instance. We also need to return lists of tokens info for the request with multiple instances. 

_pydantic model_genai.types.Content¶ 
    
Bases: `BaseModel`
Contains the multi-part content of a message.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"Content",
"description":"Contains the multi-part content of a message.",
"type":"object",
"properties":{
"parts":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Part"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of parts that constitute a single message. Each part may have\n      a different IANA MIME type.",
"title":"Parts"
},
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role.",
"title":"Role"
}
},
"$defs":{
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `parts (list[genai.types.Part] | None)`
  * `role (str | None)`



_field_ parts _:`Optional`[`list`[`Part`]]__= None_¶ 
    
List of parts that constitute a single message. Each part may have a different IANA MIME type. 

_field_ role _:`Optional`[`str`]__= None_¶ 
    
Optional. The producer of the content. Must be either ‘user’ or ‘model’. Useful to set for multi-turn conversations, otherwise can be empty. If role is not specified, SDK will determine the role. 

_class_ genai.types.ContentDict¶ 
    
Bases: `TypedDict`
Contains the multi-part content of a message. 

parts _:`Optional`[`list`[`PartDict`]]_¶ 
    
List of parts that constitute a single message. Each part may have a different IANA MIME type. 

role _:`Optional`[`str`]_¶ 
    
Optional. The producer of the content. Must be either ‘user’ or ‘model’. Useful to set for multi-turn conversations, otherwise can be empty. If role is not specified, SDK will determine the role. 

_pydantic model_genai.types.ContentEmbedding¶ 
    
Bases: `BaseModel`
The embedding generated from an input content.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ContentEmbedding",
"description":"The embedding generated from an input content.",
"type":"object",
"properties":{
"values":{
"anyOf":[
{
"items":{
"type":"number"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of floats representing an embedding.\n      ",
"title":"Values"
},
"statistics":{
"anyOf":[
{
"$ref":"#/$defs/ContentEmbeddingStatistics"
},
{
"type":"null"
}
],
"default":null,
"description":"Vertex API only. Statistics of the input text associated with this\n      embedding.\n      "
}
},
"$defs":{
"ContentEmbeddingStatistics":{
"additionalProperties":false,
"description":"Statistics of the input text associated with the result of content embedding.",
"properties":{
"truncated":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Vertex API only. If the input text was truncated due to having\n      a length longer than the allowed maximum input.\n      ",
"title":"Truncated"
},
"tokenCount":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Vertex API only. Number of tokens of the input text.\n      ",
"title":"Tokencount"
}
},
"title":"ContentEmbeddingStatistics",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `statistics (genai.types.ContentEmbeddingStatistics | None)`
  * `values (list[float] | None)`



_field_ statistics _:`Optional`[`ContentEmbeddingStatistics`]__= None_¶ 
    
Vertex API only. Statistics of the input text associated with this embedding. 

_field_ values _:`Optional`[`list`[`float`]]__= None_¶ 
    
A list of floats representing an embedding. 

_class_ genai.types.ContentEmbeddingDict¶ 
    
Bases: `TypedDict`
The embedding generated from an input content. 

statistics _:`Optional`[`ContentEmbeddingStatisticsDict`]_¶ 
    
Vertex API only. Statistics of the input text associated with this embedding. 

_pydantic model_genai.types.ContentEmbeddingStatistics¶ 
    
Bases: `BaseModel`
Statistics of the input text associated with the result of content embedding.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ContentEmbeddingStatistics",
"description":"Statistics of the input text associated with the result of content embedding.",
"type":"object",
"properties":{
"truncated":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Vertex API only. If the input text was truncated due to having\n      a length longer than the allowed maximum input.\n      ",
"title":"Truncated"
},
"tokenCount":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Vertex API only. Number of tokens of the input text.\n      ",
"title":"Tokencount"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `token_count (float | None)`
  * `truncated (bool | None)`



_field_ token_count _:`Optional`[`float`]__= None_ _(alias 'tokenCount')_¶ 
    
Vertex API only. Number of tokens of the input text. 

_field_ truncated _:`Optional`[`bool`]__= None_¶ 
    
Vertex API only. If the input text was truncated due to having a length longer than the allowed maximum input. 

_class_ genai.types.ContentEmbeddingStatisticsDict¶ 
    
Bases: `TypedDict`
Statistics of the input text associated with the result of content embedding. 

token_count _:`Optional`[`float`]_¶ 
    
Vertex API only. Number of tokens of the input text. 

truncated _:`Optional`[`bool`]_¶ 
    
Vertex API only. If the input text was truncated due to having a length longer than the allowed maximum input. 

_pydantic model_genai.types.ContextWindowCompressionConfig¶ 
    
Bases: `BaseModel`
Enables context window compression – mechanism managing model context window so it does not exceed given length.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ContextWindowCompressionConfig",
"description":"Enables context window compression -- mechanism managing model context window so it does not exceed given length.",
"type":"object",
"properties":{
"triggerTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens (before running turn) that triggers context window compression mechanism.",
"title":"Triggertokens"
},
"slidingWindow":{
"anyOf":[
{
"$ref":"#/$defs/SlidingWindow"
},
{
"type":"null"
}
],
"default":null,
"description":"Sliding window compression mechanism."
}
},
"$defs":{
"SlidingWindow":{
"additionalProperties":false,
"description":"Context window will be truncated by keeping only suffix of it.\n\nContext window will always be cut at start of USER role turn. System\ninstructions and `BidiGenerateContentSetup.prefix_turns` will not be\nsubject to the sliding window mechanism, they will always stay at the\nbeginning of context window.",
"properties":{
"targetTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Session reduction target -- how many tokens we should keep. Window shortening operation has some latency costs, so we should avoid running it on every turn. Should be < trigger_tokens. If not set, trigger_tokens/2 is assumed.",
"title":"Targettokens"
}
},
"title":"SlidingWindow",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `sliding_window (genai.types.SlidingWindow | None)`
  * `trigger_tokens (int | None)`



_field_ sliding_window _:`Optional`[`SlidingWindow`]__= None_ _(alias 'slidingWindow')_¶ 
    
Sliding window compression mechanism. 

_field_ trigger_tokens _:`Optional`[`int`]__= None_ _(alias 'triggerTokens')_¶ 
    
Number of tokens (before running turn) that triggers context window compression mechanism. 

_class_ genai.types.ContextWindowCompressionConfigDict¶ 
    
Bases: `TypedDict`
Enables context window compression – mechanism managing model context window so it does not exceed given length. 

sliding_window _:`Optional`[`SlidingWindowDict`]_¶ 
    
Sliding window compression mechanism. 

trigger_tokens _:`Optional`[`int`]_¶ 
    
Number of tokens (before running turn) that triggers context window compression mechanism. 

_pydantic model_genai.types.ControlReferenceConfig¶ 
    
Bases: `BaseModel`
Configuration for a Control reference image.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ControlReferenceConfig",
"description":"Configuration for a Control reference image.",
"type":"object",
"properties":{
"controlType":{
"anyOf":[
{
"$ref":"#/$defs/ControlReferenceType"
},
{
"type":"null"
}
],
"default":null,
"description":"The type of control reference image to use."
},
"enableControlImageComputation":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Defaults to False. When set to True, the control image will be\n      computed by the model based on the control type. When set to False,\n      the control image must be provided by the user.",
"title":"Enablecontrolimagecomputation"
}
},
"$defs":{
"ControlReferenceType":{
"description":"Enum representing the control type of a control reference image.",
"enum":[
"CONTROL_TYPE_DEFAULT",
"CONTROL_TYPE_CANNY",
"CONTROL_TYPE_SCRIBBLE",
"CONTROL_TYPE_FACE_MESH"
],
"title":"ControlReferenceType",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `control_type (genai.types.ControlReferenceType | None)`
  * `enable_control_image_computation (bool | None)`



_field_ control_type _:`Optional`[`ControlReferenceType`]__= None_ _(alias 'controlType')_¶ 
    
The type of control reference image to use. 

_field_ enable_control_image_computation _:`Optional`[`bool`]__= None_ _(alias 'enableControlImageComputation')_¶ 
    
Defaults to False. When set to True, the control image will be computed by the model based on the control type. When set to False, the control image must be provided by the user. 

_class_ genai.types.ControlReferenceConfigDict¶ 
    
Bases: `TypedDict`
Configuration for a Control reference image. 

control_type _:`Optional`[`ControlReferenceType`]_¶ 
    
The type of control reference image to use. 

enable_control_image_computation _:`Optional`[`bool`]_¶ 
    
Defaults to False. When set to True, the control image will be computed by the model based on the control type. When set to False, the control image must be provided by the user. 

_pydantic model_genai.types.ControlReferenceImage¶ 
    
Bases: `BaseModel`
A control reference image.
The image of the control reference image is either a control image provided by the user, or a regular image which the backend will use to generate a control image of. In the case of the latter, the enable_control_image_computation field in the config should be set to True.
A control image is an image that represents a sketch image of areas for the model to fill in based on the prompt.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ControlReferenceImage",
"description":"A control reference image.\n\nThe image of the control reference image is either a control image provided\nby the user, or a regular image which the backend will use to generate a\ncontrol image of. In the case of the latter, the\nenable_control_image_computation field in the config should be set to True.\n\nA control image is an image that represents a sketch image of areas for the\nmodel to fill in based on the prompt.",
"type":"object",
"properties":{
"referenceImage":{
"anyOf":[
{
"$ref":"#/$defs/Image"
},
{
"type":"null"
}
],
"default":null,
"description":"The reference image for the editing operation."
},
"referenceId":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the reference image.",
"title":"Referenceid"
},
"referenceType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The type of the reference image. Only set by the SDK.",
"title":"Referencetype"
},
"config":{
"anyOf":[
{
"$ref":"#/$defs/ControlReferenceConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Configuration for the control reference image."
},
"controlImageConfig":{
"anyOf":[
{
"$ref":"#/$defs/ControlReferenceConfig"
},
{
"type":"null"
}
],
"default":null,
"description":""
}
},
"$defs":{
"ControlReferenceConfig":{
"additionalProperties":false,
"description":"Configuration for a Control reference image.",
"properties":{
"controlType":{
"anyOf":[
{
"$ref":"#/$defs/ControlReferenceType"
},
{
"type":"null"
}
],
"default":null,
"description":"The type of control reference image to use."
},
"enableControlImageComputation":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Defaults to False. When set to True, the control image will be\n      computed by the model based on the control type. When set to False,\n      the control image must be provided by the user.",
"title":"Enablecontrolimagecomputation"
}
},
"title":"ControlReferenceConfig",
"type":"object"
},
"ControlReferenceType":{
"description":"Enum representing the control type of a control reference image.",
"enum":[
"CONTROL_TYPE_DEFAULT",
"CONTROL_TYPE_CANNY",
"CONTROL_TYPE_SCRIBBLE",
"CONTROL_TYPE_FACE_MESH"
],
"title":"ControlReferenceType",
"type":"string"
},
"Image":{
"additionalProperties":false,
"description":"An image.",
"properties":{
"gcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The Cloud Storage URI of the image. ``Image`` can contain a value\n      for this field or the ``image_bytes`` field but not both.\n      ",
"title":"Gcsuri"
},
"imageBytes":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The image bytes data. ``Image`` can contain a value for this field\n      or the ``gcs_uri`` field but not both.\n      ",
"title":"Imagebytes"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The MIME type of the image.",
"title":"Mimetype"
}
},
"title":"Image",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `config (genai.types.ControlReferenceConfig | None)`
  * `control_image_config (genai.types.ControlReferenceConfig | None)`
  * `reference_id (int | None)`
  * `reference_image (genai.types.Image | None)`
  * `reference_type (str | None)`



Validators: 
    
  * `_validate_mask_image_config` » `all fields`



_field_ config _:`Optional`[`ControlReferenceConfig`]__= None_¶ 
    
Re-map config to control_reference_config to send to API.
Configuration for the control reference image. 

Validated by: 
    
  * `_validate_mask_image_config`



_field_ control_image_config _:`Optional`[ControlReferenceConfig]__= None_ _(alias 'controlImageConfig')_¶ 
     

Validated by: 
    
  * `_validate_mask_image_config`



_field_ reference_id _:`Optional`[`int`]__= None_ _(alias 'referenceId')_¶ 
    
The id of the reference image. 

Validated by: 
    
  * `_validate_mask_image_config`



_field_ reference_image _:`Optional`[`Image`]__= None_ _(alias 'referenceImage')_¶ 
    
The reference image for the editing operation. 

Validated by: 
    
  * `_validate_mask_image_config`



_field_ reference_type _:`Optional`[`str`]__= None_ _(alias 'referenceType')_¶ 
    
The type of the reference image. Only set by the SDK. 

Validated by: 
    
  * `_validate_mask_image_config`



_class_ genai.types.ControlReferenceImageDict¶ 
    
Bases: `TypedDict`
A control reference image.
The image of the control reference image is either a control image provided by the user, or a regular image which the backend will use to generate a control image of. In the case of the latter, the enable_control_image_computation field in the config should be set to True.
A control image is an image that represents a sketch image of areas for the model to fill in based on the prompt. 

config _:`Optional`[`ControlReferenceConfigDict`]_¶ 
    
Configuration for the control reference image. 

reference_id _:`Optional`[`int`]_¶ 
    
The id of the reference image. 

reference_image _:`Optional`[`ImageDict`]_¶ 
    
The reference image for the editing operation. 

reference_type _:`Optional`[`str`]_¶ 
    
The type of the reference image. Only set by the SDK. 

_class_ genai.types.ControlReferenceType(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Enum representing the control type of a control reference image. 

CONTROL_TYPE_CANNY _= 'CONTROL_TYPE_CANNY'_¶ 


CONTROL_TYPE_DEFAULT _= 'CONTROL_TYPE_DEFAULT'_¶ 


CONTROL_TYPE_FACE_MESH _= 'CONTROL_TYPE_FACE_MESH'_¶ 


CONTROL_TYPE_SCRIBBLE _= 'CONTROL_TYPE_SCRIBBLE'_¶ 


_pydantic model_genai.types.CountTokensConfig¶ 
    
Bases: `BaseModel`
Config for the count_tokens method.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"CountTokensConfig",
"description":"Config for the count_tokens method.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
},
"systemInstruction":{
"anyOf":[
{
"$ref":"#/$defs/Content"
},
{
"items":{
"anyOf":[
{
"$ref":"#/$defs/File"
},
{
"$ref":"#/$defs/Part"
},
{
"type":"string"
}
]
},
"type":"array"
},
{
"$ref":"#/$defs/File"
},
{
"$ref":"#/$defs/Part"
},
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Instructions for the model to steer it toward better performance.\n      ",
"title":"Systeminstruction"
},
"tools":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Tool"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Code that enables the system to interact with external systems to\n      perform an action outside of the knowledge and scope of the model.\n      ",
"title":"Tools"
},
"generationConfig":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Configuration that the model uses to generate the response. Not\n      supported by the Gemini Developer API.\n      "
}
},
"$defs":{
"ApiKeyConfig":{
"additionalProperties":false,
"description":"Config for authentication with API key.",
"properties":{
"apiKeyString":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The API key to be used in the request directly.",
"title":"Apikeystring"
}
},
"title":"ApiKeyConfig",
"type":"object"
},
"AuthConfig":{
"additionalProperties":false,
"description":"Auth configuration to run the extension.",
"properties":{
"apiKeyConfig":{
"anyOf":[
{
"$ref":"#/$defs/ApiKeyConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for API key auth."
},
"authType":{
"anyOf":[
{
"$ref":"#/$defs/AuthType"
},
{
"type":"null"
}
],
"default":null,
"description":"Type of auth scheme."
},
"googleServiceAccountConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigGoogleServiceAccountConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for Google Service Account auth."
},
"httpBasicAuthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigHttpBasicAuthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for HTTP Basic auth."
},
"oauthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOauthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user oauth."
},
"oidcConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOidcConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user OIDC auth."
}
},
"title":"AuthConfig",
"type":"object"
},
"AuthConfigGoogleServiceAccountConfig":{
"additionalProperties":false,
"description":"Config for Google Service Account Authentication.",
"properties":{
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The service account that the extension execution service runs as. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified service account. - If not specified, the Vertex AI Extension Service Agent will be used to execute the Extension.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigGoogleServiceAccountConfig",
"type":"object"
},
"AuthConfigHttpBasicAuthConfig":{
"additionalProperties":false,
"description":"Config for HTTP Basic Authentication.",
"properties":{
"credentialSecret":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the SecretManager secret version resource storing the base64 encoded credentials. Format: `projects/{project}/secrets/{secrete}/versions/{version}` - If specified, the `secretmanager.versions.access` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified resource.",
"title":"Credentialsecret"
}
},
"title":"AuthConfigHttpBasicAuthConfig",
"type":"object"
},
"AuthConfigOauthConfig":{
"additionalProperties":false,
"description":"Config for user oauth.",
"properties":{
"accessToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Access token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Accesstoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate access tokens for executing the Extension. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the provided service account.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOauthConfig",
"type":"object"
},
"AuthConfigOidcConfig":{
"additionalProperties":false,
"description":"Config for user OIDC auth.",
"properties":{
"idToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"OpenID Connect formatted ID token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Idtoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate an OpenID Connect (OIDC)-compatible JWT token signed by the Google OIDC Provider (accounts.google.com) for extension endpoint (https://cloud.google.com/iam/docs/create-short-lived-credentials-direct#sa-credentials-oidc). - The audience for the token will be set to the URL in the server url defined in the OpenApi spec. - If the service account is provided, the service account should grant `iam.serviceAccounts.getOpenIdToken` permission to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOidcConfig",
"type":"object"
},
"AuthType":{
"description":"Type of auth scheme.",
"enum":[
"AUTH_TYPE_UNSPECIFIED",
"NO_AUTH",
"API_KEY_AUTH",
"HTTP_BASIC_AUTH",
"GOOGLE_SERVICE_ACCOUNT_AUTH",
"OAUTH",
"OIDC_AUTH"
],
"title":"AuthType",
"type":"string"
},
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"Content":{
"additionalProperties":false,
"description":"Contains the multi-part content of a message.",
"properties":{
"parts":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Part"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of parts that constitute a single message. Each part may have\n      a different IANA MIME type.",
"title":"Parts"
},
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role.",
"title":"Role"
}
},
"title":"Content",
"type":"object"
},
"DynamicRetrievalConfig":{
"additionalProperties":false,
"description":"Describes the options to customize dynamic retrieval.",
"properties":{
"mode":{
"anyOf":[
{
"$ref":"#/$defs/DynamicRetrievalConfigMode"
},
{
"type":"null"
}
],
"default":null,
"description":"The mode of the predictor to be used in dynamic retrieval."
},
"dynamicThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The threshold to be used in dynamic retrieval. If not set, a system default value is used.",
"title":"Dynamicthreshold"
}
},
"title":"DynamicRetrievalConfig",
"type":"object"
},
"DynamicRetrievalConfigMode":{
"description":"Config for the dynamic retrieval config mode.",
"enum":[
"MODE_UNSPECIFIED",
"MODE_DYNAMIC"
],
"title":"DynamicRetrievalConfigMode",
"type":"string"
},
"EnterpriseWebSearch":{
"additionalProperties":false,
"description":"Tool to search public web data, powered by Vertex AI Search and Sec4 compliance.",
"properties":{},
"title":"EnterpriseWebSearch",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"File":{
"additionalProperties":false,
"description":"A file uploaded to the API.",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The `File` resource name. The ID (name excluding the \"files/\" prefix) can contain up to 40 characters that are lowercase alphanumeric or dashes (-). The ID cannot start or end with a dash. If the name is empty on create, a unique name will be generated. Example: `files/123-456`",
"title":"Name"
},
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The human-readable display name for the `File`. The display name must be no more than 512 characters in length, including spaces. Example: 'Welcome Image'",
"title":"Displayname"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. MIME type of the file.",
"title":"Mimetype"
},
"sizeBytes":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Size of the file in bytes.",
"title":"Sizebytes"
},
"createTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` was created.",
"title":"Createtime"
},
"expirationTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` will be deleted. Only set if the `File` is scheduled to expire.",
"title":"Expirationtime"
},
"updateTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` was last updated.",
"title":"Updatetime"
},
"sha256Hash":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. SHA-256 hash of the uploaded bytes. The hash value is encoded in base64 format.",
"title":"Sha256Hash"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The URI of the `File`.",
"title":"Uri"
},
"downloadUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The URI of the `File`, only set for downloadable (generated) files.",
"title":"Downloaduri"
},
"state":{
"anyOf":[
{
"$ref":"#/$defs/FileState"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Processing state of the File."
},
"source":{
"anyOf":[
{
"$ref":"#/$defs/FileSource"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The source of the `File`."
},
"videoMetadata":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Metadata for a video.",
"title":"Videometadata"
},
"error":{
"anyOf":[
{
"$ref":"#/$defs/FileStatus"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Error status if File processing failed."
}
},
"title":"File",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FileSource":{
"description":"Source of the File.",
"enum":[
"SOURCE_UNSPECIFIED",
"UPLOADED",
"GENERATED"
],
"title":"FileSource",
"type":"string"
},
"FileState":{
"description":"State for the lifecycle of a File.",
"enum":[
"STATE_UNSPECIFIED",
"PROCESSING",
"ACTIVE",
"FAILED"
],
"title":"FileState",
"type":"string"
},
"FileStatus":{
"additionalProperties":false,
"description":"Status of a File that uses a common error model.",
"properties":{
"details":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Details"
},
"message":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Message"
},
"code":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The status code. 0 for OK, 1 for CANCELLED",
"title":"Code"
}
},
"title":"FileStatus",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionDeclaration":{
"additionalProperties":false,
"description":"Structured representation of a function declaration as defined by the [OpenAPI 3.0 specification](https://spec.openapis.org/oas/v3.0.3).\n\nIncluded in this declaration are the function name, description, parameters\nand response type. This FunctionDeclaration is a representation of a block of\ncode that can be used as a `Tool` by the model and executed by the client.",
"properties":{
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Description and purpose of the function. Model uses it to decide how and whether to call the function.",
"title":"Description"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Must start with a letter or an underscore. Must be a-z, A-Z, 0-9, or contain underscores, dots and dashes, with a maximum length of 64.",
"title":"Name"
},
"parameters":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Describes the parameters to this function in JSON Schema Object format. Reflects the Open API 3.03 Parameter Object. string Key: the name of the parameter. Parameter names are case sensitive. Schema Value: the Schema defining the type used for the parameter. For function with no parameters, this can be left unset. Parameter names must start with a letter or an underscore and must only contain chars a-z, A-Z, 0-9, or underscores with a maximum length of 64. Example with 1 required and 1 optional parameter: type: OBJECT properties: param1: type: STRING param2: type: INTEGER required: - param1"
},
"response":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Describes the output from this function in JSON Schema format. Reflects the Open API 3.03 Response Object. The Schema defines the type used for the response value of the function."
}
},
"title":"FunctionDeclaration",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"GenerationConfig":{
"additionalProperties":false,
"description":"Generation config.",
"properties":{
"audioTimestamp":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If enabled, audio timestamp will be included in the request to the model.",
"title":"Audiotimestamp"
},
"candidateCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of candidates to generate.",
"title":"Candidatecount"
},
"frequencyPenalty":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Frequency penalties.",
"title":"Frequencypenalty"
},
"logprobs":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Logit probabilities.",
"title":"Logprobs"
},
"maxOutputTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The maximum number of output tokens to generate per message.",
"title":"Maxoutputtokens"
},
"mediaResolution":{
"anyOf":[
{
"$ref":"#/$defs/MediaResolution"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If specified, the media resolution specified will be used."
},
"presencePenalty":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Positive penalties.",
"title":"Presencepenalty"
},
"responseLogprobs":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If true, export the logprobs results in response.",
"title":"Responselogprobs"
},
"responseMimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Output response mimetype of the generated candidate text. Supported mimetype: - `text/plain`: (default) Text output. - `application/json`: JSON response in the candidates. The model needs to be prompted to output the appropriate response type, otherwise the behavior is undefined. This is a preview feature.",
"title":"Responsemimetype"
},
"responseSchema":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The `Schema` object allows the definition of input and output data types. These types can be objects, but also primitives and arrays. Represents a select subset of an [OpenAPI 3.0 schema object](https://spec.openapis.org/oas/v3.0.3#schema). If set, a compatible response_mime_type must also be set. Compatible mimetypes: `application/json`: Schema for JSON response."
},
"routingConfig":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Routing configuration."
},
"seed":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Seed.",
"title":"Seed"
},
"stopSequences":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Stop sequences.",
"title":"Stopsequences"
},
"temperature":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Controls the randomness of predictions.",
"title":"Temperature"
},
"topK":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If specified, top-k sampling will be used.",
"title":"Topk"
},
"topP":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If specified, nucleus sampling will be used.",
"title":"Topp"
}
},
"title":"GenerationConfig",
"type":"object"
},
"GenerationConfigRoutingConfig":{
"additionalProperties":false,
"description":"The configuration for routing the request to a specific model.",
"properties":{
"autoMode":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfigAutoRoutingMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Automated routing."
},
"manualMode":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfigManualRoutingMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Manual routing."
}
},
"title":"GenerationConfigRoutingConfig",
"type":"object"
},
"GenerationConfigRoutingConfigAutoRoutingMode":{
"additionalProperties":false,
"description":"When automated routing is specified, the routing will be determined by the pretrained routing model and customer provided model routing preference.",
"properties":{
"modelRoutingPreference":{
"anyOf":[
{
"enum":[
"UNKNOWN",
"PRIORITIZE_QUALITY",
"BALANCED",
"PRIORITIZE_COST"
],
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The model routing preference.",
"title":"Modelroutingpreference"
}
},
"title":"GenerationConfigRoutingConfigAutoRoutingMode",
"type":"object"
},
"GenerationConfigRoutingConfigManualRoutingMode":{
"additionalProperties":false,
"description":"When manual routing is set, the specified model will be used directly.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The model name to use. Only the public LLM models are accepted. e.g. 'gemini-1.5-pro-001'.",
"title":"Modelname"
}
},
"title":"GenerationConfigRoutingConfigManualRoutingMode",
"type":"object"
},
"GoogleMaps":{
"additionalProperties":false,
"description":"Tool to support Google Maps in Model.",
"properties":{
"authConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Auth config for the Google Maps tool."
}
},
"title":"GoogleMaps",
"type":"object"
},
"GoogleSearch":{
"additionalProperties":false,
"description":"Tool to support Google Search in Model. Powered by Google.",
"properties":{},
"title":"GoogleSearch",
"type":"object"
},
"GoogleSearchRetrieval":{
"additionalProperties":false,
"description":"Tool to retrieve public web data for grounding, powered by Google.",
"properties":{
"dynamicRetrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/DynamicRetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the dynamic retrieval configuration for the given source."
}
},
"title":"GoogleSearchRetrieval",
"type":"object"
},
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"MediaResolution":{
"description":"The media resolution to use.",
"enum":[
"MEDIA_RESOLUTION_UNSPECIFIED",
"MEDIA_RESOLUTION_LOW",
"MEDIA_RESOLUTION_MEDIUM",
"MEDIA_RESOLUTION_HIGH"
],
"title":"MediaResolution",
"type":"string"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"RagRetrievalConfig":{
"additionalProperties":false,
"description":"Specifies the context retrieval config.",
"properties":{
"filter":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigFilter"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for filters."
},
"hybridSearch":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigHybridSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Hybrid Search."
},
"ranking":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRanking"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for ranking and reranking."
},
"topK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The number of contexts to retrieve.",
"title":"Topk"
}
},
"title":"RagRetrievalConfig",
"type":"object"
},
"RagRetrievalConfigFilter":{
"additionalProperties":false,
"description":"Config for filters.",
"properties":{
"metadataFilter":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. String for metadata filtering.",
"title":"Metadatafilter"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
},
"vectorSimilarityThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector similarity larger than the threshold.",
"title":"Vectorsimilaritythreshold"
}
},
"title":"RagRetrievalConfigFilter",
"type":"object"
},
"RagRetrievalConfigHybridSearch":{
"additionalProperties":false,
"description":"Config for Hybrid Search.",
"properties":{
"alpha":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally.",
"title":"Alpha"
}
},
"title":"RagRetrievalConfigHybridSearch",
"type":"object"
},
"RagRetrievalConfigRanking":{
"additionalProperties":false,
"description":"Config for ranking and reranking.",
"properties":{
"llmRanker":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingLlmRanker"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for LlmRanker."
},
"rankService":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingRankService"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Rank Service."
}
},
"title":"RagRetrievalConfigRanking",
"type":"object"
},
"RagRetrievalConfigRankingLlmRanker":{
"additionalProperties":false,
"description":"Config for LlmRanker.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name used for ranking. Format: `gemini-1.5-pro`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingLlmRanker",
"type":"object"
},
"RagRetrievalConfigRankingRankService":{
"additionalProperties":false,
"description":"Config for Rank Service.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name of the rank service. Format: `semantic-ranker-512@latest`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingRankService",
"type":"object"
},
"Retrieval":{
"additionalProperties":false,
"description":"Defines a retrieval tool that model can call to access external knowledge.",
"properties":{
"disableAttribution":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Deprecated. This option is no longer supported.",
"title":"Disableattribution"
},
"vertexAiSearch":{
"anyOf":[
{
"$ref":"#/$defs/VertexAISearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Set to use data source powered by Vertex AI Search."
},
"vertexRagStore":{
"anyOf":[
{
"$ref":"#/$defs/VertexRagStore"
},
{
"type":"null"
}
],
"default":null,
"description":"Set to use data source powered by Vertex RAG store. User data is uploaded via the VertexRagDataService."
}
},
"title":"Retrieval",
"type":"object"
},
"Schema":{
"additionalProperties":false,
"description":"Schema is used to define the format of input/output data.\n\nRepresents a select subset of an [OpenAPI 3.0 schema\nobject](https://spec.openapis.org/oas/v3.0.3#schema-object). More fields may\nbe added in the future as needed.",
"properties":{
"anyOf":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Schema"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The value should be validated against any (one or more) of the subschemas in the list.",
"title":"Anyof"
},
"default":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Default value of the data.",
"title":"Default"
},
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The description of the data.",
"title":"Description"
},
"enum":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Possible values of the element of primitive type with enum format. Examples: 1. We can define direction as : {type:STRING, format:enum, enum:[\"EAST\", NORTH\", \"SOUTH\", \"WEST\"]} 2. We can define apartment number as : {type:INTEGER, format:enum, enum:[\"101\", \"201\", \"301\"]}",
"title":"Enum"
},
"example":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Example of the object. Will only populated when the object is the root.",
"title":"Example"
},
"format":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The format of the data. Supported formats: for NUMBER type: \"float\", \"double\" for INTEGER type: \"int32\", \"int64\" for STRING type: \"email\", \"byte\", etc",
"title":"Format"
},
"items":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE ARRAY Schema of the elements of Type.ARRAY."
},
"maxItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the elements for Type.ARRAY.",
"title":"Maxitems"
},
"maxLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum length of the Type.STRING",
"title":"Maxlength"
},
"maxProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the properties for Type.OBJECT.",
"title":"Maxproperties"
},
"maximum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum value of the Type.INTEGER and Type.NUMBER",
"title":"Maximum"
},
"minItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the elements for Type.ARRAY.",
"title":"Minitems"
},
"minLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING",
"title":"Minlength"
},
"minProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the properties for Type.OBJECT.",
"title":"Minproperties"
},
"minimum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER Minimum value of the Type.INTEGER and Type.NUMBER",
"title":"Minimum"
},
"nullable":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Indicates if the value may be null.",
"title":"Nullable"
},
"pattern":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Pattern of the Type.STRING to restrict a string to a regular expression.",
"title":"Pattern"
},
"properties":{
"anyOf":[
{
"additionalProperties":{
"$ref":"#/$defs/Schema"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE OBJECT Properties of Type.OBJECT.",
"title":"Properties"
},
"propertyOrdering":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The order of the properties. Not a standard field in open api spec. Only used to support the order of the properties.",
"title":"Propertyordering"
},
"required":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required properties of Type.OBJECT.",
"title":"Required"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The title of the Schema.",
"title":"Title"
},
"type":{
"anyOf":[
{
"$ref":"#/$defs/Type"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The type of the data."
}
},
"title":"Schema",
"type":"object"
},
"Tool":{
"additionalProperties":false,
"description":"Tool details of a tool that the model may use to generate a response.",
"properties":{
"retrieval":{
"anyOf":[
{
"$ref":"#/$defs/Retrieval"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Retrieval tool type. System will always execute the provided retrieval tool(s) to get external knowledge to answer the prompt. Retrieval results are presented to the model for generation."
},
"googleSearch":{
"anyOf":[
{
"$ref":"#/$defs/GoogleSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google Search tool type. Specialized retrieval tool\n      that is powered by Google Search."
},
"googleSearchRetrieval":{
"anyOf":[
{
"$ref":"#/$defs/GoogleSearchRetrieval"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. GoogleSearchRetrieval tool type. Specialized retrieval tool that is powered by Google search."
},
"enterpriseWebSearch":{
"anyOf":[
{
"$ref":"#/$defs/EnterpriseWebSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Enterprise web search tool type. Specialized retrieval\n      tool that is powered by Vertex AI Search and Sec4 compliance."
},
"googleMaps":{
"anyOf":[
{
"$ref":"#/$defs/GoogleMaps"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google Maps tool type. Specialized retrieval tool\n      that is powered by Google Maps."
},
"codeExecution":{
"anyOf":[
{
"$ref":"#/$defs/ToolCodeExecution"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. CodeExecution tool type. Enables the model to execute code as part of generation. This field is only used by the Gemini Developer API services."
},
"functionDeclarations":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/FunctionDeclaration"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Function tool type. One or more function declarations to be passed to the model along with the current user query. Model may decide to call a subset of these functions by populating FunctionCall in the response. User should provide a FunctionResponse for each function call in the next turn. Based on the function responses, Model will generate the final response back to the user. Maximum 128 function declarations can be provided.",
"title":"Functiondeclarations"
}
},
"title":"Tool",
"type":"object"
},
"ToolCodeExecution":{
"additionalProperties":false,
"description":"Tool that executes code generated by the model, and automatically returns the result to the model.\n\nSee also [ExecutableCode]and [CodeExecutionResult] which are input and output\nto this tool.",
"properties":{},
"title":"ToolCodeExecution",
"type":"object"
},
"Type":{
"description":"Optional. The type of the data.",
"enum":[
"TYPE_UNSPECIFIED",
"STRING",
"NUMBER",
"INTEGER",
"BOOLEAN",
"ARRAY",
"OBJECT"
],
"title":"Type",
"type":"string"
},
"VertexAISearch":{
"additionalProperties":false,
"description":"Retrieve from Vertex AI Search datastore or engine for grounding.\n\ndatastore and engine are mutually exclusive. See\nhttps://cloud.google.com/products/agent-builder",
"properties":{
"datastore":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search data store resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`",
"title":"Datastore"
},
"engine":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search engine resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}`",
"title":"Engine"
}
},
"title":"VertexAISearch",
"type":"object"
},
"VertexRagStore":{
"additionalProperties":false,
"description":"Retrieve from Vertex RAG Store for grounding.",
"properties":{
"ragCorpora":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Deprecated. Please use rag_resources instead.",
"title":"Ragcorpora"
},
"ragResources":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/VertexRagStoreRagResource"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The representation of the rag source. It can be used to specify corpus only or ragfiles. Currently only support one corpus or multiple files from one corpus. In the future we may open up multiple corpora support.",
"title":"Ragresources"
},
"ragRetrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The retrieval config for the Rag query."
},
"similarityTopK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of top k results to return from the selected corpora.",
"title":"Similaritytopk"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only return results with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
}
},
"title":"VertexRagStore",
"type":"object"
},
"VertexRagStoreRagResource":{
"additionalProperties":false,
"description":"The definition of the Rag resource.",
"properties":{
"ragCorpus":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. RagCorpora resource name. Format: `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`",
"title":"Ragcorpus"
},
"ragFileIds":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus field.",
"title":"Ragfileids"
}
},
"title":"VertexRagStoreRagResource",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `generation_config (genai.types.GenerationConfig | None)`
  * `http_options (genai.types.HttpOptions | None)`
  * `system_instruction (genai.types.Content | list[genai.types.File | genai.types.Part | PIL.Image.Image | str] | genai.types.File | genai.types.Part | PIL.Image.Image | str | None)`
  * `tools (list[genai.types.Tool] | None)`



_field_ generation_config _:`Optional`[`GenerationConfig`]__= None_ _(alias 'generationConfig')_¶ 
    
Configuration that the model uses to generate the response. Not supported by the Gemini Developer API. 

_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_field_ system_instruction _:`Union`[`Content`, `list`[`Union`[`File`, `Part`, `Image`, `str`]], `File`, `Part`, `Image`, `str`, `None`]__= None_ _(alias 'systemInstruction')_¶ 
    
Instructions for the model to steer it toward better performance. 

_field_ tools _:`Optional`[`list`[`Tool`]]__= None_¶ 
    
Code that enables the system to interact with external systems to perform an action outside of the knowledge and scope of the model. 

_class_ genai.types.CountTokensConfigDict¶ 
    
Bases: `TypedDict`
Config for the count_tokens method. 

generation_config _:`Optional`[`GenerationConfigDict`]_¶ 
    
Configuration that the model uses to generate the response. Not supported by the Gemini Developer API. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

system_instruction _:`Union`[`Content`, `list`[`Union`[`File`, `Part`, `Image`, `str`]], `File`, `Part`, `Image`, `str`, `ContentDict`, `None`]_¶ 
    
Instructions for the model to steer it toward better performance. 

tools _:`Optional`[`list`[`ToolDict`]]_¶ 
    
Code that enables the system to interact with external systems to perform an action outside of the knowledge and scope of the model. 

_pydantic model_genai.types.CountTokensResponse¶ 
    
Bases: `BaseModel`
Response for counting tokens.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"CountTokensResponse",
"description":"Response for counting tokens.",
"type":"object",
"properties":{
"totalTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Total number of tokens.",
"title":"Totaltokens"
},
"cachedContentTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens in the cached part of the prompt (the cached content).",
"title":"Cachedcontenttokencount"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `cached_content_token_count (int | None)`
  * `total_tokens (int | None)`



_field_ cached_content_token_count _:`Optional`[`int`]__= None_ _(alias 'cachedContentTokenCount')_¶ 
    
Number of tokens in the cached part of the prompt (the cached content). 

_field_ total_tokens _:`Optional`[`int`]__= None_ _(alias 'totalTokens')_¶ 
    
Total number of tokens. 

_class_ genai.types.CountTokensResponseDict¶ 
    
Bases: `TypedDict`
Response for counting tokens. 

cached_content_token_count _:`Optional`[`int`]_¶ 
    
Number of tokens in the cached part of the prompt (the cached content). 

total_tokens _:`Optional`[`int`]_¶ 
    
Total number of tokens. 

_pydantic model_genai.types.CreateBatchJobConfig¶ 
    
Bases: `BaseModel`
Config for optional parameters.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"CreateBatchJobConfig",
"description":"Config for optional parameters.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
},
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The user-defined name of this BatchJob.\n      ",
"title":"Displayname"
},
"dest":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"GCS or BigQuery URI prefix for the output predictions. Example:\n      \"gs://path/to/output/data\" or \"bq://projectId.bqDatasetId.bqTableId\".\n      ",
"title":"Dest"
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `dest (str | None)`
  * `display_name (str | None)`
  * `http_options (genai.types.HttpOptions | None)`



_field_ dest _:`Optional`[`str`]__= None_¶ 
    
GCS or BigQuery URI prefix for the output predictions. Example: “gs://path/to/output/data” or “bq://projectId.bqDatasetId.bqTableId”. 

_field_ display_name _:`Optional`[`str`]__= None_ _(alias 'displayName')_¶ 
    
The user-defined name of this BatchJob. 

_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_class_ genai.types.CreateBatchJobConfigDict¶ 
    
Bases: `TypedDict`
Config for optional parameters. 

dest _:`Optional`[`str`]_¶ 
    
GCS or BigQuery URI prefix for the output predictions. Example: “gs://path/to/output/data” or “bq://projectId.bqDatasetId.bqTableId”. 

display_name _:`Optional`[`str`]_¶ 
    
The user-defined name of this BatchJob. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

_pydantic model_genai.types.CreateCachedContentConfig¶ 
    
Bases: `BaseModel`
Optional configuration for cached content creation.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"CreateCachedContentConfig",
"description":"Optional configuration for cached content creation.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
},
"ttl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The TTL for this resource. The expiration time is computed: now + TTL. It is a duration string, with up to nine fractional digits, terminated by 's'. Example: \"3.5s\".",
"title":"Ttl"
},
"expireTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Timestamp of when this resource is considered expired. Uses RFC 3339 format, Example: 2014-10-02T15:01:23Z.",
"title":"Expiretime"
},
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The user-generated meaningful display name of the cached content.\n      ",
"title":"Displayname"
},
"contents":{
"anyOf":[
{
"items":{
"anyOf":[
{
"$ref":"#/$defs/Content"
},
{
"items":{
"anyOf":[
{
"$ref":"#/$defs/File"
},
{
"$ref":"#/$defs/Part"
},
{
"type":"string"
}
]
},
"type":"array"
},
{
"$ref":"#/$defs/File"
},
{
"$ref":"#/$defs/Part"
},
{
"type":"string"
}
]
},
"type":"array"
},
{
"$ref":"#/$defs/Content"
},
{
"items":{
"anyOf":[
{
"$ref":"#/$defs/File"
},
{
"$ref":"#/$defs/Part"
},
{
"type":"string"
}
]
},
"type":"array"
},
{
"$ref":"#/$defs/File"
},
{
"$ref":"#/$defs/Part"
},
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The content to cache.\n      ",
"title":"Contents"
},
"systemInstruction":{
"anyOf":[
{
"$ref":"#/$defs/Content"
},
{
"items":{
"anyOf":[
{
"$ref":"#/$defs/File"
},
{
"$ref":"#/$defs/Part"
},
{
"type":"string"
}
]
},
"type":"array"
},
{
"$ref":"#/$defs/File"
},
{
"$ref":"#/$defs/Part"
},
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Developer set system instruction.\n      ",
"title":"Systeminstruction"
},
"tools":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Tool"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of `Tools` the model may use to generate the next response.\n      ",
"title":"Tools"
},
"toolConfig":{
"anyOf":[
{
"$ref":"#/$defs/ToolConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Configuration for the tools to use. This config is shared for all tools.\n      "
}
},
"$defs":{
"ApiKeyConfig":{
"additionalProperties":false,
"description":"Config for authentication with API key.",
"properties":{
"apiKeyString":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The API key to be used in the request directly.",
"title":"Apikeystring"
}
},
"title":"ApiKeyConfig",
"type":"object"
},
"AuthConfig":{
"additionalProperties":false,
"description":"Auth configuration to run the extension.",
"properties":{
"apiKeyConfig":{
"anyOf":[
{
"$ref":"#/$defs/ApiKeyConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for API key auth."
},
"authType":{
"anyOf":[
{
"$ref":"#/$defs/AuthType"
},
{
"type":"null"
}
],
"default":null,
"description":"Type of auth scheme."
},
"googleServiceAccountConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigGoogleServiceAccountConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for Google Service Account auth."
},
"httpBasicAuthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigHttpBasicAuthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for HTTP Basic auth."
},
"oauthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOauthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user oauth."
},
"oidcConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOidcConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user OIDC auth."
}
},
"title":"AuthConfig",
"type":"object"
},
"AuthConfigGoogleServiceAccountConfig":{
"additionalProperties":false,
"description":"Config for Google Service Account Authentication.",
"properties":{
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The service account that the extension execution service runs as. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified service account. - If not specified, the Vertex AI Extension Service Agent will be used to execute the Extension.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigGoogleServiceAccountConfig",
"type":"object"
},
"AuthConfigHttpBasicAuthConfig":{
"additionalProperties":false,
"description":"Config for HTTP Basic Authentication.",
"properties":{
"credentialSecret":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the SecretManager secret version resource storing the base64 encoded credentials. Format: `projects/{project}/secrets/{secrete}/versions/{version}` - If specified, the `secretmanager.versions.access` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified resource.",
"title":"Credentialsecret"
}
},
"title":"AuthConfigHttpBasicAuthConfig",
"type":"object"
},
"AuthConfigOauthConfig":{
"additionalProperties":false,
"description":"Config for user oauth.",
"properties":{
"accessToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Access token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Accesstoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate access tokens for executing the Extension. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the provided service account.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOauthConfig",
"type":"object"
},
"AuthConfigOidcConfig":{
"additionalProperties":false,
"description":"Config for user OIDC auth.",
"properties":{
"idToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"OpenID Connect formatted ID token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Idtoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate an OpenID Connect (OIDC)-compatible JWT token signed by the Google OIDC Provider (accounts.google.com) for extension endpoint (https://cloud.google.com/iam/docs/create-short-lived-credentials-direct#sa-credentials-oidc). - The audience for the token will be set to the URL in the server url defined in the OpenApi spec. - If the service account is provided, the service account should grant `iam.serviceAccounts.getOpenIdToken` permission to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOidcConfig",
"type":"object"
},
"AuthType":{
"description":"Type of auth scheme.",
"enum":[
"AUTH_TYPE_UNSPECIFIED",
"NO_AUTH",
"API_KEY_AUTH",
"HTTP_BASIC_AUTH",
"GOOGLE_SERVICE_ACCOUNT_AUTH",
"OAUTH",
"OIDC_AUTH"
],
"title":"AuthType",
"type":"string"
},
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"Content":{
"additionalProperties":false,
"description":"Contains the multi-part content of a message.",
"properties":{
"parts":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Part"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of parts that constitute a single message. Each part may have\n      a different IANA MIME type.",
"title":"Parts"
},
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role.",
"title":"Role"
}
},
"title":"Content",
"type":"object"
},
"DynamicRetrievalConfig":{
"additionalProperties":false,
"description":"Describes the options to customize dynamic retrieval.",
"properties":{
"mode":{
"anyOf":[
{
"$ref":"#/$defs/DynamicRetrievalConfigMode"
},
{
"type":"null"
}
],
"default":null,
"description":"The mode of the predictor to be used in dynamic retrieval."
},
"dynamicThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The threshold to be used in dynamic retrieval. If not set, a system default value is used.",
"title":"Dynamicthreshold"
}
},
"title":"DynamicRetrievalConfig",
"type":"object"
},
"DynamicRetrievalConfigMode":{
"description":"Config for the dynamic retrieval config mode.",
"enum":[
"MODE_UNSPECIFIED",
"MODE_DYNAMIC"
],
"title":"DynamicRetrievalConfigMode",
"type":"string"
},
"EnterpriseWebSearch":{
"additionalProperties":false,
"description":"Tool to search public web data, powered by Vertex AI Search and Sec4 compliance.",
"properties":{},
"title":"EnterpriseWebSearch",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"File":{
"additionalProperties":false,
"description":"A file uploaded to the API.",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The `File` resource name. The ID (name excluding the \"files/\" prefix) can contain up to 40 characters that are lowercase alphanumeric or dashes (-). The ID cannot start or end with a dash. If the name is empty on create, a unique name will be generated. Example: `files/123-456`",
"title":"Name"
},
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The human-readable display name for the `File`. The display name must be no more than 512 characters in length, including spaces. Example: 'Welcome Image'",
"title":"Displayname"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. MIME type of the file.",
"title":"Mimetype"
},
"sizeBytes":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Size of the file in bytes.",
"title":"Sizebytes"
},
"createTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` was created.",
"title":"Createtime"
},
"expirationTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` will be deleted. Only set if the `File` is scheduled to expire.",
"title":"Expirationtime"
},
"updateTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` was last updated.",
"title":"Updatetime"
},
"sha256Hash":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. SHA-256 hash of the uploaded bytes. The hash value is encoded in base64 format.",
"title":"Sha256Hash"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The URI of the `File`.",
"title":"Uri"
},
"downloadUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The URI of the `File`, only set for downloadable (generated) files.",
"title":"Downloaduri"
},
"state":{
"anyOf":[
{
"$ref":"#/$defs/FileState"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Processing state of the File."
},
"source":{
"anyOf":[
{
"$ref":"#/$defs/FileSource"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The source of the `File`."
},
"videoMetadata":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Metadata for a video.",
"title":"Videometadata"
},
"error":{
"anyOf":[
{
"$ref":"#/$defs/FileStatus"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Error status if File processing failed."
}
},
"title":"File",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FileSource":{
"description":"Source of the File.",
"enum":[
"SOURCE_UNSPECIFIED",
"UPLOADED",
"GENERATED"
],
"title":"FileSource",
"type":"string"
},
"FileState":{
"description":"State for the lifecycle of a File.",
"enum":[
"STATE_UNSPECIFIED",
"PROCESSING",
"ACTIVE",
"FAILED"
],
"title":"FileState",
"type":"string"
},
"FileStatus":{
"additionalProperties":false,
"description":"Status of a File that uses a common error model.",
"properties":{
"details":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Details"
},
"message":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Message"
},
"code":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The status code. 0 for OK, 1 for CANCELLED",
"title":"Code"
}
},
"title":"FileStatus",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionCallingConfig":{
"additionalProperties":false,
"description":"Function calling config.",
"properties":{
"mode":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCallingConfigMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Function calling mode."
},
"allowedFunctionNames":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Function names to call. Only set when the Mode is ANY. Function names should match [FunctionDeclaration.name]. With mode set to ANY, model will predict a function call from the set of function names provided.",
"title":"Allowedfunctionnames"
}
},
"title":"FunctionCallingConfig",
"type":"object"
},
"FunctionCallingConfigMode":{
"description":"Config for the function calling config mode.",
"enum":[
"MODE_UNSPECIFIED",
"AUTO",
"ANY",
"NONE"
],
"title":"FunctionCallingConfigMode",
"type":"string"
},
"FunctionDeclaration":{
"additionalProperties":false,
"description":"Structured representation of a function declaration as defined by the [OpenAPI 3.0 specification](https://spec.openapis.org/oas/v3.0.3).\n\nIncluded in this declaration are the function name, description, parameters\nand response type. This FunctionDeclaration is a representation of a block of\ncode that can be used as a `Tool` by the model and executed by the client.",
"properties":{
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Description and purpose of the function. Model uses it to decide how and whether to call the function.",
"title":"Description"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Must start with a letter or an underscore. Must be a-z, A-Z, 0-9, or contain underscores, dots and dashes, with a maximum length of 64.",
"title":"Name"
},
"parameters":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Describes the parameters to this function in JSON Schema Object format. Reflects the Open API 3.03 Parameter Object. string Key: the name of the parameter. Parameter names are case sensitive. Schema Value: the Schema defining the type used for the parameter. For function with no parameters, this can be left unset. Parameter names must start with a letter or an underscore and must only contain chars a-z, A-Z, 0-9, or underscores with a maximum length of 64. Example with 1 required and 1 optional parameter: type: OBJECT properties: param1: type: STRING param2: type: INTEGER required: - param1"
},
"response":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Describes the output from this function in JSON Schema format. Reflects the Open API 3.03 Response Object. The Schema defines the type used for the response value of the function."
}
},
"title":"FunctionDeclaration",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"GoogleMaps":{
"additionalProperties":false,
"description":"Tool to support Google Maps in Model.",
"properties":{
"authConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Auth config for the Google Maps tool."
}
},
"title":"GoogleMaps",
"type":"object"
},
"GoogleSearch":{
"additionalProperties":false,
"description":"Tool to support Google Search in Model. Powered by Google.",
"properties":{},
"title":"GoogleSearch",
"type":"object"
},
"GoogleSearchRetrieval":{
"additionalProperties":false,
"description":"Tool to retrieve public web data for grounding, powered by Google.",
"properties":{
"dynamicRetrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/DynamicRetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the dynamic retrieval configuration for the given source."
}
},
"title":"GoogleSearchRetrieval",
"type":"object"
},
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"LatLng":{
"additionalProperties":false,
"description":"An object that represents a latitude/longitude pair.\n\nThis is expressed as a pair of doubles to represent degrees latitude and\ndegrees longitude. Unless specified otherwise, this object must conform to the\n<a href=\"https://en.wikipedia.org/wiki/World_Geodetic_System#1984_version\">\nWGS84 standard</a>. Values must be within normalized ranges.",
"properties":{
"latitude":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"The latitude in degrees. It must be in the range [-90.0, +90.0].",
"title":"Latitude"
},
"longitude":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"The longitude in degrees. It must be in the range [-180.0, +180.0]",
"title":"Longitude"
}
},
"title":"LatLng",
"type":"object"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"RagRetrievalConfig":{
"additionalProperties":false,
"description":"Specifies the context retrieval config.",
"properties":{
"filter":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigFilter"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for filters."
},
"hybridSearch":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigHybridSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Hybrid Search."
},
"ranking":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRanking"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for ranking and reranking."
},
"topK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The number of contexts to retrieve.",
"title":"Topk"
}
},
"title":"RagRetrievalConfig",
"type":"object"
},
"RagRetrievalConfigFilter":{
"additionalProperties":false,
"description":"Config for filters.",
"properties":{
"metadataFilter":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. String for metadata filtering.",
"title":"Metadatafilter"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
},
"vectorSimilarityThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector similarity larger than the threshold.",
"title":"Vectorsimilaritythreshold"
}
},
"title":"RagRetrievalConfigFilter",
"type":"object"
},
"RagRetrievalConfigHybridSearch":{
"additionalProperties":false,
"description":"Config for Hybrid Search.",
"properties":{
"alpha":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally.",
"title":"Alpha"
}
},
"title":"RagRetrievalConfigHybridSearch",
"type":"object"
},
"RagRetrievalConfigRanking":{
"additionalProperties":false,
"description":"Config for ranking and reranking.",
"properties":{
"llmRanker":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingLlmRanker"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for LlmRanker."
},
"rankService":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingRankService"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Rank Service."
}
},
"title":"RagRetrievalConfigRanking",
"type":"object"
},
"RagRetrievalConfigRankingLlmRanker":{
"additionalProperties":false,
"description":"Config for LlmRanker.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name used for ranking. Format: `gemini-1.5-pro`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingLlmRanker",
"type":"object"
},
"RagRetrievalConfigRankingRankService":{
"additionalProperties":false,
"description":"Config for Rank Service.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name of the rank service. Format: `semantic-ranker-512@latest`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingRankService",
"type":"object"
},
"Retrieval":{
"additionalProperties":false,
"description":"Defines a retrieval tool that model can call to access external knowledge.",
"properties":{
"disableAttribution":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Deprecated. This option is no longer supported.",
"title":"Disableattribution"
},
"vertexAiSearch":{
"anyOf":[
{
"$ref":"#/$defs/VertexAISearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Set to use data source powered by Vertex AI Search."
},
"vertexRagStore":{
"anyOf":[
{
"$ref":"#/$defs/VertexRagStore"
},
{
"type":"null"
}
],
"default":null,
"description":"Set to use data source powered by Vertex RAG store. User data is uploaded via the VertexRagDataService."
}
},
"title":"Retrieval",
"type":"object"
},
"RetrievalConfig":{
"additionalProperties":false,
"description":"Retrieval config.",
"properties":{
"latLng":{
"anyOf":[
{
"$ref":"#/$defs/LatLng"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The location of the user."
}
},
"title":"RetrievalConfig",
"type":"object"
},
"Schema":{
"additionalProperties":false,
"description":"Schema is used to define the format of input/output data.\n\nRepresents a select subset of an [OpenAPI 3.0 schema\nobject](https://spec.openapis.org/oas/v3.0.3#schema-object). More fields may\nbe added in the future as needed.",
"properties":{
"anyOf":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Schema"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The value should be validated against any (one or more) of the subschemas in the list.",
"title":"Anyof"
},
"default":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Default value of the data.",
"title":"Default"
},
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The description of the data.",
"title":"Description"
},
"enum":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Possible values of the element of primitive type with enum format. Examples: 1. We can define direction as : {type:STRING, format:enum, enum:[\"EAST\", NORTH\", \"SOUTH\", \"WEST\"]} 2. We can define apartment number as : {type:INTEGER, format:enum, enum:[\"101\", \"201\", \"301\"]}",
"title":"Enum"
},
"example":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Example of the object. Will only populated when the object is the root.",
"title":"Example"
},
"format":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The format of the data. Supported formats: for NUMBER type: \"float\", \"double\" for INTEGER type: \"int32\", \"int64\" for STRING type: \"email\", \"byte\", etc",
"title":"Format"
},
"items":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE ARRAY Schema of the elements of Type.ARRAY."
},
"maxItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the elements for Type.ARRAY.",
"title":"Maxitems"
},
"maxLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum length of the Type.STRING",
"title":"Maxlength"
},
"maxProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the properties for Type.OBJECT.",
"title":"Maxproperties"
},
"maximum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum value of the Type.INTEGER and Type.NUMBER",
"title":"Maximum"
},
"minItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the elements for Type.ARRAY.",
"title":"Minitems"
},
"minLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING",
"title":"Minlength"
},
"minProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the properties for Type.OBJECT.",
"title":"Minproperties"
},
"minimum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER Minimum value of the Type.INTEGER and Type.NUMBER",
"title":"Minimum"
},
"nullable":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Indicates if the value may be null.",
"title":"Nullable"
},
"pattern":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Pattern of the Type.STRING to restrict a string to a regular expression.",
"title":"Pattern"
},
"properties":{
"anyOf":[
{
"additionalProperties":{
"$ref":"#/$defs/Schema"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE OBJECT Properties of Type.OBJECT.",
"title":"Properties"
},
"propertyOrdering":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The order of the properties. Not a standard field in open api spec. Only used to support the order of the properties.",
"title":"Propertyordering"
},
"required":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required properties of Type.OBJECT.",
"title":"Required"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The title of the Schema.",
"title":"Title"
},
"type":{
"anyOf":[
{
"$ref":"#/$defs/Type"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The type of the data."
}
},
"title":"Schema",
"type":"object"
},
"Tool":{
"additionalProperties":false,
"description":"Tool details of a tool that the model may use to generate a response.",
"properties":{
"retrieval":{
"anyOf":[
{
"$ref":"#/$defs/Retrieval"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Retrieval tool type. System will always execute the provided retrieval tool(s) to get external knowledge to answer the prompt. Retrieval results are presented to the model for generation."
},
"googleSearch":{
"anyOf":[
{
"$ref":"#/$defs/GoogleSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google Search tool type. Specialized retrieval tool\n      that is powered by Google Search."
},
"googleSearchRetrieval":{
"anyOf":[
{
"$ref":"#/$defs/GoogleSearchRetrieval"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. GoogleSearchRetrieval tool type. Specialized retrieval tool that is powered by Google search."
},
"enterpriseWebSearch":{
"anyOf":[
{
"$ref":"#/$defs/EnterpriseWebSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Enterprise web search tool type. Specialized retrieval\n      tool that is powered by Vertex AI Search and Sec4 compliance."
},
"googleMaps":{
"anyOf":[
{
"$ref":"#/$defs/GoogleMaps"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google Maps tool type. Specialized retrieval tool\n      that is powered by Google Maps."
},
"codeExecution":{
"anyOf":[
{
"$ref":"#/$defs/ToolCodeExecution"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. CodeExecution tool type. Enables the model to execute code as part of generation. This field is only used by the Gemini Developer API services."
},
"functionDeclarations":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/FunctionDeclaration"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Function tool type. One or more function declarations to be passed to the model along with the current user query. Model may decide to call a subset of these functions by populating FunctionCall in the response. User should provide a FunctionResponse for each function call in the next turn. Based on the function responses, Model will generate the final response back to the user. Maximum 128 function declarations can be provided.",
"title":"Functiondeclarations"
}
},
"title":"Tool",
"type":"object"
},
"ToolCodeExecution":{
"additionalProperties":false,
"description":"Tool that executes code generated by the model, and automatically returns the result to the model.\n\nSee also [ExecutableCode]and [CodeExecutionResult] which are input and output\nto this tool.",
"properties":{},
"title":"ToolCodeExecution",
"type":"object"
},
"ToolConfig":{
"additionalProperties":false,
"description":"Tool config.\n\nThis config is shared for all tools provided in the request.",
"properties":{
"functionCallingConfig":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCallingConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Function calling config."
},
"retrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/RetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Retrieval config."
}
},
"title":"ToolConfig",
"type":"object"
},
"Type":{
"description":"Optional. The type of the data.",
"enum":[
"TYPE_UNSPECIFIED",
"STRING",
"NUMBER",
"INTEGER",
"BOOLEAN",
"ARRAY",
"OBJECT"
],
"title":"Type",
"type":"string"
},
"VertexAISearch":{
"additionalProperties":false,
"description":"Retrieve from Vertex AI Search datastore or engine for grounding.\n\ndatastore and engine are mutually exclusive. See\nhttps://cloud.google.com/products/agent-builder",
"properties":{
"datastore":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search data store resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`",
"title":"Datastore"
},
"engine":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search engine resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}`",
"title":"Engine"
}
},
"title":"VertexAISearch",
"type":"object"
},
"VertexRagStore":{
"additionalProperties":false,
"description":"Retrieve from Vertex RAG Store for grounding.",
"properties":{
"ragCorpora":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Deprecated. Please use rag_resources instead.",
"title":"Ragcorpora"
},
"ragResources":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/VertexRagStoreRagResource"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The representation of the rag source. It can be used to specify corpus only or ragfiles. Currently only support one corpus or multiple files from one corpus. In the future we may open up multiple corpora support.",
"title":"Ragresources"
},
"ragRetrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The retrieval config for the Rag query."
},
"similarityTopK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of top k results to return from the selected corpora.",
"title":"Similaritytopk"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only return results with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
}
},
"title":"VertexRagStore",
"type":"object"
},
"VertexRagStoreRagResource":{
"additionalProperties":false,
"description":"The definition of the Rag resource.",
"properties":{
"ragCorpus":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. RagCorpora resource name. Format: `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`",
"title":"Ragcorpus"
},
"ragFileIds":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus field.",
"title":"Ragfileids"
}
},
"title":"VertexRagStoreRagResource",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `contents (list[genai.types.Content | list[genai.types.File | genai.types.Part | PIL.Image.Image | str] | genai.types.File | genai.types.Part | PIL.Image.Image | str] | genai.types.Content | list[genai.types.File | genai.types.Part | PIL.Image.Image | str] | genai.types.File | genai.types.Part | PIL.Image.Image | str | None)`
  * `display_name (str | None)`
  * `expire_time (datetime.datetime | None)`
  * `http_options (genai.types.HttpOptions | None)`
  * `system_instruction (genai.types.Content | list[genai.types.File | genai.types.Part | PIL.Image.Image | str] | genai.types.File | genai.types.Part | PIL.Image.Image | str | None)`
  * `tool_config (genai.types.ToolConfig | None)`
  * `tools (list[genai.types.Tool] | None)`
  * `ttl (str | None)`



_field_ contents _:`Union`[`list`[`Union`[`Content`, `list`[`Union`[`File`, `Part`, `Image`, `str`]], `File`, `Part`, `Image`, `str`]], `Content`, `list`[`Union`[`File`, `Part`, `Image`, `str`]], `File`, `Part`, `Image`, `str`, `None`]__= None_¶ 
    
The content to cache. 

_field_ display_name _:`Optional`[`str`]__= None_ _(alias 'displayName')_¶ 
    
The user-generated meaningful display name of the cached content. 

_field_ expire_time _:`Optional`[`datetime`]__= None_ _(alias 'expireTime')_¶ 
    
Timestamp of when this resource is considered expired. Uses RFC 3339 format, Example: 2014-10-02T15:01:23Z. 

_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_field_ system_instruction _:`Union`[`Content`, `list`[`Union`[`File`, `Part`, `Image`, `str`]], `File`, `Part`, `Image`, `str`, `None`]__= None_ _(alias 'systemInstruction')_¶ 
    
Developer set system instruction. 

_field_ tool_config _:`Optional`[`ToolConfig`]__= None_ _(alias 'toolConfig')_¶ 
    
Configuration for the tools to use. This config is shared for all tools. 

_field_ tools _:`Optional`[`list`[`Tool`]]__= None_¶ 
    
A list of Tools the model may use to generate the next response. 

_field_ ttl _:`Optional`[`str`]__= None_¶ 
    
The TTL for this resource. The expiration time is computed: now + TTL. It is a duration string, with up to nine fractional digits, terminated by ‘s’. Example: “3.5s”. 

_class_ genai.types.CreateCachedContentConfigDict¶ 
    
Bases: `TypedDict`
Optional configuration for cached content creation. 

contents _:`Union`[`list`[`Union`[`Content`, `list`[`Union`[`File`, `Part`, `Image`, `str`]], `File`, `Part`, `Image`, `str`, `ContentDict`]], `Content`, `list`[`Union`[`File`, `Part`, `Image`, `str`]], `File`, `Part`, `Image`, `str`, `ContentDict`, `None`]_¶ 
    
The content to cache. 

display_name _:`Optional`[`str`]_¶ 
    
The user-generated meaningful display name of the cached content. 

expire_time _:`Optional`[`datetime`]_¶ 
    
01:23Z. 

Type: 
    
Timestamp of when this resource is considered expired. Uses RFC 3339 format, Example 

Type: 
    
2014-10-02T15 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

system_instruction _:`Union`[`Content`, `list`[`Union`[`File`, `Part`, `Image`, `str`]], `File`, `Part`, `Image`, `str`, `ContentDict`, `None`]_¶ 
    
Developer set system instruction. 

tool_config _:`Optional`[`ToolConfigDict`]_¶ 
    
Configuration for the tools to use. This config is shared for all tools. 

tools _:`Optional`[`list`[`ToolDict`]]_¶ 
    
A list of Tools the model may use to generate the next response. 

ttl _:`Optional`[`str`]_¶ 
    
“3.5s”. 

Type: 
    
The TTL for this resource. The expiration time is computed 

Type: 
    
now + TTL. It is a duration string, with up to nine fractional digits, terminated by ‘s’. Example 

_pydantic model_genai.types.CreateFileConfig¶ 
    
Bases: `BaseModel`
Used to override the default configuration.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"CreateFileConfig",
"description":"Used to override the default configuration.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `http_options (genai.types.HttpOptions | None)`



_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_class_ genai.types.CreateFileConfigDict¶ 
    
Bases: `TypedDict`
Used to override the default configuration. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

_pydantic model_genai.types.CreateFileResponse¶ 
    
Bases: `BaseModel`
Response for the create file method.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"CreateFileResponse",
"description":"Response for the create file method.",
"type":"object",
"properties":{
"httpHeaders":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to retain the HTTP headers in the request",
"title":"Httpheaders"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `http_headers (dict[str, str] | None)`



_field_ http_headers _:`Optional`[`dict`[`str`, `str`]]__= None_ _(alias 'httpHeaders')_¶ 
    
Used to retain the HTTP headers in the request 

_class_ genai.types.CreateFileResponseDict¶ 
    
Bases: `TypedDict`
Response for the create file method. 

http_headers _:`Optional`[`dict`[`str`, `str`]]_¶ 
    
Used to retain the HTTP headers in the request 

_pydantic model_genai.types.CreateTuningJobConfig¶ 
    
Bases: `BaseModel`
Supervised fine-tuning job creation request - optional fields.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"CreateTuningJobConfig",
"description":"Supervised fine-tuning job creation request - optional fields.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
},
"validationDataset":{
"anyOf":[
{
"$ref":"#/$defs/TuningValidationDataset"
},
{
"type":"null"
}
],
"default":null,
"description":"Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file."
},
"tunedModelDisplayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The display name of the tuned Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.",
"title":"Tunedmodeldisplayname"
},
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The description of the TuningJob",
"title":"Description"
},
"epochCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of complete passes the model makes over the entire training dataset during training.",
"title":"Epochcount"
},
"learningRateMultiplier":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Multiplier for adjusting the default learning rate.",
"title":"Learningratemultiplier"
},
"exportLastCheckpointOnly":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If set to true, disable intermediate checkpoints for SFT and only the last checkpoint will be exported. Otherwise, enable intermediate checkpoints for SFT.",
"title":"Exportlastcheckpointonly"
},
"adapterSize":{
"anyOf":[
{
"$ref":"#/$defs/AdapterSize"
},
{
"type":"null"
}
],
"default":null,
"description":"Adapter size for tuning."
},
"batchSize":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The batch size hyperparameter for tuning. If not set, a default of 4 or 16 will be used based on the number of training examples.",
"title":"Batchsize"
},
"learningRate":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"The learning rate hyperparameter for tuning. If not set, a default of 0.001 or 0.0002 will be calculated based on the number of training examples.",
"title":"Learningrate"
}
},
"$defs":{
"AdapterSize":{
"description":"Optional. Adapter size for tuning.",
"enum":[
"ADAPTER_SIZE_UNSPECIFIED",
"ADAPTER_SIZE_ONE",
"ADAPTER_SIZE_TWO",
"ADAPTER_SIZE_FOUR",
"ADAPTER_SIZE_EIGHT",
"ADAPTER_SIZE_SIXTEEN",
"ADAPTER_SIZE_THIRTY_TWO"
],
"title":"AdapterSize",
"type":"string"
},
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
},
"TuningValidationDataset":{
"additionalProperties":false,
"properties":{
"gcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"GCS URI of the file containing validation dataset in JSONL format.",
"title":"Gcsuri"
}
},
"title":"TuningValidationDataset",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `adapter_size (genai.types.AdapterSize | None)`
  * `batch_size (int | None)`
  * `description (str | None)`
  * `epoch_count (int | None)`
  * `export_last_checkpoint_only (bool | None)`
  * `http_options (genai.types.HttpOptions | None)`
  * `learning_rate (float | None)`
  * `learning_rate_multiplier (float | None)`
  * `tuned_model_display_name (str | None)`
  * `validation_dataset (genai.types.TuningValidationDataset | None)`



_field_ adapter_size _:`Optional`[`AdapterSize`]__= None_ _(alias 'adapterSize')_¶ 
    
Adapter size for tuning. 

_field_ batch_size _:`Optional`[`int`]__= None_ _(alias 'batchSize')_¶ 
    
The batch size hyperparameter for tuning. If not set, a default of 4 or 16 will be used based on the number of training examples. 

_field_ description _:`Optional`[`str`]__= None_¶ 
    
The description of the TuningJob 

_field_ epoch_count _:`Optional`[`int`]__= None_ _(alias 'epochCount')_¶ 
    
Number of complete passes the model makes over the entire training dataset during training. 

_field_ export_last_checkpoint_only _:`Optional`[`bool`]__= None_ _(alias 'exportLastCheckpointOnly')_¶ 
    
If set to true, disable intermediate checkpoints for SFT and only the last checkpoint will be exported. Otherwise, enable intermediate checkpoints for SFT. 

_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_field_ learning_rate _:`Optional`[`float`]__= None_ _(alias 'learningRate')_¶ 
    
The learning rate hyperparameter for tuning. If not set, a default of 0.001 or 0.0002 will be calculated based on the number of training examples. 

_field_ learning_rate_multiplier _:`Optional`[`float`]__= None_ _(alias 'learningRateMultiplier')_¶ 
    
Multiplier for adjusting the default learning rate. 

_field_ tuned_model_display_name _:`Optional`[`str`]__= None_ _(alias 'tunedModelDisplayName')_¶ 
    
The display name of the tuned Model. The name can be up to 128 characters long and can consist of any UTF-8 characters. 

_field_ validation_dataset _:`Optional`[`TuningValidationDataset`]__= None_ _(alias 'validationDataset')_¶ 
    
Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file. 

_class_ genai.types.CreateTuningJobConfigDict¶ 
    
Bases: `TypedDict`
Supervised fine-tuning job creation request - optional fields. 

adapter_size _:`Optional`[`AdapterSize`]_¶ 
    
Adapter size for tuning. 

batch_size _:`Optional`[`int`]_¶ 
    
The batch size hyperparameter for tuning. If not set, a default of 4 or 16 will be used based on the number of training examples. 

description _:`Optional`[`str`]_¶ 
    
The description of the TuningJob 

epoch_count _:`Optional`[`int`]_¶ 
    
Number of complete passes the model makes over the entire training dataset during training. 

export_last_checkpoint_only _:`Optional`[`bool`]_¶ 
    
If set to true, disable intermediate checkpoints for SFT and only the last checkpoint will be exported. Otherwise, enable intermediate checkpoints for SFT. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

learning_rate _:`Optional`[`float`]_¶ 
    
The learning rate hyperparameter for tuning. If not set, a default of 0.001 or 0.0002 will be calculated based on the number of training examples. 

learning_rate_multiplier _:`Optional`[`float`]_¶ 
    
Multiplier for adjusting the default learning rate. 

tuned_model_display_name _:`Optional`[`str`]_¶ 
    
The display name of the tuned Model. The name can be up to 128 characters long and can consist of any UTF-8 characters. 

validation_dataset _:`Optional`[`TuningValidationDatasetDict`]_¶ 
    
Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file. 

_pydantic model_genai.types.DatasetDistribution¶ 
    
Bases: `BaseModel`
Distribution computed over a tuning dataset.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"DatasetDistribution",
"description":"Distribution computed over a tuning dataset.",
"type":"object",
"properties":{
"buckets":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/DatasetDistributionDistributionBucket"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Defines the histogram bucket.",
"title":"Buckets"
},
"max":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The maximum of the population values.",
"title":"Max"
},
"mean":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The arithmetic mean of the values in the population.",
"title":"Mean"
},
"median":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The median of the values in the population.",
"title":"Median"
},
"min":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The minimum of the population values.",
"title":"Min"
},
"p5":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 5th percentile of the values in the population.",
"title":"P5"
},
"p95":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 95th percentile of the values in the population.",
"title":"P95"
},
"sum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sum of a given population of values.",
"title":"Sum"
}
},
"$defs":{
"DatasetDistributionDistributionBucket":{
"additionalProperties":false,
"description":"Dataset bucket used to create a histogram for the distribution given a population of values.",
"properties":{
"count":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of values in the bucket.",
"title":"Count"
},
"left":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Left bound of the bucket.",
"title":"Left"
},
"right":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Right bound of the bucket.",
"title":"Right"
}
},
"title":"DatasetDistributionDistributionBucket",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `buckets (list[genai.types.DatasetDistributionDistributionBucket] | None)`
  * `max (float | None)`
  * `mean (float | None)`
  * `median (float | None)`
  * `min (float | None)`
  * `p5 (float | None)`
  * `p95 (float | None)`
  * `sum (float | None)`



_field_ buckets _:`Optional`[`list`[`DatasetDistributionDistributionBucket`]]__= None_¶ 
    
Output only. Defines the histogram bucket. 

_field_ max _:`Optional`[`float`]__= None_¶ 
    
Output only. The maximum of the population values. 

_field_ mean _:`Optional`[`float`]__= None_¶ 
    
Output only. The arithmetic mean of the values in the population. 

_field_ median _:`Optional`[`float`]__= None_¶ 
    
Output only. The median of the values in the population. 

_field_ min _:`Optional`[`float`]__= None_¶ 
    
Output only. The minimum of the population values. 

_field_ p5 _:`Optional`[`float`]__= None_¶ 
    
Output only. The 5th percentile of the values in the population. 

_field_ p95 _:`Optional`[`float`]__= None_¶ 
    
Output only. The 95th percentile of the values in the population. 

_field_ sum _:`Optional`[`float`]__= None_¶ 
    
Output only. Sum of a given population of values. 

_class_ genai.types.DatasetDistributionDict¶ 
    
Bases: `TypedDict`
Distribution computed over a tuning dataset. 

buckets _:`Optional`[`list`[`DatasetDistributionDistributionBucketDict`]]_¶ 
    
Output only. Defines the histogram bucket. 

max _:`Optional`[`float`]_¶ 
    
Output only. The maximum of the population values. 

mean _:`Optional`[`float`]_¶ 
    
Output only. The arithmetic mean of the values in the population. 

median _:`Optional`[`float`]_¶ 
    
Output only. The median of the values in the population. 

min _:`Optional`[`float`]_¶ 
    
Output only. The minimum of the population values. 

p5 _:`Optional`[`float`]_¶ 
    
Output only. The 5th percentile of the values in the population. 

p95 _:`Optional`[`float`]_¶ 
    
Output only. The 95th percentile of the values in the population. 

sum _:`Optional`[`float`]_¶ 
    
Output only. Sum of a given population of values. 

_pydantic model_genai.types.DatasetDistributionDistributionBucket¶ 
    
Bases: `BaseModel`
Dataset bucket used to create a histogram for the distribution given a population of values.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"DatasetDistributionDistributionBucket",
"description":"Dataset bucket used to create a histogram for the distribution given a population of values.",
"type":"object",
"properties":{
"count":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of values in the bucket.",
"title":"Count"
},
"left":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Left bound of the bucket.",
"title":"Left"
},
"right":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Right bound of the bucket.",
"title":"Right"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `count (int | None)`
  * `left (float | None)`
  * `right (float | None)`



_field_ count _:`Optional`[`int`]__= None_¶ 
    
Output only. Number of values in the bucket. 

_field_ left _:`Optional`[`float`]__= None_¶ 
    
Output only. Left bound of the bucket. 

_field_ right _:`Optional`[`float`]__= None_¶ 
    
Output only. Right bound of the bucket. 

_class_ genai.types.DatasetDistributionDistributionBucketDict¶ 
    
Bases: `TypedDict`
Dataset bucket used to create a histogram for the distribution given a population of values. 

count _:`Optional`[`int`]_¶ 
    
Output only. Number of values in the bucket. 

left _:`Optional`[`float`]_¶ 
    
Output only. Left bound of the bucket. 

right _:`Optional`[`float`]_¶ 
    
Output only. Right bound of the bucket. 

_pydantic model_genai.types.DatasetStats¶ 
    
Bases: `BaseModel`
Statistics computed over a tuning dataset.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"DatasetStats",
"description":"Statistics computed over a tuning dataset.",
"type":"object",
"properties":{
"totalBillableCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of billable characters in the tuning dataset.",
"title":"Totalbillablecharactercount"
},
"totalTuningCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tuning characters in the tuning dataset.",
"title":"Totaltuningcharactercount"
},
"tuningDatasetExampleCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of examples in the tuning dataset.",
"title":"Tuningdatasetexamplecount"
},
"tuningStepCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tuning steps for this Tuning Job.",
"title":"Tuningstepcount"
},
"userDatasetExamples":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Content"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sample user messages in the training dataset uri.",
"title":"Userdatasetexamples"
},
"userInputTokenDistribution":{
"anyOf":[
{
"$ref":"#/$defs/DatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the user input tokens."
},
"userMessagePerExampleDistribution":{
"anyOf":[
{
"$ref":"#/$defs/DatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the messages per example."
},
"userOutputTokenDistribution":{
"anyOf":[
{
"$ref":"#/$defs/DatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the user output tokens."
}
},
"$defs":{
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"Content":{
"additionalProperties":false,
"description":"Contains the multi-part content of a message.",
"properties":{
"parts":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Part"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of parts that constitute a single message. Each part may have\n      a different IANA MIME type.",
"title":"Parts"
},
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role.",
"title":"Role"
}
},
"title":"Content",
"type":"object"
},
"DatasetDistribution":{
"additionalProperties":false,
"description":"Distribution computed over a tuning dataset.",
"properties":{
"buckets":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/DatasetDistributionDistributionBucket"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Defines the histogram bucket.",
"title":"Buckets"
},
"max":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The maximum of the population values.",
"title":"Max"
},
"mean":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The arithmetic mean of the values in the population.",
"title":"Mean"
},
"median":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The median of the values in the population.",
"title":"Median"
},
"min":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The minimum of the population values.",
"title":"Min"
},
"p5":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 5th percentile of the values in the population.",
"title":"P5"
},
"p95":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 95th percentile of the values in the population.",
"title":"P95"
},
"sum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sum of a given population of values.",
"title":"Sum"
}
},
"title":"DatasetDistribution",
"type":"object"
},
"DatasetDistributionDistributionBucket":{
"additionalProperties":false,
"description":"Dataset bucket used to create a histogram for the distribution given a population of values.",
"properties":{
"count":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of values in the bucket.",
"title":"Count"
},
"left":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Left bound of the bucket.",
"title":"Left"
},
"right":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Right bound of the bucket.",
"title":"Right"
}
},
"title":"DatasetDistributionDistributionBucket",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `total_billable_character_count (int | None)`
  * `total_tuning_character_count (int | None)`
  * `tuning_dataset_example_count (int | None)`
  * `tuning_step_count (int | None)`
  * `user_dataset_examples (list[genai.types.Content] | None)`
  * `user_input_token_distribution (genai.types.DatasetDistribution | None)`
  * `user_message_per_example_distribution (genai.types.DatasetDistribution | None)`
  * `user_output_token_distribution (genai.types.DatasetDistribution | None)`



_field_ total_billable_character_count _:`Optional`[`int`]__= None_ _(alias 'totalBillableCharacterCount')_¶ 
    
Output only. Number of billable characters in the tuning dataset. 

_field_ total_tuning_character_count _:`Optional`[`int`]__= None_ _(alias 'totalTuningCharacterCount')_¶ 
    
Output only. Number of tuning characters in the tuning dataset. 

_field_ tuning_dataset_example_count _:`Optional`[`int`]__= None_ _(alias 'tuningDatasetExampleCount')_¶ 
    
Output only. Number of examples in the tuning dataset. 

_field_ tuning_step_count _:`Optional`[`int`]__= None_ _(alias 'tuningStepCount')_¶ 
    
Output only. Number of tuning steps for this Tuning Job. 

_field_ user_dataset_examples _:`Optional`[`list`[`Content`]]__= None_ _(alias 'userDatasetExamples')_¶ 
    
Output only. Sample user messages in the training dataset uri. 

_field_ user_input_token_distribution _:`Optional`[`DatasetDistribution`]__= None_ _(alias 'userInputTokenDistribution')_¶ 
    
Output only. Dataset distributions for the user input tokens. 

_field_ user_message_per_example_distribution _:`Optional`[`DatasetDistribution`]__= None_ _(alias 'userMessagePerExampleDistribution')_¶ 
    
Output only. Dataset distributions for the messages per example. 

_field_ user_output_token_distribution _:`Optional`[`DatasetDistribution`]__= None_ _(alias 'userOutputTokenDistribution')_¶ 
    
Output only. Dataset distributions for the user output tokens. 

_class_ genai.types.DatasetStatsDict¶ 
    
Bases: `TypedDict`
Statistics computed over a tuning dataset. 

total_billable_character_count _:`Optional`[`int`]_¶ 
    
Output only. Number of billable characters in the tuning dataset. 

total_tuning_character_count _:`Optional`[`int`]_¶ 
    
Output only. Number of tuning characters in the tuning dataset. 

tuning_dataset_example_count _:`Optional`[`int`]_¶ 
    
Output only. Number of examples in the tuning dataset. 

tuning_step_count _:`Optional`[`int`]_¶ 
    
Output only. Number of tuning steps for this Tuning Job. 

user_dataset_examples _:`Optional`[`list`[`ContentDict`]]_¶ 
    
Output only. Sample user messages in the training dataset uri. 

user_input_token_distribution _:`Optional`[`DatasetDistributionDict`]_¶ 
    
Output only. Dataset distributions for the user input tokens. 

user_message_per_example_distribution _:`Optional`[`DatasetDistributionDict`]_¶ 
    
Output only. Dataset distributions for the messages per example. 

user_output_token_distribution _:`Optional`[`DatasetDistributionDict`]_¶ 
    
Output only. Dataset distributions for the user output tokens. 

_pydantic model_genai.types.DeleteBatchJobConfig¶ 
    
Bases: `BaseModel`
Optional parameters for models.get method.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"DeleteBatchJobConfig",
"description":"Optional parameters for models.get method.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `http_options (genai.types.HttpOptions | None)`



_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_class_ genai.types.DeleteBatchJobConfigDict¶ 
    
Bases: `TypedDict`
Optional parameters for models.get method. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

_pydantic model_genai.types.DeleteCachedContentConfig¶ 
    
Bases: `BaseModel`
Optional parameters for caches.delete method.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"DeleteCachedContentConfig",
"description":"Optional parameters for caches.delete method.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `http_options (genai.types.HttpOptions | None)`



_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_class_ genai.types.DeleteCachedContentConfigDict¶ 
    
Bases: `TypedDict`
Optional parameters for caches.delete method. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

_pydantic model_genai.types.DeleteCachedContentResponse¶ 
    
Bases: `BaseModel`
Empty response for caches.delete method.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"DeleteCachedContentResponse",
"description":"Empty response for caches.delete method.",
"type":"object",
"properties":{},
"additionalProperties":false
}

```


_class_ genai.types.DeleteCachedContentResponseDict¶ 
    
Bases: `TypedDict`
Empty response for caches.delete method. 

_pydantic model_genai.types.DeleteFileConfig¶ 
    
Bases: `BaseModel`
Used to override the default configuration.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"DeleteFileConfig",
"description":"Used to override the default configuration.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `http_options (genai.types.HttpOptions | None)`



_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_class_ genai.types.DeleteFileConfigDict¶ 
    
Bases: `TypedDict`
Used to override the default configuration. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

_pydantic model_genai.types.DeleteFileResponse¶ 
    
Bases: `BaseModel`
Response for the delete file method.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"DeleteFileResponse",
"description":"Response for the delete file method.",
"type":"object",
"properties":{},
"additionalProperties":false
}

```


_class_ genai.types.DeleteFileResponseDict¶ 
    
Bases: `TypedDict`
Response for the delete file method. 

_pydantic model_genai.types.DeleteModelConfig¶ 
    
Bases: `BaseModel`
Configuration for deleting a tuned model.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"DeleteModelConfig",
"description":"Configuration for deleting a tuned model.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `http_options (genai.types.HttpOptions | None)`



_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_class_ genai.types.DeleteModelConfigDict¶ 
    
Bases: `TypedDict`
Configuration for deleting a tuned model. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

_pydantic model_genai.types.DeleteModelResponse¶ 
    
Bases: `BaseModel`
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"DeleteModelResponse",
"type":"object",
"properties":{},
"additionalProperties":false
}

```


_class_ genai.types.DeleteModelResponseDict¶ 
    
Bases: `TypedDict` 

_pydantic model_genai.types.DeleteResourceJob¶ 
    
Bases: `BaseModel`
The return value of delete operation.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"DeleteResourceJob",
"description":"The return value of delete operation.",
"type":"object",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Name"
},
"done":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Done"
},
"error":{
"anyOf":[
{
"$ref":"#/$defs/JobError"
},
{
"type":"null"
}
],
"default":null,
"description":""
}
},
"$defs":{
"JobError":{
"additionalProperties":false,
"description":"Job error.",
"properties":{
"details":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Details"
},
"code":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The status code.",
"title":"Code"
},
"message":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the `details` field.",
"title":"Message"
}
},
"title":"JobError",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `done (bool | None)`
  * `error (genai.types.JobError | None)`
  * `name (str | None)`



_field_ done _:`Optional`[`bool`]__= None_¶ 


_field_ error _:`Optional`[`JobError`]__= None_¶ 


_field_ name _:`Optional`[`str`]__= None_¶ 


_class_ genai.types.DeleteResourceJobDict¶ 
    
Bases: `TypedDict`
The return value of delete operation. 

done _:`Optional`[`bool`]_¶ 


error _:`Optional`[`JobErrorDict`]_¶ 


name _:`Optional`[`str`]_¶ 


_pydantic model_genai.types.DistillationDataStats¶ 
    
Bases: `BaseModel`
Statistics computed for datasets used for distillation.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"DistillationDataStats",
"description":"Statistics computed for datasets used for distillation.",
"type":"object",
"properties":{
"trainingDatasetStats":{
"anyOf":[
{
"$ref":"#/$defs/DatasetStats"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Statistics computed for the training dataset."
}
},
"$defs":{
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"Content":{
"additionalProperties":false,
"description":"Contains the multi-part content of a message.",
"properties":{
"parts":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Part"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of parts that constitute a single message. Each part may have\n      a different IANA MIME type.",
"title":"Parts"
},
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role.",
"title":"Role"
}
},
"title":"Content",
"type":"object"
},
"DatasetDistribution":{
"additionalProperties":false,
"description":"Distribution computed over a tuning dataset.",
"properties":{
"buckets":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/DatasetDistributionDistributionBucket"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Defines the histogram bucket.",
"title":"Buckets"
},
"max":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The maximum of the population values.",
"title":"Max"
},
"mean":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The arithmetic mean of the values in the population.",
"title":"Mean"
},
"median":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The median of the values in the population.",
"title":"Median"
},
"min":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The minimum of the population values.",
"title":"Min"
},
"p5":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 5th percentile of the values in the population.",
"title":"P5"
},
"p95":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 95th percentile of the values in the population.",
"title":"P95"
},
"sum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sum of a given population of values.",
"title":"Sum"
}
},
"title":"DatasetDistribution",
"type":"object"
},
"DatasetDistributionDistributionBucket":{
"additionalProperties":false,
"description":"Dataset bucket used to create a histogram for the distribution given a population of values.",
"properties":{
"count":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of values in the bucket.",
"title":"Count"
},
"left":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Left bound of the bucket.",
"title":"Left"
},
"right":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Right bound of the bucket.",
"title":"Right"
}
},
"title":"DatasetDistributionDistributionBucket",
"type":"object"
},
"DatasetStats":{
"additionalProperties":false,
"description":"Statistics computed over a tuning dataset.",
"properties":{
"totalBillableCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of billable characters in the tuning dataset.",
"title":"Totalbillablecharactercount"
},
"totalTuningCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tuning characters in the tuning dataset.",
"title":"Totaltuningcharactercount"
},
"tuningDatasetExampleCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of examples in the tuning dataset.",
"title":"Tuningdatasetexamplecount"
},
"tuningStepCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tuning steps for this Tuning Job.",
"title":"Tuningstepcount"
},
"userDatasetExamples":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Content"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sample user messages in the training dataset uri.",
"title":"Userdatasetexamples"
},
"userInputTokenDistribution":{
"anyOf":[
{
"$ref":"#/$defs/DatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the user input tokens."
},
"userMessagePerExampleDistribution":{
"anyOf":[
{
"$ref":"#/$defs/DatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the messages per example."
},
"userOutputTokenDistribution":{
"anyOf":[
{
"$ref":"#/$defs/DatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the user output tokens."
}
},
"title":"DatasetStats",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `training_dataset_stats (genai.types.DatasetStats | None)`



_field_ training_dataset_stats _:`Optional`[`DatasetStats`]__= None_ _(alias 'trainingDatasetStats')_¶ 
    
Output only. Statistics computed for the training dataset. 

_class_ genai.types.DistillationDataStatsDict¶ 
    
Bases: `TypedDict`
Statistics computed for datasets used for distillation. 

training_dataset_stats _:`Optional`[`DatasetStatsDict`]_¶ 
    
Output only. Statistics computed for the training dataset. 

_pydantic model_genai.types.DistillationHyperParameters¶ 
    
Bases: `BaseModel`
Hyperparameters for Distillation.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"DistillationHyperParameters",
"description":"Hyperparameters for Distillation.",
"type":"object",
"properties":{
"adapterSize":{
"anyOf":[
{
"$ref":"#/$defs/AdapterSize"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Adapter size for distillation."
},
"epochCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of complete passes the model makes over the entire training dataset during training.",
"title":"Epochcount"
},
"learningRateMultiplier":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Multiplier for adjusting the default learning rate.",
"title":"Learningratemultiplier"
}
},
"$defs":{
"AdapterSize":{
"description":"Optional. Adapter size for tuning.",
"enum":[
"ADAPTER_SIZE_UNSPECIFIED",
"ADAPTER_SIZE_ONE",
"ADAPTER_SIZE_TWO",
"ADAPTER_SIZE_FOUR",
"ADAPTER_SIZE_EIGHT",
"ADAPTER_SIZE_SIXTEEN",
"ADAPTER_SIZE_THIRTY_TWO"
],
"title":"AdapterSize",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `adapter_size (genai.types.AdapterSize | None)`
  * `epoch_count (int | None)`
  * `learning_rate_multiplier (float | None)`



_field_ adapter_size _:`Optional`[`AdapterSize`]__= None_ _(alias 'adapterSize')_¶ 
    
Optional. Adapter size for distillation. 

_field_ epoch_count _:`Optional`[`int`]__= None_ _(alias 'epochCount')_¶ 
    
Optional. Number of complete passes the model makes over the entire training dataset during training. 

_field_ learning_rate_multiplier _:`Optional`[`float`]__= None_ _(alias 'learningRateMultiplier')_¶ 
    
Optional. Multiplier for adjusting the default learning rate. 

_class_ genai.types.DistillationHyperParametersDict¶ 
    
Bases: `TypedDict`
Hyperparameters for Distillation. 

adapter_size _:`Optional`[`AdapterSize`]_¶ 
    
Optional. Adapter size for distillation. 

epoch_count _:`Optional`[`int`]_¶ 
    
Optional. Number of complete passes the model makes over the entire training dataset during training. 

learning_rate_multiplier _:`Optional`[`float`]_¶ 
    
Optional. Multiplier for adjusting the default learning rate. 

_pydantic model_genai.types.DistillationSpec¶ 
    
Bases: `BaseModel`
Tuning Spec for Distillation.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"DistillationSpec",
"description":"Tuning Spec for Distillation.",
"type":"object",
"properties":{
"baseTeacherModel":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base teacher model that is being distilled, e.g., \"gemini-1.0-pro-002\".",
"title":"Baseteachermodel"
},
"hyperParameters":{
"anyOf":[
{
"$ref":"#/$defs/DistillationHyperParameters"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Hyperparameters for Distillation."
},
"pipelineRootDirectory":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. A path in a Cloud Storage bucket, which will be treated as the root output directory of the distillation pipeline. It is used by the system to generate the paths of output artifacts.",
"title":"Pipelinerootdirectory"
},
"studentModel":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The student model that is being tuned, e.g., \"google/gemma-2b-1.1-it\".",
"title":"Studentmodel"
},
"trainingDatasetUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file.",
"title":"Trainingdataseturi"
},
"tunedTeacherModelSource":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The resource name of the Tuned teacher model. Format: `projects/{project}/locations/{location}/models/{model}`.",
"title":"Tunedteachermodelsource"
},
"validationDatasetUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Cloud Storage path to file containing validation dataset for tuning. The dataset must be formatted as a JSONL file.",
"title":"Validationdataseturi"
}
},
"$defs":{
"AdapterSize":{
"description":"Optional. Adapter size for tuning.",
"enum":[
"ADAPTER_SIZE_UNSPECIFIED",
"ADAPTER_SIZE_ONE",
"ADAPTER_SIZE_TWO",
"ADAPTER_SIZE_FOUR",
"ADAPTER_SIZE_EIGHT",
"ADAPTER_SIZE_SIXTEEN",
"ADAPTER_SIZE_THIRTY_TWO"
],
"title":"AdapterSize",
"type":"string"
},
"DistillationHyperParameters":{
"additionalProperties":false,
"description":"Hyperparameters for Distillation.",
"properties":{
"adapterSize":{
"anyOf":[
{
"$ref":"#/$defs/AdapterSize"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Adapter size for distillation."
},
"epochCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of complete passes the model makes over the entire training dataset during training.",
"title":"Epochcount"
},
"learningRateMultiplier":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Multiplier for adjusting the default learning rate.",
"title":"Learningratemultiplier"
}
},
"title":"DistillationHyperParameters",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `base_teacher_model (str | None)`
  * `hyper_parameters (genai.types.DistillationHyperParameters | None)`
  * `pipeline_root_directory (str | None)`
  * `student_model (str | None)`
  * `training_dataset_uri (str | None)`
  * `tuned_teacher_model_source (str | None)`
  * `validation_dataset_uri (str | None)`



_field_ base_teacher_model _:`Optional`[`str`]__= None_ _(alias 'baseTeacherModel')_¶ 
    
The base teacher model that is being distilled, e.g., “gemini-1.0-pro-002”. 

_field_ hyper_parameters _:`Optional`[`DistillationHyperParameters`]__= None_ _(alias 'hyperParameters')_¶ 
    
Optional. Hyperparameters for Distillation. 

_field_ pipeline_root_directory _:`Optional`[`str`]__= None_ _(alias 'pipelineRootDirectory')_¶ 
    
Required. A path in a Cloud Storage bucket, which will be treated as the root output directory of the distillation pipeline. It is used by the system to generate the paths of output artifacts. 

_field_ student_model _:`Optional`[`str`]__= None_ _(alias 'studentModel')_¶ 
    
The student model that is being tuned, e.g., “google/gemma-2b-1.1-it”. 

_field_ training_dataset_uri _:`Optional`[`str`]__= None_ _(alias 'trainingDatasetUri')_¶ 
    
Required. Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file. 

_field_ tuned_teacher_model_source _:`Optional`[`str`]__= None_ _(alias 'tunedTeacherModelSource')_¶ 
    
The resource name of the Tuned teacher model. Format: projects/{project}/locations/{location}/models/{model}. 

_field_ validation_dataset_uri _:`Optional`[`str`]__= None_ _(alias 'validationDatasetUri')_¶ 
    
Optional. Cloud Storage path to file containing validation dataset for tuning. The dataset must be formatted as a JSONL file. 

_class_ genai.types.DistillationSpecDict¶ 
    
Bases: `TypedDict`
Tuning Spec for Distillation. 

base_teacher_model _:`Optional`[`str`]_¶ 
    
The base teacher model that is being distilled, e.g., “gemini-1.0-pro-002”. 

hyper_parameters _:`Optional`[`DistillationHyperParametersDict`]_¶ 
    
Optional. Hyperparameters for Distillation. 

pipeline_root_directory _:`Optional`[`str`]_¶ 
    
Required. A path in a Cloud Storage bucket, which will be treated as the root output directory of the distillation pipeline. It is used by the system to generate the paths of output artifacts. 

student_model _:`Optional`[`str`]_¶ 
    
The student model that is being tuned, e.g., “google/gemma-2b-1.1-it”. 

training_dataset_uri _:`Optional`[`str`]_¶ 
    
Required. Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file. 

tuned_teacher_model_source _:`Optional`[`str`]_¶ 
    
projects/{project}/locations/{location}/models/{model}. 

Type: 
    
The resource name of the Tuned teacher model. Format 

validation_dataset_uri _:`Optional`[`str`]_¶ 
    
Optional. Cloud Storage path to file containing validation dataset for tuning. The dataset must be formatted as a JSONL file. 

_pydantic model_genai.types.DownloadFileConfig¶ 
    
Bases: `BaseModel`
Used to override the default configuration.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"DownloadFileConfig",
"description":"Used to override the default configuration.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `http_options (genai.types.HttpOptions | None)`



_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_class_ genai.types.DownloadFileConfigDict¶ 
    
Bases: `TypedDict`
Used to override the default configuration. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

_pydantic model_genai.types.DynamicRetrievalConfig¶ 
    
Bases: `BaseModel`
Describes the options to customize dynamic retrieval.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"DynamicRetrievalConfig",
"description":"Describes the options to customize dynamic retrieval.",
"type":"object",
"properties":{
"mode":{
"anyOf":[
{
"$ref":"#/$defs/DynamicRetrievalConfigMode"
},
{
"type":"null"
}
],
"default":null,
"description":"The mode of the predictor to be used in dynamic retrieval."
},
"dynamicThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The threshold to be used in dynamic retrieval. If not set, a system default value is used.",
"title":"Dynamicthreshold"
}
},
"$defs":{
"DynamicRetrievalConfigMode":{
"description":"Config for the dynamic retrieval config mode.",
"enum":[
"MODE_UNSPECIFIED",
"MODE_DYNAMIC"
],
"title":"DynamicRetrievalConfigMode",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `dynamic_threshold (float | None)`
  * `mode (genai.types.DynamicRetrievalConfigMode | None)`



_field_ dynamic_threshold _:`Optional`[`float`]__= None_ _(alias 'dynamicThreshold')_¶ 
    
Optional. The threshold to be used in dynamic retrieval. If not set, a system default value is used. 

_field_ mode _:`Optional`[`DynamicRetrievalConfigMode`]__= None_¶ 
    
The mode of the predictor to be used in dynamic retrieval. 

_class_ genai.types.DynamicRetrievalConfigDict¶ 
    
Bases: `TypedDict`
Describes the options to customize dynamic retrieval. 

dynamic_threshold _:`Optional`[`float`]_¶ 
    
Optional. The threshold to be used in dynamic retrieval. If not set, a system default value is used. 

mode _:`Optional`[`DynamicRetrievalConfigMode`]_¶ 
    
The mode of the predictor to be used in dynamic retrieval. 

_class_ genai.types.DynamicRetrievalConfigMode(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Config for the dynamic retrieval config mode. 

MODE_DYNAMIC _= 'MODE_DYNAMIC'_¶ 


MODE_UNSPECIFIED _= 'MODE_UNSPECIFIED'_¶ 


_pydantic model_genai.types.EditImageConfig¶ 
    
Bases: `BaseModel`
Configuration for editing an image.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"EditImageConfig",
"description":"Configuration for editing an image.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
},
"outputGcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Cloud Storage URI used to store the generated images.\n      ",
"title":"Outputgcsuri"
},
"negativePrompt":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Description of what to discourage in the generated images.\n      ",
"title":"Negativeprompt"
},
"numberOfImages":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of images to generate.\n      ",
"title":"Numberofimages"
},
"aspectRatio":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Aspect ratio of the generated images.\n      ",
"title":"Aspectratio"
},
"guidanceScale":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Controls how much the model adheres to the text prompt. Large\n      values increase output and prompt alignment, but may compromise image\n      quality.\n      ",
"title":"Guidancescale"
},
"seed":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Random seed for image generation. This is not available when\n      ``add_watermark`` is set to true.\n      ",
"title":"Seed"
},
"safetyFilterLevel":{
"anyOf":[
{
"$ref":"#/$defs/SafetyFilterLevel"
},
{
"type":"null"
}
],
"default":null,
"description":"Filter level for safety filtering.\n      "
},
"personGeneration":{
"anyOf":[
{
"$ref":"#/$defs/PersonGeneration"
},
{
"type":"null"
}
],
"default":null,
"description":"Allows generation of people by the model.\n      "
},
"includeSafetyAttributes":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Whether to report the safety scores of each generated image and\n      the positive prompt in the response.\n      ",
"title":"Includesafetyattributes"
},
"includeRaiReason":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Whether to include the Responsible AI filter reason if the image\n      is filtered out of the response.\n      ",
"title":"Includeraireason"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/ImagePromptLanguage"
},
{
"type":"null"
}
],
"default":null,
"description":"Language of the text in the prompt.\n      "
},
"outputMimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"MIME type of the generated image.\n      ",
"title":"Outputmimetype"
},
"outputCompressionQuality":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Compression quality of the generated image (for ``image/jpeg``\n      only).\n      ",
"title":"Outputcompressionquality"
},
"editMode":{
"anyOf":[
{
"$ref":"#/$defs/EditMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Describes the editing mode for the request."
},
"baseSteps":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The number of sampling steps. A higher value has better image\n      quality, while a lower value has better latency.",
"title":"Basesteps"
}
},
"$defs":{
"EditMode":{
"description":"Enum representing the Imagen 3 Edit mode.",
"enum":[
"EDIT_MODE_DEFAULT",
"EDIT_MODE_INPAINT_REMOVAL",
"EDIT_MODE_INPAINT_INSERTION",
"EDIT_MODE_OUTPAINT",
"EDIT_MODE_CONTROLLED_EDITING",
"EDIT_MODE_STYLE",
"EDIT_MODE_BGSWAP",
"EDIT_MODE_PRODUCT_IMAGE"
],
"title":"EditMode",
"type":"string"
},
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
},
"ImagePromptLanguage":{
"description":"Enum that specifies the language of the text in the prompt.",
"enum":[
"auto",
"en",
"ja",
"ko",
"hi"
],
"title":"ImagePromptLanguage",
"type":"string"
},
"PersonGeneration":{
"description":"Enum that controls the generation of people.",
"enum":[
"DONT_ALLOW",
"ALLOW_ADULT",
"ALLOW_ALL"
],
"title":"PersonGeneration",
"type":"string"
},
"SafetyFilterLevel":{
"description":"Enum that controls the safety filter level for objectionable content.",
"enum":[
"BLOCK_LOW_AND_ABOVE",
"BLOCK_MEDIUM_AND_ABOVE",
"BLOCK_ONLY_HIGH",
"BLOCK_NONE"
],
"title":"SafetyFilterLevel",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `aspect_ratio (str | None)`
  * `base_steps (int | None)`
  * `edit_mode (genai.types.EditMode | None)`
  * `guidance_scale (float | None)`
  * `http_options (genai.types.HttpOptions | None)`
  * `include_rai_reason (bool | None)`
  * `include_safety_attributes (bool | None)`
  * `language (genai.types.ImagePromptLanguage | None)`
  * `negative_prompt (str | None)`
  * `number_of_images (int | None)`
  * `output_compression_quality (int | None)`
  * `output_gcs_uri (str | None)`
  * `output_mime_type (str | None)`
  * `person_generation (genai.types.PersonGeneration | None)`
  * `safety_filter_level (genai.types.SafetyFilterLevel | None)`
  * `seed (int | None)`



_field_ aspect_ratio _:`Optional`[`str`]__= None_ _(alias 'aspectRatio')_¶ 
    
Aspect ratio of the generated images. 

_field_ base_steps _:`Optional`[`int`]__= None_ _(alias 'baseSteps')_¶ 
    
The number of sampling steps. A higher value has better image quality, while a lower value has better latency. 

_field_ edit_mode _:`Optional`[`EditMode`]__= None_ _(alias 'editMode')_¶ 
    
Describes the editing mode for the request. 

_field_ guidance_scale _:`Optional`[`float`]__= None_ _(alias 'guidanceScale')_¶ 
    
Controls how much the model adheres to the text prompt. Large values increase output and prompt alignment, but may compromise image quality. 

_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_field_ include_rai_reason _:`Optional`[`bool`]__= None_ _(alias 'includeRaiReason')_¶ 
    
Whether to include the Responsible AI filter reason if the image is filtered out of the response. 

_field_ include_safety_attributes _:`Optional`[`bool`]__= None_ _(alias 'includeSafetyAttributes')_¶ 
    
Whether to report the safety scores of each generated image and the positive prompt in the response. 

_field_ language _:`Optional`[`ImagePromptLanguage`]__= None_¶ 
    
Language of the text in the prompt. 

_field_ negative_prompt _:`Optional`[`str`]__= None_ _(alias 'negativePrompt')_¶ 
    
Description of what to discourage in the generated images. 

_field_ number_of_images _:`Optional`[`int`]__= None_ _(alias 'numberOfImages')_¶ 
    
Number of images to generate. 

_field_ output_compression_quality _:`Optional`[`int`]__= None_ _(alias 'outputCompressionQuality')_¶ 
    
Compression quality of the generated image (for `image/jpeg` only). 

_field_ output_gcs_uri _:`Optional`[`str`]__= None_ _(alias 'outputGcsUri')_¶ 
    
Cloud Storage URI used to store the generated images. 

_field_ output_mime_type _:`Optional`[`str`]__= None_ _(alias 'outputMimeType')_¶ 
    
MIME type of the generated image. 

_field_ person_generation _:`Optional`[`PersonGeneration`]__= None_ _(alias 'personGeneration')_¶ 
    
Allows generation of people by the model. 

_field_ safety_filter_level _:`Optional`[`SafetyFilterLevel`]__= None_ _(alias 'safetyFilterLevel')_¶ 
    
Filter level for safety filtering. 

_field_ seed _:`Optional`[`int`]__= None_¶ 
    
Random seed for image generation. This is not available when `add_watermark` is set to true. 

_class_ genai.types.EditImageConfigDict¶ 
    
Bases: `TypedDict`
Configuration for editing an image. 

aspect_ratio _:`Optional`[`str`]_¶ 
    
Aspect ratio of the generated images. 

base_steps _:`Optional`[`int`]_¶ 
    
The number of sampling steps. A higher value has better image quality, while a lower value has better latency. 

edit_mode _:`Optional`[`EditMode`]_¶ 
    
Describes the editing mode for the request. 

guidance_scale _:`Optional`[`float`]_¶ 
    
Controls how much the model adheres to the text prompt. Large values increase output and prompt alignment, but may compromise image quality. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

include_rai_reason _:`Optional`[`bool`]_¶ 
    
Whether to include the Responsible AI filter reason if the image is filtered out of the response. 

include_safety_attributes _:`Optional`[`bool`]_¶ 
    
Whether to report the safety scores of each generated image and the positive prompt in the response. 

language _:`Optional`[`ImagePromptLanguage`]_¶ 
    
Language of the text in the prompt. 

negative_prompt _:`Optional`[`str`]_¶ 
    
Description of what to discourage in the generated images. 

number_of_images _:`Optional`[`int`]_¶ 
    
Number of images to generate. 

output_compression_quality _:`Optional`[`int`]_¶ 
    
Compression quality of the generated image (for `image/jpeg` only). 

output_gcs_uri _:`Optional`[`str`]_¶ 
    
Cloud Storage URI used to store the generated images. 

output_mime_type _:`Optional`[`str`]_¶ 
    
MIME type of the generated image. 

person_generation _:`Optional`[`PersonGeneration`]_¶ 
    
Allows generation of people by the model. 

safety_filter_level _:`Optional`[`SafetyFilterLevel`]_¶ 
    
Filter level for safety filtering. 

seed _:`Optional`[`int`]_¶ 
    
Random seed for image generation. This is not available when `add_watermark` is set to true. 

_pydantic model_genai.types.EditImageResponse¶ 
    
Bases: `BaseModel`
Response for the request to edit an image.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"EditImageResponse",
"description":"Response for the request to edit an image.",
"type":"object",
"properties":{
"generatedImages":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/GeneratedImage"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Generated images.",
"title":"Generatedimages"
}
},
"$defs":{
"GeneratedImage":{
"additionalProperties":false,
"description":"An output image.",
"properties":{
"image":{
"anyOf":[
{
"$ref":"#/$defs/Image"
},
{
"type":"null"
}
],
"default":null,
"description":"The output image data.\n      "
},
"raiFilteredReason":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Responsible AI filter reason if the image is filtered out of the\n      response.\n      ",
"title":"Raifilteredreason"
},
"safetyAttributes":{
"anyOf":[
{
"$ref":"#/$defs/SafetyAttributes"
},
{
"type":"null"
}
],
"default":null,
"description":"Safety attributes of the image. Lists of RAI categories and their\n      scores of each content.\n      "
},
"enhancedPrompt":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The rewritten prompt used for the image generation if the prompt\n      enhancer is enabled.\n      ",
"title":"Enhancedprompt"
}
},
"title":"GeneratedImage",
"type":"object"
},
"Image":{
"additionalProperties":false,
"description":"An image.",
"properties":{
"gcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The Cloud Storage URI of the image. ``Image`` can contain a value\n      for this field or the ``image_bytes`` field but not both.\n      ",
"title":"Gcsuri"
},
"imageBytes":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The image bytes data. ``Image`` can contain a value for this field\n      or the ``gcs_uri`` field but not both.\n      ",
"title":"Imagebytes"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The MIME type of the image.",
"title":"Mimetype"
}
},
"title":"Image",
"type":"object"
},
"SafetyAttributes":{
"additionalProperties":false,
"description":"Safety attributes of a GeneratedImage or the user-provided prompt.",
"properties":{
"categories":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of RAI categories.\n      ",
"title":"Categories"
},
"scores":{
"anyOf":[
{
"items":{
"type":"number"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of scores of each categories.\n      ",
"title":"Scores"
},
"contentType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Internal use only.\n      ",
"title":"Contenttype"
}
},
"title":"SafetyAttributes",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `generated_images (list[genai.types.GeneratedImage] | None)`



_field_ generated_images _:`Optional`[`list`[`GeneratedImage`]]__= None_ _(alias 'generatedImages')_¶ 
    
Generated images. 

_class_ genai.types.EditImageResponseDict¶ 
    
Bases: `TypedDict`
Response for the request to edit an image. 

generated_images _:`Optional`[`list`[`GeneratedImageDict`]]_¶ 
    
Generated images. 

_class_ genai.types.EditMode(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Enum representing the Imagen 3 Edit mode. 

EDIT_MODE_BGSWAP _= 'EDIT_MODE_BGSWAP'_¶ 


EDIT_MODE_CONTROLLED_EDITING _= 'EDIT_MODE_CONTROLLED_EDITING'_¶ 


EDIT_MODE_DEFAULT _= 'EDIT_MODE_DEFAULT'_¶ 


EDIT_MODE_INPAINT_INSERTION _= 'EDIT_MODE_INPAINT_INSERTION'_¶ 


EDIT_MODE_INPAINT_REMOVAL _= 'EDIT_MODE_INPAINT_REMOVAL'_¶ 


EDIT_MODE_OUTPAINT _= 'EDIT_MODE_OUTPAINT'_¶ 


EDIT_MODE_PRODUCT_IMAGE _= 'EDIT_MODE_PRODUCT_IMAGE'_¶ 


EDIT_MODE_STYLE _= 'EDIT_MODE_STYLE'_¶ 


_pydantic model_genai.types.EmbedContentConfig¶ 
    
Bases: `BaseModel`
Optional parameters for the embed_content method.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"EmbedContentConfig",
"description":"Optional parameters for the embed_content method.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
},
"taskType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Type of task for which the embedding will be used.\n      ",
"title":"Tasktype"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Title for the text. Only applicable when TaskType is\n      `RETRIEVAL_DOCUMENT`.\n      ",
"title":"Title"
},
"outputDimensionality":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Reduced dimension for the output embedding. If set,\n      excessive values in the output embedding are truncated from the end.\n      Supported by newer models since 2024 only. You cannot set this value if\n      using the earlier model (`models/embedding-001`).\n      ",
"title":"Outputdimensionality"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Vertex API only. The MIME type of the input.\n      ",
"title":"Mimetype"
},
"autoTruncate":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Vertex API only. Whether to silently truncate inputs longer than\n      the max sequence length. If this option is set to false, oversized inputs\n      will lead to an INVALID_ARGUMENT error, similar to other text APIs.\n      ",
"title":"Autotruncate"
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `auto_truncate (bool | None)`
  * `http_options (genai.types.HttpOptions | None)`
  * `mime_type (str | None)`
  * `output_dimensionality (int | None)`
  * `task_type (str | None)`
  * `title (str | None)`



_field_ auto_truncate _:`Optional`[`bool`]__= None_ _(alias 'autoTruncate')_¶ 
    
Vertex API only. Whether to silently truncate inputs longer than the max sequence length. If this option is set to false, oversized inputs will lead to an INVALID_ARGUMENT error, similar to other text APIs. 

_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_field_ mime_type _:`Optional`[`str`]__= None_ _(alias 'mimeType')_¶ 
    
Vertex API only. The MIME type of the input. 

_field_ output_dimensionality _:`Optional`[`int`]__= None_ _(alias 'outputDimensionality')_¶ 
    
Reduced dimension for the output embedding. If set, excessive values in the output embedding are truncated from the end. Supported by newer models since 2024 only. You cannot set this value if using the earlier model (models/embedding-001). 

_field_ task_type _:`Optional`[`str`]__= None_ _(alias 'taskType')_¶ 
    
Type of task for which the embedding will be used. 

_field_ title _:`Optional`[`str`]__= None_¶ 
    
Title for the text. Only applicable when TaskType is RETRIEVAL_DOCUMENT. 

_class_ genai.types.EmbedContentConfigDict¶ 
    
Bases: `TypedDict`
Optional parameters for the embed_content method. 

auto_truncate _:`Optional`[`bool`]_¶ 
    
Vertex API only. Whether to silently truncate inputs longer than the max sequence length. If this option is set to false, oversized inputs will lead to an INVALID_ARGUMENT error, similar to other text APIs. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

mime_type _:`Optional`[`str`]_¶ 
    
Vertex API only. The MIME type of the input. 

output_dimensionality _:`Optional`[`int`]_¶ 
    
Reduced dimension for the output embedding. If set, excessive values in the output embedding are truncated from the end. Supported by newer models since 2024 only. You cannot set this value if using the earlier model (models/embedding-001). 

task_type _:`Optional`[`str`]_¶ 
    
Type of task for which the embedding will be used. 

title _:`Optional`[`str`]_¶ 
    
Title for the text. Only applicable when TaskType is RETRIEVAL_DOCUMENT. 

_pydantic model_genai.types.EmbedContentMetadata¶ 
    
Bases: `BaseModel`
Request-level metadata for the Vertex Embed Content API.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"EmbedContentMetadata",
"description":"Request-level metadata for the Vertex Embed Content API.",
"type":"object",
"properties":{
"billableCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Vertex API only. The total number of billable characters included\n      in the request.\n      ",
"title":"Billablecharactercount"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `billable_character_count (int | None)`



_field_ billable_character_count _:`Optional`[`int`]__= None_ _(alias 'billableCharacterCount')_¶ 
    
Vertex API only. The total number of billable characters included in the request. 

_class_ genai.types.EmbedContentMetadataDict¶ 
    
Bases: `TypedDict`
Request-level metadata for the Vertex Embed Content API. 

billable_character_count _:`Optional`[`int`]_¶ 
    
Vertex API only. The total number of billable characters included in the request. 

_pydantic model_genai.types.EmbedContentResponse¶ 
    
Bases: `BaseModel`
Response for the embed_content method.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"EmbedContentResponse",
"description":"Response for the embed_content method.",
"type":"object",
"properties":{
"embeddings":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/ContentEmbedding"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The embeddings for each request, in the same order as provided in\n      the batch request.\n      ",
"title":"Embeddings"
},
"metadata":{
"anyOf":[
{
"$ref":"#/$defs/EmbedContentMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Vertex API only. Metadata about the request.\n      "
}
},
"$defs":{
"ContentEmbedding":{
"additionalProperties":false,
"description":"The embedding generated from an input content.",
"properties":{
"values":{
"anyOf":[
{
"items":{
"type":"number"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of floats representing an embedding.\n      ",
"title":"Values"
},
"statistics":{
"anyOf":[
{
"$ref":"#/$defs/ContentEmbeddingStatistics"
},
{
"type":"null"
}
],
"default":null,
"description":"Vertex API only. Statistics of the input text associated with this\n      embedding.\n      "
}
},
"title":"ContentEmbedding",
"type":"object"
},
"ContentEmbeddingStatistics":{
"additionalProperties":false,
"description":"Statistics of the input text associated with the result of content embedding.",
"properties":{
"truncated":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Vertex API only. If the input text was truncated due to having\n      a length longer than the allowed maximum input.\n      ",
"title":"Truncated"
},
"tokenCount":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Vertex API only. Number of tokens of the input text.\n      ",
"title":"Tokencount"
}
},
"title":"ContentEmbeddingStatistics",
"type":"object"
},
"EmbedContentMetadata":{
"additionalProperties":false,
"description":"Request-level metadata for the Vertex Embed Content API.",
"properties":{
"billableCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Vertex API only. The total number of billable characters included\n      in the request.\n      ",
"title":"Billablecharactercount"
}
},
"title":"EmbedContentMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `embeddings (list[genai.types.ContentEmbedding] | None)`
  * `metadata (genai.types.EmbedContentMetadata | None)`



_field_ embeddings _:`Optional`[`list`[`ContentEmbedding`]]__= None_¶ 
    
The embeddings for each request, in the same order as provided in the batch request. 

_field_ metadata _:`Optional`[`EmbedContentMetadata`]__= None_¶ 
    
Vertex API only. Metadata about the request. 

_class_ genai.types.EmbedContentResponseDict¶ 
    
Bases: `TypedDict`
Response for the embed_content method. 

embeddings _:`Optional`[`list`[`ContentEmbeddingDict`]]_¶ 
    
The embeddings for each request, in the same order as provided in the batch request. 

metadata _:`Optional`[`EmbedContentMetadataDict`]_¶ 
    
Vertex API only. Metadata about the request. 

_pydantic model_genai.types.EncryptionSpec¶ 
    
Bases: `BaseModel`
Represents a customer-managed encryption key spec that can be applied to a top-level resource.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"EncryptionSpec",
"description":"Represents a customer-managed encryption key spec that can be applied to a top-level resource.",
"type":"object",
"properties":{
"kmsKeyName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.",
"title":"Kmskeyname"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `kms_key_name (str | None)`



_field_ kms_key_name _:`Optional`[`str`]__= None_ _(alias 'kmsKeyName')_¶ 
    
Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the compute resource is created. 

_class_ genai.types.EncryptionSpecDict¶ 
    
Bases: `TypedDict`
Represents a customer-managed encryption key spec that can be applied to a top-level resource. 

kms_key_name _:`Optional`[`str`]_¶ 
    
projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the compute resource is created. 

Type: 
    
Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form 

_class_ genai.types.EndSensitivity(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
End of speech sensitivity. 

END_SENSITIVITY_HIGH _= 'END_SENSITIVITY_HIGH'_¶ 


END_SENSITIVITY_LOW _= 'END_SENSITIVITY_LOW'_¶ 


END_SENSITIVITY_UNSPECIFIED _= 'END_SENSITIVITY_UNSPECIFIED'_¶ 


_pydantic model_genai.types.Endpoint¶ 
    
Bases: `BaseModel`
An endpoint where you deploy models.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"Endpoint",
"description":"An endpoint where you deploy models.",
"type":"object",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Resource name of the endpoint.",
"title":"Name"
},
"deployedModelId":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"ID of the model that's deployed to the endpoint.",
"title":"Deployedmodelid"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `deployed_model_id (str | None)`
  * `name (str | None)`



_field_ deployed_model_id _:`Optional`[`str`]__= None_ _(alias 'deployedModelId')_¶ 
    
ID of the model that’s deployed to the endpoint. 

_field_ name _:`Optional`[`str`]__= None_¶ 
    
Resource name of the endpoint. 

_class_ genai.types.EndpointDict¶ 
    
Bases: `TypedDict`
An endpoint where you deploy models. 

deployed_model_id _:`Optional`[`str`]_¶ 
    
ID of the model that’s deployed to the endpoint. 

name _:`Optional`[`str`]_¶ 
    
Resource name of the endpoint. 

_pydantic model_genai.types.EnterpriseWebSearch¶ 
    
Bases: `BaseModel`
Tool to search public web data, powered by Vertex AI Search and Sec4 compliance.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"EnterpriseWebSearch",
"description":"Tool to search public web data, powered by Vertex AI Search and Sec4 compliance.",
"type":"object",
"properties":{},
"additionalProperties":false
}

```


_class_ genai.types.EnterpriseWebSearchDict¶ 
    
Bases: `TypedDict`
Tool to search public web data, powered by Vertex AI Search and Sec4 compliance. 

_pydantic model_genai.types.ExecutableCode¶ 
    
Bases: `BaseModel`
Code generated by the model that is meant to be executed, and the result returned to the model.
Generated when using the [FunctionDeclaration] tool and [FunctionCallingConfig] mode is set to [Mode.CODE].
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ExecutableCode",
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"type":"object",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"$defs":{
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `code (str | None)`
  * `language (genai.types.Language | None)`



_field_ code _:`Optional`[`str`]__= None_¶ 
    
Required. The code to be executed. 

_field_ language _:`Optional`[`Language`]__= None_¶ 
    
Required. Programming language of the code. 

_class_ genai.types.ExecutableCodeDict¶ 
    
Bases: `TypedDict`
Code generated by the model that is meant to be executed, and the result returned to the model.
Generated when using the [FunctionDeclaration] tool and [FunctionCallingConfig] mode is set to [Mode.CODE]. 

code _:`Optional`[`str`]_¶ 
    
Required. The code to be executed. 

language _:`Optional`[`Language`]_¶ 
    
Required. Programming language of the code. 

_class_ genai.types.FeatureSelectionPreference(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Options for feature selection preference. 

BALANCED _= 'BALANCED'_¶ 


FEATURE_SELECTION_PREFERENCE_UNSPECIFIED _= 'FEATURE_SELECTION_PREFERENCE_UNSPECIFIED'_¶ 


PRIORITIZE_COST _= 'PRIORITIZE_COST'_¶ 


PRIORITIZE_QUALITY _= 'PRIORITIZE_QUALITY'_¶ 


_pydantic model_genai.types.FetchPredictOperationConfig¶ 
    
Bases: `BaseModel`
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"FetchPredictOperationConfig",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `http_options (genai.types.HttpOptions | None)`



_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_class_ genai.types.FetchPredictOperationConfigDict¶ 
    
Bases: `TypedDict` 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

_pydantic model_genai.types.File¶ 
    
Bases: `BaseModel`
A file uploaded to the API.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"File",
"description":"A file uploaded to the API.",
"type":"object",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The `File` resource name. The ID (name excluding the \"files/\" prefix) can contain up to 40 characters that are lowercase alphanumeric or dashes (-). The ID cannot start or end with a dash. If the name is empty on create, a unique name will be generated. Example: `files/123-456`",
"title":"Name"
},
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The human-readable display name for the `File`. The display name must be no more than 512 characters in length, including spaces. Example: 'Welcome Image'",
"title":"Displayname"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. MIME type of the file.",
"title":"Mimetype"
},
"sizeBytes":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Size of the file in bytes.",
"title":"Sizebytes"
},
"createTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` was created.",
"title":"Createtime"
},
"expirationTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` will be deleted. Only set if the `File` is scheduled to expire.",
"title":"Expirationtime"
},
"updateTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` was last updated.",
"title":"Updatetime"
},
"sha256Hash":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. SHA-256 hash of the uploaded bytes. The hash value is encoded in base64 format.",
"title":"Sha256Hash"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The URI of the `File`.",
"title":"Uri"
},
"downloadUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The URI of the `File`, only set for downloadable (generated) files.",
"title":"Downloaduri"
},
"state":{
"anyOf":[
{
"$ref":"#/$defs/FileState"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Processing state of the File."
},
"source":{
"anyOf":[
{
"$ref":"#/$defs/FileSource"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The source of the `File`."
},
"videoMetadata":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Metadata for a video.",
"title":"Videometadata"
},
"error":{
"anyOf":[
{
"$ref":"#/$defs/FileStatus"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Error status if File processing failed."
}
},
"$defs":{
"FileSource":{
"description":"Source of the File.",
"enum":[
"SOURCE_UNSPECIFIED",
"UPLOADED",
"GENERATED"
],
"title":"FileSource",
"type":"string"
},
"FileState":{
"description":"State for the lifecycle of a File.",
"enum":[
"STATE_UNSPECIFIED",
"PROCESSING",
"ACTIVE",
"FAILED"
],
"title":"FileState",
"type":"string"
},
"FileStatus":{
"additionalProperties":false,
"description":"Status of a File that uses a common error model.",
"properties":{
"details":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Details"
},
"message":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Message"
},
"code":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The status code. 0 for OK, 1 for CANCELLED",
"title":"Code"
}
},
"title":"FileStatus",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `create_time (datetime.datetime | None)`
  * `display_name (str | None)`
  * `download_uri (str | None)`
  * `error (genai.types.FileStatus | None)`
  * `expiration_time (datetime.datetime | None)`
  * `mime_type (str | None)`
  * `name (str | None)`
  * `sha256_hash (str | None)`
  * `size_bytes (int | None)`
  * `source (genai.types.FileSource | None)`
  * `state (genai.types.FileState | None)`
  * `update_time (datetime.datetime | None)`
  * `uri (str | None)`
  * `video_metadata (dict[str, Any] | None)`



_field_ create_time _:`Optional`[`datetime`]__= None_ _(alias 'createTime')_¶ 
    
Output only. The timestamp of when the File was created. 

_field_ display_name _:`Optional`[`str`]__= None_ _(alias 'displayName')_¶ 
    
Optional. The human-readable display name for the File. The display name must be no more than 512 characters in length, including spaces. Example: ‘Welcome Image’ 

_field_ download_uri _:`Optional`[`str`]__= None_ _(alias 'downloadUri')_¶ 
    
Output only. The URI of the File, only set for downloadable (generated) files. 

_field_ error _:`Optional`[`FileStatus`]__= None_¶ 
    
Output only. Error status if File processing failed. 

_field_ expiration_time _:`Optional`[`datetime`]__= None_ _(alias 'expirationTime')_¶ 
    
Output only. The timestamp of when the File will be deleted. Only set if the File is scheduled to expire. 

_field_ mime_type _:`Optional`[`str`]__= None_ _(alias 'mimeType')_¶ 
    
Output only. MIME type of the file. 

_field_ name _:`Optional`[`str`]__= None_¶ 
    
The File resource name. The ID (name excluding the “files/” prefix) can contain up to 40 characters that are lowercase alphanumeric or dashes (-). The ID cannot start or end with a dash. If the name is empty on create, a unique name will be generated. Example: files/123-456 

_field_ sha256_hash _:`Optional`[`str`]__= None_ _(alias 'sha256Hash')_¶ 
    
Output only. SHA-256 hash of the uploaded bytes. The hash value is encoded in base64 format. 

_field_ size_bytes _:`Optional`[`int`]__= None_ _(alias 'sizeBytes')_¶ 
    
Output only. Size of the file in bytes. 

_field_ source _:`Optional`[`FileSource`]__= None_¶ 
    
Output only. The source of the File. 

_field_ state _:`Optional`[`FileState`]__= None_¶ 
    
Output only. Processing state of the File. 

_field_ update_time _:`Optional`[`datetime`]__= None_ _(alias 'updateTime')_¶ 
    
Output only. The timestamp of when the File was last updated. 

_field_ uri _:`Optional`[`str`]__= None_¶ 
    
Output only. The URI of the File. 

_field_ video_metadata _:`Optional`[`dict`[`str`, `Any`]]__= None_ _(alias 'videoMetadata')_¶ 
    
Output only. Metadata for a video. 

_pydantic model_genai.types.FileData¶ 
    
Bases: `BaseModel`
URI based data.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"FileData",
"description":"URI based data.",
"type":"object",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `file_uri (str | None)`
  * `mime_type (str | None)`



_field_ file_uri _:`Optional`[`str`]__= None_ _(alias 'fileUri')_¶ 
    
Required. URI. 

_field_ mime_type _:`Optional`[`str`]__= None_ _(alias 'mimeType')_¶ 
    
Required. The IANA standard MIME type of the source data. 

_class_ genai.types.FileDataDict¶ 
    
Bases: `TypedDict`
URI based data. 

file_uri _:`Optional`[`str`]_¶ 
    
Required. URI. 

mime_type _:`Optional`[`str`]_¶ 
    
Required. The IANA standard MIME type of the source data. 

_class_ genai.types.FileDict¶ 
    
Bases: `TypedDict`
A file uploaded to the API. 

create_time _:`Optional`[`datetime`]_¶ 
    
Output only. The timestamp of when the File was created. 

display_name _:`Optional`[`str`]_¶ 
    
‘Welcome Image’ 

Type: 
    
Optional. The human-readable display name for the File. The display name must be no more than 512 characters in length, including spaces. Example 

download_uri _:`Optional`[`str`]_¶ 
    
Output only. The URI of the File, only set for downloadable (generated) files. 

error _:`Optional`[`FileStatusDict`]_¶ 
    
Output only. Error status if File processing failed. 

expiration_time _:`Optional`[`datetime`]_¶ 
    
Output only. The timestamp of when the File will be deleted. Only set if the File is scheduled to expire. 

mime_type _:`Optional`[`str`]_¶ 
    
Output only. MIME type of the file. 

name _:`Optional`[`str`]_¶ 
    
files/123-456 

Type: 
    
The File resource name. The ID (name excluding the “files/” prefix) can contain up to 40 characters that are lowercase alphanumeric or dashes (-). The ID cannot start or end with a dash. If the name is empty on create, a unique name will be generated. Example 

sha256_hash _:`Optional`[`str`]_¶ 
    
Output only. SHA-256 hash of the uploaded bytes. The hash value is encoded in base64 format. 

size_bytes _:`Optional`[`int`]_¶ 
    
Output only. Size of the file in bytes. 

source _:`Optional`[`FileSource`]_¶ 
    
Output only. The source of the File. 

state _:`Optional`[`FileState`]_¶ 
    
Output only. Processing state of the File. 

update_time _:`Optional`[`datetime`]_¶ 
    
Output only. The timestamp of when the File was last updated. 

uri _:`Optional`[`str`]_¶ 
    
Output only. The URI of the File. 

video_metadata _:`Optional`[`dict`[`str`, `Any`]]_¶ 
    
Output only. Metadata for a video. 

_class_ genai.types.FileSource(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Source of the File. 

GENERATED _= 'GENERATED'_¶ 


SOURCE_UNSPECIFIED _= 'SOURCE_UNSPECIFIED'_¶ 


UPLOADED _= 'UPLOADED'_¶ 


_class_ genai.types.FileState(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
State for the lifecycle of a File. 

ACTIVE _= 'ACTIVE'_¶ 


FAILED _= 'FAILED'_¶ 


PROCESSING _= 'PROCESSING'_¶ 


STATE_UNSPECIFIED _= 'STATE_UNSPECIFIED'_¶ 


_pydantic model_genai.types.FileStatus¶ 
    
Bases: `BaseModel`
Status of a File that uses a common error model.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"FileStatus",
"description":"Status of a File that uses a common error model.",
"type":"object",
"properties":{
"details":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Details"
},
"message":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Message"
},
"code":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The status code. 0 for OK, 1 for CANCELLED",
"title":"Code"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `code (int | None)`
  * `details (list[dict[str, Any]] | None)`
  * `message (str | None)`



_field_ code _:`Optional`[`int`]__= None_¶ 
    
The status code. 0 for OK, 1 for CANCELLED 

_field_ details _:`Optional`[`list`[`dict`[`str`, `Any`]]]__= None_¶ 
    
A list of messages that carry the error details. There is a common set of message types for APIs to use. 

_field_ message _:`Optional`[`str`]__= None_¶ 
    
A list of messages that carry the error details. There is a common set of message types for APIs to use. 

_class_ genai.types.FileStatusDict¶ 
    
Bases: `TypedDict`
Status of a File that uses a common error model. 

code _:`Optional`[`int`]_¶ 
    
The status code. 0 for OK, 1 for CANCELLED 

details _:`Optional`[`list`[`dict`[`str`, `Any`]]]_¶ 
    
A list of messages that carry the error details. There is a common set of message types for APIs to use. 

message _:`Optional`[`str`]_¶ 
    
A list of messages that carry the error details. There is a common set of message types for APIs to use. 

_class_ genai.types.FinishReason(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Output only. The reason why the model stopped generating tokens.
If empty, the model has not stopped generating the tokens. 

BLOCKLIST _= 'BLOCKLIST'_¶ 


FINISH_REASON_UNSPECIFIED _= 'FINISH_REASON_UNSPECIFIED'_¶ 


IMAGE_SAFETY _= 'IMAGE_SAFETY'_¶ 


LANGUAGE _= 'LANGUAGE'_¶ 


MALFORMED_FUNCTION_CALL _= 'MALFORMED_FUNCTION_CALL'_¶ 


MAX_TOKENS _= 'MAX_TOKENS'_¶ 


OTHER _= 'OTHER'_¶ 


PROHIBITED_CONTENT _= 'PROHIBITED_CONTENT'_¶ 


RECITATION _= 'RECITATION'_¶ 


SAFETY _= 'SAFETY'_¶ 


SPII _= 'SPII'_¶ 


STOP _= 'STOP'_¶ 


_pydantic model_genai.types.FunctionCall¶ 
    
Bases: `BaseModel`
A function call.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"FunctionCall",
"description":"A function call.",
"type":"object",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `args (dict[str, Any] | None)`
  * `id (str | None)`
  * `name (str | None)`



_field_ args _:`Optional`[`dict`[`str`, `Any`]]__= None_¶ 
    
Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details. 

_field_ id _:`Optional`[`str`]__= None_¶ 
    
The unique id of the function call. If populated, the client to execute the function_call and return the response with the matching id. 

_field_ name _:`Optional`[`str`]__= None_¶ 
    
Required. The name of the function to call. Matches [FunctionDeclaration.name]. 

_class_ genai.types.FunctionCallDict¶ 
    
Bases: `TypedDict`
A function call. 

args _:`Optional`[`dict`[`str`, `Any`]]_¶ 
    
Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details. 

id _:`Optional`[`str`]_¶ 
    
The unique id of the function call. If populated, the client to execute the function_call and return the response with the matching id. 

name _:`Optional`[`str`]_¶ 
    
Required. The name of the function to call. Matches [FunctionDeclaration.name]. 

_pydantic model_genai.types.FunctionCallingConfig¶ 
    
Bases: `BaseModel`
Function calling config.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"FunctionCallingConfig",
"description":"Function calling config.",
"type":"object",
"properties":{
"mode":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCallingConfigMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Function calling mode."
},
"allowedFunctionNames":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Function names to call. Only set when the Mode is ANY. Function names should match [FunctionDeclaration.name]. With mode set to ANY, model will predict a function call from the set of function names provided.",
"title":"Allowedfunctionnames"
}
},
"$defs":{
"FunctionCallingConfigMode":{
"description":"Config for the function calling config mode.",
"enum":[
"MODE_UNSPECIFIED",
"AUTO",
"ANY",
"NONE"
],
"title":"FunctionCallingConfigMode",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `allowed_function_names (list[str] | None)`
  * `mode (genai.types.FunctionCallingConfigMode | None)`



_field_ allowed_function_names _:`Optional`[`list`[`str`]]__= None_ _(alias 'allowedFunctionNames')_¶ 
    
Optional. Function names to call. Only set when the Mode is ANY. Function names should match [FunctionDeclaration.name]. With mode set to ANY, model will predict a function call from the set of function names provided. 

_field_ mode _:`Optional`[`FunctionCallingConfigMode`]__= None_¶ 
    
Optional. Function calling mode. 

_class_ genai.types.FunctionCallingConfigDict¶ 
    
Bases: `TypedDict`
Function calling config. 

allowed_function_names _:`Optional`[`list`[`str`]]_¶ 
    
Optional. Function names to call. Only set when the Mode is ANY. Function names should match [FunctionDeclaration.name]. With mode set to ANY, model will predict a function call from the set of function names provided. 

mode _:`Optional`[`FunctionCallingConfigMode`]_¶ 
    
Optional. Function calling mode. 

_class_ genai.types.FunctionCallingConfigMode(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Config for the function calling config mode. 

ANY _= 'ANY'_¶ 


AUTO _= 'AUTO'_¶ 


MODE_UNSPECIFIED _= 'MODE_UNSPECIFIED'_¶ 


NONE _= 'NONE'_¶ 


_pydantic model_genai.types.FunctionDeclaration¶ 
    
Bases: `BaseModel`
Structured representation of a function declaration as defined by the [OpenAPI 3.0 specification](https://spec.openapis.org/oas/v3.0.3).
Included in this declaration are the function name, description, parameters and response type. This FunctionDeclaration is a representation of a block of code that can be used as a Tool by the model and executed by the client.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"FunctionDeclaration",
"description":"Structured representation of a function declaration as defined by the [OpenAPI 3.0 specification](https://spec.openapis.org/oas/v3.0.3).\n\nIncluded in this declaration are the function name, description, parameters\nand response type. This FunctionDeclaration is a representation of a block of\ncode that can be used as a `Tool` by the model and executed by the client.",
"type":"object",
"properties":{
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Description and purpose of the function. Model uses it to decide how and whether to call the function.",
"title":"Description"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Must start with a letter or an underscore. Must be a-z, A-Z, 0-9, or contain underscores, dots and dashes, with a maximum length of 64.",
"title":"Name"
},
"parameters":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Describes the parameters to this function in JSON Schema Object format. Reflects the Open API 3.03 Parameter Object. string Key: the name of the parameter. Parameter names are case sensitive. Schema Value: the Schema defining the type used for the parameter. For function with no parameters, this can be left unset. Parameter names must start with a letter or an underscore and must only contain chars a-z, A-Z, 0-9, or underscores with a maximum length of 64. Example with 1 required and 1 optional parameter: type: OBJECT properties: param1: type: STRING param2: type: INTEGER required: - param1"
},
"response":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Describes the output from this function in JSON Schema format. Reflects the Open API 3.03 Response Object. The Schema defines the type used for the response value of the function."
}
},
"$defs":{
"Schema":{
"additionalProperties":false,
"description":"Schema is used to define the format of input/output data.\n\nRepresents a select subset of an [OpenAPI 3.0 schema\nobject](https://spec.openapis.org/oas/v3.0.3#schema-object). More fields may\nbe added in the future as needed.",
"properties":{
"anyOf":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Schema"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The value should be validated against any (one or more) of the subschemas in the list.",
"title":"Anyof"
},
"default":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Default value of the data.",
"title":"Default"
},
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The description of the data.",
"title":"Description"
},
"enum":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Possible values of the element of primitive type with enum format. Examples: 1. We can define direction as : {type:STRING, format:enum, enum:[\"EAST\", NORTH\", \"SOUTH\", \"WEST\"]} 2. We can define apartment number as : {type:INTEGER, format:enum, enum:[\"101\", \"201\", \"301\"]}",
"title":"Enum"
},
"example":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Example of the object. Will only populated when the object is the root.",
"title":"Example"
},
"format":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The format of the data. Supported formats: for NUMBER type: \"float\", \"double\" for INTEGER type: \"int32\", \"int64\" for STRING type: \"email\", \"byte\", etc",
"title":"Format"
},
"items":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE ARRAY Schema of the elements of Type.ARRAY."
},
"maxItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the elements for Type.ARRAY.",
"title":"Maxitems"
},
"maxLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum length of the Type.STRING",
"title":"Maxlength"
},
"maxProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the properties for Type.OBJECT.",
"title":"Maxproperties"
},
"maximum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum value of the Type.INTEGER and Type.NUMBER",
"title":"Maximum"
},
"minItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the elements for Type.ARRAY.",
"title":"Minitems"
},
"minLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING",
"title":"Minlength"
},
"minProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the properties for Type.OBJECT.",
"title":"Minproperties"
},
"minimum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER Minimum value of the Type.INTEGER and Type.NUMBER",
"title":"Minimum"
},
"nullable":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Indicates if the value may be null.",
"title":"Nullable"
},
"pattern":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Pattern of the Type.STRING to restrict a string to a regular expression.",
"title":"Pattern"
},
"properties":{
"anyOf":[
{
"additionalProperties":{
"$ref":"#/$defs/Schema"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE OBJECT Properties of Type.OBJECT.",
"title":"Properties"
},
"propertyOrdering":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The order of the properties. Not a standard field in open api spec. Only used to support the order of the properties.",
"title":"Propertyordering"
},
"required":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required properties of Type.OBJECT.",
"title":"Required"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The title of the Schema.",
"title":"Title"
},
"type":{
"anyOf":[
{
"$ref":"#/$defs/Type"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The type of the data."
}
},
"title":"Schema",
"type":"object"
},
"Type":{
"description":"Optional. The type of the data.",
"enum":[
"TYPE_UNSPECIFIED",
"STRING",
"NUMBER",
"INTEGER",
"BOOLEAN",
"ARRAY",
"OBJECT"
],
"title":"Type",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `description (str | None)`
  * `name (str | None)`
  * `parameters (genai.types.Schema | None)`
  * `response (genai.types.Schema | None)`



_field_ description _:`Optional`[`str`]__= None_¶ 
    
Optional. Description and purpose of the function. Model uses it to decide how and whether to call the function. 

_field_ name _:`Optional`[`str`]__= None_¶ 
    
Required. The name of the function to call. Must start with a letter or an underscore. Must be a-z, A-Z, 0-9, or contain underscores, dots and dashes, with a maximum length of 64. 

_field_ parameters _:`Optional`[`Schema`]__= None_¶ 
    
Optional. Describes the parameters to this function in JSON Schema Object format. Reflects the Open API 3.03 Parameter Object. string Key: the name of the parameter. Parameter names are case sensitive. Schema Value: the Schema defining the type used for the parameter. For function with no parameters, this can be left unset. Parameter names must start with a letter or an underscore and must only contain chars a-z, A-Z, 0-9, or underscores with a maximum length of 64. Example with 1 required and 1 optional parameter: type: OBJECT properties: param1: type: STRING param2: type: INTEGER required: - param1 

_field_ response _:`Optional`[`Schema`]__= None_¶ 
    
Optional. Describes the output from this function in JSON Schema format. Reflects the Open API 3.03 Response Object. The Schema defines the type used for the response value of the function. 

_classmethod_ from_callable(_*_ , _client_ , _callable_)¶ 
    
Converts a Callable to a FunctionDeclaration based on the client. 

Return type: 
    
`FunctionDeclaration` 

_classmethod_ from_callable_with_api_option(_*_ , _callable_ , _api_option ='GEMINI_API'_)¶ 
    
Converts a Callable to a FunctionDeclaration based on the API option.
Supported API option is ‘VERTEX_AI’ or ‘GEMINI_API’. If api_option is unset, it will default to ‘GEMINI_API’. If unsupported api_option is provided, it will raise ValueError. 

Return type: 
    
`FunctionDeclaration` 

_class_ genai.types.FunctionDeclarationDict¶ 
    
Bases: `TypedDict`
Structured representation of a function declaration as defined by the [OpenAPI 3.0 specification](https://spec.openapis.org/oas/v3.0.3).
Included in this declaration are the function name, description, parameters and response type. This FunctionDeclaration is a representation of a block of code that can be used as a Tool by the model and executed by the client. 

description _:`Optional`[`str`]_¶ 
    
Optional. Description and purpose of the function. Model uses it to decide how and whether to call the function. 

name _:`Optional`[`str`]_¶ 
    
Required. The name of the function to call. Must start with a letter or an underscore. Must be a-z, A-Z, 0-9, or contain underscores, dots and dashes, with a maximum length of 64. 

parameters _:`Optional`[`SchemaDict`]_¶ 
    
the Schema defining the type used for the parameter. For function with no parameters, this can be left unset. Parameter names must start with a letter or an underscore and must only contain chars a-z, A-Z, 0-9, or underscores with a maximum length of 64. Example with 1 required and 1 optional parameter: type: OBJECT properties: param1: type: STRING param2: type: INTEGER required: - param1 

Type: 
    
Optional. Describes the parameters to this function in JSON Schema Object format. Reflects the Open API 3.03 Parameter Object. string Key 

Type: 
    
the name of the parameter. Parameter names are case sensitive. Schema Value 

response _:`Optional`[`SchemaDict`]_¶ 
    
Optional. Describes the output from this function in JSON Schema format. Reflects the Open API 3.03 Response Object. The Schema defines the type used for the response value of the function. 

_pydantic model_genai.types.FunctionResponse¶ 
    
Bases: `BaseModel`
A function response.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"FunctionResponse",
"description":"A function response.",
"type":"object",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `id (str | None)`
  * `name (str | None)`
  * `response (dict[str, Any] | None)`



_field_ id _:`Optional`[`str`]__= None_¶ 
    
The id of the function call this response is for. Populated by the client to match the corresponding function call id. 

_field_ name _:`Optional`[`str`]__= None_¶ 
    
Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name]. 

_field_ response _:`Optional`[`dict`[`str`, `Any`]]__= None_¶ 
    
Required. The function response in JSON object format. Use “output” key to specify function output and “error” key to specify error details (if any). If “output” and “error” keys are not specified, then whole “response” is treated as function output. 

_class_ genai.types.FunctionResponseDict¶ 
    
Bases: `TypedDict`
A function response. 

id _:`Optional`[`str`]_¶ 
    
The id of the function call this response is for. Populated by the client to match the corresponding function call id. 

name _:`Optional`[`str`]_¶ 
    
Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name]. 

response _:`Optional`[`dict`[`str`, `Any`]]_¶ 
    
Required. The function response in JSON object format. Use “output” key to specify function output and “error” key to specify error details (if any). If “output” and “error” keys are not specified, then whole “response” is treated as function output. 

_pydantic model_genai.types.GenerateContentConfig¶ 
    
Bases: `BaseModel`
Optional model configuration parameters.
For more information, see Content generation parameters.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GenerateContentConfig",
"description":"Optional model configuration parameters.\n\nFor more information, see `Content generation parameters\n<https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/content-generation-parameters>`_.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
},
"systemInstruction":{
"anyOf":[
{
"$ref":"#/$defs/Content"
},
{
"items":{
"anyOf":[
{
"$ref":"#/$defs/File"
},
{
"$ref":"#/$defs/Part"
},
{
"type":"string"
}
]
},
"type":"array"
},
{
"$ref":"#/$defs/File"
},
{
"$ref":"#/$defs/Part"
},
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Instructions for the model to steer it toward better performance.\n      For example, \"Answer as concisely as possible\" or \"Don't use technical\n      terms in your response\".\n      ",
"title":"Systeminstruction"
},
"temperature":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Value that controls the degree of randomness in token selection.\n      Lower temperatures are good for prompts that require a less open-ended or\n      creative response, while higher temperatures can lead to more diverse or\n      creative results.\n      ",
"title":"Temperature"
},
"topP":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Tokens are selected from the most to least probable until the sum\n      of their probabilities equals this value. Use a lower value for less\n      random responses and a higher value for more random responses.\n      ",
"title":"Topp"
},
"topK":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"For each token selection step, the ``top_k`` tokens with the\n      highest probabilities are sampled. Then tokens are further filtered based\n      on ``top_p`` with the final token selected using temperature sampling. Use\n      a lower number for less random responses and a higher number for more\n      random responses.\n      ",
"title":"Topk"
},
"candidateCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of response variations to return.\n      ",
"title":"Candidatecount"
},
"maxOutputTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Maximum number of tokens that can be generated in the response.\n      ",
"title":"Maxoutputtokens"
},
"stopSequences":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of strings that tells the model to stop generating text if one\n      of the strings is encountered in the response.\n      ",
"title":"Stopsequences"
},
"responseLogprobs":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Whether to return the log probabilities of the tokens that were\n      chosen by the model at each step.\n      ",
"title":"Responselogprobs"
},
"logprobs":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of top candidate tokens to return the log probabilities for\n      at each generation step.\n      ",
"title":"Logprobs"
},
"presencePenalty":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Positive values penalize tokens that already appear in the\n      generated text, increasing the probability of generating more diverse\n      content.\n      ",
"title":"Presencepenalty"
},
"frequencyPenalty":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Positive values penalize tokens that repeatedly appear in the\n      generated text, increasing the probability of generating more diverse\n      content.\n      ",
"title":"Frequencypenalty"
},
"seed":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"When ``seed`` is fixed to a specific number, the model makes a best\n      effort to provide the same response for repeated requests. By default, a\n      random number is used.\n      ",
"title":"Seed"
},
"responseMimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output response mimetype of the generated candidate text.\n      Supported mimetype:\n        - `text/plain`: (default) Text output.\n        - `application/json`: JSON response in the candidates.\n      The model needs to be prompted to output the appropriate response type,\n      otherwise the behavior is undefined.\n      This is a preview feature.\n      ",
"title":"Responsemimetype"
},
"responseSchema":{
"anyOf":[
{
"type":"object"
},
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"The `Schema` object allows the definition of input and output data types.\n      These types can be objects, but also primitives and arrays.\n      Represents a select subset of an [OpenAPI 3.0 schema\n      object](https://spec.openapis.org/oas/v3.0.3#schema).\n      If set, a compatible response_mime_type must also be set.\n      Compatible mimetypes: `application/json`: Schema for JSON response.\n      ",
"title":"Responseschema"
},
"routingConfig":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Configuration for model router requests.\n      "
},
"modelSelectionConfig":{
"anyOf":[
{
"$ref":"#/$defs/ModelSelectionConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Configuration for model selection.\n      "
},
"safetySettings":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/SafetySetting"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Safety settings in the request to block unsafe content in the\n      response.\n      ",
"title":"Safetysettings"
},
"tools":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Tool"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Code that enables the system to interact with external systems to\n      perform an action outside of the knowledge and scope of the model.\n      ",
"title":"Tools"
},
"toolConfig":{
"anyOf":[
{
"$ref":"#/$defs/ToolConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Associates model output to a specific function call.\n      "
},
"labels":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Labels with user-defined metadata to break down billed charges.",
"title":"Labels"
},
"cachedContent":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Resource name of a context cache that can be used in subsequent\n      requests.\n      ",
"title":"Cachedcontent"
},
"responseModalities":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The requested modalities of the response. Represents the set of\n      modalities that the model can return.\n      ",
"title":"Responsemodalities"
},
"mediaResolution":{
"anyOf":[
{
"$ref":"#/$defs/MediaResolution"
},
{
"type":"null"
}
],
"default":null,
"description":"If specified, the media resolution specified will be used.\n    "
},
"speechConfig":{
"anyOf":[
{
"$ref":"#/$defs/SpeechConfig"
},
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The speech generation configuration.\n      ",
"title":"Speechconfig"
},
"audioTimestamp":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If enabled, audio timestamp will be included in the request to the\n       model.\n      ",
"title":"Audiotimestamp"
},
"automaticFunctionCalling":{
"anyOf":[
{
"$ref":"#/$defs/AutomaticFunctionCallingConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The configuration for automatic function calling.\n      "
},
"thinkingConfig":{
"anyOf":[
{
"$ref":"#/$defs/ThinkingConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The thinking features configuration.\n      "
}
},
"$defs":{
"ApiKeyConfig":{
"additionalProperties":false,
"description":"Config for authentication with API key.",
"properties":{
"apiKeyString":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The API key to be used in the request directly.",
"title":"Apikeystring"
}
},
"title":"ApiKeyConfig",
"type":"object"
},
"AuthConfig":{
"additionalProperties":false,
"description":"Auth configuration to run the extension.",
"properties":{
"apiKeyConfig":{
"anyOf":[
{
"$ref":"#/$defs/ApiKeyConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for API key auth."
},
"authType":{
"anyOf":[
{
"$ref":"#/$defs/AuthType"
},
{
"type":"null"
}
],
"default":null,
"description":"Type of auth scheme."
},
"googleServiceAccountConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigGoogleServiceAccountConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for Google Service Account auth."
},
"httpBasicAuthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigHttpBasicAuthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for HTTP Basic auth."
},
"oauthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOauthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user oauth."
},
"oidcConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOidcConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user OIDC auth."
}
},
"title":"AuthConfig",
"type":"object"
},
"AuthConfigGoogleServiceAccountConfig":{
"additionalProperties":false,
"description":"Config for Google Service Account Authentication.",
"properties":{
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The service account that the extension execution service runs as. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified service account. - If not specified, the Vertex AI Extension Service Agent will be used to execute the Extension.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigGoogleServiceAccountConfig",
"type":"object"
},
"AuthConfigHttpBasicAuthConfig":{
"additionalProperties":false,
"description":"Config for HTTP Basic Authentication.",
"properties":{
"credentialSecret":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the SecretManager secret version resource storing the base64 encoded credentials. Format: `projects/{project}/secrets/{secrete}/versions/{version}` - If specified, the `secretmanager.versions.access` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified resource.",
"title":"Credentialsecret"
}
},
"title":"AuthConfigHttpBasicAuthConfig",
"type":"object"
},
"AuthConfigOauthConfig":{
"additionalProperties":false,
"description":"Config for user oauth.",
"properties":{
"accessToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Access token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Accesstoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate access tokens for executing the Extension. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the provided service account.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOauthConfig",
"type":"object"
},
"AuthConfigOidcConfig":{
"additionalProperties":false,
"description":"Config for user OIDC auth.",
"properties":{
"idToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"OpenID Connect formatted ID token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Idtoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate an OpenID Connect (OIDC)-compatible JWT token signed by the Google OIDC Provider (accounts.google.com) for extension endpoint (https://cloud.google.com/iam/docs/create-short-lived-credentials-direct#sa-credentials-oidc). - The audience for the token will be set to the URL in the server url defined in the OpenApi spec. - If the service account is provided, the service account should grant `iam.serviceAccounts.getOpenIdToken` permission to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOidcConfig",
"type":"object"
},
"AuthType":{
"description":"Type of auth scheme.",
"enum":[
"AUTH_TYPE_UNSPECIFIED",
"NO_AUTH",
"API_KEY_AUTH",
"HTTP_BASIC_AUTH",
"GOOGLE_SERVICE_ACCOUNT_AUTH",
"OAUTH",
"OIDC_AUTH"
],
"title":"AuthType",
"type":"string"
},
"AutomaticFunctionCallingConfig":{
"additionalProperties":false,
"description":"The configuration for automatic function calling.",
"properties":{
"disable":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Whether to disable automatic function calling.\n      If not set or set to False, will enable automatic function calling.\n      If set to True, will disable automatic function calling.\n      ",
"title":"Disable"
},
"maximumRemoteCalls":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":10,
"description":"If automatic function calling is enabled,\n      maximum number of remote calls for automatic function calling.\n      This number should be a positive integer.\n      If not set, SDK will set maximum number of remote calls to 10.\n      ",
"title":"Maximumremotecalls"
},
"ignoreCallHistory":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If automatic function calling is enabled,\n      whether to ignore call history to the response.\n      If not set, SDK will set ignore_call_history to false,\n      and will append the call history to\n      GenerateContentResponse.automatic_function_calling_history.\n      ",
"title":"Ignorecallhistory"
}
},
"title":"AutomaticFunctionCallingConfig",
"type":"object"
},
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"Content":{
"additionalProperties":false,
"description":"Contains the multi-part content of a message.",
"properties":{
"parts":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Part"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of parts that constitute a single message. Each part may have\n      a different IANA MIME type.",
"title":"Parts"
},
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role.",
"title":"Role"
}
},
"title":"Content",
"type":"object"
},
"DynamicRetrievalConfig":{
"additionalProperties":false,
"description":"Describes the options to customize dynamic retrieval.",
"properties":{
"mode":{
"anyOf":[
{
"$ref":"#/$defs/DynamicRetrievalConfigMode"
},
{
"type":"null"
}
],
"default":null,
"description":"The mode of the predictor to be used in dynamic retrieval."
},
"dynamicThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The threshold to be used in dynamic retrieval. If not set, a system default value is used.",
"title":"Dynamicthreshold"
}
},
"title":"DynamicRetrievalConfig",
"type":"object"
},
"DynamicRetrievalConfigMode":{
"description":"Config for the dynamic retrieval config mode.",
"enum":[
"MODE_UNSPECIFIED",
"MODE_DYNAMIC"
],
"title":"DynamicRetrievalConfigMode",
"type":"string"
},
"EnterpriseWebSearch":{
"additionalProperties":false,
"description":"Tool to search public web data, powered by Vertex AI Search and Sec4 compliance.",
"properties":{},
"title":"EnterpriseWebSearch",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"FeatureSelectionPreference":{
"description":"Options for feature selection preference.",
"enum":[
"FEATURE_SELECTION_PREFERENCE_UNSPECIFIED",
"PRIORITIZE_QUALITY",
"BALANCED",
"PRIORITIZE_COST"
],
"title":"FeatureSelectionPreference",
"type":"string"
},
"File":{
"additionalProperties":false,
"description":"A file uploaded to the API.",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The `File` resource name. The ID (name excluding the \"files/\" prefix) can contain up to 40 characters that are lowercase alphanumeric or dashes (-). The ID cannot start or end with a dash. If the name is empty on create, a unique name will be generated. Example: `files/123-456`",
"title":"Name"
},
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The human-readable display name for the `File`. The display name must be no more than 512 characters in length, including spaces. Example: 'Welcome Image'",
"title":"Displayname"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. MIME type of the file.",
"title":"Mimetype"
},
"sizeBytes":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Size of the file in bytes.",
"title":"Sizebytes"
},
"createTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` was created.",
"title":"Createtime"
},
"expirationTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` will be deleted. Only set if the `File` is scheduled to expire.",
"title":"Expirationtime"
},
"updateTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` was last updated.",
"title":"Updatetime"
},
"sha256Hash":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. SHA-256 hash of the uploaded bytes. The hash value is encoded in base64 format.",
"title":"Sha256Hash"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The URI of the `File`.",
"title":"Uri"
},
"downloadUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The URI of the `File`, only set for downloadable (generated) files.",
"title":"Downloaduri"
},
"state":{
"anyOf":[
{
"$ref":"#/$defs/FileState"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Processing state of the File."
},
"source":{
"anyOf":[
{
"$ref":"#/$defs/FileSource"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The source of the `File`."
},
"videoMetadata":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Metadata for a video.",
"title":"Videometadata"
},
"error":{
"anyOf":[
{
"$ref":"#/$defs/FileStatus"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Error status if File processing failed."
}
},
"title":"File",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FileSource":{
"description":"Source of the File.",
"enum":[
"SOURCE_UNSPECIFIED",
"UPLOADED",
"GENERATED"
],
"title":"FileSource",
"type":"string"
},
"FileState":{
"description":"State for the lifecycle of a File.",
"enum":[
"STATE_UNSPECIFIED",
"PROCESSING",
"ACTIVE",
"FAILED"
],
"title":"FileState",
"type":"string"
},
"FileStatus":{
"additionalProperties":false,
"description":"Status of a File that uses a common error model.",
"properties":{
"details":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Details"
},
"message":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Message"
},
"code":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The status code. 0 for OK, 1 for CANCELLED",
"title":"Code"
}
},
"title":"FileStatus",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionCallingConfig":{
"additionalProperties":false,
"description":"Function calling config.",
"properties":{
"mode":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCallingConfigMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Function calling mode."
},
"allowedFunctionNames":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Function names to call. Only set when the Mode is ANY. Function names should match [FunctionDeclaration.name]. With mode set to ANY, model will predict a function call from the set of function names provided.",
"title":"Allowedfunctionnames"
}
},
"title":"FunctionCallingConfig",
"type":"object"
},
"FunctionCallingConfigMode":{
"description":"Config for the function calling config mode.",
"enum":[
"MODE_UNSPECIFIED",
"AUTO",
"ANY",
"NONE"
],
"title":"FunctionCallingConfigMode",
"type":"string"
},
"FunctionDeclaration":{
"additionalProperties":false,
"description":"Structured representation of a function declaration as defined by the [OpenAPI 3.0 specification](https://spec.openapis.org/oas/v3.0.3).\n\nIncluded in this declaration are the function name, description, parameters\nand response type. This FunctionDeclaration is a representation of a block of\ncode that can be used as a `Tool` by the model and executed by the client.",
"properties":{
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Description and purpose of the function. Model uses it to decide how and whether to call the function.",
"title":"Description"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Must start with a letter or an underscore. Must be a-z, A-Z, 0-9, or contain underscores, dots and dashes, with a maximum length of 64.",
"title":"Name"
},
"parameters":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Describes the parameters to this function in JSON Schema Object format. Reflects the Open API 3.03 Parameter Object. string Key: the name of the parameter. Parameter names are case sensitive. Schema Value: the Schema defining the type used for the parameter. For function with no parameters, this can be left unset. Parameter names must start with a letter or an underscore and must only contain chars a-z, A-Z, 0-9, or underscores with a maximum length of 64. Example with 1 required and 1 optional parameter: type: OBJECT properties: param1: type: STRING param2: type: INTEGER required: - param1"
},
"response":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Describes the output from this function in JSON Schema format. Reflects the Open API 3.03 Response Object. The Schema defines the type used for the response value of the function."
}
},
"title":"FunctionDeclaration",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"GenerationConfigRoutingConfig":{
"additionalProperties":false,
"description":"The configuration for routing the request to a specific model.",
"properties":{
"autoMode":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfigAutoRoutingMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Automated routing."
},
"manualMode":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfigManualRoutingMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Manual routing."
}
},
"title":"GenerationConfigRoutingConfig",
"type":"object"
},
"GenerationConfigRoutingConfigAutoRoutingMode":{
"additionalProperties":false,
"description":"When automated routing is specified, the routing will be determined by the pretrained routing model and customer provided model routing preference.",
"properties":{
"modelRoutingPreference":{
"anyOf":[
{
"enum":[
"UNKNOWN",
"PRIORITIZE_QUALITY",
"BALANCED",
"PRIORITIZE_COST"
],
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The model routing preference.",
"title":"Modelroutingpreference"
}
},
"title":"GenerationConfigRoutingConfigAutoRoutingMode",
"type":"object"
},
"GenerationConfigRoutingConfigManualRoutingMode":{
"additionalProperties":false,
"description":"When manual routing is set, the specified model will be used directly.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The model name to use. Only the public LLM models are accepted. e.g. 'gemini-1.5-pro-001'.",
"title":"Modelname"
}
},
"title":"GenerationConfigRoutingConfigManualRoutingMode",
"type":"object"
},
"GoogleMaps":{
"additionalProperties":false,
"description":"Tool to support Google Maps in Model.",
"properties":{
"authConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Auth config for the Google Maps tool."
}
},
"title":"GoogleMaps",
"type":"object"
},
"GoogleSearch":{
"additionalProperties":false,
"description":"Tool to support Google Search in Model. Powered by Google.",
"properties":{},
"title":"GoogleSearch",
"type":"object"
},
"GoogleSearchRetrieval":{
"additionalProperties":false,
"description":"Tool to retrieve public web data for grounding, powered by Google.",
"properties":{
"dynamicRetrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/DynamicRetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the dynamic retrieval configuration for the given source."
}
},
"title":"GoogleSearchRetrieval",
"type":"object"
},
"HarmBlockMethod":{
"description":"Optional.\n\nSpecify if the threshold is used for probability or severity score. If not\nspecified, the threshold is used for probability score.",
"enum":[
"HARM_BLOCK_METHOD_UNSPECIFIED",
"SEVERITY",
"PROBABILITY"
],
"title":"HarmBlockMethod",
"type":"string"
},
"HarmBlockThreshold":{
"description":"Required. The harm block threshold.",
"enum":[
"HARM_BLOCK_THRESHOLD_UNSPECIFIED",
"BLOCK_LOW_AND_ABOVE",
"BLOCK_MEDIUM_AND_ABOVE",
"BLOCK_ONLY_HIGH",
"BLOCK_NONE",
"OFF"
],
"title":"HarmBlockThreshold",
"type":"string"
},
"HarmCategory":{
"description":"Required. Harm category.",
"enum":[
"HARM_CATEGORY_UNSPECIFIED",
"HARM_CATEGORY_HATE_SPEECH",
"HARM_CATEGORY_DANGEROUS_CONTENT",
"HARM_CATEGORY_HARASSMENT",
"HARM_CATEGORY_SEXUALLY_EXPLICIT",
"HARM_CATEGORY_CIVIC_INTEGRITY"
],
"title":"HarmCategory",
"type":"string"
},
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"LatLng":{
"additionalProperties":false,
"description":"An object that represents a latitude/longitude pair.\n\nThis is expressed as a pair of doubles to represent degrees latitude and\ndegrees longitude. Unless specified otherwise, this object must conform to the\n<a href=\"https://en.wikipedia.org/wiki/World_Geodetic_System#1984_version\">\nWGS84 standard</a>. Values must be within normalized ranges.",
"properties":{
"latitude":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"The latitude in degrees. It must be in the range [-90.0, +90.0].",
"title":"Latitude"
},
"longitude":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"The longitude in degrees. It must be in the range [-180.0, +180.0]",
"title":"Longitude"
}
},
"title":"LatLng",
"type":"object"
},
"MediaResolution":{
"description":"The media resolution to use.",
"enum":[
"MEDIA_RESOLUTION_UNSPECIFIED",
"MEDIA_RESOLUTION_LOW",
"MEDIA_RESOLUTION_MEDIUM",
"MEDIA_RESOLUTION_HIGH"
],
"title":"MediaResolution",
"type":"string"
},
"ModelSelectionConfig":{
"additionalProperties":false,
"description":"Config for model selection.",
"properties":{
"featureSelectionPreference":{
"anyOf":[
{
"$ref":"#/$defs/FeatureSelectionPreference"
},
{
"type":"null"
}
],
"default":null,
"description":"Options for feature selection preference."
}
},
"title":"ModelSelectionConfig",
"type":"object"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"PrebuiltVoiceConfig":{
"additionalProperties":false,
"description":"The configuration for the prebuilt speaker to use.",
"properties":{
"voiceName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The name of the prebuilt voice to use.\n      ",
"title":"Voicename"
}
},
"title":"PrebuiltVoiceConfig",
"type":"object"
},
"RagRetrievalConfig":{
"additionalProperties":false,
"description":"Specifies the context retrieval config.",
"properties":{
"filter":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigFilter"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for filters."
},
"hybridSearch":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigHybridSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Hybrid Search."
},
"ranking":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRanking"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for ranking and reranking."
},
"topK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The number of contexts to retrieve.",
"title":"Topk"
}
},
"title":"RagRetrievalConfig",
"type":"object"
},
"RagRetrievalConfigFilter":{
"additionalProperties":false,
"description":"Config for filters.",
"properties":{
"metadataFilter":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. String for metadata filtering.",
"title":"Metadatafilter"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
},
"vectorSimilarityThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector similarity larger than the threshold.",
"title":"Vectorsimilaritythreshold"
}
},
"title":"RagRetrievalConfigFilter",
"type":"object"
},
"RagRetrievalConfigHybridSearch":{
"additionalProperties":false,
"description":"Config for Hybrid Search.",
"properties":{
"alpha":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally.",
"title":"Alpha"
}
},
"title":"RagRetrievalConfigHybridSearch",
"type":"object"
},
"RagRetrievalConfigRanking":{
"additionalProperties":false,
"description":"Config for ranking and reranking.",
"properties":{
"llmRanker":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingLlmRanker"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for LlmRanker."
},
"rankService":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingRankService"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Rank Service."
}
},
"title":"RagRetrievalConfigRanking",
"type":"object"
},
"RagRetrievalConfigRankingLlmRanker":{
"additionalProperties":false,
"description":"Config for LlmRanker.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name used for ranking. Format: `gemini-1.5-pro`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingLlmRanker",
"type":"object"
},
"RagRetrievalConfigRankingRankService":{
"additionalProperties":false,
"description":"Config for Rank Service.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name of the rank service. Format: `semantic-ranker-512@latest`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingRankService",
"type":"object"
},
"Retrieval":{
"additionalProperties":false,
"description":"Defines a retrieval tool that model can call to access external knowledge.",
"properties":{
"disableAttribution":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Deprecated. This option is no longer supported.",
"title":"Disableattribution"
},
"vertexAiSearch":{
"anyOf":[
{
"$ref":"#/$defs/VertexAISearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Set to use data source powered by Vertex AI Search."
},
"vertexRagStore":{
"anyOf":[
{
"$ref":"#/$defs/VertexRagStore"
},
{
"type":"null"
}
],
"default":null,
"description":"Set to use data source powered by Vertex RAG store. User data is uploaded via the VertexRagDataService."
}
},
"title":"Retrieval",
"type":"object"
},
"RetrievalConfig":{
"additionalProperties":false,
"description":"Retrieval config.",
"properties":{
"latLng":{
"anyOf":[
{
"$ref":"#/$defs/LatLng"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The location of the user."
}
},
"title":"RetrievalConfig",
"type":"object"
},
"SafetySetting":{
"additionalProperties":false,
"description":"Safety settings.",
"properties":{
"method":{
"anyOf":[
{
"$ref":"#/$defs/HarmBlockMethod"
},
{
"type":"null"
}
],
"default":null,
"description":"Determines if the harm block method uses probability or probability\n      and severity scores."
},
"category":{
"anyOf":[
{
"$ref":"#/$defs/HarmCategory"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Harm category."
},
"threshold":{
"anyOf":[
{
"$ref":"#/$defs/HarmBlockThreshold"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The harm block threshold."
}
},
"title":"SafetySetting",
"type":"object"
},
"Schema":{
"additionalProperties":false,
"description":"Schema is used to define the format of input/output data.\n\nRepresents a select subset of an [OpenAPI 3.0 schema\nobject](https://spec.openapis.org/oas/v3.0.3#schema-object). More fields may\nbe added in the future as needed.",
"properties":{
"anyOf":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Schema"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The value should be validated against any (one or more) of the subschemas in the list.",
"title":"Anyof"
},
"default":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Default value of the data.",
"title":"Default"
},
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The description of the data.",
"title":"Description"
},
"enum":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Possible values of the element of primitive type with enum format. Examples: 1. We can define direction as : {type:STRING, format:enum, enum:[\"EAST\", NORTH\", \"SOUTH\", \"WEST\"]} 2. We can define apartment number as : {type:INTEGER, format:enum, enum:[\"101\", \"201\", \"301\"]}",
"title":"Enum"
},
"example":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Example of the object. Will only populated when the object is the root.",
"title":"Example"
},
"format":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The format of the data. Supported formats: for NUMBER type: \"float\", \"double\" for INTEGER type: \"int32\", \"int64\" for STRING type: \"email\", \"byte\", etc",
"title":"Format"
},
"items":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE ARRAY Schema of the elements of Type.ARRAY."
},
"maxItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the elements for Type.ARRAY.",
"title":"Maxitems"
},
"maxLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum length of the Type.STRING",
"title":"Maxlength"
},
"maxProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the properties for Type.OBJECT.",
"title":"Maxproperties"
},
"maximum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum value of the Type.INTEGER and Type.NUMBER",
"title":"Maximum"
},
"minItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the elements for Type.ARRAY.",
"title":"Minitems"
},
"minLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING",
"title":"Minlength"
},
"minProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the properties for Type.OBJECT.",
"title":"Minproperties"
},
"minimum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER Minimum value of the Type.INTEGER and Type.NUMBER",
"title":"Minimum"
},
"nullable":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Indicates if the value may be null.",
"title":"Nullable"
},
"pattern":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Pattern of the Type.STRING to restrict a string to a regular expression.",
"title":"Pattern"
},
"properties":{
"anyOf":[
{
"additionalProperties":{
"$ref":"#/$defs/Schema"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE OBJECT Properties of Type.OBJECT.",
"title":"Properties"
},
"propertyOrdering":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The order of the properties. Not a standard field in open api spec. Only used to support the order of the properties.",
"title":"Propertyordering"
},
"required":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required properties of Type.OBJECT.",
"title":"Required"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The title of the Schema.",
"title":"Title"
},
"type":{
"anyOf":[
{
"$ref":"#/$defs/Type"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The type of the data."
}
},
"title":"Schema",
"type":"object"
},
"SpeechConfig":{
"additionalProperties":false,
"description":"The speech generation configuration.",
"properties":{
"voiceConfig":{
"anyOf":[
{
"$ref":"#/$defs/VoiceConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The configuration for the speaker to use.\n      "
},
"languageCode":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Language code (ISO 639. e.g. en-US) for the speech synthesization.\n      Only available for Live API.\n      ",
"title":"Languagecode"
}
},
"title":"SpeechConfig",
"type":"object"
},
"ThinkingConfig":{
"additionalProperties":false,
"description":"The thinking features configuration.",
"properties":{
"includeThoughts":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates whether to include thoughts in the response. If true, thoughts are returned only if the model supports thought and thoughts are available.\n      ",
"title":"Includethoughts"
},
"thinkingBudget":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates the thinking budget in tokens.\n      ",
"title":"Thinkingbudget"
}
},
"title":"ThinkingConfig",
"type":"object"
},
"Tool":{
"additionalProperties":false,
"description":"Tool details of a tool that the model may use to generate a response.",
"properties":{
"retrieval":{
"anyOf":[
{
"$ref":"#/$defs/Retrieval"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Retrieval tool type. System will always execute the provided retrieval tool(s) to get external knowledge to answer the prompt. Retrieval results are presented to the model for generation."
},
"googleSearch":{
"anyOf":[
{
"$ref":"#/$defs/GoogleSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google Search tool type. Specialized retrieval tool\n      that is powered by Google Search."
},
"googleSearchRetrieval":{
"anyOf":[
{
"$ref":"#/$defs/GoogleSearchRetrieval"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. GoogleSearchRetrieval tool type. Specialized retrieval tool that is powered by Google search."
},
"enterpriseWebSearch":{
"anyOf":[
{
"$ref":"#/$defs/EnterpriseWebSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Enterprise web search tool type. Specialized retrieval\n      tool that is powered by Vertex AI Search and Sec4 compliance."
},
"googleMaps":{
"anyOf":[
{
"$ref":"#/$defs/GoogleMaps"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google Maps tool type. Specialized retrieval tool\n      that is powered by Google Maps."
},
"codeExecution":{
"anyOf":[
{
"$ref":"#/$defs/ToolCodeExecution"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. CodeExecution tool type. Enables the model to execute code as part of generation. This field is only used by the Gemini Developer API services."
},
"functionDeclarations":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/FunctionDeclaration"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Function tool type. One or more function declarations to be passed to the model along with the current user query. Model may decide to call a subset of these functions by populating FunctionCall in the response. User should provide a FunctionResponse for each function call in the next turn. Based on the function responses, Model will generate the final response back to the user. Maximum 128 function declarations can be provided.",
"title":"Functiondeclarations"
}
},
"title":"Tool",
"type":"object"
},
"ToolCodeExecution":{
"additionalProperties":false,
"description":"Tool that executes code generated by the model, and automatically returns the result to the model.\n\nSee also [ExecutableCode]and [CodeExecutionResult] which are input and output\nto this tool.",
"properties":{},
"title":"ToolCodeExecution",
"type":"object"
},
"ToolConfig":{
"additionalProperties":false,
"description":"Tool config.\n\nThis config is shared for all tools provided in the request.",
"properties":{
"functionCallingConfig":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCallingConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Function calling config."
},
"retrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/RetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Retrieval config."
}
},
"title":"ToolConfig",
"type":"object"
},
"Type":{
"description":"Optional. The type of the data.",
"enum":[
"TYPE_UNSPECIFIED",
"STRING",
"NUMBER",
"INTEGER",
"BOOLEAN",
"ARRAY",
"OBJECT"
],
"title":"Type",
"type":"string"
},
"VertexAISearch":{
"additionalProperties":false,
"description":"Retrieve from Vertex AI Search datastore or engine for grounding.\n\ndatastore and engine are mutually exclusive. See\nhttps://cloud.google.com/products/agent-builder",
"properties":{
"datastore":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search data store resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`",
"title":"Datastore"
},
"engine":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search engine resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}`",
"title":"Engine"
}
},
"title":"VertexAISearch",
"type":"object"
},
"VertexRagStore":{
"additionalProperties":false,
"description":"Retrieve from Vertex RAG Store for grounding.",
"properties":{
"ragCorpora":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Deprecated. Please use rag_resources instead.",
"title":"Ragcorpora"
},
"ragResources":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/VertexRagStoreRagResource"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The representation of the rag source. It can be used to specify corpus only or ragfiles. Currently only support one corpus or multiple files from one corpus. In the future we may open up multiple corpora support.",
"title":"Ragresources"
},
"ragRetrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The retrieval config for the Rag query."
},
"similarityTopK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of top k results to return from the selected corpora.",
"title":"Similaritytopk"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only return results with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
}
},
"title":"VertexRagStore",
"type":"object"
},
"VertexRagStoreRagResource":{
"additionalProperties":false,
"description":"The definition of the Rag resource.",
"properties":{
"ragCorpus":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. RagCorpora resource name. Format: `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`",
"title":"Ragcorpus"
},
"ragFileIds":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus field.",
"title":"Ragfileids"
}
},
"title":"VertexRagStoreRagResource",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
},
"VoiceConfig":{
"additionalProperties":false,
"description":"The configuration for the voice to use.",
"properties":{
"prebuiltVoiceConfig":{
"anyOf":[
{
"$ref":"#/$defs/PrebuiltVoiceConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The configuration for the speaker to use.\n      "
}
},
"title":"VoiceConfig",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `audio_timestamp (bool | None)`
  * `automatic_function_calling (genai.types.AutomaticFunctionCallingConfig | None)`
  * `cached_content (str | None)`
  * `candidate_count (int | None)`
  * `frequency_penalty (float | None)`
  * `http_options (genai.types.HttpOptions | None)`
  * `labels (dict[str, str] | None)`
  * `logprobs (int | None)`
  * `max_output_tokens (int | None)`
  * `media_resolution (genai.types.MediaResolution | None)`
  * `model_selection_config (genai.types.ModelSelectionConfig | None)`
  * `presence_penalty (float | None)`
  * `response_logprobs (bool | None)`
  * `response_mime_type (str | None)`
  * `response_modalities (list[str] | None)`
  * `response_schema (dict[Any, Any] | type | genai.types.Schema | types.GenericAlias | types.UnionType | _UnionGenericAlias | None)`
  * `routing_config (genai.types.GenerationConfigRoutingConfig | None)`
  * `safety_settings (list[genai.types.SafetySetting] | None)`
  * `seed (int | None)`
  * `speech_config (genai.types.SpeechConfig | str | None)`
  * `stop_sequences (list[str] | None)`
  * `system_instruction (genai.types.Content | list[genai.types.File | genai.types.Part | PIL.Image.Image | str] | genai.types.File | genai.types.Part | PIL.Image.Image | str | None)`
  * `temperature (float | None)`
  * `thinking_config (genai.types.ThinkingConfig | None)`
  * `tool_config (genai.types.ToolConfig | None)`
  * `tools (list[genai.types.Tool | Callable[[...], Any]] | None)`
  * `top_k (float | None)`
  * `top_p (float | None)`



Validators: 
    
  * `_convert_literal_to_enum` » `response_schema`



_field_ audio_timestamp _:`Optional`[`bool`]__= None_ _(alias 'audioTimestamp')_¶ 
    
If enabled, audio timestamp will be included in the request to the model. 

_field_ automatic_function_calling _:`Optional`[`AutomaticFunctionCallingConfig`]__= None_ _(alias 'automaticFunctionCalling')_¶ 
    
The configuration for automatic function calling. 

_field_ cached_content _:`Optional`[`str`]__= None_ _(alias 'cachedContent')_¶ 
    
Resource name of a context cache that can be used in subsequent requests. 

_field_ candidate_count _:`Optional`[`int`]__= None_ _(alias 'candidateCount')_¶ 
    
Number of response variations to return. 

_field_ frequency_penalty _:`Optional`[`float`]__= None_ _(alias 'frequencyPenalty')_¶ 
    
Positive values penalize tokens that repeatedly appear in the generated text, increasing the probability of generating more diverse content. 

_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_field_ labels _:`Optional`[`dict`[`str`, `str`]]__= None_¶ 
    
Labels with user-defined metadata to break down billed charges. 

_field_ logprobs _:`Optional`[`int`]__= None_¶ 
    
Number of top candidate tokens to return the log probabilities for at each generation step. 

_field_ max_output_tokens _:`Optional`[`int`]__= None_ _(alias 'maxOutputTokens')_¶ 
    
Maximum number of tokens that can be generated in the response. 

_field_ media_resolution _:`Optional`[`MediaResolution`]__= None_ _(alias 'mediaResolution')_¶ 
    
If specified, the media resolution specified will be used. 

_field_ model_selection_config _:`Optional`[`ModelSelectionConfig`]__= None_ _(alias 'modelSelectionConfig')_¶ 
    
Configuration for model selection. 

_field_ presence_penalty _:`Optional`[`float`]__= None_ _(alias 'presencePenalty')_¶ 
    
Positive values penalize tokens that already appear in the generated text, increasing the probability of generating more diverse content. 

_field_ response_logprobs _:`Optional`[`bool`]__= None_ _(alias 'responseLogprobs')_¶ 
    
Whether to return the log probabilities of the tokens that were chosen by the model at each step. 

_field_ response_mime_type _:`Optional`[`str`]__= None_ _(alias 'responseMimeType')_¶ 
    
Output response mimetype of the generated candidate text. Supported mimetype:
>   * text/plain: (default) Text output.
>   * application/json: JSON response in the candidates.
> 

The model needs to be prompted to output the appropriate response type, otherwise the behavior is undefined. This is a preview feature. 

_field_ response_modalities _:`Optional`[`list`[`str`]]__= None_ _(alias 'responseModalities')_¶ 
    
The requested modalities of the response. Represents the set of modalities that the model can return. 

_field_ response_schema _:`Union`[`dict`[`Any`, `Any`], `type`, `Schema`, `GenericAlias`, , `_UnionGenericAlias`, `None`]__= None_ _(alias 'responseSchema')_¶ 
    
The Schema object allows the definition of input and output data types. These types can be objects, but also primitives and arrays. Represents a select subset of an [OpenAPI 3.0 schema object](https://spec.openapis.org/oas/v3.0.3#schema). If set, a compatible response_mime_type must also be set. Compatible mimetypes: application/json: Schema for JSON response. 

Validated by: 
    
  * `_convert_literal_to_enum`



_field_ routing_config _:`Optional`[`GenerationConfigRoutingConfig`]__= None_ _(alias 'routingConfig')_¶ 
    
Configuration for model router requests. 

_field_ safety_settings _:`Optional`[`list`[`SafetySetting`]]__= None_ _(alias 'safetySettings')_¶ 
    
Safety settings in the request to block unsafe content in the response. 

_field_ seed _:`Optional`[`int`]__= None_¶ 
    
When `seed` is fixed to a specific number, the model makes a best effort to provide the same response for repeated requests. By default, a random number is used. 

_field_ speech_config _:`Union`[`SpeechConfig`, `str`, `None`]__= None_ _(alias 'speechConfig')_¶ 
    
The speech generation configuration. 

_field_ stop_sequences _:`Optional`[`list`[`str`]]__= None_ _(alias 'stopSequences')_¶ 
    
List of strings that tells the model to stop generating text if one of the strings is encountered in the response. 

_field_ system_instruction _:`Union`[`Content`, `list`[`Union`[`File`, `Part`, `Image`, `str`]], `File`, `Part`, `Image`, `str`, `None`]__= None_ _(alias 'systemInstruction')_¶ 
    
Instructions for the model to steer it toward better performance. For example, “Answer as concisely as possible” or “Don’t use technical terms in your response”. 

_field_ temperature _:`Optional`[`float`]__= None_¶ 
    
Value that controls the degree of randomness in token selection. Lower temperatures are good for prompts that require a less open-ended or creative response, while higher temperatures can lead to more diverse or creative results. 

_field_ thinking_config _:`Optional`[`ThinkingConfig`]__= None_ _(alias 'thinkingConfig')_¶ 
    
The thinking features configuration. 

_field_ tool_config _:`Optional`[`ToolConfig`]__= None_ _(alias 'toolConfig')_¶ 
    
Associates model output to a specific function call. 

_field_ tools _:`Optional`[`list`[`Union`[`Tool`, `Callable`[`...`, `Any`]]]]__= None_¶ 
    
Code that enables the system to interact with external systems to perform an action outside of the knowledge and scope of the model. 

_field_ top_k _:`Optional`[`float`]__= None_ _(alias 'topK')_¶ 
    
For each token selection step, the `top_k` tokens with the highest probabilities are sampled. Then tokens are further filtered based on `top_p` with the final token selected using temperature sampling. Use a lower number for less random responses and a higher number for more random responses. 

_field_ top_p _:`Optional`[`float`]__= None_ _(alias 'topP')_¶ 
    
Tokens are selected from the most to least probable until the sum of their probabilities equals this value. Use a lower value for less random responses and a higher value for more random responses. 

_class_ genai.types.GenerateContentConfigDict¶ 
    
Bases: `TypedDict`
Optional model configuration parameters.
For more information, see Content generation parameters. 

audio_timestamp _:`Optional`[`bool`]_¶ 
    
If enabled, audio timestamp will be included in the request to the model. 

automatic_function_calling _:`Optional`[`AutomaticFunctionCallingConfigDict`]_¶ 
    
The configuration for automatic function calling. 

cached_content _:`Optional`[`str`]_¶ 
    
Resource name of a context cache that can be used in subsequent requests. 

candidate_count _:`Optional`[`int`]_¶ 
    
Number of response variations to return. 

frequency_penalty _:`Optional`[`float`]_¶ 
    
Positive values penalize tokens that repeatedly appear in the generated text, increasing the probability of generating more diverse content. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

labels _:`Optional`[`dict`[`str`, `str`]]_¶ 
    
Labels with user-defined metadata to break down billed charges. 

logprobs _:`Optional`[`int`]_¶ 
    
Number of top candidate tokens to return the log probabilities for at each generation step. 

max_output_tokens _:`Optional`[`int`]_¶ 
    
Maximum number of tokens that can be generated in the response. 

media_resolution _:`Optional`[`MediaResolution`]_¶ 
    
If specified, the media resolution specified will be used. 

model_selection_config _:`Optional`[`ModelSelectionConfigDict`]_¶ 
    
Configuration for model selection. 

presence_penalty _:`Optional`[`float`]_¶ 
    
Positive values penalize tokens that already appear in the generated text, increasing the probability of generating more diverse content. 

response_logprobs _:`Optional`[`bool`]_¶ 
    
Whether to return the log probabilities of the tokens that were chosen by the model at each step. 

response_mime_type _:`Optional`[`str`]_¶ 
    
Output response mimetype of the generated candidate text. Supported mimetype:
>   * text/plain: (default) Text output.
>   * application/json: JSON response in the candidates.
> 

The model needs to be prompted to output the appropriate response type, otherwise the behavior is undefined. This is a preview feature. 

response_modalities _:`Optional`[`list`[`str`]]_¶ 
    
The requested modalities of the response. Represents the set of modalities that the model can return. 

response_schema _:`Union`[`dict`[`Any`, `Any`], `type`, `Schema`, `GenericAlias`, , `_UnionGenericAlias`, `SchemaDict`, `None`]_¶ 
    
The Schema object allows the definition of input and output data types. These types can be objects, but also primitives and arrays. Represents a select subset of an [OpenAPI 3.0 schema object](https://spec.openapis.org/oas/v3.0.3#schema). If set, a compatible response_mime_type must also be set. Compatible mimetypes: application/json: Schema for JSON response. 

routing_config _:`Optional`[`GenerationConfigRoutingConfigDict`]_¶ 
    
Configuration for model router requests. 

safety_settings _:`Optional`[`list`[`SafetySettingDict`]]_¶ 
    
Safety settings in the request to block unsafe content in the response. 

seed _:`Optional`[`int`]_¶ 
    
When `seed` is fixed to a specific number, the model makes a best effort to provide the same response for repeated requests. By default, a random number is used. 

speech_config _:`Union`[`SpeechConfig`, `str`, `SpeechConfigDict`, `None`]_¶ 
    
The speech generation configuration. 

stop_sequences _:`Optional`[`list`[`str`]]_¶ 
    
List of strings that tells the model to stop generating text if one of the strings is encountered in the response. 

system_instruction _:`Union`[`Content`, `list`[`Union`[`File`, `Part`, `Image`, `str`]], `File`, `Part`, `Image`, `str`, `ContentDict`, `None`]_¶ 
    
Instructions for the model to steer it toward better performance. For example, “Answer as concisely as possible” or “Don’t use technical terms in your response”. 

temperature _:`Optional`[`float`]_¶ 
    
Value that controls the degree of randomness in token selection. Lower temperatures are good for prompts that require a less open-ended or creative response, while higher temperatures can lead to more diverse or creative results. 

thinking_config _:`Optional`[`ThinkingConfigDict`]_¶ 
    
The thinking features configuration. 

tool_config _:`Optional`[`ToolConfigDict`]_¶ 
    
Associates model output to a specific function call. 

tools _:`Optional`[`list`[`Union`[`ToolDict`, `Callable`[`...`, `Any`]]]]_¶ 
    
Code that enables the system to interact with external systems to perform an action outside of the knowledge and scope of the model. 

top_k _:`Optional`[`float`]_¶ 
    
For each token selection step, the `top_k` tokens with the highest probabilities are sampled. Then tokens are further filtered based on `top_p` with the final token selected using temperature sampling. Use a lower number for less random responses and a higher number for more random responses. 

top_p _:`Optional`[`float`]_¶ 
    
Tokens are selected from the most to least probable until the sum of their probabilities equals this value. Use a lower value for less random responses and a higher value for more random responses. 

_pydantic model_genai.types.GenerateContentResponse¶ 
    
Bases: `BaseModel`
Response message for PredictionService.GenerateContent.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GenerateContentResponse",
"description":"Response message for PredictionService.GenerateContent.",
"type":"object",
"properties":{
"candidates":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Candidate"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Response variations returned by the model.\n      ",
"title":"Candidates"
},
"createTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Timestamp when the request is made to the server.\n      ",
"title":"Createtime"
},
"responseId":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Identifier for each response.\n      ",
"title":"Responseid"
},
"modelVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The model version used to generate the response.",
"title":"Modelversion"
},
"promptFeedback":{
"anyOf":[
{
"$ref":"#/$defs/GenerateContentResponsePromptFeedback"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Content filter results for a prompt sent in the request. Note: Sent only in the first stream chunk. Only happens when no candidates were generated due to content violations."
},
"usageMetadata":{
"anyOf":[
{
"$ref":"#/$defs/GenerateContentResponseUsageMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Usage metadata about the response(s)."
},
"automaticFunctionCallingHistory":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Content"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"title":"Automaticfunctioncallinghistory"
},
"parsed":{
"anyOf":[
{
"$ref":"#/$defs/BaseModel"
},
{
"type":"object"
},
{
"description":"Create a collection of name/value pairs.\n\nExample enumeration:\n\n>>> class Color(Enum):\n...     RED = 1\n...     BLUE = 2\n...     GREEN = 3\n\nAccess them by:\n\n- attribute access:\n\n  >>> Color.RED\n  <Color.RED: 1>\n\n- value lookup:\n\n  >>> Color(1)\n  <Color.RED: 1>\n\n- name lookup:\n\n  >>> Color['RED']\n  <Color.RED: 1>\n\nEnumerations can be iterated over, and know how many members they have:\n\n>>> len(Color)\n3\n\n>>> list(Color)\n[<Color.RED: 1>, <Color.BLUE: 2>, <Color.GREEN: 3>]\n\nMethods can be added to enumerations, and members can have their own\nattributes -- see the documentation for details.",
"enum":[],
"title":"Enum"
},
{
"type":"null"
}
],
"default":null,
"description":"First candidate from the parsed response if response_schema is provided. Not available for streaming.",
"title":"Parsed"
}
},
"$defs":{
"BaseModel":{
"properties":{},
"title":"BaseModel",
"type":"object"
},
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"BlockedReason":{
"description":"Output only. Blocked reason.",
"enum":[
"BLOCKED_REASON_UNSPECIFIED",
"SAFETY",
"OTHER",
"BLOCKLIST",
"PROHIBITED_CONTENT"
],
"title":"BlockedReason",
"type":"string"
},
"Candidate":{
"additionalProperties":false,
"description":"A response candidate generated from the model.",
"properties":{
"content":{
"anyOf":[
{
"$ref":"#/$defs/Content"
},
{
"type":"null"
}
],
"default":null,
"description":"Contains the multi-part content of the response.\n      "
},
"citationMetadata":{
"anyOf":[
{
"$ref":"#/$defs/CitationMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Source attribution of the generated content.\n      "
},
"finishMessage":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Describes the reason the model stopped generating tokens.\n      ",
"title":"Finishmessage"
},
"tokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens for this candidate.\n      ",
"title":"Tokencount"
},
"finishReason":{
"anyOf":[
{
"$ref":"#/$defs/FinishReason"
},
{
"type":"null"
}
],
"default":null,
"description":"The reason why the model stopped generating tokens.\n      If empty, the model has not stopped generating the tokens.\n      "
},
"avgLogprobs":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Average log probability score of the candidate.",
"title":"Avglogprobs"
},
"groundingMetadata":{
"anyOf":[
{
"$ref":"#/$defs/GroundingMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Metadata specifies sources used to ground generated content."
},
"index":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Index of the candidate.",
"title":"Index"
},
"logprobsResult":{
"anyOf":[
{
"$ref":"#/$defs/LogprobsResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Log-likelihood scores for the response tokens and top tokens"
},
"safetyRatings":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/SafetyRating"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. List of ratings for the safety of a response candidate. There is at most one rating per category.",
"title":"Safetyratings"
}
},
"title":"Candidate",
"type":"object"
},
"Citation":{
"additionalProperties":false,
"description":"Source attributions for content.",
"properties":{
"endIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. End index into the content.",
"title":"Endindex"
},
"license":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. License of the attribution.",
"title":"License"
},
"publicationDate":{
"anyOf":[
{
"$ref":"#/$defs/GoogleTypeDate"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Publication date of the attribution."
},
"startIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Start index into the content.",
"title":"Startindex"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Title of the attribution.",
"title":"Title"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Url reference of the attribution.",
"title":"Uri"
}
},
"title":"Citation",
"type":"object"
},
"CitationMetadata":{
"additionalProperties":false,
"description":"Citation information when the model quotes another source.",
"properties":{
"citations":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Citation"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Contains citation information when the model directly quotes, at\n      length, from another source. Can include traditional websites and code\n      repositories.\n      ",
"title":"Citations"
}
},
"title":"CitationMetadata",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"Content":{
"additionalProperties":false,
"description":"Contains the multi-part content of a message.",
"properties":{
"parts":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Part"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of parts that constitute a single message. Each part may have\n      a different IANA MIME type.",
"title":"Parts"
},
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role.",
"title":"Role"
}
},
"title":"Content",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FinishReason":{
"description":"Output only. The reason why the model stopped generating tokens.\n\nIf empty, the model has not stopped generating the tokens.",
"enum":[
"FINISH_REASON_UNSPECIFIED",
"STOP",
"MAX_TOKENS",
"SAFETY",
"RECITATION",
"LANGUAGE",
"OTHER",
"BLOCKLIST",
"PROHIBITED_CONTENT",
"SPII",
"MALFORMED_FUNCTION_CALL",
"IMAGE_SAFETY"
],
"title":"FinishReason",
"type":"string"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"GenerateContentResponsePromptFeedback":{
"additionalProperties":false,
"description":"Content filter results for a prompt sent in the request.",
"properties":{
"blockReason":{
"anyOf":[
{
"$ref":"#/$defs/BlockedReason"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Blocked reason."
},
"blockReasonMessage":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. A readable block reason message.",
"title":"Blockreasonmessage"
},
"safetyRatings":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/SafetyRating"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Safety ratings.",
"title":"Safetyratings"
}
},
"title":"GenerateContentResponsePromptFeedback",
"type":"object"
},
"GenerateContentResponseUsageMetadata":{
"additionalProperties":false,
"description":"Usage metadata about response(s).",
"properties":{
"cacheTokensDetails":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/ModalityTokenCount"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. List of modalities of the cached content in the request input.",
"title":"Cachetokensdetails"
},
"cachedContentTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tokens in the cached part in the input (the cached content).",
"title":"Cachedcontenttokencount"
},
"candidatesTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens in the response(s).",
"title":"Candidatestokencount"
},
"candidatesTokensDetails":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/ModalityTokenCount"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. List of modalities that were returned in the response.",
"title":"Candidatestokensdetails"
},
"promptTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens in the request. When `cached_content` is set, this is still the total effective prompt size meaning this includes the number of tokens in the cached content.",
"title":"Prompttokencount"
},
"promptTokensDetails":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/ModalityTokenCount"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. List of modalities that were processed in the request input.",
"title":"Prompttokensdetails"
},
"thoughtsTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tokens present in thoughts output.",
"title":"Thoughtstokencount"
},
"toolUsePromptTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tokens present in tool-use prompt(s).",
"title":"Tooluseprompttokencount"
},
"toolUsePromptTokensDetails":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/ModalityTokenCount"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. List of modalities that were processed for tool-use request inputs.",
"title":"Tooluseprompttokensdetails"
},
"totalTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Total token count for prompt, response candidates, and tool-use prompts (if present).",
"title":"Totaltokencount"
},
"trafficType":{
"anyOf":[
{
"$ref":"#/$defs/TrafficType"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Traffic type. This shows whether a request consumes Pay-As-You-Go or Provisioned Throughput quota."
}
},
"title":"GenerateContentResponseUsageMetadata",
"type":"object"
},
"GoogleTypeDate":{
"additionalProperties":false,
"description":"Represents a whole or partial calendar date, such as a birthday.\n\nThe time of day and time zone are either specified elsewhere or are\ninsignificant. The date is relative to the Gregorian Calendar. This can\nrepresent one of the following: * A full date, with non-zero year, month, and\nday values. * A month and day, with a zero year (for example, an anniversary).\n* A year on its own, with a zero month and a zero day. * A year and month,\nwith a zero day (for example, a credit card expiration date). Related types: *\ngoogle.type.TimeOfDay * google.type.DateTime * google.protobuf.Timestamp",
"properties":{
"day":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.",
"title":"Day"
},
"month":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.",
"title":"Month"
},
"year":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year.",
"title":"Year"
}
},
"title":"GoogleTypeDate",
"type":"object"
},
"GroundingChunk":{
"additionalProperties":false,
"description":"Grounding chunk.",
"properties":{
"retrievedContext":{
"anyOf":[
{
"$ref":"#/$defs/GroundingChunkRetrievedContext"
},
{
"type":"null"
}
],
"default":null,
"description":"Grounding chunk from context retrieved by the retrieval tools."
},
"web":{
"anyOf":[
{
"$ref":"#/$defs/GroundingChunkWeb"
},
{
"type":"null"
}
],
"default":null,
"description":"Grounding chunk from the web."
}
},
"title":"GroundingChunk",
"type":"object"
},
"GroundingChunkRetrievedContext":{
"additionalProperties":false,
"description":"Chunk from context retrieved by the retrieval tools.",
"properties":{
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Text of the attribution.",
"title":"Text"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Title of the attribution.",
"title":"Title"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"URI reference of the attribution.",
"title":"Uri"
}
},
"title":"GroundingChunkRetrievedContext",
"type":"object"
},
"GroundingChunkWeb":{
"additionalProperties":false,
"description":"Chunk from the web.",
"properties":{
"domain":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Domain of the (original) URI.",
"title":"Domain"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Title of the chunk.",
"title":"Title"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"URI reference of the chunk.",
"title":"Uri"
}
},
"title":"GroundingChunkWeb",
"type":"object"
},
"GroundingMetadata":{
"additionalProperties":false,
"description":"Metadata returned to client when grounding is enabled.",
"properties":{
"groundingChunks":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/GroundingChunk"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of supporting references retrieved from specified grounding source.",
"title":"Groundingchunks"
},
"groundingSupports":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/GroundingSupport"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. List of grounding support.",
"title":"Groundingsupports"
},
"retrievalMetadata":{
"anyOf":[
{
"$ref":"#/$defs/RetrievalMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Output only. Retrieval metadata."
},
"retrievalQueries":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Queries executed by the retrieval tools.",
"title":"Retrievalqueries"
},
"searchEntryPoint":{
"anyOf":[
{
"$ref":"#/$defs/SearchEntryPoint"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google search entry for the following-up web searches."
},
"webSearchQueries":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Web search queries for the following-up web search.",
"title":"Websearchqueries"
}
},
"title":"GroundingMetadata",
"type":"object"
},
"GroundingSupport":{
"additionalProperties":false,
"description":"Grounding support.",
"properties":{
"confidenceScores":{
"anyOf":[
{
"items":{
"type":"number"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Confidence score of the support references. Ranges from 0 to 1. 1 is the most confident. This list must have the same size as the grounding_chunk_indices.",
"title":"Confidencescores"
},
"groundingChunkIndices":{
"anyOf":[
{
"items":{
"type":"integer"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of indices (into 'grounding_chunk') specifying the citations associated with the claim. For instance [1,3,4] means that grounding_chunk[1], grounding_chunk[3], grounding_chunk[4] are the retrieved content attributed to the claim.",
"title":"Groundingchunkindices"
},
"segment":{
"anyOf":[
{
"$ref":"#/$defs/Segment"
},
{
"type":"null"
}
],
"default":null,
"description":"Segment of the content this support belongs to."
}
},
"title":"GroundingSupport",
"type":"object"
},
"HarmCategory":{
"description":"Required. Harm category.",
"enum":[
"HARM_CATEGORY_UNSPECIFIED",
"HARM_CATEGORY_HATE_SPEECH",
"HARM_CATEGORY_DANGEROUS_CONTENT",
"HARM_CATEGORY_HARASSMENT",
"HARM_CATEGORY_SEXUALLY_EXPLICIT",
"HARM_CATEGORY_CIVIC_INTEGRITY"
],
"title":"HarmCategory",
"type":"string"
},
"HarmProbability":{
"description":"Output only. Harm probability levels in the content.",
"enum":[
"HARM_PROBABILITY_UNSPECIFIED",
"NEGLIGIBLE",
"LOW",
"MEDIUM",
"HIGH"
],
"title":"HarmProbability",
"type":"string"
},
"HarmSeverity":{
"description":"Output only. Harm severity levels in the content.",
"enum":[
"HARM_SEVERITY_UNSPECIFIED",
"HARM_SEVERITY_NEGLIGIBLE",
"HARM_SEVERITY_LOW",
"HARM_SEVERITY_MEDIUM",
"HARM_SEVERITY_HIGH"
],
"title":"HarmSeverity",
"type":"string"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"LogprobsResult":{
"additionalProperties":false,
"description":"Logprobs Result",
"properties":{
"chosenCandidates":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/LogprobsResultCandidate"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Length = total number of decoding steps. The chosen candidates may or may not be in top_candidates.",
"title":"Chosencandidates"
},
"topCandidates":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/LogprobsResultTopCandidates"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Length = total number of decoding steps.",
"title":"Topcandidates"
}
},
"title":"LogprobsResult",
"type":"object"
},
"LogprobsResultCandidate":{
"additionalProperties":false,
"description":"Candidate for the logprobs token and score.",
"properties":{
"logProbability":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"The candidate's log probability.",
"title":"Logprobability"
},
"token":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The candidate's token string value.",
"title":"Token"
},
"tokenId":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The candidate's token id value.",
"title":"Tokenid"
}
},
"title":"LogprobsResultCandidate",
"type":"object"
},
"LogprobsResultTopCandidates":{
"additionalProperties":false,
"description":"Candidates with top log probabilities at each decoding step.",
"properties":{
"candidates":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/LogprobsResultCandidate"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Sorted by log probability in descending order.",
"title":"Candidates"
}
},
"title":"LogprobsResultTopCandidates",
"type":"object"
},
"MediaModality":{
"description":"Server content modalities.",
"enum":[
"MODALITY_UNSPECIFIED",
"TEXT",
"IMAGE",
"VIDEO",
"AUDIO",
"DOCUMENT"
],
"title":"MediaModality",
"type":"string"
},
"ModalityTokenCount":{
"additionalProperties":false,
"description":"Represents token counting info for a single modality.",
"properties":{
"modality":{
"anyOf":[
{
"$ref":"#/$defs/MediaModality"
},
{
"type":"null"
}
],
"default":null,
"description":"The modality associated with this token count."
},
"tokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens.",
"title":"Tokencount"
}
},
"title":"ModalityTokenCount",
"type":"object"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"RetrievalMetadata":{
"additionalProperties":false,
"description":"Metadata related to retrieval in the grounding flow.",
"properties":{
"googleSearchDynamicRetrievalScore":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Score indicating how likely information from Google Search could help answer the prompt. The score is in the range `[0, 1]`, where 0 is the least likely and 1 is the most likely. This score is only populated when Google Search grounding and dynamic retrieval is enabled. It will be compared to the threshold to determine whether to trigger Google Search.",
"title":"Googlesearchdynamicretrievalscore"
}
},
"title":"RetrievalMetadata",
"type":"object"
},
"SafetyRating":{
"additionalProperties":false,
"description":"Safety rating corresponding to the generated content.",
"properties":{
"blocked":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Indicates whether the content was filtered out because of this rating.",
"title":"Blocked"
},
"category":{
"anyOf":[
{
"$ref":"#/$defs/HarmCategory"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm category."
},
"probability":{
"anyOf":[
{
"$ref":"#/$defs/HarmProbability"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm probability levels in the content."
},
"probabilityScore":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm probability score.",
"title":"Probabilityscore"
},
"severity":{
"anyOf":[
{
"$ref":"#/$defs/HarmSeverity"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm severity levels in the content."
},
"severityScore":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm severity score.",
"title":"Severityscore"
}
},
"title":"SafetyRating",
"type":"object"
},
"SearchEntryPoint":{
"additionalProperties":false,
"description":"Google search entry point.",
"properties":{
"renderedContent":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Web content snippet that can be embedded in a web page or an app webview.",
"title":"Renderedcontent"
},
"sdkBlob":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Base64 encoded JSON representing array of tuple.",
"title":"Sdkblob"
}
},
"title":"SearchEntryPoint",
"type":"object"
},
"Segment":{
"additionalProperties":false,
"description":"Segment of the content.",
"properties":{
"endIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. End index in the given Part, measured in bytes. Offset from the start of the Part, exclusive, starting at zero.",
"title":"Endindex"
},
"partIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The index of a Part object within its parent Content object.",
"title":"Partindex"
},
"startIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Start index in the given Part, measured in bytes. Offset from the start of the Part, inclusive, starting at zero.",
"title":"Startindex"
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The text corresponding to the segment from the response.",
"title":"Text"
}
},
"title":"Segment",
"type":"object"
},
"TrafficType":{
"description":"Output only.\n\nTraffic type. This shows whether a request consumes Pay-As-You-Go or\nProvisioned Throughput quota.",
"enum":[
"TRAFFIC_TYPE_UNSPECIFIED",
"ON_DEMAND",
"PROVISIONED_THROUGHPUT"
],
"title":"TrafficType",
"type":"string"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `automatic_function_calling_history (list[genai.types.Content] | None)`
  * `candidates (list[genai.types.Candidate] | None)`
  * `create_time (datetime.datetime | None)`
  * `model_version (str | None)`
  * `parsed (pydantic.main.BaseModel | dict[Any, Any] | enum.Enum | None)`
  * `prompt_feedback (genai.types.GenerateContentResponsePromptFeedback | None)`
  * `response_id (str | None)`
  * `usage_metadata (genai.types.GenerateContentResponseUsageMetadata | None)`



_field_ automatic_function_calling_history _:`Optional`[`list`[`Content`]]__= None_ _(alias 'automaticFunctionCallingHistory')_¶ 


_field_ candidates _:`Optional`[`list`[`Candidate`]]__= None_¶ 
    
Response variations returned by the model. 

_field_ create_time _:`Optional`[`datetime`]__= None_ _(alias 'createTime')_¶ 
    
Timestamp when the request is made to the server. 

_field_ model_version _:`Optional`[`str`]__= None_ _(alias 'modelVersion')_¶ 
    
Output only. The model version used to generate the response. 

_field_ parsed _:`Union`[`BaseModel`, `dict`[`Any`, `Any`], `Enum`, `None`]__= None_¶ 
    
First candidate from the parsed response if response_schema is provided. Not available for streaming. 

_field_ prompt_feedback _:`Optional`[`GenerateContentResponsePromptFeedback`]__= None_ _(alias 'promptFeedback')_¶ 
    
Output only. Content filter results for a prompt sent in the request. Note: Sent only in the first stream chunk. Only happens when no candidates were generated due to content violations. 

_field_ response_id _:`Optional`[`str`]__= None_ _(alias 'responseId')_¶ 
    
Identifier for each response. 

_field_ usage_metadata _:`Optional`[`GenerateContentResponseUsageMetadata`]__= None_ _(alias 'usageMetadata')_¶ 
    
Usage metadata about the response(s). 

_property_ code_execution_result _: str|None_¶ 
    
Returns the code execution result in the response. 

_property_ executable_code _: str|None_¶ 
    
Returns the executable code in the response. 

_property_ function_calls _: list[FunctionCall]|None_¶ 
    
Returns the list of function calls in the response. 

_property_ text _: str|None_¶ 
    
Returns the concatenation of all text parts in the response. 

_class_ genai.types.GenerateContentResponseDict¶ 
    
Bases: `TypedDict`
Response message for PredictionService.GenerateContent. 

candidates _:`Optional`[`list`[`CandidateDict`]]_¶ 
    
Response variations returned by the model. 

create_time _:`Optional`[`datetime`]_¶ 
    
Timestamp when the request is made to the server. 

model_version _:`Optional`[`str`]_¶ 
    
Output only. The model version used to generate the response. 

prompt_feedback _:`Optional`[`GenerateContentResponsePromptFeedbackDict`]_¶ 
    
Sent only in the first stream chunk. Only happens when no candidates were generated due to content violations. 

Type: 
    
Output only. Content filter results for a prompt sent in the request. Note 

response_id _:`Optional`[`str`]_¶ 
    
Identifier for each response. 

usage_metadata _:`Optional`[`GenerateContentResponseUsageMetadataDict`]_¶ 
    
Usage metadata about the response(s). 

_pydantic model_genai.types.GenerateContentResponsePromptFeedback¶ 
    
Bases: `BaseModel`
Content filter results for a prompt sent in the request.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GenerateContentResponsePromptFeedback",
"description":"Content filter results for a prompt sent in the request.",
"type":"object",
"properties":{
"blockReason":{
"anyOf":[
{
"$ref":"#/$defs/BlockedReason"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Blocked reason."
},
"blockReasonMessage":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. A readable block reason message.",
"title":"Blockreasonmessage"
},
"safetyRatings":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/SafetyRating"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Safety ratings.",
"title":"Safetyratings"
}
},
"$defs":{
"BlockedReason":{
"description":"Output only. Blocked reason.",
"enum":[
"BLOCKED_REASON_UNSPECIFIED",
"SAFETY",
"OTHER",
"BLOCKLIST",
"PROHIBITED_CONTENT"
],
"title":"BlockedReason",
"type":"string"
},
"HarmCategory":{
"description":"Required. Harm category.",
"enum":[
"HARM_CATEGORY_UNSPECIFIED",
"HARM_CATEGORY_HATE_SPEECH",
"HARM_CATEGORY_DANGEROUS_CONTENT",
"HARM_CATEGORY_HARASSMENT",
"HARM_CATEGORY_SEXUALLY_EXPLICIT",
"HARM_CATEGORY_CIVIC_INTEGRITY"
],
"title":"HarmCategory",
"type":"string"
},
"HarmProbability":{
"description":"Output only. Harm probability levels in the content.",
"enum":[
"HARM_PROBABILITY_UNSPECIFIED",
"NEGLIGIBLE",
"LOW",
"MEDIUM",
"HIGH"
],
"title":"HarmProbability",
"type":"string"
},
"HarmSeverity":{
"description":"Output only. Harm severity levels in the content.",
"enum":[
"HARM_SEVERITY_UNSPECIFIED",
"HARM_SEVERITY_NEGLIGIBLE",
"HARM_SEVERITY_LOW",
"HARM_SEVERITY_MEDIUM",
"HARM_SEVERITY_HIGH"
],
"title":"HarmSeverity",
"type":"string"
},
"SafetyRating":{
"additionalProperties":false,
"description":"Safety rating corresponding to the generated content.",
"properties":{
"blocked":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Indicates whether the content was filtered out because of this rating.",
"title":"Blocked"
},
"category":{
"anyOf":[
{
"$ref":"#/$defs/HarmCategory"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm category."
},
"probability":{
"anyOf":[
{
"$ref":"#/$defs/HarmProbability"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm probability levels in the content."
},
"probabilityScore":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm probability score.",
"title":"Probabilityscore"
},
"severity":{
"anyOf":[
{
"$ref":"#/$defs/HarmSeverity"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm severity levels in the content."
},
"severityScore":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm severity score.",
"title":"Severityscore"
}
},
"title":"SafetyRating",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `block_reason (genai.types.BlockedReason | None)`
  * `block_reason_message (str | None)`
  * `safety_ratings (list[genai.types.SafetyRating] | None)`



_field_ block_reason _:`Optional`[`BlockedReason`]__= None_ _(alias 'blockReason')_¶ 
    
Output only. Blocked reason. 

_field_ block_reason_message _:`Optional`[`str`]__= None_ _(alias 'blockReasonMessage')_¶ 
    
Output only. A readable block reason message. 

_field_ safety_ratings _:`Optional`[`list`[`SafetyRating`]]__= None_ _(alias 'safetyRatings')_¶ 
    
Output only. Safety ratings. 

_class_ genai.types.GenerateContentResponsePromptFeedbackDict¶ 
    
Bases: `TypedDict`
Content filter results for a prompt sent in the request. 

block_reason _:`Optional`[`BlockedReason`]_¶ 
    
Output only. Blocked reason. 

block_reason_message _:`Optional`[`str`]_¶ 
    
Output only. A readable block reason message. 

safety_ratings _:`Optional`[`list`[`SafetyRatingDict`]]_¶ 
    
Output only. Safety ratings. 

_pydantic model_genai.types.GenerateContentResponseUsageMetadata¶ 
    
Bases: `BaseModel`
Usage metadata about response(s).
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GenerateContentResponseUsageMetadata",
"description":"Usage metadata about response(s).",
"type":"object",
"properties":{
"cacheTokensDetails":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/ModalityTokenCount"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. List of modalities of the cached content in the request input.",
"title":"Cachetokensdetails"
},
"cachedContentTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tokens in the cached part in the input (the cached content).",
"title":"Cachedcontenttokencount"
},
"candidatesTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens in the response(s).",
"title":"Candidatestokencount"
},
"candidatesTokensDetails":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/ModalityTokenCount"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. List of modalities that were returned in the response.",
"title":"Candidatestokensdetails"
},
"promptTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens in the request. When `cached_content` is set, this is still the total effective prompt size meaning this includes the number of tokens in the cached content.",
"title":"Prompttokencount"
},
"promptTokensDetails":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/ModalityTokenCount"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. List of modalities that were processed in the request input.",
"title":"Prompttokensdetails"
},
"thoughtsTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tokens present in thoughts output.",
"title":"Thoughtstokencount"
},
"toolUsePromptTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tokens present in tool-use prompt(s).",
"title":"Tooluseprompttokencount"
},
"toolUsePromptTokensDetails":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/ModalityTokenCount"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. List of modalities that were processed for tool-use request inputs.",
"title":"Tooluseprompttokensdetails"
},
"totalTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Total token count for prompt, response candidates, and tool-use prompts (if present).",
"title":"Totaltokencount"
},
"trafficType":{
"anyOf":[
{
"$ref":"#/$defs/TrafficType"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Traffic type. This shows whether a request consumes Pay-As-You-Go or Provisioned Throughput quota."
}
},
"$defs":{
"MediaModality":{
"description":"Server content modalities.",
"enum":[
"MODALITY_UNSPECIFIED",
"TEXT",
"IMAGE",
"VIDEO",
"AUDIO",
"DOCUMENT"
],
"title":"MediaModality",
"type":"string"
},
"ModalityTokenCount":{
"additionalProperties":false,
"description":"Represents token counting info for a single modality.",
"properties":{
"modality":{
"anyOf":[
{
"$ref":"#/$defs/MediaModality"
},
{
"type":"null"
}
],
"default":null,
"description":"The modality associated with this token count."
},
"tokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens.",
"title":"Tokencount"
}
},
"title":"ModalityTokenCount",
"type":"object"
},
"TrafficType":{
"description":"Output only.\n\nTraffic type. This shows whether a request consumes Pay-As-You-Go or\nProvisioned Throughput quota.",
"enum":[
"TRAFFIC_TYPE_UNSPECIFIED",
"ON_DEMAND",
"PROVISIONED_THROUGHPUT"
],
"title":"TrafficType",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `cache_tokens_details (list[genai.types.ModalityTokenCount] | None)`
  * `cached_content_token_count (int | None)`
  * `candidates_token_count (int | None)`
  * `candidates_tokens_details (list[genai.types.ModalityTokenCount] | None)`
  * `prompt_token_count (int | None)`
  * `prompt_tokens_details (list[genai.types.ModalityTokenCount] | None)`
  * `thoughts_token_count (int | None)`
  * `tool_use_prompt_token_count (int | None)`
  * `tool_use_prompt_tokens_details (list[genai.types.ModalityTokenCount] | None)`
  * `total_token_count (int | None)`
  * `traffic_type (genai.types.TrafficType | None)`



_field_ cache_tokens_details _:`Optional`[`list`[`ModalityTokenCount`]]__= None_ _(alias 'cacheTokensDetails')_¶ 
    
Output only. List of modalities of the cached content in the request input. 

_field_ cached_content_token_count _:`Optional`[`int`]__= None_ _(alias 'cachedContentTokenCount')_¶ 
    
Output only. Number of tokens in the cached part in the input (the cached content). 

_field_ candidates_token_count _:`Optional`[`int`]__= None_ _(alias 'candidatesTokenCount')_¶ 
    
Number of tokens in the response(s). 

_field_ candidates_tokens_details _:`Optional`[`list`[`ModalityTokenCount`]]__= None_ _(alias 'candidatesTokensDetails')_¶ 
    
Output only. List of modalities that were returned in the response. 

_field_ prompt_token_count _:`Optional`[`int`]__= None_ _(alias 'promptTokenCount')_¶ 
    
Number of tokens in the request. When cached_content is set, this is still the total effective prompt size meaning this includes the number of tokens in the cached content. 

_field_ prompt_tokens_details _:`Optional`[`list`[`ModalityTokenCount`]]__= None_ _(alias 'promptTokensDetails')_¶ 
    
Output only. List of modalities that were processed in the request input. 

_field_ thoughts_token_count _:`Optional`[`int`]__= None_ _(alias 'thoughtsTokenCount')_¶ 
    
Output only. Number of tokens present in thoughts output. 

_field_ tool_use_prompt_token_count _:`Optional`[`int`]__= None_ _(alias 'toolUsePromptTokenCount')_¶ 
    
Output only. Number of tokens present in tool-use prompt(s). 

_field_ tool_use_prompt_tokens_details _:`Optional`[`list`[`ModalityTokenCount`]]__= None_ _(alias 'toolUsePromptTokensDetails')_¶ 
    
Output only. List of modalities that were processed for tool-use request inputs. 

_field_ total_token_count _:`Optional`[`int`]__= None_ _(alias 'totalTokenCount')_¶ 
    
Total token count for prompt, response candidates, and tool-use prompts (if present). 

_field_ traffic_type _:`Optional`[`TrafficType`]__= None_ _(alias 'trafficType')_¶ 
    
Output only. Traffic type. This shows whether a request consumes Pay-As-You-Go or Provisioned Throughput quota. 

_class_ genai.types.GenerateContentResponseUsageMetadataDict¶ 
    
Bases: `TypedDict`
Usage metadata about response(s). 

cache_tokens_details _:`Optional`[`list`[`ModalityTokenCountDict`]]_¶ 
    
Output only. List of modalities of the cached content in the request input. 

cached_content_token_count _:`Optional`[`int`]_¶ 
    
Output only. Number of tokens in the cached part in the input (the cached content). 

candidates_token_count _:`Optional`[`int`]_¶ 
    
Number of tokens in the response(s). 

candidates_tokens_details _:`Optional`[`list`[`ModalityTokenCountDict`]]_¶ 
    
Output only. List of modalities that were returned in the response. 

prompt_token_count _:`Optional`[`int`]_¶ 
    
Number of tokens in the request. When cached_content is set, this is still the total effective prompt size meaning this includes the number of tokens in the cached content. 

prompt_tokens_details _:`Optional`[`list`[`ModalityTokenCountDict`]]_¶ 
    
Output only. List of modalities that were processed in the request input. 

thoughts_token_count _:`Optional`[`int`]_¶ 
    
Output only. Number of tokens present in thoughts output. 

tool_use_prompt_token_count _:`Optional`[`int`]_¶ 
    
Output only. Number of tokens present in tool-use prompt(s). 

tool_use_prompt_tokens_details _:`Optional`[`list`[`ModalityTokenCountDict`]]_¶ 
    
Output only. List of modalities that were processed for tool-use request inputs. 

total_token_count _:`Optional`[`int`]_¶ 
    
Total token count for prompt, response candidates, and tool-use prompts (if present). 

traffic_type _:`Optional`[`TrafficType`]_¶ 
    
Output only. Traffic type. This shows whether a request consumes Pay-As-You-Go or Provisioned Throughput quota. 

_pydantic model_genai.types.GenerateImagesConfig¶ 
    
Bases: `BaseModel`
The config for generating an images.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GenerateImagesConfig",
"description":"The config for generating an images.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
},
"outputGcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Cloud Storage URI used to store the generated images.\n      ",
"title":"Outputgcsuri"
},
"negativePrompt":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Description of what to discourage in the generated images.\n      ",
"title":"Negativeprompt"
},
"numberOfImages":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of images to generate.\n      ",
"title":"Numberofimages"
},
"aspectRatio":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Aspect ratio of the generated images.\n      ",
"title":"Aspectratio"
},
"guidanceScale":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Controls how much the model adheres to the text prompt. Large\n      values increase output and prompt alignment, but may compromise image\n      quality.\n      ",
"title":"Guidancescale"
},
"seed":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Random seed for image generation. This is not available when\n      ``add_watermark`` is set to true.\n      ",
"title":"Seed"
},
"safetyFilterLevel":{
"anyOf":[
{
"$ref":"#/$defs/SafetyFilterLevel"
},
{
"type":"null"
}
],
"default":null,
"description":"Filter level for safety filtering.\n      "
},
"personGeneration":{
"anyOf":[
{
"$ref":"#/$defs/PersonGeneration"
},
{
"type":"null"
}
],
"default":null,
"description":"Allows generation of people by the model.\n      "
},
"includeSafetyAttributes":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Whether to report the safety scores of each generated image and\n      the positive prompt in the response.\n      ",
"title":"Includesafetyattributes"
},
"includeRaiReason":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Whether to include the Responsible AI filter reason if the image\n      is filtered out of the response.\n      ",
"title":"Includeraireason"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/ImagePromptLanguage"
},
{
"type":"null"
}
],
"default":null,
"description":"Language of the text in the prompt.\n      "
},
"outputMimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"MIME type of the generated image.\n      ",
"title":"Outputmimetype"
},
"outputCompressionQuality":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Compression quality of the generated image (for ``image/jpeg``\n      only).\n      ",
"title":"Outputcompressionquality"
},
"addWatermark":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Whether to add a watermark to the generated images.\n      ",
"title":"Addwatermark"
},
"enhancePrompt":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Whether to use the prompt rewriting logic.\n      ",
"title":"Enhanceprompt"
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
},
"ImagePromptLanguage":{
"description":"Enum that specifies the language of the text in the prompt.",
"enum":[
"auto",
"en",
"ja",
"ko",
"hi"
],
"title":"ImagePromptLanguage",
"type":"string"
},
"PersonGeneration":{
"description":"Enum that controls the generation of people.",
"enum":[
"DONT_ALLOW",
"ALLOW_ADULT",
"ALLOW_ALL"
],
"title":"PersonGeneration",
"type":"string"
},
"SafetyFilterLevel":{
"description":"Enum that controls the safety filter level for objectionable content.",
"enum":[
"BLOCK_LOW_AND_ABOVE",
"BLOCK_MEDIUM_AND_ABOVE",
"BLOCK_ONLY_HIGH",
"BLOCK_NONE"
],
"title":"SafetyFilterLevel",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `add_watermark (bool | None)`
  * `aspect_ratio (str | None)`
  * `enhance_prompt (bool | None)`
  * `guidance_scale (float | None)`
  * `http_options (genai.types.HttpOptions | None)`
  * `include_rai_reason (bool | None)`
  * `include_safety_attributes (bool | None)`
  * `language (genai.types.ImagePromptLanguage | None)`
  * `negative_prompt (str | None)`
  * `number_of_images (int | None)`
  * `output_compression_quality (int | None)`
  * `output_gcs_uri (str | None)`
  * `output_mime_type (str | None)`
  * `person_generation (genai.types.PersonGeneration | None)`
  * `safety_filter_level (genai.types.SafetyFilterLevel | None)`
  * `seed (int | None)`



_field_ add_watermark _:`Optional`[`bool`]__= None_ _(alias 'addWatermark')_¶ 
    
Whether to add a watermark to the generated images. 

_field_ aspect_ratio _:`Optional`[`str`]__= None_ _(alias 'aspectRatio')_¶ 
    
Aspect ratio of the generated images. 

_field_ enhance_prompt _:`Optional`[`bool`]__= None_ _(alias 'enhancePrompt')_¶ 
    
Whether to use the prompt rewriting logic. 

_field_ guidance_scale _:`Optional`[`float`]__= None_ _(alias 'guidanceScale')_¶ 
    
Controls how much the model adheres to the text prompt. Large values increase output and prompt alignment, but may compromise image quality. 

_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_field_ include_rai_reason _:`Optional`[`bool`]__= None_ _(alias 'includeRaiReason')_¶ 
    
Whether to include the Responsible AI filter reason if the image is filtered out of the response. 

_field_ include_safety_attributes _:`Optional`[`bool`]__= None_ _(alias 'includeSafetyAttributes')_¶ 
    
Whether to report the safety scores of each generated image and the positive prompt in the response. 

_field_ language _:`Optional`[`ImagePromptLanguage`]__= None_¶ 
    
Language of the text in the prompt. 

_field_ negative_prompt _:`Optional`[`str`]__= None_ _(alias 'negativePrompt')_¶ 
    
Description of what to discourage in the generated images. 

_field_ number_of_images _:`Optional`[`int`]__= None_ _(alias 'numberOfImages')_¶ 
    
Number of images to generate. 

_field_ output_compression_quality _:`Optional`[`int`]__= None_ _(alias 'outputCompressionQuality')_¶ 
    
Compression quality of the generated image (for `image/jpeg` only). 

_field_ output_gcs_uri _:`Optional`[`str`]__= None_ _(alias 'outputGcsUri')_¶ 
    
Cloud Storage URI used to store the generated images. 

_field_ output_mime_type _:`Optional`[`str`]__= None_ _(alias 'outputMimeType')_¶ 
    
MIME type of the generated image. 

_field_ person_generation _:`Optional`[`PersonGeneration`]__= None_ _(alias 'personGeneration')_¶ 
    
Allows generation of people by the model. 

_field_ safety_filter_level _:`Optional`[`SafetyFilterLevel`]__= None_ _(alias 'safetyFilterLevel')_¶ 
    
Filter level for safety filtering. 

_field_ seed _:`Optional`[`int`]__= None_¶ 
    
Random seed for image generation. This is not available when `add_watermark` is set to true. 

_class_ genai.types.GenerateImagesConfigDict¶ 
    
Bases: `TypedDict`
The config for generating an images. 

add_watermark _:`Optional`[`bool`]_¶ 
    
Whether to add a watermark to the generated images. 

aspect_ratio _:`Optional`[`str`]_¶ 
    
Aspect ratio of the generated images. 

enhance_prompt _:`Optional`[`bool`]_¶ 
    
Whether to use the prompt rewriting logic. 

guidance_scale _:`Optional`[`float`]_¶ 
    
Controls how much the model adheres to the text prompt. Large values increase output and prompt alignment, but may compromise image quality. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

include_rai_reason _:`Optional`[`bool`]_¶ 
    
Whether to include the Responsible AI filter reason if the image is filtered out of the response. 

include_safety_attributes _:`Optional`[`bool`]_¶ 
    
Whether to report the safety scores of each generated image and the positive prompt in the response. 

language _:`Optional`[`ImagePromptLanguage`]_¶ 
    
Language of the text in the prompt. 

negative_prompt _:`Optional`[`str`]_¶ 
    
Description of what to discourage in the generated images. 

number_of_images _:`Optional`[`int`]_¶ 
    
Number of images to generate. 

output_compression_quality _:`Optional`[`int`]_¶ 
    
Compression quality of the generated image (for `image/jpeg` only). 

output_gcs_uri _:`Optional`[`str`]_¶ 
    
Cloud Storage URI used to store the generated images. 

output_mime_type _:`Optional`[`str`]_¶ 
    
MIME type of the generated image. 

person_generation _:`Optional`[`PersonGeneration`]_¶ 
    
Allows generation of people by the model. 

safety_filter_level _:`Optional`[`SafetyFilterLevel`]_¶ 
    
Filter level for safety filtering. 

seed _:`Optional`[`int`]_¶ 
    
Random seed for image generation. This is not available when `add_watermark` is set to true. 

_pydantic model_genai.types.GenerateImagesResponse¶ 
    
Bases: `BaseModel`
The output images response.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GenerateImagesResponse",
"description":"The output images response.",
"type":"object",
"properties":{
"generatedImages":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/GeneratedImage"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of generated images.\n      ",
"title":"Generatedimages"
},
"positivePromptSafetyAttributes":{
"anyOf":[
{
"$ref":"#/$defs/SafetyAttributes"
},
{
"type":"null"
}
],
"default":null,
"description":"Safety attributes of the positive prompt. Only populated if\n      ``include_safety_attributes`` is set to True.\n      "
}
},
"$defs":{
"GeneratedImage":{
"additionalProperties":false,
"description":"An output image.",
"properties":{
"image":{
"anyOf":[
{
"$ref":"#/$defs/Image"
},
{
"type":"null"
}
],
"default":null,
"description":"The output image data.\n      "
},
"raiFilteredReason":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Responsible AI filter reason if the image is filtered out of the\n      response.\n      ",
"title":"Raifilteredreason"
},
"safetyAttributes":{
"anyOf":[
{
"$ref":"#/$defs/SafetyAttributes"
},
{
"type":"null"
}
],
"default":null,
"description":"Safety attributes of the image. Lists of RAI categories and their\n      scores of each content.\n      "
},
"enhancedPrompt":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The rewritten prompt used for the image generation if the prompt\n      enhancer is enabled.\n      ",
"title":"Enhancedprompt"
}
},
"title":"GeneratedImage",
"type":"object"
},
"Image":{
"additionalProperties":false,
"description":"An image.",
"properties":{
"gcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The Cloud Storage URI of the image. ``Image`` can contain a value\n      for this field or the ``image_bytes`` field but not both.\n      ",
"title":"Gcsuri"
},
"imageBytes":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The image bytes data. ``Image`` can contain a value for this field\n      or the ``gcs_uri`` field but not both.\n      ",
"title":"Imagebytes"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The MIME type of the image.",
"title":"Mimetype"
}
},
"title":"Image",
"type":"object"
},
"SafetyAttributes":{
"additionalProperties":false,
"description":"Safety attributes of a GeneratedImage or the user-provided prompt.",
"properties":{
"categories":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of RAI categories.\n      ",
"title":"Categories"
},
"scores":{
"anyOf":[
{
"items":{
"type":"number"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of scores of each categories.\n      ",
"title":"Scores"
},
"contentType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Internal use only.\n      ",
"title":"Contenttype"
}
},
"title":"SafetyAttributes",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `generated_images (list[genai.types.GeneratedImage] | None)`
  * `positive_prompt_safety_attributes (genai.types.SafetyAttributes | None)`



_field_ generated_images _:`Optional`[`list`[`GeneratedImage`]]__= None_ _(alias 'generatedImages')_¶ 
    
List of generated images. 

_field_ positive_prompt_safety_attributes _:`Optional`[`SafetyAttributes`]__= None_ _(alias 'positivePromptSafetyAttributes')_¶ 
    
Safety attributes of the positive prompt. Only populated if `include_safety_attributes` is set to True. 

_class_ genai.types.GenerateImagesResponseDict¶ 
    
Bases: `TypedDict`
The output images response. 

generated_images _:`Optional`[`list`[`GeneratedImageDict`]]_¶ 
    
List of generated images. 

positive_prompt_safety_attributes _:`Optional`[`SafetyAttributesDict`]_¶ 
    
Safety attributes of the positive prompt. Only populated if `include_safety_attributes` is set to True. 

_pydantic model_genai.types.GenerateVideosConfig¶ 
    
Bases: `BaseModel`
Configuration for generating videos.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GenerateVideosConfig",
"description":"Configuration for generating videos.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
},
"numberOfVideos":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of output videos.",
"title":"Numberofvideos"
},
"outputGcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The gcs bucket where to save the generated videos.",
"title":"Outputgcsuri"
},
"fps":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Frames per second for video generation.",
"title":"Fps"
},
"durationSeconds":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Duration of the clip for video generation in seconds.",
"title":"Durationseconds"
},
"seed":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The RNG seed. If RNG seed is exactly same for each request with unchanged inputs, the prediction results will be consistent. Otherwise, a random RNG seed will be used each time to produce a different result.",
"title":"Seed"
},
"aspectRatio":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The aspect ratio for the generated video. 16:9 (landscape) and 9:16 (portrait) are supported.",
"title":"Aspectratio"
},
"resolution":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The resolution for the generated video. 1280x720, 1920x1080 are supported.",
"title":"Resolution"
},
"personGeneration":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Whether allow to generate person videos, and restrict to specific ages. Supported values are: dont_allow, allow_adult.",
"title":"Persongeneration"
},
"pubsubTopic":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The pubsub topic where to publish the video generation progress.",
"title":"Pubsubtopic"
},
"negativePrompt":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional field in addition to the text content. Negative prompts can be explicitly stated here to help generate the video.",
"title":"Negativeprompt"
},
"enhancePrompt":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Whether to use the prompt rewriting logic.",
"title":"Enhanceprompt"
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `aspect_ratio (str | None)`
  * `duration_seconds (int | None)`
  * `enhance_prompt (bool | None)`
  * `fps (int | None)`
  * `http_options (genai.types.HttpOptions | None)`
  * `negative_prompt (str | None)`
  * `number_of_videos (int | None)`
  * `output_gcs_uri (str | None)`
  * `person_generation (str | None)`
  * `pubsub_topic (str | None)`
  * `resolution (str | None)`
  * `seed (int | None)`



_field_ aspect_ratio _:`Optional`[`str`]__= None_ _(alias 'aspectRatio')_¶ 
    
The aspect ratio for the generated video. 16:9 (landscape) and 9:16 (portrait) are supported. 

_field_ duration_seconds _:`Optional`[`int`]__= None_ _(alias 'durationSeconds')_¶ 
    
Duration of the clip for video generation in seconds. 

_field_ enhance_prompt _:`Optional`[`bool`]__= None_ _(alias 'enhancePrompt')_¶ 
    
Whether to use the prompt rewriting logic. 

_field_ fps _:`Optional`[`int`]__= None_¶ 
    
Frames per second for video generation. 

_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_field_ negative_prompt _:`Optional`[`str`]__= None_ _(alias 'negativePrompt')_¶ 
    
Optional field in addition to the text content. Negative prompts can be explicitly stated here to help generate the video. 

_field_ number_of_videos _:`Optional`[`int`]__= None_ _(alias 'numberOfVideos')_¶ 
    
Number of output videos. 

_field_ output_gcs_uri _:`Optional`[`str`]__= None_ _(alias 'outputGcsUri')_¶ 
    
The gcs bucket where to save the generated videos. 

_field_ person_generation _:`Optional`[`str`]__= None_ _(alias 'personGeneration')_¶ 
    
Whether allow to generate person videos, and restrict to specific ages. Supported values are: dont_allow, allow_adult. 

_field_ pubsub_topic _:`Optional`[`str`]__= None_ _(alias 'pubsubTopic')_¶ 
    
The pubsub topic where to publish the video generation progress. 

_field_ resolution _:`Optional`[`str`]__= None_¶ 
    
The resolution for the generated video. 1280x720, 1920x1080 are supported. 

_field_ seed _:`Optional`[`int`]__= None_¶ 
    
The RNG seed. If RNG seed is exactly same for each request with unchanged inputs, the prediction results will be consistent. Otherwise, a random RNG seed will be used each time to produce a different result. 

_class_ genai.types.GenerateVideosConfigDict¶ 
    
Bases: `TypedDict`
Configuration for generating videos. 

aspect_ratio _:`Optional`[`str`]_¶ 
    
16 (portrait) are supported. 

Type: 
    
The aspect ratio for the generated video. 16 

Type: 
    
9 (landscape) and 9 

duration_seconds _:`Optional`[`int`]_¶ 
    
Duration of the clip for video generation in seconds. 

enhance_prompt _:`Optional`[`bool`]_¶ 
    
Whether to use the prompt rewriting logic. 

fps _:`Optional`[`int`]_¶ 
    
Frames per second for video generation. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

negative_prompt _:`Optional`[`str`]_¶ 
    
Optional field in addition to the text content. Negative prompts can be explicitly stated here to help generate the video. 

number_of_videos _:`Optional`[`int`]_¶ 
    
Number of output videos. 

output_gcs_uri _:`Optional`[`str`]_¶ 
    
The gcs bucket where to save the generated videos. 

person_generation _:`Optional`[`str`]_¶ 
    
dont_allow, allow_adult. 

Type: 
    
Whether allow to generate person videos, and restrict to specific ages. Supported values are 

pubsub_topic _:`Optional`[`str`]_¶ 
    
The pubsub topic where to publish the video generation progress. 

resolution _:`Optional`[`str`]_¶ 
    
The resolution for the generated video. 1280x720, 1920x1080 are supported. 

seed _:`Optional`[`int`]_¶ 
    
The RNG seed. If RNG seed is exactly same for each request with unchanged inputs, the prediction results will be consistent. Otherwise, a random RNG seed will be used each time to produce a different result. 

_pydantic model_genai.types.GenerateVideosOperation¶ 
    
Bases: `BaseModel`
A video generation operation.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GenerateVideosOperation",
"description":"A video generation operation.",
"type":"object",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`.",
"title":"Name"
},
"metadata":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata.  Any method that returns a long-running operation should document the metadata type, if any.",
"title":"Metadata"
},
"done":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available.",
"title":"Done"
},
"error":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"The error result of the operation in case of failure or cancellation.",
"title":"Error"
},
"response":{
"anyOf":[
{
"$ref":"#/$defs/GenerateVideosResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"The generated videos."
},
"result":{
"anyOf":[
{
"$ref":"#/$defs/GenerateVideosResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"The generated videos."
}
},
"$defs":{
"GenerateVideosResponse":{
"additionalProperties":false,
"description":"Response with generated videos.",
"properties":{
"generatedVideos":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/GeneratedVideo"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of the generated videos",
"title":"Generatedvideos"
},
"raiMediaFilteredCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Returns if any videos were filtered due to RAI policies.",
"title":"Raimediafilteredcount"
},
"raiMediaFilteredReasons":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Returns rai failure reasons if any.",
"title":"Raimediafilteredreasons"
}
},
"title":"GenerateVideosResponse",
"type":"object"
},
"GeneratedVideo":{
"additionalProperties":false,
"description":"A generated video.",
"properties":{
"video":{
"anyOf":[
{
"$ref":"#/$defs/Video"
},
{
"type":"null"
}
],
"default":null,
"description":"The output video"
}
},
"title":"GeneratedVideo",
"type":"object"
},
"Video":{
"additionalProperties":false,
"description":"A generated video.",
"properties":{
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Path to another storage.",
"title":"Uri"
},
"videoBytes":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Video bytes.",
"title":"Videobytes"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Video encoding, for example \"video/mp4\".",
"title":"Mimetype"
}
},
"title":"Video",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `done (bool | None)`
  * `error (dict[str, Any] | None)`
  * `metadata (dict[str, Any] | None)`
  * `name (str | None)`
  * `response (genai.types.GenerateVideosResponse | None)`
  * `result (genai.types.GenerateVideosResponse | None)`



_field_ done _:`Optional`[`bool`]__= None_¶ 
    
If the value is false, it means the operation is still in progress. If true, the operation is completed, and either error or response is available. 

_field_ error _:`Optional`[`dict`[`str`, `Any`]]__= None_¶ 
    
The error result of the operation in case of failure or cancellation. 

_field_ metadata _:`Optional`[`dict`[`str`, `Any`]]__= None_¶ 
    
Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any. 

_field_ name _:`Optional`[`str`]__= None_¶ 
    
The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the name should be a resource name ending with operations/{unique_id}. 

_field_ response _:`Optional`[`GenerateVideosResponse`]__= None_¶ 
    
The generated videos. 

_field_ result _:`Optional`[`GenerateVideosResponse`]__= None_¶ 
    
The generated videos. 

_class_ genai.types.GenerateVideosOperationDict¶ 
    
Bases: `TypedDict`
A video generation operation. 

done _:`Optional`[`bool`]_¶ 
    
If the value is false, it means the operation is still in progress. If true, the operation is completed, and either error or response is available. 

error _:`Optional`[`dict`[`str`, `Any`]]_¶ 
    
The error result of the operation in case of failure or cancellation. 

metadata _:`Optional`[`dict`[`str`, `Any`]]_¶ 
    
Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any. 

name _:`Optional`[`str`]_¶ 
    
The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the name should be a resource name ending with operations/{unique_id}. 

response _:`Optional`[`GenerateVideosResponseDict`]_¶ 
    
The generated videos. 

result _:`Optional`[`GenerateVideosResponseDict`]_¶ 
    
The generated videos. 

_pydantic model_genai.types.GenerateVideosResponse¶ 
    
Bases: `BaseModel`
Response with generated videos.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GenerateVideosResponse",
"description":"Response with generated videos.",
"type":"object",
"properties":{
"generatedVideos":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/GeneratedVideo"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of the generated videos",
"title":"Generatedvideos"
},
"raiMediaFilteredCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Returns if any videos were filtered due to RAI policies.",
"title":"Raimediafilteredcount"
},
"raiMediaFilteredReasons":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Returns rai failure reasons if any.",
"title":"Raimediafilteredreasons"
}
},
"$defs":{
"GeneratedVideo":{
"additionalProperties":false,
"description":"A generated video.",
"properties":{
"video":{
"anyOf":[
{
"$ref":"#/$defs/Video"
},
{
"type":"null"
}
],
"default":null,
"description":"The output video"
}
},
"title":"GeneratedVideo",
"type":"object"
},
"Video":{
"additionalProperties":false,
"description":"A generated video.",
"properties":{
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Path to another storage.",
"title":"Uri"
},
"videoBytes":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Video bytes.",
"title":"Videobytes"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Video encoding, for example \"video/mp4\".",
"title":"Mimetype"
}
},
"title":"Video",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `generated_videos (list[genai.types.GeneratedVideo] | None)`
  * `rai_media_filtered_count (int | None)`
  * `rai_media_filtered_reasons (list[str] | None)`



_field_ generated_videos _:`Optional`[`list`[`GeneratedVideo`]]__= None_ _(alias 'generatedVideos')_¶ 
    
List of the generated videos 

_field_ rai_media_filtered_count _:`Optional`[`int`]__= None_ _(alias 'raiMediaFilteredCount')_¶ 
    
Returns if any videos were filtered due to RAI policies. 

_field_ rai_media_filtered_reasons _:`Optional`[`list`[`str`]]__= None_ _(alias 'raiMediaFilteredReasons')_¶ 
    
Returns rai failure reasons if any. 

_class_ genai.types.GenerateVideosResponseDict¶ 
    
Bases: `TypedDict`
Response with generated videos. 

generated_videos _:`Optional`[`list`[`GeneratedVideoDict`]]_¶ 
    
List of the generated videos 

rai_media_filtered_count _:`Optional`[`int`]_¶ 
    
Returns if any videos were filtered due to RAI policies. 

rai_media_filtered_reasons _:`Optional`[`list`[`str`]]_¶ 
    
Returns rai failure reasons if any. 

_pydantic model_genai.types.GeneratedImage¶ 
    
Bases: `BaseModel`
An output image.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GeneratedImage",
"description":"An output image.",
"type":"object",
"properties":{
"image":{
"anyOf":[
{
"$ref":"#/$defs/Image"
},
{
"type":"null"
}
],
"default":null,
"description":"The output image data.\n      "
},
"raiFilteredReason":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Responsible AI filter reason if the image is filtered out of the\n      response.\n      ",
"title":"Raifilteredreason"
},
"safetyAttributes":{
"anyOf":[
{
"$ref":"#/$defs/SafetyAttributes"
},
{
"type":"null"
}
],
"default":null,
"description":"Safety attributes of the image. Lists of RAI categories and their\n      scores of each content.\n      "
},
"enhancedPrompt":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The rewritten prompt used for the image generation if the prompt\n      enhancer is enabled.\n      ",
"title":"Enhancedprompt"
}
},
"$defs":{
"Image":{
"additionalProperties":false,
"description":"An image.",
"properties":{
"gcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The Cloud Storage URI of the image. ``Image`` can contain a value\n      for this field or the ``image_bytes`` field but not both.\n      ",
"title":"Gcsuri"
},
"imageBytes":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The image bytes data. ``Image`` can contain a value for this field\n      or the ``gcs_uri`` field but not both.\n      ",
"title":"Imagebytes"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The MIME type of the image.",
"title":"Mimetype"
}
},
"title":"Image",
"type":"object"
},
"SafetyAttributes":{
"additionalProperties":false,
"description":"Safety attributes of a GeneratedImage or the user-provided prompt.",
"properties":{
"categories":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of RAI categories.\n      ",
"title":"Categories"
},
"scores":{
"anyOf":[
{
"items":{
"type":"number"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of scores of each categories.\n      ",
"title":"Scores"
},
"contentType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Internal use only.\n      ",
"title":"Contenttype"
}
},
"title":"SafetyAttributes",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `enhanced_prompt (str | None)`
  * `image (genai.types.Image | None)`
  * `rai_filtered_reason (str | None)`
  * `safety_attributes (genai.types.SafetyAttributes | None)`



_field_ enhanced_prompt _:`Optional`[`str`]__= None_ _(alias 'enhancedPrompt')_¶ 
    
The rewritten prompt used for the image generation if the prompt enhancer is enabled. 

_field_ image _:`Optional`[`Image`]__= None_¶ 
    
The output image data. 

_field_ rai_filtered_reason _:`Optional`[`str`]__= None_ _(alias 'raiFilteredReason')_¶ 
    
Responsible AI filter reason if the image is filtered out of the response. 

_field_ safety_attributes _:`Optional`[`SafetyAttributes`]__= None_ _(alias 'safetyAttributes')_¶ 
    
Safety attributes of the image. Lists of RAI categories and their scores of each content. 

_class_ genai.types.GeneratedImageDict¶ 
    
Bases: `TypedDict`
An output image. 

enhanced_prompt _:`Optional`[`str`]_¶ 
    
The rewritten prompt used for the image generation if the prompt enhancer is enabled. 

image _:`Optional`[`ImageDict`]_¶ 
    
The output image data. 

rai_filtered_reason _:`Optional`[`str`]_¶ 
    
Responsible AI filter reason if the image is filtered out of the response. 

safety_attributes _:`Optional`[`SafetyAttributesDict`]_¶ 
    
Safety attributes of the image. Lists of RAI categories and their scores of each content. 

_pydantic model_genai.types.GeneratedVideo¶ 
    
Bases: `BaseModel`
A generated video.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GeneratedVideo",
"description":"A generated video.",
"type":"object",
"properties":{
"video":{
"anyOf":[
{
"$ref":"#/$defs/Video"
},
{
"type":"null"
}
],
"default":null,
"description":"The output video"
}
},
"$defs":{
"Video":{
"additionalProperties":false,
"description":"A generated video.",
"properties":{
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Path to another storage.",
"title":"Uri"
},
"videoBytes":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Video bytes.",
"title":"Videobytes"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Video encoding, for example \"video/mp4\".",
"title":"Mimetype"
}
},
"title":"Video",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `video (genai.types.Video | None)`



_field_ video _:`Optional`[`Video`]__= None_¶ 
    
The output video 

_class_ genai.types.GeneratedVideoDict¶ 
    
Bases: `TypedDict`
A generated video. 

video _:`Optional`[`VideoDict`]_¶ 
    
The output video 

_pydantic model_genai.types.GenerationConfig¶ 
    
Bases: `BaseModel`
Generation config.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GenerationConfig",
"description":"Generation config.",
"type":"object",
"properties":{
"audioTimestamp":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If enabled, audio timestamp will be included in the request to the model.",
"title":"Audiotimestamp"
},
"candidateCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of candidates to generate.",
"title":"Candidatecount"
},
"frequencyPenalty":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Frequency penalties.",
"title":"Frequencypenalty"
},
"logprobs":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Logit probabilities.",
"title":"Logprobs"
},
"maxOutputTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The maximum number of output tokens to generate per message.",
"title":"Maxoutputtokens"
},
"mediaResolution":{
"anyOf":[
{
"$ref":"#/$defs/MediaResolution"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If specified, the media resolution specified will be used."
},
"presencePenalty":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Positive penalties.",
"title":"Presencepenalty"
},
"responseLogprobs":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If true, export the logprobs results in response.",
"title":"Responselogprobs"
},
"responseMimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Output response mimetype of the generated candidate text. Supported mimetype: - `text/plain`: (default) Text output. - `application/json`: JSON response in the candidates. The model needs to be prompted to output the appropriate response type, otherwise the behavior is undefined. This is a preview feature.",
"title":"Responsemimetype"
},
"responseSchema":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The `Schema` object allows the definition of input and output data types. These types can be objects, but also primitives and arrays. Represents a select subset of an [OpenAPI 3.0 schema object](https://spec.openapis.org/oas/v3.0.3#schema). If set, a compatible response_mime_type must also be set. Compatible mimetypes: `application/json`: Schema for JSON response."
},
"routingConfig":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Routing configuration."
},
"seed":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Seed.",
"title":"Seed"
},
"stopSequences":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Stop sequences.",
"title":"Stopsequences"
},
"temperature":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Controls the randomness of predictions.",
"title":"Temperature"
},
"topK":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If specified, top-k sampling will be used.",
"title":"Topk"
},
"topP":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If specified, nucleus sampling will be used.",
"title":"Topp"
}
},
"$defs":{
"GenerationConfigRoutingConfig":{
"additionalProperties":false,
"description":"The configuration for routing the request to a specific model.",
"properties":{
"autoMode":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfigAutoRoutingMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Automated routing."
},
"manualMode":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfigManualRoutingMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Manual routing."
}
},
"title":"GenerationConfigRoutingConfig",
"type":"object"
},
"GenerationConfigRoutingConfigAutoRoutingMode":{
"additionalProperties":false,
"description":"When automated routing is specified, the routing will be determined by the pretrained routing model and customer provided model routing preference.",
"properties":{
"modelRoutingPreference":{
"anyOf":[
{
"enum":[
"UNKNOWN",
"PRIORITIZE_QUALITY",
"BALANCED",
"PRIORITIZE_COST"
],
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The model routing preference.",
"title":"Modelroutingpreference"
}
},
"title":"GenerationConfigRoutingConfigAutoRoutingMode",
"type":"object"
},
"GenerationConfigRoutingConfigManualRoutingMode":{
"additionalProperties":false,
"description":"When manual routing is set, the specified model will be used directly.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The model name to use. Only the public LLM models are accepted. e.g. 'gemini-1.5-pro-001'.",
"title":"Modelname"
}
},
"title":"GenerationConfigRoutingConfigManualRoutingMode",
"type":"object"
},
"MediaResolution":{
"description":"The media resolution to use.",
"enum":[
"MEDIA_RESOLUTION_UNSPECIFIED",
"MEDIA_RESOLUTION_LOW",
"MEDIA_RESOLUTION_MEDIUM",
"MEDIA_RESOLUTION_HIGH"
],
"title":"MediaResolution",
"type":"string"
},
"Schema":{
"additionalProperties":false,
"description":"Schema is used to define the format of input/output data.\n\nRepresents a select subset of an [OpenAPI 3.0 schema\nobject](https://spec.openapis.org/oas/v3.0.3#schema-object). More fields may\nbe added in the future as needed.",
"properties":{
"anyOf":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Schema"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The value should be validated against any (one or more) of the subschemas in the list.",
"title":"Anyof"
},
"default":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Default value of the data.",
"title":"Default"
},
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The description of the data.",
"title":"Description"
},
"enum":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Possible values of the element of primitive type with enum format. Examples: 1. We can define direction as : {type:STRING, format:enum, enum:[\"EAST\", NORTH\", \"SOUTH\", \"WEST\"]} 2. We can define apartment number as : {type:INTEGER, format:enum, enum:[\"101\", \"201\", \"301\"]}",
"title":"Enum"
},
"example":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Example of the object. Will only populated when the object is the root.",
"title":"Example"
},
"format":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The format of the data. Supported formats: for NUMBER type: \"float\", \"double\" for INTEGER type: \"int32\", \"int64\" for STRING type: \"email\", \"byte\", etc",
"title":"Format"
},
"items":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE ARRAY Schema of the elements of Type.ARRAY."
},
"maxItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the elements for Type.ARRAY.",
"title":"Maxitems"
},
"maxLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum length of the Type.STRING",
"title":"Maxlength"
},
"maxProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the properties for Type.OBJECT.",
"title":"Maxproperties"
},
"maximum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum value of the Type.INTEGER and Type.NUMBER",
"title":"Maximum"
},
"minItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the elements for Type.ARRAY.",
"title":"Minitems"
},
"minLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING",
"title":"Minlength"
},
"minProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the properties for Type.OBJECT.",
"title":"Minproperties"
},
"minimum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER Minimum value of the Type.INTEGER and Type.NUMBER",
"title":"Minimum"
},
"nullable":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Indicates if the value may be null.",
"title":"Nullable"
},
"pattern":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Pattern of the Type.STRING to restrict a string to a regular expression.",
"title":"Pattern"
},
"properties":{
"anyOf":[
{
"additionalProperties":{
"$ref":"#/$defs/Schema"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE OBJECT Properties of Type.OBJECT.",
"title":"Properties"
},
"propertyOrdering":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The order of the properties. Not a standard field in open api spec. Only used to support the order of the properties.",
"title":"Propertyordering"
},
"required":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required properties of Type.OBJECT.",
"title":"Required"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The title of the Schema.",
"title":"Title"
},
"type":{
"anyOf":[
{
"$ref":"#/$defs/Type"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The type of the data."
}
},
"title":"Schema",
"type":"object"
},
"Type":{
"description":"Optional. The type of the data.",
"enum":[
"TYPE_UNSPECIFIED",
"STRING",
"NUMBER",
"INTEGER",
"BOOLEAN",
"ARRAY",
"OBJECT"
],
"title":"Type",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `audio_timestamp (bool | None)`
  * `candidate_count (int | None)`
  * `frequency_penalty (float | None)`
  * `logprobs (int | None)`
  * `max_output_tokens (int | None)`
  * `media_resolution (genai.types.MediaResolution | None)`
  * `presence_penalty (float | None)`
  * `response_logprobs (bool | None)`
  * `response_mime_type (str | None)`
  * `response_schema (genai.types.Schema | None)`
  * `routing_config (genai.types.GenerationConfigRoutingConfig | None)`
  * `seed (int | None)`
  * `stop_sequences (list[str] | None)`
  * `temperature (float | None)`
  * `top_k (float | None)`
  * `top_p (float | None)`



_field_ audio_timestamp _:`Optional`[`bool`]__= None_ _(alias 'audioTimestamp')_¶ 
    
Optional. If enabled, audio timestamp will be included in the request to the model. 

_field_ candidate_count _:`Optional`[`int`]__= None_ _(alias 'candidateCount')_¶ 
    
Optional. Number of candidates to generate. 

_field_ frequency_penalty _:`Optional`[`float`]__= None_ _(alias 'frequencyPenalty')_¶ 
    
Optional. Frequency penalties. 

_field_ logprobs _:`Optional`[`int`]__= None_¶ 
    
Optional. Logit probabilities. 

_field_ max_output_tokens _:`Optional`[`int`]__= None_ _(alias 'maxOutputTokens')_¶ 
    
Optional. The maximum number of output tokens to generate per message. 

_field_ media_resolution _:`Optional`[`MediaResolution`]__= None_ _(alias 'mediaResolution')_¶ 
    
Optional. If specified, the media resolution specified will be used. 

_field_ presence_penalty _:`Optional`[`float`]__= None_ _(alias 'presencePenalty')_¶ 
    
Optional. Positive penalties. 

_field_ response_logprobs _:`Optional`[`bool`]__= None_ _(alias 'responseLogprobs')_¶ 
    
Optional. If true, export the logprobs results in response. 

_field_ response_mime_type _:`Optional`[`str`]__= None_ _(alias 'responseMimeType')_¶ 
    
Optional. Output response mimetype of the generated candidate text. Supported mimetype: - text/plain: (default) Text output. - application/json: JSON response in the candidates. The model needs to be prompted to output the appropriate response type, otherwise the behavior is undefined. This is a preview feature. 

_field_ response_schema _:`Optional`[`Schema`]__= None_ _(alias 'responseSchema')_¶ 
    
Optional. The Schema object allows the definition of input and output data types. These types can be objects, but also primitives and arrays. Represents a select subset of an [OpenAPI 3.0 schema object](https://spec.openapis.org/oas/v3.0.3#schema). If set, a compatible response_mime_type must also be set. Compatible mimetypes: application/json: Schema for JSON response. 

_field_ routing_config _:`Optional`[`GenerationConfigRoutingConfig`]__= None_ _(alias 'routingConfig')_¶ 
    
Optional. Routing configuration. 

_field_ seed _:`Optional`[`int`]__= None_¶ 
    
Optional. Seed. 

_field_ stop_sequences _:`Optional`[`list`[`str`]]__= None_ _(alias 'stopSequences')_¶ 
    
Optional. Stop sequences. 

_field_ temperature _:`Optional`[`float`]__= None_¶ 
    
Optional. Controls the randomness of predictions. 

_field_ top_k _:`Optional`[`float`]__= None_ _(alias 'topK')_¶ 
    
Optional. If specified, top-k sampling will be used. 

_field_ top_p _:`Optional`[`float`]__= None_ _(alias 'topP')_¶ 
    
Optional. If specified, nucleus sampling will be used. 

_class_ genai.types.GenerationConfigDict¶ 
    
Bases: `TypedDict`
Generation config. 

audio_timestamp _:`Optional`[`bool`]_¶ 
    
Optional. If enabled, audio timestamp will be included in the request to the model. 

candidate_count _:`Optional`[`int`]_¶ 
    
Optional. Number of candidates to generate. 

frequency_penalty _:`Optional`[`float`]_¶ 
    
Optional. Frequency penalties. 

logprobs _:`Optional`[`int`]_¶ 
    
Optional. Logit probabilities. 

max_output_tokens _:`Optional`[`int`]_¶ 
    
Optional. The maximum number of output tokens to generate per message. 

media_resolution _:`Optional`[`MediaResolution`]_¶ 
    
Optional. If specified, the media resolution specified will be used. 

presence_penalty _:`Optional`[`float`]_¶ 
    
Optional. Positive penalties. 

response_logprobs _:`Optional`[`bool`]_¶ 
    
Optional. If true, export the logprobs results in response. 

response_mime_type _:`Optional`[`str`]_¶ 
    
(default) Text output. - application/json: JSON response in the candidates. The model needs to be prompted to output the appropriate response type, otherwise the behavior is undefined. This is a preview feature. 

Type: 
    
Optional. Output response mimetype of the generated candidate text. Supported mimetype 

Type: 
    
  * text/plain



response_schema _:`Optional`[`SchemaDict`]_¶ 
    
application/json: Schema for JSON response. 

Type: 
    
Optional. The Schema object allows the definition of input and output data types. These types can be objects, but also primitives and arrays. Represents a select subset of an [OpenAPI 3.0 schema object](https 

Type: 
    
//spec.openapis.org/oas/v3.0.3#schema). If set, a compatible response_mime_type must also be set. Compatible mimetypes 

routing_config _:`Optional`[`GenerationConfigRoutingConfigDict`]_¶ 
    
Optional. Routing configuration. 

seed _:`Optional`[`int`]_¶ 
    
Optional. Seed. 

stop_sequences _:`Optional`[`list`[`str`]]_¶ 
    
Optional. Stop sequences. 

temperature _:`Optional`[`float`]_¶ 
    
Optional. Controls the randomness of predictions. 

top_k _:`Optional`[`float`]_¶ 
    
Optional. If specified, top-k sampling will be used. 

top_p _:`Optional`[`float`]_¶ 
    
Optional. If specified, nucleus sampling will be used. 

_pydantic model_genai.types.GenerationConfigRoutingConfig¶ 
    
Bases: `BaseModel`
The configuration for routing the request to a specific model.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GenerationConfigRoutingConfig",
"description":"The configuration for routing the request to a specific model.",
"type":"object",
"properties":{
"autoMode":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfigAutoRoutingMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Automated routing."
},
"manualMode":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfigManualRoutingMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Manual routing."
}
},
"$defs":{
"GenerationConfigRoutingConfigAutoRoutingMode":{
"additionalProperties":false,
"description":"When automated routing is specified, the routing will be determined by the pretrained routing model and customer provided model routing preference.",
"properties":{
"modelRoutingPreference":{
"anyOf":[
{
"enum":[
"UNKNOWN",
"PRIORITIZE_QUALITY",
"BALANCED",
"PRIORITIZE_COST"
],
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The model routing preference.",
"title":"Modelroutingpreference"
}
},
"title":"GenerationConfigRoutingConfigAutoRoutingMode",
"type":"object"
},
"GenerationConfigRoutingConfigManualRoutingMode":{
"additionalProperties":false,
"description":"When manual routing is set, the specified model will be used directly.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The model name to use. Only the public LLM models are accepted. e.g. 'gemini-1.5-pro-001'.",
"title":"Modelname"
}
},
"title":"GenerationConfigRoutingConfigManualRoutingMode",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `auto_mode (genai.types.GenerationConfigRoutingConfigAutoRoutingMode | None)`
  * `manual_mode (genai.types.GenerationConfigRoutingConfigManualRoutingMode | None)`



_field_ auto_mode _:`Optional`[`GenerationConfigRoutingConfigAutoRoutingMode`]__= None_ _(alias 'autoMode')_¶ 
    
Automated routing. 

_field_ manual_mode _:`Optional`[`GenerationConfigRoutingConfigManualRoutingMode`]__= None_ _(alias 'manualMode')_¶ 
    
Manual routing. 

_pydantic model_genai.types.GenerationConfigRoutingConfigAutoRoutingMode¶ 
    
Bases: `BaseModel`
When automated routing is specified, the routing will be determined by the pretrained routing model and customer provided model routing preference.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GenerationConfigRoutingConfigAutoRoutingMode",
"description":"When automated routing is specified, the routing will be determined by the pretrained routing model and customer provided model routing preference.",
"type":"object",
"properties":{
"modelRoutingPreference":{
"anyOf":[
{
"enum":[
"UNKNOWN",
"PRIORITIZE_QUALITY",
"BALANCED",
"PRIORITIZE_COST"
],
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The model routing preference.",
"title":"Modelroutingpreference"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `model_routing_preference (Literal['UNKNOWN', 'PRIORITIZE_QUALITY', 'BALANCED', 'PRIORITIZE_COST'] | None)`



_field_ model_routing_preference _:`Optional`[`Literal`[`'UNKNOWN'`, `'PRIORITIZE_QUALITY'`, `'BALANCED'`, `'PRIORITIZE_COST'`]]__= None_ _(alias 'modelRoutingPreference')_¶ 
    
The model routing preference. 

_class_ genai.types.GenerationConfigRoutingConfigAutoRoutingModeDict¶ 
    
Bases: `TypedDict`
When automated routing is specified, the routing will be determined by the pretrained routing model and customer provided model routing preference. 

model_routing_preference _:`Optional`[`Literal`[`'UNKNOWN'`, `'PRIORITIZE_QUALITY'`, `'BALANCED'`, `'PRIORITIZE_COST'`]]_¶ 
    
The model routing preference. 

_class_ genai.types.GenerationConfigRoutingConfigDict¶ 
    
Bases: `TypedDict`
The configuration for routing the request to a specific model. 

auto_mode _:`Optional`[`GenerationConfigRoutingConfigAutoRoutingModeDict`]_¶ 
    
Automated routing. 

manual_mode _:`Optional`[`GenerationConfigRoutingConfigManualRoutingModeDict`]_¶ 
    
Manual routing. 

_pydantic model_genai.types.GenerationConfigRoutingConfigManualRoutingMode¶ 
    
Bases: `BaseModel`
When manual routing is set, the specified model will be used directly.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GenerationConfigRoutingConfigManualRoutingMode",
"description":"When manual routing is set, the specified model will be used directly.",
"type":"object",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The model name to use. Only the public LLM models are accepted. e.g. 'gemini-1.5-pro-001'.",
"title":"Modelname"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `model_name (str | None)`



_field_ model_name _:`Optional`[`str`]__= None_ _(alias 'modelName')_¶ 
    
The model name to use. Only the public LLM models are accepted. e.g. ‘gemini-1.5-pro-001’. 

_class_ genai.types.GenerationConfigRoutingConfigManualRoutingModeDict¶ 
    
Bases: `TypedDict`
When manual routing is set, the specified model will be used directly. 

model_name _:`Optional`[`str`]_¶ 
    
The model name to use. Only the public LLM models are accepted. e.g. ‘gemini-1.5-pro-001’. 

_pydantic model_genai.types.GetBatchJobConfig¶ 
    
Bases: `BaseModel`
Optional parameters.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GetBatchJobConfig",
"description":"Optional parameters.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `http_options (genai.types.HttpOptions | None)`



_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_class_ genai.types.GetBatchJobConfigDict¶ 
    
Bases: `TypedDict`
Optional parameters. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

_pydantic model_genai.types.GetCachedContentConfig¶ 
    
Bases: `BaseModel`
Optional parameters for caches.get method.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GetCachedContentConfig",
"description":"Optional parameters for caches.get method.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `http_options (genai.types.HttpOptions | None)`



_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_class_ genai.types.GetCachedContentConfigDict¶ 
    
Bases: `TypedDict`
Optional parameters for caches.get method. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

_pydantic model_genai.types.GetFileConfig¶ 
    
Bases: `BaseModel`
Used to override the default configuration.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GetFileConfig",
"description":"Used to override the default configuration.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `http_options (genai.types.HttpOptions | None)`



_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_class_ genai.types.GetFileConfigDict¶ 
    
Bases: `TypedDict`
Used to override the default configuration. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

_pydantic model_genai.types.GetModelConfig¶ 
    
Bases: `BaseModel`
Optional parameters for models.get method.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GetModelConfig",
"description":"Optional parameters for models.get method.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `http_options (genai.types.HttpOptions | None)`



_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_class_ genai.types.GetModelConfigDict¶ 
    
Bases: `TypedDict`
Optional parameters for models.get method. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

_pydantic model_genai.types.GetOperationConfig¶ 
    
Bases: `BaseModel`
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GetOperationConfig",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `http_options (genai.types.HttpOptions | None)`



_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_class_ genai.types.GetOperationConfigDict¶ 
    
Bases: `TypedDict` 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

_pydantic model_genai.types.GetTuningJobConfig¶ 
    
Bases: `BaseModel`
Optional parameters for tunings.get method.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GetTuningJobConfig",
"description":"Optional parameters for tunings.get method.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `http_options (genai.types.HttpOptions | None)`



_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_class_ genai.types.GetTuningJobConfigDict¶ 
    
Bases: `TypedDict`
Optional parameters for tunings.get method. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

_pydantic model_genai.types.GoogleMaps¶ 
    
Bases: `BaseModel`
Tool to support Google Maps in Model.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GoogleMaps",
"description":"Tool to support Google Maps in Model.",
"type":"object",
"properties":{
"authConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Auth config for the Google Maps tool."
}
},
"$defs":{
"ApiKeyConfig":{
"additionalProperties":false,
"description":"Config for authentication with API key.",
"properties":{
"apiKeyString":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The API key to be used in the request directly.",
"title":"Apikeystring"
}
},
"title":"ApiKeyConfig",
"type":"object"
},
"AuthConfig":{
"additionalProperties":false,
"description":"Auth configuration to run the extension.",
"properties":{
"apiKeyConfig":{
"anyOf":[
{
"$ref":"#/$defs/ApiKeyConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for API key auth."
},
"authType":{
"anyOf":[
{
"$ref":"#/$defs/AuthType"
},
{
"type":"null"
}
],
"default":null,
"description":"Type of auth scheme."
},
"googleServiceAccountConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigGoogleServiceAccountConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for Google Service Account auth."
},
"httpBasicAuthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigHttpBasicAuthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for HTTP Basic auth."
},
"oauthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOauthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user oauth."
},
"oidcConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOidcConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user OIDC auth."
}
},
"title":"AuthConfig",
"type":"object"
},
"AuthConfigGoogleServiceAccountConfig":{
"additionalProperties":false,
"description":"Config for Google Service Account Authentication.",
"properties":{
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The service account that the extension execution service runs as. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified service account. - If not specified, the Vertex AI Extension Service Agent will be used to execute the Extension.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigGoogleServiceAccountConfig",
"type":"object"
},
"AuthConfigHttpBasicAuthConfig":{
"additionalProperties":false,
"description":"Config for HTTP Basic Authentication.",
"properties":{
"credentialSecret":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the SecretManager secret version resource storing the base64 encoded credentials. Format: `projects/{project}/secrets/{secrete}/versions/{version}` - If specified, the `secretmanager.versions.access` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified resource.",
"title":"Credentialsecret"
}
},
"title":"AuthConfigHttpBasicAuthConfig",
"type":"object"
},
"AuthConfigOauthConfig":{
"additionalProperties":false,
"description":"Config for user oauth.",
"properties":{
"accessToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Access token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Accesstoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate access tokens for executing the Extension. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the provided service account.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOauthConfig",
"type":"object"
},
"AuthConfigOidcConfig":{
"additionalProperties":false,
"description":"Config for user OIDC auth.",
"properties":{
"idToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"OpenID Connect formatted ID token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Idtoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate an OpenID Connect (OIDC)-compatible JWT token signed by the Google OIDC Provider (accounts.google.com) for extension endpoint (https://cloud.google.com/iam/docs/create-short-lived-credentials-direct#sa-credentials-oidc). - The audience for the token will be set to the URL in the server url defined in the OpenApi spec. - If the service account is provided, the service account should grant `iam.serviceAccounts.getOpenIdToken` permission to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOidcConfig",
"type":"object"
},
"AuthType":{
"description":"Type of auth scheme.",
"enum":[
"AUTH_TYPE_UNSPECIFIED",
"NO_AUTH",
"API_KEY_AUTH",
"HTTP_BASIC_AUTH",
"GOOGLE_SERVICE_ACCOUNT_AUTH",
"OAUTH",
"OIDC_AUTH"
],
"title":"AuthType",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `auth_config (genai.types.AuthConfig | None)`



_field_ auth_config _:`Optional`[`AuthConfig`]__= None_ _(alias 'authConfig')_¶ 
    
Optional. Auth config for the Google Maps tool. 

_class_ genai.types.GoogleMapsDict¶ 
    
Bases: `TypedDict`
Tool to support Google Maps in Model. 

auth_config _:`Optional`[`AuthConfigDict`]_¶ 
    
Optional. Auth config for the Google Maps tool. 

_pydantic model_genai.types.GoogleRpcStatus¶ 
    
Bases: `BaseModel`
The Status type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs.
It is used by [gRPC](https://github.com/grpc). Each Status message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GoogleRpcStatus",
"description":"The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs.\n\nIt is used by [gRPC](https://github.com/grpc). Each `Status` message contains\nthree pieces of data: error code, error message, and error details. You can\nfind out more about this error model and how to work with it in the [API\nDesign Guide](https://cloud.google.com/apis/design/errors).",
"type":"object",
"properties":{
"code":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The status code, which should be an enum value of google.rpc.Code.",
"title":"Code"
},
"details":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Details"
},
"message":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.",
"title":"Message"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `code (int | None)`
  * `details (list[dict[str, Any]] | None)`
  * `message (str | None)`



_field_ code _:`Optional`[`int`]__= None_¶ 
    
The status code, which should be an enum value of google.rpc.Code. 

_field_ details _:`Optional`[`list`[`dict`[`str`, `Any`]]]__= None_¶ 
    
A list of messages that carry the error details. There is a common set of message types for APIs to use. 

_field_ message _:`Optional`[`str`]__= None_¶ 
    
A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client. 

_class_ genai.types.GoogleRpcStatusDict¶ 
    
Bases: `TypedDict`
The Status type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs.
It is used by [gRPC](https://github.com/grpc). Each Status message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors). 

code _:`Optional`[`int`]_¶ 
    
The status code, which should be an enum value of google.rpc.Code. 

details _:`Optional`[`list`[`dict`[`str`, `Any`]]]_¶ 
    
A list of messages that carry the error details. There is a common set of message types for APIs to use. 

message _:`Optional`[`str`]_¶ 
    
A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client. 

_pydantic model_genai.types.GoogleSearch¶ 
    
Bases: `BaseModel`
Tool to support Google Search in Model. Powered by Google.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GoogleSearch",
"description":"Tool to support Google Search in Model. Powered by Google.",
"type":"object",
"properties":{},
"additionalProperties":false
}

```


_class_ genai.types.GoogleSearchDict¶ 
    
Bases: `TypedDict`
Tool to support Google Search in Model. Powered by Google. 

_pydantic model_genai.types.GoogleSearchRetrieval¶ 
    
Bases: `BaseModel`
Tool to retrieve public web data for grounding, powered by Google.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GoogleSearchRetrieval",
"description":"Tool to retrieve public web data for grounding, powered by Google.",
"type":"object",
"properties":{
"dynamicRetrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/DynamicRetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the dynamic retrieval configuration for the given source."
}
},
"$defs":{
"DynamicRetrievalConfig":{
"additionalProperties":false,
"description":"Describes the options to customize dynamic retrieval.",
"properties":{
"mode":{
"anyOf":[
{
"$ref":"#/$defs/DynamicRetrievalConfigMode"
},
{
"type":"null"
}
],
"default":null,
"description":"The mode of the predictor to be used in dynamic retrieval."
},
"dynamicThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The threshold to be used in dynamic retrieval. If not set, a system default value is used.",
"title":"Dynamicthreshold"
}
},
"title":"DynamicRetrievalConfig",
"type":"object"
},
"DynamicRetrievalConfigMode":{
"description":"Config for the dynamic retrieval config mode.",
"enum":[
"MODE_UNSPECIFIED",
"MODE_DYNAMIC"
],
"title":"DynamicRetrievalConfigMode",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `dynamic_retrieval_config (genai.types.DynamicRetrievalConfig | None)`



_field_ dynamic_retrieval_config _:`Optional`[`DynamicRetrievalConfig`]__= None_ _(alias 'dynamicRetrievalConfig')_¶ 
    
Specifies the dynamic retrieval configuration for the given source. 

_class_ genai.types.GoogleSearchRetrievalDict¶ 
    
Bases: `TypedDict`
Tool to retrieve public web data for grounding, powered by Google. 

dynamic_retrieval_config _:`Optional`[`DynamicRetrievalConfigDict`]_¶ 
    
Specifies the dynamic retrieval configuration for the given source. 

_pydantic model_genai.types.GoogleTypeDate¶ 
    
Bases: `BaseModel`
Represents a whole or partial calendar date, such as a birthday.
The time of day and time zone are either specified elsewhere or are insignificant. The date is relative to the Gregorian Calendar. This can represent one of the following: * A full date, with non-zero year, month, and day values. * A month and day, with a zero year (for example, an anniversary). * A year on its own, with a zero month and a zero day. * A year and month, with a zero day (for example, a credit card expiration date). Related types: * google.type.TimeOfDay * google.type.DateTime * google.protobuf.Timestamp
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GoogleTypeDate",
"description":"Represents a whole or partial calendar date, such as a birthday.\n\nThe time of day and time zone are either specified elsewhere or are\ninsignificant. The date is relative to the Gregorian Calendar. This can\nrepresent one of the following: * A full date, with non-zero year, month, and\nday values. * A month and day, with a zero year (for example, an anniversary).\n* A year on its own, with a zero month and a zero day. * A year and month,\nwith a zero day (for example, a credit card expiration date). Related types: *\ngoogle.type.TimeOfDay * google.type.DateTime * google.protobuf.Timestamp",
"type":"object",
"properties":{
"day":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.",
"title":"Day"
},
"month":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.",
"title":"Month"
},
"year":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year.",
"title":"Year"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `day (int | None)`
  * `month (int | None)`
  * `year (int | None)`



_field_ day _:`Optional`[`int`]__= None_¶ 
    
Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn’t significant. 

_field_ month _:`Optional`[`int`]__= None_¶ 
    
Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day. 

_field_ year _:`Optional`[`int`]__= None_¶ 
    
Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year. 

_class_ genai.types.GoogleTypeDateDict¶ 
    
Bases: `TypedDict`
Represents a whole or partial calendar date, such as a birthday.
The time of day and time zone are either specified elsewhere or are insignificant. The date is relative to the Gregorian Calendar. This can represent one of the following: * A full date, with non-zero year, month, and day values. * A month and day, with a zero year (for example, an anniversary). * A year on its own, with a zero month and a zero day. * A year and month, with a zero day (for example, a credit card expiration date). Related types: * google.type.TimeOfDay * google.type.DateTime * google.protobuf.Timestamp 

day _:`Optional`[`int`]_¶ 
    
Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn’t significant. 

month _:`Optional`[`int`]_¶ 
    
Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day. 

year _:`Optional`[`int`]_¶ 
    
Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year. 

_pydantic model_genai.types.GroundingChunk¶ 
    
Bases: `BaseModel`
Grounding chunk.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GroundingChunk",
"description":"Grounding chunk.",
"type":"object",
"properties":{
"retrievedContext":{
"anyOf":[
{
"$ref":"#/$defs/GroundingChunkRetrievedContext"
},
{
"type":"null"
}
],
"default":null,
"description":"Grounding chunk from context retrieved by the retrieval tools."
},
"web":{
"anyOf":[
{
"$ref":"#/$defs/GroundingChunkWeb"
},
{
"type":"null"
}
],
"default":null,
"description":"Grounding chunk from the web."
}
},
"$defs":{
"GroundingChunkRetrievedContext":{
"additionalProperties":false,
"description":"Chunk from context retrieved by the retrieval tools.",
"properties":{
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Text of the attribution.",
"title":"Text"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Title of the attribution.",
"title":"Title"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"URI reference of the attribution.",
"title":"Uri"
}
},
"title":"GroundingChunkRetrievedContext",
"type":"object"
},
"GroundingChunkWeb":{
"additionalProperties":false,
"description":"Chunk from the web.",
"properties":{
"domain":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Domain of the (original) URI.",
"title":"Domain"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Title of the chunk.",
"title":"Title"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"URI reference of the chunk.",
"title":"Uri"
}
},
"title":"GroundingChunkWeb",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `retrieved_context (genai.types.GroundingChunkRetrievedContext | None)`
  * `web (genai.types.GroundingChunkWeb | None)`



_field_ retrieved_context _:`Optional`[`GroundingChunkRetrievedContext`]__= None_ _(alias 'retrievedContext')_¶ 
    
Grounding chunk from context retrieved by the retrieval tools. 

_field_ web _:`Optional`[`GroundingChunkWeb`]__= None_¶ 
    
Grounding chunk from the web. 

_class_ genai.types.GroundingChunkDict¶ 
    
Bases: `TypedDict`
Grounding chunk. 

retrieved_context _:`Optional`[`GroundingChunkRetrievedContextDict`]_¶ 
    
Grounding chunk from context retrieved by the retrieval tools. 

web _:`Optional`[`GroundingChunkWebDict`]_¶ 
    
Grounding chunk from the web. 

_pydantic model_genai.types.GroundingChunkRetrievedContext¶ 
    
Bases: `BaseModel`
Chunk from context retrieved by the retrieval tools.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GroundingChunkRetrievedContext",
"description":"Chunk from context retrieved by the retrieval tools.",
"type":"object",
"properties":{
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Text of the attribution.",
"title":"Text"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Title of the attribution.",
"title":"Title"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"URI reference of the attribution.",
"title":"Uri"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `text (str | None)`
  * `title (str | None)`
  * `uri (str | None)`



_field_ text _:`Optional`[`str`]__= None_¶ 
    
Text of the attribution. 

_field_ title _:`Optional`[`str`]__= None_¶ 
    
Title of the attribution. 

_field_ uri _:`Optional`[`str`]__= None_¶ 
    
URI reference of the attribution. 

_class_ genai.types.GroundingChunkRetrievedContextDict¶ 
    
Bases: `TypedDict`
Chunk from context retrieved by the retrieval tools. 

text _:`Optional`[`str`]_¶ 
    
Text of the attribution. 

title _:`Optional`[`str`]_¶ 
    
Title of the attribution. 

uri _:`Optional`[`str`]_¶ 
    
URI reference of the attribution. 

_pydantic model_genai.types.GroundingChunkWeb¶ 
    
Bases: `BaseModel`
Chunk from the web.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GroundingChunkWeb",
"description":"Chunk from the web.",
"type":"object",
"properties":{
"domain":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Domain of the (original) URI.",
"title":"Domain"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Title of the chunk.",
"title":"Title"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"URI reference of the chunk.",
"title":"Uri"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `domain (str | None)`
  * `title (str | None)`
  * `uri (str | None)`



_field_ domain _:`Optional`[`str`]__= None_¶ 
    
Domain of the (original) URI. 

_field_ title _:`Optional`[`str`]__= None_¶ 
    
Title of the chunk. 

_field_ uri _:`Optional`[`str`]__= None_¶ 
    
URI reference of the chunk. 

_class_ genai.types.GroundingChunkWebDict¶ 
    
Bases: `TypedDict`
Chunk from the web. 

domain _:`Optional`[`str`]_¶ 
    
Domain of the (original) URI. 

title _:`Optional`[`str`]_¶ 
    
Title of the chunk. 

uri _:`Optional`[`str`]_¶ 
    
URI reference of the chunk. 

_pydantic model_genai.types.GroundingMetadata¶ 
    
Bases: `BaseModel`
Metadata returned to client when grounding is enabled.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GroundingMetadata",
"description":"Metadata returned to client when grounding is enabled.",
"type":"object",
"properties":{
"groundingChunks":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/GroundingChunk"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of supporting references retrieved from specified grounding source.",
"title":"Groundingchunks"
},
"groundingSupports":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/GroundingSupport"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. List of grounding support.",
"title":"Groundingsupports"
},
"retrievalMetadata":{
"anyOf":[
{
"$ref":"#/$defs/RetrievalMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Output only. Retrieval metadata."
},
"retrievalQueries":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Queries executed by the retrieval tools.",
"title":"Retrievalqueries"
},
"searchEntryPoint":{
"anyOf":[
{
"$ref":"#/$defs/SearchEntryPoint"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google search entry for the following-up web searches."
},
"webSearchQueries":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Web search queries for the following-up web search.",
"title":"Websearchqueries"
}
},
"$defs":{
"GroundingChunk":{
"additionalProperties":false,
"description":"Grounding chunk.",
"properties":{
"retrievedContext":{
"anyOf":[
{
"$ref":"#/$defs/GroundingChunkRetrievedContext"
},
{
"type":"null"
}
],
"default":null,
"description":"Grounding chunk from context retrieved by the retrieval tools."
},
"web":{
"anyOf":[
{
"$ref":"#/$defs/GroundingChunkWeb"
},
{
"type":"null"
}
],
"default":null,
"description":"Grounding chunk from the web."
}
},
"title":"GroundingChunk",
"type":"object"
},
"GroundingChunkRetrievedContext":{
"additionalProperties":false,
"description":"Chunk from context retrieved by the retrieval tools.",
"properties":{
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Text of the attribution.",
"title":"Text"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Title of the attribution.",
"title":"Title"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"URI reference of the attribution.",
"title":"Uri"
}
},
"title":"GroundingChunkRetrievedContext",
"type":"object"
},
"GroundingChunkWeb":{
"additionalProperties":false,
"description":"Chunk from the web.",
"properties":{
"domain":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Domain of the (original) URI.",
"title":"Domain"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Title of the chunk.",
"title":"Title"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"URI reference of the chunk.",
"title":"Uri"
}
},
"title":"GroundingChunkWeb",
"type":"object"
},
"GroundingSupport":{
"additionalProperties":false,
"description":"Grounding support.",
"properties":{
"confidenceScores":{
"anyOf":[
{
"items":{
"type":"number"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Confidence score of the support references. Ranges from 0 to 1. 1 is the most confident. This list must have the same size as the grounding_chunk_indices.",
"title":"Confidencescores"
},
"groundingChunkIndices":{
"anyOf":[
{
"items":{
"type":"integer"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of indices (into 'grounding_chunk') specifying the citations associated with the claim. For instance [1,3,4] means that grounding_chunk[1], grounding_chunk[3], grounding_chunk[4] are the retrieved content attributed to the claim.",
"title":"Groundingchunkindices"
},
"segment":{
"anyOf":[
{
"$ref":"#/$defs/Segment"
},
{
"type":"null"
}
],
"default":null,
"description":"Segment of the content this support belongs to."
}
},
"title":"GroundingSupport",
"type":"object"
},
"RetrievalMetadata":{
"additionalProperties":false,
"description":"Metadata related to retrieval in the grounding flow.",
"properties":{
"googleSearchDynamicRetrievalScore":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Score indicating how likely information from Google Search could help answer the prompt. The score is in the range `[0, 1]`, where 0 is the least likely and 1 is the most likely. This score is only populated when Google Search grounding and dynamic retrieval is enabled. It will be compared to the threshold to determine whether to trigger Google Search.",
"title":"Googlesearchdynamicretrievalscore"
}
},
"title":"RetrievalMetadata",
"type":"object"
},
"SearchEntryPoint":{
"additionalProperties":false,
"description":"Google search entry point.",
"properties":{
"renderedContent":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Web content snippet that can be embedded in a web page or an app webview.",
"title":"Renderedcontent"
},
"sdkBlob":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Base64 encoded JSON representing array of tuple.",
"title":"Sdkblob"
}
},
"title":"SearchEntryPoint",
"type":"object"
},
"Segment":{
"additionalProperties":false,
"description":"Segment of the content.",
"properties":{
"endIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. End index in the given Part, measured in bytes. Offset from the start of the Part, exclusive, starting at zero.",
"title":"Endindex"
},
"partIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The index of a Part object within its parent Content object.",
"title":"Partindex"
},
"startIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Start index in the given Part, measured in bytes. Offset from the start of the Part, inclusive, starting at zero.",
"title":"Startindex"
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The text corresponding to the segment from the response.",
"title":"Text"
}
},
"title":"Segment",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `grounding_chunks (list[genai.types.GroundingChunk] | None)`
  * `grounding_supports (list[genai.types.GroundingSupport] | None)`
  * `retrieval_metadata (genai.types.RetrievalMetadata | None)`
  * `retrieval_queries (list[str] | None)`
  * `search_entry_point (genai.types.SearchEntryPoint | None)`
  * `web_search_queries (list[str] | None)`



_field_ grounding_chunks _:`Optional`[`list`[`GroundingChunk`]]__= None_ _(alias 'groundingChunks')_¶ 
    
List of supporting references retrieved from specified grounding source. 

_field_ grounding_supports _:`Optional`[`list`[`GroundingSupport`]]__= None_ _(alias 'groundingSupports')_¶ 
    
Optional. List of grounding support. 

_field_ retrieval_metadata _:`Optional`[`RetrievalMetadata`]__= None_ _(alias 'retrievalMetadata')_¶ 
    
Optional. Output only. Retrieval metadata. 

_field_ retrieval_queries _:`Optional`[`list`[`str`]]__= None_ _(alias 'retrievalQueries')_¶ 
    
Optional. Queries executed by the retrieval tools. 

_field_ search_entry_point _:`Optional`[`SearchEntryPoint`]__= None_ _(alias 'searchEntryPoint')_¶ 
    
Optional. Google search entry for the following-up web searches. 

_field_ web_search_queries _:`Optional`[`list`[`str`]]__= None_ _(alias 'webSearchQueries')_¶ 
    
Optional. Web search queries for the following-up web search. 

_class_ genai.types.GroundingMetadataDict¶ 
    
Bases: `TypedDict`
Metadata returned to client when grounding is enabled. 

grounding_chunks _:`Optional`[`list`[`GroundingChunkDict`]]_¶ 
    
List of supporting references retrieved from specified grounding source. 

grounding_supports _:`Optional`[`list`[`GroundingSupportDict`]]_¶ 
    
Optional. List of grounding support. 

retrieval_metadata _:`Optional`[`RetrievalMetadataDict`]_¶ 
    
Optional. Output only. Retrieval metadata. 

retrieval_queries _:`Optional`[`list`[`str`]]_¶ 
    
Optional. Queries executed by the retrieval tools. 

search_entry_point _:`Optional`[`SearchEntryPointDict`]_¶ 
    
Optional. Google search entry for the following-up web searches. 

web_search_queries _:`Optional`[`list`[`str`]]_¶ 
    
Optional. Web search queries for the following-up web search. 

_pydantic model_genai.types.GroundingSupport¶ 
    
Bases: `BaseModel`
Grounding support.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"GroundingSupport",
"description":"Grounding support.",
"type":"object",
"properties":{
"confidenceScores":{
"anyOf":[
{
"items":{
"type":"number"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Confidence score of the support references. Ranges from 0 to 1. 1 is the most confident. This list must have the same size as the grounding_chunk_indices.",
"title":"Confidencescores"
},
"groundingChunkIndices":{
"anyOf":[
{
"items":{
"type":"integer"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of indices (into 'grounding_chunk') specifying the citations associated with the claim. For instance [1,3,4] means that grounding_chunk[1], grounding_chunk[3], grounding_chunk[4] are the retrieved content attributed to the claim.",
"title":"Groundingchunkindices"
},
"segment":{
"anyOf":[
{
"$ref":"#/$defs/Segment"
},
{
"type":"null"
}
],
"default":null,
"description":"Segment of the content this support belongs to."
}
},
"$defs":{
"Segment":{
"additionalProperties":false,
"description":"Segment of the content.",
"properties":{
"endIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. End index in the given Part, measured in bytes. Offset from the start of the Part, exclusive, starting at zero.",
"title":"Endindex"
},
"partIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The index of a Part object within its parent Content object.",
"title":"Partindex"
},
"startIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Start index in the given Part, measured in bytes. Offset from the start of the Part, inclusive, starting at zero.",
"title":"Startindex"
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The text corresponding to the segment from the response.",
"title":"Text"
}
},
"title":"Segment",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `confidence_scores (list[float] | None)`
  * `grounding_chunk_indices (list[int] | None)`
  * `segment (genai.types.Segment | None)`



_field_ confidence_scores _:`Optional`[`list`[`float`]]__= None_ _(alias 'confidenceScores')_¶ 
    
Confidence score of the support references. Ranges from 0 to 1. 1 is the most confident. This list must have the same size as the grounding_chunk_indices. 

_field_ grounding_chunk_indices _:`Optional`[`list`[`int`]]__= None_ _(alias 'groundingChunkIndices')_¶ 
    
A list of indices (into ‘grounding_chunk’) specifying the citations associated with the claim. For instance [1,3,4] means that grounding_chunk[1], grounding_chunk[3], grounding_chunk[4] are the retrieved content attributed to the claim. 

_field_ segment _:`Optional`[`Segment`]__= None_¶ 
    
Segment of the content this support belongs to. 

_class_ genai.types.GroundingSupportDict¶ 
    
Bases: `TypedDict`
Grounding support. 

confidence_scores _:`Optional`[`list`[`float`]]_¶ 
    
Confidence score of the support references. Ranges from 0 to 1. 1 is the most confident. This list must have the same size as the grounding_chunk_indices. 

grounding_chunk_indices _:`Optional`[`list`[`int`]]_¶ 
    
A list of indices (into ‘grounding_chunk’) specifying the citations associated with the claim. For instance [1,3,4] means that grounding_chunk[1], grounding_chunk[3], grounding_chunk[4] are the retrieved content attributed to the claim. 

segment _:`Optional`[`SegmentDict`]_¶ 
    
Segment of the content this support belongs to. 

_class_ genai.types.HarmBlockMethod(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Optional.
Specify if the threshold is used for probability or severity score. If not specified, the threshold is used for probability score. 

HARM_BLOCK_METHOD_UNSPECIFIED _= 'HARM_BLOCK_METHOD_UNSPECIFIED'_¶ 


PROBABILITY _= 'PROBABILITY'_¶ 


SEVERITY _= 'SEVERITY'_¶ 


_class_ genai.types.HarmBlockThreshold(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Required. The harm block threshold. 

BLOCK_LOW_AND_ABOVE _= 'BLOCK_LOW_AND_ABOVE'_¶ 


BLOCK_MEDIUM_AND_ABOVE _= 'BLOCK_MEDIUM_AND_ABOVE'_¶ 


BLOCK_NONE _= 'BLOCK_NONE'_¶ 


BLOCK_ONLY_HIGH _= 'BLOCK_ONLY_HIGH'_¶ 


HARM_BLOCK_THRESHOLD_UNSPECIFIED _= 'HARM_BLOCK_THRESHOLD_UNSPECIFIED'_¶ 


OFF _= 'OFF'_¶ 


_class_ genai.types.HarmCategory(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Required. Harm category. 

HARM_CATEGORY_CIVIC_INTEGRITY _= 'HARM_CATEGORY_CIVIC_INTEGRITY'_¶ 


HARM_CATEGORY_DANGEROUS_CONTENT _= 'HARM_CATEGORY_DANGEROUS_CONTENT'_¶ 


HARM_CATEGORY_HARASSMENT _= 'HARM_CATEGORY_HARASSMENT'_¶ 


HARM_CATEGORY_HATE_SPEECH _= 'HARM_CATEGORY_HATE_SPEECH'_¶ 


HARM_CATEGORY_SEXUALLY_EXPLICIT _= 'HARM_CATEGORY_SEXUALLY_EXPLICIT'_¶ 


HARM_CATEGORY_UNSPECIFIED _= 'HARM_CATEGORY_UNSPECIFIED'_¶ 


_class_ genai.types.HarmProbability(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Output only. Harm probability levels in the content. 

HARM_PROBABILITY_UNSPECIFIED _= 'HARM_PROBABILITY_UNSPECIFIED'_¶ 


HIGH _= 'HIGH'_¶ 


LOW _= 'LOW'_¶ 


MEDIUM _= 'MEDIUM'_¶ 


NEGLIGIBLE _= 'NEGLIGIBLE'_¶ 


_class_ genai.types.HarmSeverity(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Output only. Harm severity levels in the content. 

HARM_SEVERITY_HIGH _= 'HARM_SEVERITY_HIGH'_¶ 


HARM_SEVERITY_LOW _= 'HARM_SEVERITY_LOW'_¶ 


HARM_SEVERITY_MEDIUM _= 'HARM_SEVERITY_MEDIUM'_¶ 


HARM_SEVERITY_NEGLIGIBLE _= 'HARM_SEVERITY_NEGLIGIBLE'_¶ 


HARM_SEVERITY_UNSPECIFIED _= 'HARM_SEVERITY_UNSPECIFIED'_¶ 


_pydantic model_genai.types.HttpOptions¶ 
    
Bases: `BaseModel`
HTTP options to be used in each of the requests.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"HttpOptions",
"description":"HTTP options to be used in each of the requests.",
"type":"object",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `api_version (str | None)`
  * `async_client_args (dict[str, Any] | None)`
  * `base_url (str | None)`
  * `client_args (dict[str, Any] | None)`
  * `headers (dict[str, str] | None)`
  * `timeout (int | None)`



_field_ api_version _:`Optional`[`str`]__= None_ _(alias 'apiVersion')_¶ 
    
Specifies the version of the API to use. 

_field_ async_client_args _:`Optional`[`dict`[`str`, `Any`]]__= None_ _(alias 'asyncClientArgs')_¶ 
    
Args passed to the async HTTP client. 

_field_ base_url _:`Optional`[`str`]__= None_ _(alias 'baseUrl')_¶ 
    
The base URL for the AI platform service endpoint. 

_field_ client_args _:`Optional`[`dict`[`str`, `Any`]]__= None_ _(alias 'clientArgs')_¶ 
    
Args passed to the HTTP client. 

_field_ headers _:`Optional`[`dict`[`str`, `str`]]__= None_¶ 
    
Additional HTTP headers to be sent with the request. 

_field_ timeout _:`Optional`[`int`]__= None_¶ 
    
Timeout for the request in milliseconds. 

_class_ genai.types.HttpOptionsDict¶ 
    
Bases: `TypedDict`
HTTP options to be used in each of the requests. 

api_version _:`Optional`[`str`]_¶ 
    
Specifies the version of the API to use. 

async_client_args _:`Optional`[`dict`[`str`, `Any`]]_¶ 
    
Args passed to the async HTTP client. 

base_url _:`Optional`[`str`]_¶ 
    
The base URL for the AI platform service endpoint. 

client_args _:`Optional`[`dict`[`str`, `Any`]]_¶ 
    
Args passed to the HTTP client. 

headers _:`Optional`[`dict`[`str`, `str`]]_¶ 
    
Additional HTTP headers to be sent with the request. 

timeout _:`Optional`[`int`]_¶ 
    
Timeout for the request in milliseconds. 

_pydantic model_genai.types.Image¶ 
    
Bases: `BaseModel`
An image.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"Image",
"description":"An image.",
"type":"object",
"properties":{
"gcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The Cloud Storage URI of the image. ``Image`` can contain a value\n      for this field or the ``image_bytes`` field but not both.\n      ",
"title":"Gcsuri"
},
"imageBytes":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The image bytes data. ``Image`` can contain a value for this field\n      or the ``gcs_uri`` field but not both.\n      ",
"title":"Imagebytes"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The MIME type of the image.",
"title":"Mimetype"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `gcs_uri (str | None)`
  * `image_bytes (bytes | None)`
  * `mime_type (str | None)`



_field_ gcs_uri _:`Optional`[`str`]__= None_ _(alias 'gcsUri')_¶ 
    
The Cloud Storage URI of the image. `Image` can contain a value for this field or the `image_bytes` field but not both. 

_field_ image_bytes _:`Optional`[`bytes`]__= None_ _(alias 'imageBytes')_¶ 
    
The image bytes data. `Image` can contain a value for this field or the `gcs_uri` field but not both. 

_field_ mime_type _:`Optional`[`str`]__= None_ _(alias 'mimeType')_¶ 
    
The MIME type of the image. 

_classmethod_ from_file(_*_ , _location_ , _mime_type =None_)¶ 
    
Lazy-loads an image from a local file or Google Cloud Storage. 

Return type: 
    
`Image` 

Parameters: 
    
  * **location** – The local path or Google Cloud Storage URI from which to load the image.
  * **mime_type** – The MIME type of the image. If not provided, the MIME type will be automatically determined.



Returns: 
    
A loaded image as an Image object. 

model_post_init(_context_ , _/_)¶ 
    
This function is meant to behave like a BaseModel method to initialise private attributes.
It takes context as an argument since that’s what pydantic-core passes when calling it. 

Return type: 
    
`None` 

Parameters: 
    
  * **self** – The BaseModel instance.
  * **context** – The context.



save(_location_)¶ 
    
Saves the image to a file. 

Return type: 
    
`None` 

Parameters: 
    
**location** – Local path where to save the image. 

show()¶ 
    
Shows the image.
This method only works in a notebook environment. 

Return type: 
    
`None` 

_class_ genai.types.ImageDict¶ 
    
Bases: `TypedDict`
An image. 

gcs_uri _:`Optional`[`str`]_¶ 
    
The Cloud Storage URI of the image. `Image` can contain a value for this field or the `image_bytes` field but not both. 

image_bytes _:`Optional`[`bytes`]_¶ 
    
The image bytes data. `Image` can contain a value for this field or the `gcs_uri` field but not both. 

mime_type _:`Optional`[`str`]_¶ 
    
The MIME type of the image. 

_class_ genai.types.ImagePromptLanguage(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Enum that specifies the language of the text in the prompt. 

auto _= 'auto'_¶ 


en _= 'en'_¶ 


hi _= 'hi'_¶ 


ja _= 'ja'_¶ 


ko _= 'ko'_¶ 


_pydantic model_genai.types.JSONSchema¶ 
    
Bases: `BaseModel`
A subset of JSON Schema according to 2020-12 JSON Schema draft.
Represents a subset of a JSON Schema object that is used by the Gemini model. The difference between this class and the Schema class is that this class is compatible with OpenAPI 3.1 schema objects. And the Schema class is used to make API call to Gemini model.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"$defs":{
"JSONSchema":{
"description":"A subset of JSON Schema according to 2020-12 JSON Schema draft.\n\nRepresents a subset of a JSON Schema object that is used by the Gemini model.\nThe difference between this class and the Schema class is that this class is\ncompatible with OpenAPI 3.1 schema objects. And the Schema class is used to\nmake API call to Gemini model.",
"properties":{
"type":{
"anyOf":[
{
"$ref":"#/$defs/JSONSchemaType"
},
{
"items":{
"$ref":"#/$defs/JSONSchemaType"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Validation succeeds if the type of the instance matches the type represented by the given type, or matches at least one of the given types.",
"title":"Type"
},
"format":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Define semantic information about a string instance.",
"title":"Format"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A preferably short description about the purpose of the instance described by the schema.",
"title":"Title"
},
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"An explanation about the purpose of the instance described by the schema.",
"title":"Description"
},
"default":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"This keyword can be used to supply a default JSON value associated with a particular schema.",
"title":"Default"
},
"items":{
"anyOf":[
{
"$ref":"#/$defs/JSONSchema"
},
{
"type":"null"
}
],
"default":null,
"description":"Validation succeeds if each element of the instance not covered by prefixItems validates against this schema."
},
"min_items":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"An array instance is valid if its size is greater than, or equal to, the value of this keyword.",
"title":"Min Items"
},
"max_items":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"An array instance is valid if its size is less than, or equal to, the value of this keyword.",
"title":"Max Items"
},
"enum":{
"anyOf":[
{
"items":{},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Validation succeeds if the instance is equal to one of the elements in this keyword\u2019s array value.",
"title":"Enum"
},
"properties":{
"anyOf":[
{
"additionalProperties":{
"$ref":"#/$defs/JSONSchema"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Validation succeeds if, for each name that appears in both the instance and as a name within this keyword\u2019s value, the child instance for that name successfully validates against the corresponding schema.",
"title":"Properties"
},
"required":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"An object instance is valid against this keyword if every item in the array is the name of a property in the instance.",
"title":"Required"
},
"min_properties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"An object instance is valid if its number of properties is greater than, or equal to, the value of this keyword.",
"title":"Min Properties"
},
"max_properties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"An object instance is valid if its number of properties is less than, or equal to, the value of this keyword.",
"title":"Max Properties"
},
"minimum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Validation succeeds if the numeric instance is greater than or equal to the given number.",
"title":"Minimum"
},
"maximum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Validation succeeds if the numeric instance is less than or equal to the given number.",
"title":"Maximum"
},
"min_length":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"A string instance is valid against this keyword if its length is greater than, or equal to, the value of this keyword.",
"title":"Min Length"
},
"max_length":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"A string instance is valid against this keyword if its length is less than, or equal to, the value of this keyword.",
"title":"Max Length"
},
"pattern":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A string instance is considered valid if the regular expression matches the instance successfully.",
"title":"Pattern"
},
"any_of":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/JSONSchema"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"An instance validates successfully against this keyword if it validates successfully against at least one schema defined by this keyword\u2019s value.",
"title":"Any Of"
}
},
"title":"JSONSchema",
"type":"object"
},
"JSONSchemaType":{
"description":"The type of the data supported by JSON Schema.\n\nThe values of the enums are lower case strings, while the values of the enums\nfor the Type class are upper case strings.",
"enum":[
"null",
"boolean",
"object",
"array",
"number",
"integer",
"string"
],
"title":"JSONSchemaType",
"type":"string"
}
},
"$ref":"#/$defs/JSONSchema"
}

```


Fields: 
    
  * `any_of (list[genai.types.JSONSchema] | None)`
  * `default (Any | None)`
  * `description (str | None)`
  * `enum (list[Any] | None)`
  * `format (str | None)`
  * `items (genai.types.JSONSchema | None)`
  * `max_items (int | None)`
  * `max_length (int | None)`
  * `max_properties (int | None)`
  * `maximum (float | None)`
  * `min_items (int | None)`
  * `min_length (int | None)`
  * `min_properties (int | None)`
  * `minimum (float | None)`
  * `pattern (str | None)`
  * `properties (dict[str, genai.types.JSONSchema] | None)`
  * `required (list[str] | None)`
  * `title (str | None)`
  * `type (genai.types.JSONSchemaType | list[genai.types.JSONSchemaType] | None)`



_field_ any_of _:`Optional`[`list`[JSONSchema]]__= None_¶ 
    
An instance validates successfully against this keyword if it validates successfully against at least one schema defined by this keyword’s value. 

_field_ default _:`Optional`[`Any`]__= None_¶ 
    
This keyword can be used to supply a default JSON value associated with a particular schema. 

_field_ description _:`Optional`[`str`]__= None_¶ 
    
An explanation about the purpose of the instance described by the schema. 

_field_ enum _:`Optional`[`list`[`Any`]]__= None_¶ 
    
Validation succeeds if the instance is equal to one of the elements in this keyword’s array value. 

_field_ format _:`Optional`[`str`]__= None_¶ 
    
Define semantic information about a string instance. 

_field_ items _:`Optional`[JSONSchema]__= None_¶ 
    
Validation succeeds if each element of the instance not covered by prefixItems validates against this schema. 

_field_ max_items _:`Optional`[`int`]__= None_¶ 
    
An array instance is valid if its size is less than, or equal to, the value of this keyword. 

_field_ max_length _:`Optional`[`int`]__= None_¶ 
    
A string instance is valid against this keyword if its length is less than, or equal to, the value of this keyword. 

_field_ max_properties _:`Optional`[`int`]__= None_¶ 
    
An object instance is valid if its number of properties is less than, or equal to, the value of this keyword. 

_field_ maximum _:`Optional`[`float`]__= None_¶ 
    
Validation succeeds if the numeric instance is less than or equal to the given number. 

_field_ min_items _:`Optional`[`int`]__= None_¶ 
    
An array instance is valid if its size is greater than, or equal to, the value of this keyword. 

_field_ min_length _:`Optional`[`int`]__= None_¶ 
    
A string instance is valid against this keyword if its length is greater than, or equal to, the value of this keyword. 

_field_ min_properties _:`Optional`[`int`]__= None_¶ 
    
An object instance is valid if its number of properties is greater than, or equal to, the value of this keyword. 

_field_ minimum _:`Optional`[`float`]__= None_¶ 
    
Validation succeeds if the numeric instance is greater than or equal to the given number. 

_field_ pattern _:`Optional`[`str`]__= None_¶ 
    
A string instance is considered valid if the regular expression matches the instance successfully. 

_field_ properties _:`Optional`[`dict`[`str`, JSONSchema]]__= None_¶ 
    
Validation succeeds if, for each name that appears in both the instance and as a name within this keyword’s value, the child instance for that name successfully validates against the corresponding schema. 

_field_ required _:`Optional`[`list`[`str`]]__= None_¶ 
    
An object instance is valid against this keyword if every item in the array is the name of a property in the instance. 

_field_ title _:`Optional`[`str`]__= None_¶ 
    
A preferably short description about the purpose of the instance described by the schema. 

_field_ type _:`Union`[`JSONSchemaType`, `list`[`JSONSchemaType`], `None`]__= None_¶ 
    
Validation succeeds if the type of the instance matches the type represented by the given type, or matches at least one of the given types. 

_class_ genai.types.JSONSchemaType(_* values_)¶ 
    
Bases: `Enum`
The type of the data supported by JSON Schema.
The values of the enums are lower case strings, while the values of the enums for the Type class are upper case strings. 

ARRAY _= 'array'_¶ 


BOOLEAN _= 'boolean'_¶ 


INTEGER _= 'integer'_¶ 


NULL _= 'null'_¶ 


NUMBER _= 'number'_¶ 


OBJECT _= 'object'_¶ 


STRING _= 'string'_¶ 


_pydantic model_genai.types.JobError¶ 
    
Bases: `BaseModel`
Job error.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"JobError",
"description":"Job error.",
"type":"object",
"properties":{
"details":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Details"
},
"code":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The status code.",
"title":"Code"
},
"message":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the `details` field.",
"title":"Message"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `code (int | None)`
  * `details (list[str] | None)`
  * `message (str | None)`



_field_ code _:`Optional`[`int`]__= None_¶ 
    
The status code. 

_field_ details _:`Optional`[`list`[`str`]]__= None_¶ 
    
A list of messages that carry the error details. There is a common set of message types for APIs to use. 

_field_ message _:`Optional`[`str`]__= None_¶ 
    
A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the details field. 

_class_ genai.types.JobErrorDict¶ 
    
Bases: `TypedDict`
Job error. 

code _:`Optional`[`int`]_¶ 
    
The status code. 

details _:`Optional`[`list`[`str`]]_¶ 
    
A list of messages that carry the error details. There is a common set of message types for APIs to use. 

message _:`Optional`[`str`]_¶ 
    
A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the details field. 

_class_ genai.types.JobState(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Job state. 

JOB_STATE_CANCELLED _= 'JOB_STATE_CANCELLED'_¶ 


JOB_STATE_CANCELLING _= 'JOB_STATE_CANCELLING'_¶ 


JOB_STATE_EXPIRED _= 'JOB_STATE_EXPIRED'_¶ 


JOB_STATE_FAILED _= 'JOB_STATE_FAILED'_¶ 


JOB_STATE_PARTIALLY_SUCCEEDED _= 'JOB_STATE_PARTIALLY_SUCCEEDED'_¶ 


JOB_STATE_PAUSED _= 'JOB_STATE_PAUSED'_¶ 


JOB_STATE_PENDING _= 'JOB_STATE_PENDING'_¶ 


JOB_STATE_QUEUED _= 'JOB_STATE_QUEUED'_¶ 


JOB_STATE_RUNNING _= 'JOB_STATE_RUNNING'_¶ 


JOB_STATE_SUCCEEDED _= 'JOB_STATE_SUCCEEDED'_¶ 


JOB_STATE_UNSPECIFIED _= 'JOB_STATE_UNSPECIFIED'_¶ 


JOB_STATE_UPDATING _= 'JOB_STATE_UPDATING'_¶ 


_class_ genai.types.Language(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Required. Programming language of the code. 

LANGUAGE_UNSPECIFIED _= 'LANGUAGE_UNSPECIFIED'_¶ 


PYTHON _= 'PYTHON'_¶ 


_pydantic model_genai.types.LatLng¶ 
    
Bases: `BaseModel`
An object that represents a latitude/longitude pair.
This is expressed as a pair of doubles to represent degrees latitude and degrees longitude. Unless specified otherwise, this object must conform to the <a href=”https://en.wikipedia.org/wiki/World_Geodetic_System#1984_version”> WGS84 standard</a>. Values must be within normalized ranges.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"LatLng",
"description":"An object that represents a latitude/longitude pair.\n\nThis is expressed as a pair of doubles to represent degrees latitude and\ndegrees longitude. Unless specified otherwise, this object must conform to the\n<a href=\"https://en.wikipedia.org/wiki/World_Geodetic_System#1984_version\">\nWGS84 standard</a>. Values must be within normalized ranges.",
"type":"object",
"properties":{
"latitude":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"The latitude in degrees. It must be in the range [-90.0, +90.0].",
"title":"Latitude"
},
"longitude":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"The longitude in degrees. It must be in the range [-180.0, +180.0]",
"title":"Longitude"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `latitude (float | None)`
  * `longitude (float | None)`



_field_ latitude _:`Optional`[`float`]__= None_¶ 
    
The latitude in degrees. It must be in the range [-90.0, +90.0]. 

_field_ longitude _:`Optional`[`float`]__= None_¶ 
    
The longitude in degrees. It must be in the range [-180.0, +180.0] 

_class_ genai.types.LatLngDict¶ 
    
Bases: `TypedDict`
An object that represents a latitude/longitude pair.
This is expressed as a pair of doubles to represent degrees latitude and degrees longitude. Unless specified otherwise, this object must conform to the <a href=”https://en.wikipedia.org/wiki/World_Geodetic_System#1984_version”> WGS84 standard</a>. Values must be within normalized ranges. 

latitude _:`Optional`[`float`]_¶ 
    
The latitude in degrees. It must be in the range [-90.0, +90.0]. 

longitude _:`Optional`[`float`]_¶ 
    
The longitude in degrees. It must be in the range [-180.0, +180.0] 

_pydantic model_genai.types.ListBatchJobsConfig¶ 
    
Bases: `BaseModel`
Config for optional parameters.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ListBatchJobsConfig",
"description":"Config for optional parameters.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
},
"pageSize":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Pagesize"
},
"pageToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Pagetoken"
},
"filter":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Filter"
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `filter (str | None)`
  * `http_options (genai.types.HttpOptions | None)`
  * `page_size (int | None)`
  * `page_token (str | None)`



_field_ filter _:`Optional`[`str`]__= None_¶ 


_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_field_ page_size _:`Optional`[`int`]__= None_ _(alias 'pageSize')_¶ 


_field_ page_token _:`Optional`[`str`]__= None_ _(alias 'pageToken')_¶ 


_class_ genai.types.ListBatchJobsConfigDict¶ 
    
Bases: `TypedDict`
Config for optional parameters. 

filter _:`Optional`[`str`]_¶ 


http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

page_size _:`Optional`[`int`]_¶ 


page_token _:`Optional`[`str`]_¶ 


_pydantic model_genai.types.ListBatchJobsResponse¶ 
    
Bases: `BaseModel`
Config for batches.list return value.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ListBatchJobsResponse",
"description":"Config for batches.list return value.",
"type":"object",
"properties":{
"nextPageToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Nextpagetoken"
},
"batchJobs":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/BatchJob"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Batchjobs"
}
},
"$defs":{
"BatchJob":{
"additionalProperties":false,
"description":"Config for batches.create return value.",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Resource name of the Job.",
"title":"Name"
},
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The user-defined name of this Job.",
"title":"Displayname"
},
"state":{
"anyOf":[
{
"$ref":"#/$defs/JobState"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The detailed state of the job."
},
"error":{
"anyOf":[
{
"$ref":"#/$defs/JobError"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Only populated when the job's state is JOB_STATE_FAILED or JOB_STATE_CANCELLED."
},
"createTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Time when the Job was created.",
"title":"Createtime"
},
"startTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Time when the Job for the first time entered the `JOB_STATE_RUNNING` state.",
"title":"Starttime"
},
"endTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Time when the Job entered any of the following states: `JOB_STATE_SUCCEEDED`, `JOB_STATE_FAILED`, `JOB_STATE_CANCELLED`.",
"title":"Endtime"
},
"updateTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Time when the Job was most recently updated.",
"title":"Updatetime"
},
"model":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The name of the model that produces the predictions via the BatchJob.\n      ",
"title":"Model"
},
"src":{
"anyOf":[
{
"$ref":"#/$defs/BatchJobSource"
},
{
"type":"null"
}
],
"default":null,
"description":"Configuration for the input data.\n      "
},
"dest":{
"anyOf":[
{
"$ref":"#/$defs/BatchJobDestination"
},
{
"type":"null"
}
],
"default":null,
"description":"Configuration for the output data.\n      "
}
},
"title":"BatchJob",
"type":"object"
},
"BatchJobDestination":{
"additionalProperties":false,
"description":"Config for `des` parameter.",
"properties":{
"format":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Storage format of the output files. Must be one of:\n      'jsonl', 'bigquery'.\n      ",
"title":"Format"
},
"gcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The Google Cloud Storage URI to the output file.\n      ",
"title":"Gcsuri"
},
"bigqueryUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The BigQuery URI to the output table.\n      ",
"title":"Bigqueryuri"
}
},
"title":"BatchJobDestination",
"type":"object"
},
"BatchJobSource":{
"additionalProperties":false,
"description":"Config for `src` parameter.",
"properties":{
"format":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Storage format of the input files. Must be one of:\n      'jsonl', 'bigquery'.\n      ",
"title":"Format"
},
"gcsUri":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The Google Cloud Storage URIs to input files.\n      ",
"title":"Gcsuri"
},
"bigqueryUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The BigQuery URI to input table.\n      ",
"title":"Bigqueryuri"
}
},
"title":"BatchJobSource",
"type":"object"
},
"JobError":{
"additionalProperties":false,
"description":"Job error.",
"properties":{
"details":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Details"
},
"code":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The status code.",
"title":"Code"
},
"message":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the `details` field.",
"title":"Message"
}
},
"title":"JobError",
"type":"object"
},
"JobState":{
"description":"Job state.",
"enum":[
"JOB_STATE_UNSPECIFIED",
"JOB_STATE_QUEUED",
"JOB_STATE_PENDING",
"JOB_STATE_RUNNING",
"JOB_STATE_SUCCEEDED",
"JOB_STATE_FAILED",
"JOB_STATE_CANCELLING",
"JOB_STATE_CANCELLED",
"JOB_STATE_PAUSED",
"JOB_STATE_EXPIRED",
"JOB_STATE_UPDATING",
"JOB_STATE_PARTIALLY_SUCCEEDED"
],
"title":"JobState",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `batch_jobs (list[genai.types.BatchJob] | None)`
  * `next_page_token (str | None)`



_field_ batch_jobs _:`Optional`[`list`[`BatchJob`]]__= None_ _(alias 'batchJobs')_¶ 


_field_ next_page_token _:`Optional`[`str`]__= None_ _(alias 'nextPageToken')_¶ 


_class_ genai.types.ListBatchJobsResponseDict¶ 
    
Bases: `TypedDict`
Config for batches.list return value. 

batch_jobs _:`Optional`[`list`[`BatchJobDict`]]_¶ 


next_page_token _:`Optional`[`str`]_¶ 


_pydantic model_genai.types.ListCachedContentsConfig¶ 
    
Bases: `BaseModel`
Config for caches.list method.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ListCachedContentsConfig",
"description":"Config for caches.list method.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
},
"pageSize":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Pagesize"
},
"pageToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Pagetoken"
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `http_options (genai.types.HttpOptions | None)`
  * `page_size (int | None)`
  * `page_token (str | None)`



_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_field_ page_size _:`Optional`[`int`]__= None_ _(alias 'pageSize')_¶ 


_field_ page_token _:`Optional`[`str`]__= None_ _(alias 'pageToken')_¶ 


_class_ genai.types.ListCachedContentsConfigDict¶ 
    
Bases: `TypedDict`
Config for caches.list method. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

page_size _:`Optional`[`int`]_¶ 


page_token _:`Optional`[`str`]_¶ 


_pydantic model_genai.types.ListCachedContentsResponse¶ 
    
Bases: `BaseModel`
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ListCachedContentsResponse",
"type":"object",
"properties":{
"nextPageToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Nextpagetoken"
},
"cachedContents":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/CachedContent"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of cached contents.\n      ",
"title":"Cachedcontents"
}
},
"$defs":{
"CachedContent":{
"additionalProperties":false,
"description":"A resource used in LLM queries for users to explicitly specify what to cache.",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The server-generated resource name of the cached content.",
"title":"Name"
},
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The user-generated meaningful display name of the cached content.",
"title":"Displayname"
},
"model":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The name of the publisher model to use for cached content.",
"title":"Model"
},
"createTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Creation time of the cache entry.",
"title":"Createtime"
},
"updateTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"When the cache entry was last updated in UTC time.",
"title":"Updatetime"
},
"expireTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Expiration time of the cached content.",
"title":"Expiretime"
},
"usageMetadata":{
"anyOf":[
{
"$ref":"#/$defs/CachedContentUsageMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata on the usage of the cached content."
}
},
"title":"CachedContent",
"type":"object"
},
"CachedContentUsageMetadata":{
"additionalProperties":false,
"description":"Metadata on the usage of the cached content.",
"properties":{
"audioDurationSeconds":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Duration of audio in seconds.",
"title":"Audiodurationseconds"
},
"imageCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of images.",
"title":"Imagecount"
},
"textCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of text characters.",
"title":"Textcount"
},
"totalTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Total number of tokens that the cached content consumes.",
"title":"Totaltokencount"
},
"videoDurationSeconds":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Duration of video in seconds.",
"title":"Videodurationseconds"
}
},
"title":"CachedContentUsageMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `cached_contents (list[genai.types.CachedContent] | None)`
  * `next_page_token (str | None)`



_field_ cached_contents _:`Optional`[`list`[`CachedContent`]]__= None_ _(alias 'cachedContents')_¶ 
    
List of cached contents. 

_field_ next_page_token _:`Optional`[`str`]__= None_ _(alias 'nextPageToken')_¶ 


_class_ genai.types.ListCachedContentsResponseDict¶ 
    
Bases: `TypedDict` 

cached_contents _:`Optional`[`list`[`CachedContentDict`]]_¶ 
    
List of cached contents. 

next_page_token _:`Optional`[`str`]_¶ 


_pydantic model_genai.types.ListFilesConfig¶ 
    
Bases: `BaseModel`
Used to override the default configuration.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ListFilesConfig",
"description":"Used to override the default configuration.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
},
"pageSize":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Pagesize"
},
"pageToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Pagetoken"
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `http_options (genai.types.HttpOptions | None)`
  * `page_size (int | None)`
  * `page_token (str | None)`



_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_field_ page_size _:`Optional`[`int`]__= None_ _(alias 'pageSize')_¶ 


_field_ page_token _:`Optional`[`str`]__= None_ _(alias 'pageToken')_¶ 


_class_ genai.types.ListFilesConfigDict¶ 
    
Bases: `TypedDict`
Used to override the default configuration. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

page_size _:`Optional`[`int`]_¶ 


page_token _:`Optional`[`str`]_¶ 


_pydantic model_genai.types.ListFilesResponse¶ 
    
Bases: `BaseModel`
Response for the list files method.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ListFilesResponse",
"description":"Response for the list files method.",
"type":"object",
"properties":{
"nextPageToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A token to retrieve next page of results.",
"title":"Nextpagetoken"
},
"files":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/File"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The list of files.",
"title":"Files"
}
},
"$defs":{
"File":{
"additionalProperties":false,
"description":"A file uploaded to the API.",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The `File` resource name. The ID (name excluding the \"files/\" prefix) can contain up to 40 characters that are lowercase alphanumeric or dashes (-). The ID cannot start or end with a dash. If the name is empty on create, a unique name will be generated. Example: `files/123-456`",
"title":"Name"
},
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The human-readable display name for the `File`. The display name must be no more than 512 characters in length, including spaces. Example: 'Welcome Image'",
"title":"Displayname"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. MIME type of the file.",
"title":"Mimetype"
},
"sizeBytes":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Size of the file in bytes.",
"title":"Sizebytes"
},
"createTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` was created.",
"title":"Createtime"
},
"expirationTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` will be deleted. Only set if the `File` is scheduled to expire.",
"title":"Expirationtime"
},
"updateTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` was last updated.",
"title":"Updatetime"
},
"sha256Hash":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. SHA-256 hash of the uploaded bytes. The hash value is encoded in base64 format.",
"title":"Sha256Hash"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The URI of the `File`.",
"title":"Uri"
},
"downloadUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The URI of the `File`, only set for downloadable (generated) files.",
"title":"Downloaduri"
},
"state":{
"anyOf":[
{
"$ref":"#/$defs/FileState"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Processing state of the File."
},
"source":{
"anyOf":[
{
"$ref":"#/$defs/FileSource"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The source of the `File`."
},
"videoMetadata":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Metadata for a video.",
"title":"Videometadata"
},
"error":{
"anyOf":[
{
"$ref":"#/$defs/FileStatus"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Error status if File processing failed."
}
},
"title":"File",
"type":"object"
},
"FileSource":{
"description":"Source of the File.",
"enum":[
"SOURCE_UNSPECIFIED",
"UPLOADED",
"GENERATED"
],
"title":"FileSource",
"type":"string"
},
"FileState":{
"description":"State for the lifecycle of a File.",
"enum":[
"STATE_UNSPECIFIED",
"PROCESSING",
"ACTIVE",
"FAILED"
],
"title":"FileState",
"type":"string"
},
"FileStatus":{
"additionalProperties":false,
"description":"Status of a File that uses a common error model.",
"properties":{
"details":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Details"
},
"message":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Message"
},
"code":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The status code. 0 for OK, 1 for CANCELLED",
"title":"Code"
}
},
"title":"FileStatus",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `files (list[genai.types.File] | None)`
  * `next_page_token (str | None)`



_field_ files _:`Optional`[`list`[`File`]]__= None_¶ 
    
The list of files. 

_field_ next_page_token _:`Optional`[`str`]__= None_ _(alias 'nextPageToken')_¶ 
    
A token to retrieve next page of results. 

_class_ genai.types.ListFilesResponseDict¶ 
    
Bases: `TypedDict`
Response for the list files method. 

files _:`Optional`[`list`[`FileDict`]]_¶ 
    
The list of files. 

next_page_token _:`Optional`[`str`]_¶ 
    
A token to retrieve next page of results. 

_pydantic model_genai.types.ListModelsConfig¶ 
    
Bases: `BaseModel`
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ListModelsConfig",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
},
"pageSize":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Pagesize"
},
"pageToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Pagetoken"
},
"filter":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Filter"
},
"queryBase":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Set true to list base models, false to list tuned models.",
"title":"Querybase"
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `filter (str | None)`
  * `http_options (genai.types.HttpOptions | None)`
  * `page_size (int | None)`
  * `page_token (str | None)`
  * `query_base (bool | None)`



_field_ filter _:`Optional`[`str`]__= None_¶ 


_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_field_ page_size _:`Optional`[`int`]__= None_ _(alias 'pageSize')_¶ 


_field_ page_token _:`Optional`[`str`]__= None_ _(alias 'pageToken')_¶ 


_field_ query_base _:`Optional`[`bool`]__= None_ _(alias 'queryBase')_¶ 
    
Set true to list base models, false to list tuned models. 

_class_ genai.types.ListModelsConfigDict¶ 
    
Bases: `TypedDict` 

filter _:`Optional`[`str`]_¶ 


http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

page_size _:`Optional`[`int`]_¶ 


page_token _:`Optional`[`str`]_¶ 


query_base _:`Optional`[`bool`]_¶ 
    
Set true to list base models, false to list tuned models. 

_pydantic model_genai.types.ListModelsResponse¶ 
    
Bases: `BaseModel`
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ListModelsResponse",
"type":"object",
"properties":{
"nextPageToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Nextpagetoken"
},
"models":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Model"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Models"
}
},
"$defs":{
"Checkpoint":{
"additionalProperties":false,
"description":"Describes the machine learning model version checkpoint.",
"properties":{
"checkpointId":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The ID of the checkpoint.\n      ",
"title":"Checkpointid"
},
"epoch":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The epoch of the checkpoint.\n      ",
"title":"Epoch"
},
"step":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The step of the checkpoint.\n      ",
"title":"Step"
}
},
"title":"Checkpoint",
"type":"object"
},
"Endpoint":{
"additionalProperties":false,
"description":"An endpoint where you deploy models.",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Resource name of the endpoint.",
"title":"Name"
},
"deployedModelId":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"ID of the model that's deployed to the endpoint.",
"title":"Deployedmodelid"
}
},
"title":"Endpoint",
"type":"object"
},
"Model":{
"additionalProperties":false,
"description":"A trained machine learning model.",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Resource name of the model.",
"title":"Name"
},
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Display name of the model.",
"title":"Displayname"
},
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Description of the model.",
"title":"Description"
},
"version":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Version ID of the model. A new version is committed when a new\n      model version is uploaded or trained under an existing model ID. The\n      version ID is an auto-incrementing decimal number in string\n      representation.",
"title":"Version"
},
"endpoints":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Endpoint"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of deployed models created from this base model. Note that a\n      model could have been deployed to endpoints in different locations.",
"title":"Endpoints"
},
"labels":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Labels with user-defined metadata to organize your models.",
"title":"Labels"
},
"tunedModelInfo":{
"anyOf":[
{
"$ref":"#/$defs/TunedModelInfo"
},
{
"type":"null"
}
],
"default":null,
"description":"Information about the tuned model from the base model."
},
"inputTokenLimit":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The maximum number of input tokens that the model can handle.",
"title":"Inputtokenlimit"
},
"outputTokenLimit":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The maximum number of output tokens that the model can generate.",
"title":"Outputtokenlimit"
},
"supportedActions":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of actions that are supported by the model.",
"title":"Supportedactions"
},
"defaultCheckpointId":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The default checkpoint id of a model version.\n      ",
"title":"Defaultcheckpointid"
},
"checkpoints":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Checkpoint"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The checkpoints of the model.",
"title":"Checkpoints"
}
},
"title":"Model",
"type":"object"
},
"TunedModelInfo":{
"additionalProperties":false,
"description":"A tuned machine learning model.",
"properties":{
"baseModel":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"ID of the base model that you want to tune.",
"title":"Basemodel"
},
"createTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Date and time when the base model was created.",
"title":"Createtime"
},
"updateTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Date and time when the base model was last updated.",
"title":"Updatetime"
}
},
"title":"TunedModelInfo",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `models (list[genai.types.Model] | None)`
  * `next_page_token (str | None)`



_field_ models _:`Optional`[`list`[`Model`]]__= None_¶ 


_field_ next_page_token _:`Optional`[`str`]__= None_ _(alias 'nextPageToken')_¶ 


_class_ genai.types.ListModelsResponseDict¶ 
    
Bases: `TypedDict` 

models _:`Optional`[`list`[`ModelDict`]]_¶ 


next_page_token _:`Optional`[`str`]_¶ 


_pydantic model_genai.types.ListTuningJobsConfig¶ 
    
Bases: `BaseModel`
Configuration for the list tuning jobs method.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ListTuningJobsConfig",
"description":"Configuration for the list tuning jobs method.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
},
"pageSize":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Pagesize"
},
"pageToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Pagetoken"
},
"filter":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Filter"
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `filter (str | None)`
  * `http_options (genai.types.HttpOptions | None)`
  * `page_size (int | None)`
  * `page_token (str | None)`



_field_ filter _:`Optional`[`str`]__= None_¶ 


_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_field_ page_size _:`Optional`[`int`]__= None_ _(alias 'pageSize')_¶ 


_field_ page_token _:`Optional`[`str`]__= None_ _(alias 'pageToken')_¶ 


_class_ genai.types.ListTuningJobsConfigDict¶ 
    
Bases: `TypedDict`
Configuration for the list tuning jobs method. 

filter _:`Optional`[`str`]_¶ 


http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

page_size _:`Optional`[`int`]_¶ 


page_token _:`Optional`[`str`]_¶ 


_pydantic model_genai.types.ListTuningJobsResponse¶ 
    
Bases: `BaseModel`
Response for the list tuning jobs method.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ListTuningJobsResponse",
"description":"Response for the list tuning jobs method.",
"type":"object",
"properties":{
"nextPageToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A token to retrieve the next page of results. Pass to ListTuningJobsRequest.page_token to obtain that page.",
"title":"Nextpagetoken"
},
"tuningJobs":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/TuningJob"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of TuningJobs in the requested page.",
"title":"Tuningjobs"
}
},
"$defs":{
"AdapterSize":{
"description":"Optional. Adapter size for tuning.",
"enum":[
"ADAPTER_SIZE_UNSPECIFIED",
"ADAPTER_SIZE_ONE",
"ADAPTER_SIZE_TWO",
"ADAPTER_SIZE_FOUR",
"ADAPTER_SIZE_EIGHT",
"ADAPTER_SIZE_SIXTEEN",
"ADAPTER_SIZE_THIRTY_TWO"
],
"title":"AdapterSize",
"type":"string"
},
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"Content":{
"additionalProperties":false,
"description":"Contains the multi-part content of a message.",
"properties":{
"parts":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Part"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of parts that constitute a single message. Each part may have\n      a different IANA MIME type.",
"title":"Parts"
},
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role.",
"title":"Role"
}
},
"title":"Content",
"type":"object"
},
"DatasetDistribution":{
"additionalProperties":false,
"description":"Distribution computed over a tuning dataset.",
"properties":{
"buckets":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/DatasetDistributionDistributionBucket"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Defines the histogram bucket.",
"title":"Buckets"
},
"max":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The maximum of the population values.",
"title":"Max"
},
"mean":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The arithmetic mean of the values in the population.",
"title":"Mean"
},
"median":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The median of the values in the population.",
"title":"Median"
},
"min":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The minimum of the population values.",
"title":"Min"
},
"p5":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 5th percentile of the values in the population.",
"title":"P5"
},
"p95":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 95th percentile of the values in the population.",
"title":"P95"
},
"sum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sum of a given population of values.",
"title":"Sum"
}
},
"title":"DatasetDistribution",
"type":"object"
},
"DatasetDistributionDistributionBucket":{
"additionalProperties":false,
"description":"Dataset bucket used to create a histogram for the distribution given a population of values.",
"properties":{
"count":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of values in the bucket.",
"title":"Count"
},
"left":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Left bound of the bucket.",
"title":"Left"
},
"right":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Right bound of the bucket.",
"title":"Right"
}
},
"title":"DatasetDistributionDistributionBucket",
"type":"object"
},
"DatasetStats":{
"additionalProperties":false,
"description":"Statistics computed over a tuning dataset.",
"properties":{
"totalBillableCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of billable characters in the tuning dataset.",
"title":"Totalbillablecharactercount"
},
"totalTuningCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tuning characters in the tuning dataset.",
"title":"Totaltuningcharactercount"
},
"tuningDatasetExampleCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of examples in the tuning dataset.",
"title":"Tuningdatasetexamplecount"
},
"tuningStepCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tuning steps for this Tuning Job.",
"title":"Tuningstepcount"
},
"userDatasetExamples":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Content"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sample user messages in the training dataset uri.",
"title":"Userdatasetexamples"
},
"userInputTokenDistribution":{
"anyOf":[
{
"$ref":"#/$defs/DatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the user input tokens."
},
"userMessagePerExampleDistribution":{
"anyOf":[
{
"$ref":"#/$defs/DatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the messages per example."
},
"userOutputTokenDistribution":{
"anyOf":[
{
"$ref":"#/$defs/DatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the user output tokens."
}
},
"title":"DatasetStats",
"type":"object"
},
"DistillationDataStats":{
"additionalProperties":false,
"description":"Statistics computed for datasets used for distillation.",
"properties":{
"trainingDatasetStats":{
"anyOf":[
{
"$ref":"#/$defs/DatasetStats"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Statistics computed for the training dataset."
}
},
"title":"DistillationDataStats",
"type":"object"
},
"DistillationHyperParameters":{
"additionalProperties":false,
"description":"Hyperparameters for Distillation.",
"properties":{
"adapterSize":{
"anyOf":[
{
"$ref":"#/$defs/AdapterSize"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Adapter size for distillation."
},
"epochCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of complete passes the model makes over the entire training dataset during training.",
"title":"Epochcount"
},
"learningRateMultiplier":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Multiplier for adjusting the default learning rate.",
"title":"Learningratemultiplier"
}
},
"title":"DistillationHyperParameters",
"type":"object"
},
"DistillationSpec":{
"additionalProperties":false,
"description":"Tuning Spec for Distillation.",
"properties":{
"baseTeacherModel":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base teacher model that is being distilled, e.g., \"gemini-1.0-pro-002\".",
"title":"Baseteachermodel"
},
"hyperParameters":{
"anyOf":[
{
"$ref":"#/$defs/DistillationHyperParameters"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Hyperparameters for Distillation."
},
"pipelineRootDirectory":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. A path in a Cloud Storage bucket, which will be treated as the root output directory of the distillation pipeline. It is used by the system to generate the paths of output artifacts.",
"title":"Pipelinerootdirectory"
},
"studentModel":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The student model that is being tuned, e.g., \"google/gemma-2b-1.1-it\".",
"title":"Studentmodel"
},
"trainingDatasetUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file.",
"title":"Trainingdataseturi"
},
"tunedTeacherModelSource":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The resource name of the Tuned teacher model. Format: `projects/{project}/locations/{location}/models/{model}`.",
"title":"Tunedteachermodelsource"
},
"validationDatasetUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Cloud Storage path to file containing validation dataset for tuning. The dataset must be formatted as a JSONL file.",
"title":"Validationdataseturi"
}
},
"title":"DistillationSpec",
"type":"object"
},
"EncryptionSpec":{
"additionalProperties":false,
"description":"Represents a customer-managed encryption key spec that can be applied to a top-level resource.",
"properties":{
"kmsKeyName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.",
"title":"Kmskeyname"
}
},
"title":"EncryptionSpec",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"GoogleRpcStatus":{
"additionalProperties":false,
"description":"The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs.\n\nIt is used by [gRPC](https://github.com/grpc). Each `Status` message contains\nthree pieces of data: error code, error message, and error details. You can\nfind out more about this error model and how to work with it in the [API\nDesign Guide](https://cloud.google.com/apis/design/errors).",
"properties":{
"code":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The status code, which should be an enum value of google.rpc.Code.",
"title":"Code"
},
"details":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Details"
},
"message":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.",
"title":"Message"
}
},
"title":"GoogleRpcStatus",
"type":"object"
},
"JobState":{
"description":"Job state.",
"enum":[
"JOB_STATE_UNSPECIFIED",
"JOB_STATE_QUEUED",
"JOB_STATE_PENDING",
"JOB_STATE_RUNNING",
"JOB_STATE_SUCCEEDED",
"JOB_STATE_FAILED",
"JOB_STATE_CANCELLING",
"JOB_STATE_CANCELLED",
"JOB_STATE_PAUSED",
"JOB_STATE_EXPIRED",
"JOB_STATE_UPDATING",
"JOB_STATE_PARTIALLY_SUCCEEDED"
],
"title":"JobState",
"type":"string"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"PartnerModelTuningSpec":{
"additionalProperties":false,
"description":"Tuning spec for Partner models.",
"properties":{
"hyperParameters":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Hyperparameters for tuning. The accepted hyper_parameters and their valid range of values will differ depending on the base model.",
"title":"Hyperparameters"
},
"trainingDatasetUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file.",
"title":"Trainingdataseturi"
},
"validationDatasetUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Cloud Storage path to file containing validation dataset for tuning. The dataset must be formatted as a JSONL file.",
"title":"Validationdataseturi"
}
},
"title":"PartnerModelTuningSpec",
"type":"object"
},
"SupervisedHyperParameters":{
"additionalProperties":false,
"description":"Hyperparameters for SFT.",
"properties":{
"adapterSize":{
"anyOf":[
{
"$ref":"#/$defs/AdapterSize"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Adapter size for tuning."
},
"epochCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of complete passes the model makes over the entire training dataset during training.",
"title":"Epochcount"
},
"learningRateMultiplier":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Multiplier for adjusting the default learning rate.",
"title":"Learningratemultiplier"
}
},
"title":"SupervisedHyperParameters",
"type":"object"
},
"SupervisedTuningDataStats":{
"additionalProperties":false,
"description":"Tuning data statistics for Supervised Tuning.",
"properties":{
"totalBillableCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of billable characters in the tuning dataset.",
"title":"Totalbillablecharactercount"
},
"totalBillableTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of billable tokens in the tuning dataset.",
"title":"Totalbillabletokencount"
},
"totalTruncatedExampleCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The number of examples in the dataset that have been truncated by any amount.",
"title":"Totaltruncatedexamplecount"
},
"totalTuningCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tuning characters in the tuning dataset.",
"title":"Totaltuningcharactercount"
},
"truncatedExampleIndices":{
"anyOf":[
{
"items":{
"type":"integer"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A partial sample of the indices (starting from 1) of the truncated examples.",
"title":"Truncatedexampleindices"
},
"tuningDatasetExampleCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of examples in the tuning dataset.",
"title":"Tuningdatasetexamplecount"
},
"tuningStepCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tuning steps for this Tuning Job.",
"title":"Tuningstepcount"
},
"userDatasetExamples":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Content"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sample user messages in the training dataset uri.",
"title":"Userdatasetexamples"
},
"userInputTokenDistribution":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedTuningDatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the user input tokens."
},
"userMessagePerExampleDistribution":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedTuningDatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the messages per example."
},
"userOutputTokenDistribution":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedTuningDatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the user output tokens."
}
},
"title":"SupervisedTuningDataStats",
"type":"object"
},
"SupervisedTuningDatasetDistribution":{
"additionalProperties":false,
"description":"Dataset distribution for Supervised Tuning.",
"properties":{
"billableSum":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sum of a given population of values that are billable.",
"title":"Billablesum"
},
"buckets":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/SupervisedTuningDatasetDistributionDatasetBucket"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Defines the histogram bucket.",
"title":"Buckets"
},
"max":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The maximum of the population values.",
"title":"Max"
},
"mean":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The arithmetic mean of the values in the population.",
"title":"Mean"
},
"median":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The median of the values in the population.",
"title":"Median"
},
"min":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The minimum of the population values.",
"title":"Min"
},
"p5":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 5th percentile of the values in the population.",
"title":"P5"
},
"p95":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 95th percentile of the values in the population.",
"title":"P95"
},
"sum":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sum of a given population of values.",
"title":"Sum"
}
},
"title":"SupervisedTuningDatasetDistribution",
"type":"object"
},
"SupervisedTuningDatasetDistributionDatasetBucket":{
"additionalProperties":false,
"description":"Dataset bucket used to create a histogram for the distribution given a population of values.",
"properties":{
"count":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of values in the bucket.",
"title":"Count"
},
"left":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Left bound of the bucket.",
"title":"Left"
},
"right":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Right bound of the bucket.",
"title":"Right"
}
},
"title":"SupervisedTuningDatasetDistributionDatasetBucket",
"type":"object"
},
"SupervisedTuningSpec":{
"additionalProperties":false,
"description":"Tuning Spec for Supervised Tuning for first party models.",
"properties":{
"hyperParameters":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedHyperParameters"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Hyperparameters for SFT."
},
"trainingDatasetUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file.",
"title":"Trainingdataseturi"
},
"validationDatasetUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Cloud Storage path to file containing validation dataset for tuning. The dataset must be formatted as a JSONL file.",
"title":"Validationdataseturi"
},
"exportLastCheckpointOnly":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If set to true, disable intermediate checkpoints for SFT and only the last checkpoint will be exported.",
"title":"Exportlastcheckpointonly"
}
},
"title":"SupervisedTuningSpec",
"type":"object"
},
"TunedModel":{
"additionalProperties":false,
"properties":{
"model":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The resource name of the TunedModel. Format: `projects/{project}/locations/{location}/models/{model}`.",
"title":"Model"
},
"endpoint":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. A resource name of an Endpoint. Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`.",
"title":"Endpoint"
},
"checkpoints":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/TunedModelCheckpoint"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The checkpoints associated with this TunedModel.\n      This field is only populated for tuning jobs that enable intermediate\n      checkpoints.",
"title":"Checkpoints"
}
},
"title":"TunedModel",
"type":"object"
},
"TunedModelCheckpoint":{
"additionalProperties":false,
"description":"TunedModelCheckpoint for the Tuned Model of a Tuning Job.",
"properties":{
"checkpointId":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The ID of the checkpoint.\n      ",
"title":"Checkpointid"
},
"epoch":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The epoch of the checkpoint.\n      ",
"title":"Epoch"
},
"step":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The step of the checkpoint.\n      ",
"title":"Step"
},
"endpoint":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The Endpoint resource name that the checkpoint is deployed to.\n      Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`.\n      ",
"title":"Endpoint"
}
},
"title":"TunedModelCheckpoint",
"type":"object"
},
"TuningDataStats":{
"additionalProperties":false,
"description":"The tuning data statistic values for TuningJob.",
"properties":{
"distillationDataStats":{
"anyOf":[
{
"$ref":"#/$defs/DistillationDataStats"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Statistics for distillation."
},
"supervisedTuningDataStats":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedTuningDataStats"
},
{
"type":"null"
}
],
"default":null,
"description":"The SFT Tuning data stats."
}
},
"title":"TuningDataStats",
"type":"object"
},
"TuningJob":{
"additionalProperties":false,
"description":"A tuning job.",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Identifier. Resource name of a TuningJob. Format: `projects/{project}/locations/{location}/tuningJobs/{tuning_job}`",
"title":"Name"
},
"state":{
"anyOf":[
{
"$ref":"#/$defs/JobState"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The detailed state of the job."
},
"createTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Time when the TuningJob was created.",
"title":"Createtime"
},
"startTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Time when the TuningJob for the first time entered the `JOB_STATE_RUNNING` state.",
"title":"Starttime"
},
"endTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Time when the TuningJob entered any of the following JobStates: `JOB_STATE_SUCCEEDED`, `JOB_STATE_FAILED`, `JOB_STATE_CANCELLED`, `JOB_STATE_EXPIRED`.",
"title":"Endtime"
},
"updateTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Time when the TuningJob was most recently updated.",
"title":"Updatetime"
},
"error":{
"anyOf":[
{
"$ref":"#/$defs/GoogleRpcStatus"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Only populated when job's state is `JOB_STATE_FAILED` or `JOB_STATE_CANCELLED`."
},
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The description of the TuningJob.",
"title":"Description"
},
"baseModel":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base model that is being tuned, e.g., \"gemini-1.0-pro-002\". .",
"title":"Basemodel"
},
"tunedModel":{
"anyOf":[
{
"$ref":"#/$defs/TunedModel"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The tuned model resources associated with this TuningJob."
},
"supervisedTuningSpec":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedTuningSpec"
},
{
"type":"null"
}
],
"default":null,
"description":"Tuning Spec for Supervised Fine Tuning."
},
"tuningDataStats":{
"anyOf":[
{
"$ref":"#/$defs/TuningDataStats"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The tuning data statistics associated with this TuningJob."
},
"encryptionSpec":{
"anyOf":[
{
"$ref":"#/$defs/EncryptionSpec"
},
{
"type":"null"
}
],
"default":null,
"description":"Customer-managed encryption key options for a TuningJob. If this is set, then all resources created by the TuningJob will be encrypted with the provided encryption key."
},
"partnerModelTuningSpec":{
"anyOf":[
{
"$ref":"#/$defs/PartnerModelTuningSpec"
},
{
"type":"null"
}
],
"default":null,
"description":"Tuning Spec for open sourced and third party Partner models."
},
"distillationSpec":{
"anyOf":[
{
"$ref":"#/$defs/DistillationSpec"
},
{
"type":"null"
}
],
"default":null,
"description":"Tuning Spec for Distillation."
},
"experiment":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The Experiment associated with this TuningJob.",
"title":"Experiment"
},
"labels":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The labels with user-defined metadata to organize TuningJob and generated resources such as Model and Endpoint. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.",
"title":"Labels"
},
"pipelineJob":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The resource name of the PipelineJob associated with the TuningJob. Format: `projects/{project}/locations/{location}/pipelineJobs/{pipeline_job}`.",
"title":"Pipelinejob"
},
"tunedModelDisplayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The display name of the TunedModel. The name can be up to 128 characters long and can consist of any UTF-8 characters.",
"title":"Tunedmodeldisplayname"
}
},
"title":"TuningJob",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `next_page_token (str | None)`
  * `tuning_jobs (list[genai.types.TuningJob] | None)`



_field_ next_page_token _:`Optional`[`str`]__= None_ _(alias 'nextPageToken')_¶ 
    
A token to retrieve the next page of results. Pass to ListTuningJobsRequest.page_token to obtain that page. 

_field_ tuning_jobs _:`Optional`[`list`[`TuningJob`]]__= None_ _(alias 'tuningJobs')_¶ 
    
List of TuningJobs in the requested page. 

_class_ genai.types.ListTuningJobsResponseDict¶ 
    
Bases: `TypedDict`
Response for the list tuning jobs method. 

next_page_token _:`Optional`[`str`]_¶ 
    
A token to retrieve the next page of results. Pass to ListTuningJobsRequest.page_token to obtain that page. 

tuning_jobs _:`Optional`[`list`[`TuningJobDict`]]_¶ 
    
List of TuningJobs in the requested page. 

_pydantic model_genai.types.LiveClientContent¶ 
    
Bases: `BaseModel`
Incremental update of the current conversation delivered from the client.
All the content here will unconditionally be appended to the conversation history and used as part of the prompt to the model to generate content.
A message here will interrupt any current model generation.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"LiveClientContent",
"description":"Incremental update of the current conversation delivered from the client.\n\nAll the content here will unconditionally be appended to the conversation\nhistory and used as part of the prompt to the model to generate content.\n\nA message here will interrupt any current model generation.",
"type":"object",
"properties":{
"turns":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Content"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The content appended to the current conversation with the model.\n\n      For single-turn queries, this is a single instance. For multi-turn\n      queries, this is a repeated field that contains conversation history and\n      latest request.\n      ",
"title":"Turns"
},
"turnComplete":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If true, indicates that the server content generation should start with\n  the currently accumulated prompt. Otherwise, the server will await\n  additional messages before starting generation.",
"title":"Turncomplete"
}
},
"$defs":{
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"Content":{
"additionalProperties":false,
"description":"Contains the multi-part content of a message.",
"properties":{
"parts":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Part"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of parts that constitute a single message. Each part may have\n      a different IANA MIME type.",
"title":"Parts"
},
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role.",
"title":"Role"
}
},
"title":"Content",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `turn_complete (bool | None)`
  * `turns (list[genai.types.Content] | None)`



_field_ turn_complete _:`Optional`[`bool`]__= None_ _(alias 'turnComplete')_¶ 
    
If true, indicates that the server content generation should start with the currently accumulated prompt. Otherwise, the server will await additional messages before starting generation. 

_field_ turns _:`Optional`[`list`[`Content`]]__= None_¶ 
    
The content appended to the current conversation with the model.
For single-turn queries, this is a single instance. For multi-turn queries, this is a repeated field that contains conversation history and latest request. 

_class_ genai.types.LiveClientContentDict¶ 
    
Bases: `TypedDict`
Incremental update of the current conversation delivered from the client.
All the content here will unconditionally be appended to the conversation history and used as part of the prompt to the model to generate content.
A message here will interrupt any current model generation. 

turn_complete _:`Optional`[`bool`]_¶ 
    
If true, indicates that the server content generation should start with the currently accumulated prompt. Otherwise, the server will await additional messages before starting generation. 

turns _:`Optional`[`list`[`ContentDict`]]_¶ 
    
The content appended to the current conversation with the model.
For single-turn queries, this is a single instance. For multi-turn queries, this is a repeated field that contains conversation history and latest request. 

_pydantic model_genai.types.LiveClientMessage¶ 
    
Bases: `BaseModel`
Messages sent by the client in the API call.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"LiveClientMessage",
"description":"Messages sent by the client in the API call.",
"type":"object",
"properties":{
"setup":{
"anyOf":[
{
"$ref":"#/$defs/LiveClientSetup"
},
{
"type":"null"
}
],
"default":null,
"description":"Message to be sent by the system when connecting to the API. SDK users should not send this message."
},
"clientContent":{
"anyOf":[
{
"$ref":"#/$defs/LiveClientContent"
},
{
"type":"null"
}
],
"default":null,
"description":"Incremental update of the current conversation delivered from the client."
},
"realtimeInput":{
"anyOf":[
{
"$ref":"#/$defs/LiveClientRealtimeInput"
},
{
"type":"null"
}
],
"default":null,
"description":"User input that is sent in real time."
},
"toolResponse":{
"anyOf":[
{
"$ref":"#/$defs/LiveClientToolResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Response to a `ToolCallMessage` received from the server."
}
},
"$defs":{
"ActivityEnd":{
"additionalProperties":false,
"description":"Marks the end of user activity.\n\nThis can only be sent if automatic (i.e. server-side) activity detection is\ndisabled.",
"properties":{},
"title":"ActivityEnd",
"type":"object"
},
"ActivityStart":{
"additionalProperties":false,
"description":"Marks the start of user activity.\n\nThis can only be sent if automatic (i.e. server-side) activity detection is\ndisabled.",
"properties":{},
"title":"ActivityStart",
"type":"object"
},
"ApiKeyConfig":{
"additionalProperties":false,
"description":"Config for authentication with API key.",
"properties":{
"apiKeyString":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The API key to be used in the request directly.",
"title":"Apikeystring"
}
},
"title":"ApiKeyConfig",
"type":"object"
},
"AudioTranscriptionConfig":{
"additionalProperties":false,
"description":"The audio transcription configuration in Setup.",
"properties":{},
"title":"AudioTranscriptionConfig",
"type":"object"
},
"AuthConfig":{
"additionalProperties":false,
"description":"Auth configuration to run the extension.",
"properties":{
"apiKeyConfig":{
"anyOf":[
{
"$ref":"#/$defs/ApiKeyConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for API key auth."
},
"authType":{
"anyOf":[
{
"$ref":"#/$defs/AuthType"
},
{
"type":"null"
}
],
"default":null,
"description":"Type of auth scheme."
},
"googleServiceAccountConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigGoogleServiceAccountConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for Google Service Account auth."
},
"httpBasicAuthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigHttpBasicAuthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for HTTP Basic auth."
},
"oauthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOauthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user oauth."
},
"oidcConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOidcConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user OIDC auth."
}
},
"title":"AuthConfig",
"type":"object"
},
"AuthConfigGoogleServiceAccountConfig":{
"additionalProperties":false,
"description":"Config for Google Service Account Authentication.",
"properties":{
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The service account that the extension execution service runs as. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified service account. - If not specified, the Vertex AI Extension Service Agent will be used to execute the Extension.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigGoogleServiceAccountConfig",
"type":"object"
},
"AuthConfigHttpBasicAuthConfig":{
"additionalProperties":false,
"description":"Config for HTTP Basic Authentication.",
"properties":{
"credentialSecret":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the SecretManager secret version resource storing the base64 encoded credentials. Format: `projects/{project}/secrets/{secrete}/versions/{version}` - If specified, the `secretmanager.versions.access` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified resource.",
"title":"Credentialsecret"
}
},
"title":"AuthConfigHttpBasicAuthConfig",
"type":"object"
},
"AuthConfigOauthConfig":{
"additionalProperties":false,
"description":"Config for user oauth.",
"properties":{
"accessToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Access token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Accesstoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate access tokens for executing the Extension. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the provided service account.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOauthConfig",
"type":"object"
},
"AuthConfigOidcConfig":{
"additionalProperties":false,
"description":"Config for user OIDC auth.",
"properties":{
"idToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"OpenID Connect formatted ID token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Idtoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate an OpenID Connect (OIDC)-compatible JWT token signed by the Google OIDC Provider (accounts.google.com) for extension endpoint (https://cloud.google.com/iam/docs/create-short-lived-credentials-direct#sa-credentials-oidc). - The audience for the token will be set to the URL in the server url defined in the OpenApi spec. - If the service account is provided, the service account should grant `iam.serviceAccounts.getOpenIdToken` permission to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOidcConfig",
"type":"object"
},
"AuthType":{
"description":"Type of auth scheme.",
"enum":[
"AUTH_TYPE_UNSPECIFIED",
"NO_AUTH",
"API_KEY_AUTH",
"HTTP_BASIC_AUTH",
"GOOGLE_SERVICE_ACCOUNT_AUTH",
"OAUTH",
"OIDC_AUTH"
],
"title":"AuthType",
"type":"string"
},
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"Content":{
"additionalProperties":false,
"description":"Contains the multi-part content of a message.",
"properties":{
"parts":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Part"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of parts that constitute a single message. Each part may have\n      a different IANA MIME type.",
"title":"Parts"
},
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role.",
"title":"Role"
}
},
"title":"Content",
"type":"object"
},
"ContextWindowCompressionConfig":{
"additionalProperties":false,
"description":"Enables context window compression -- mechanism managing model context window so it does not exceed given length.",
"properties":{
"triggerTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens (before running turn) that triggers context window compression mechanism.",
"title":"Triggertokens"
},
"slidingWindow":{
"anyOf":[
{
"$ref":"#/$defs/SlidingWindow"
},
{
"type":"null"
}
],
"default":null,
"description":"Sliding window compression mechanism."
}
},
"title":"ContextWindowCompressionConfig",
"type":"object"
},
"DynamicRetrievalConfig":{
"additionalProperties":false,
"description":"Describes the options to customize dynamic retrieval.",
"properties":{
"mode":{
"anyOf":[
{
"$ref":"#/$defs/DynamicRetrievalConfigMode"
},
{
"type":"null"
}
],
"default":null,
"description":"The mode of the predictor to be used in dynamic retrieval."
},
"dynamicThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The threshold to be used in dynamic retrieval. If not set, a system default value is used.",
"title":"Dynamicthreshold"
}
},
"title":"DynamicRetrievalConfig",
"type":"object"
},
"DynamicRetrievalConfigMode":{
"description":"Config for the dynamic retrieval config mode.",
"enum":[
"MODE_UNSPECIFIED",
"MODE_DYNAMIC"
],
"title":"DynamicRetrievalConfigMode",
"type":"string"
},
"EnterpriseWebSearch":{
"additionalProperties":false,
"description":"Tool to search public web data, powered by Vertex AI Search and Sec4 compliance.",
"properties":{},
"title":"EnterpriseWebSearch",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"File":{
"additionalProperties":false,
"description":"A file uploaded to the API.",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The `File` resource name. The ID (name excluding the \"files/\" prefix) can contain up to 40 characters that are lowercase alphanumeric or dashes (-). The ID cannot start or end with a dash. If the name is empty on create, a unique name will be generated. Example: `files/123-456`",
"title":"Name"
},
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The human-readable display name for the `File`. The display name must be no more than 512 characters in length, including spaces. Example: 'Welcome Image'",
"title":"Displayname"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. MIME type of the file.",
"title":"Mimetype"
},
"sizeBytes":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Size of the file in bytes.",
"title":"Sizebytes"
},
"createTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` was created.",
"title":"Createtime"
},
"expirationTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` will be deleted. Only set if the `File` is scheduled to expire.",
"title":"Expirationtime"
},
"updateTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` was last updated.",
"title":"Updatetime"
},
"sha256Hash":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. SHA-256 hash of the uploaded bytes. The hash value is encoded in base64 format.",
"title":"Sha256Hash"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The URI of the `File`.",
"title":"Uri"
},
"downloadUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The URI of the `File`, only set for downloadable (generated) files.",
"title":"Downloaduri"
},
"state":{
"anyOf":[
{
"$ref":"#/$defs/FileState"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Processing state of the File."
},
"source":{
"anyOf":[
{
"$ref":"#/$defs/FileSource"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The source of the `File`."
},
"videoMetadata":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Metadata for a video.",
"title":"Videometadata"
},
"error":{
"anyOf":[
{
"$ref":"#/$defs/FileStatus"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Error status if File processing failed."
}
},
"title":"File",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FileSource":{
"description":"Source of the File.",
"enum":[
"SOURCE_UNSPECIFIED",
"UPLOADED",
"GENERATED"
],
"title":"FileSource",
"type":"string"
},
"FileState":{
"description":"State for the lifecycle of a File.",
"enum":[
"STATE_UNSPECIFIED",
"PROCESSING",
"ACTIVE",
"FAILED"
],
"title":"FileState",
"type":"string"
},
"FileStatus":{
"additionalProperties":false,
"description":"Status of a File that uses a common error model.",
"properties":{
"details":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Details"
},
"message":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Message"
},
"code":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The status code. 0 for OK, 1 for CANCELLED",
"title":"Code"
}
},
"title":"FileStatus",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionDeclaration":{
"additionalProperties":false,
"description":"Structured representation of a function declaration as defined by the [OpenAPI 3.0 specification](https://spec.openapis.org/oas/v3.0.3).\n\nIncluded in this declaration are the function name, description, parameters\nand response type. This FunctionDeclaration is a representation of a block of\ncode that can be used as a `Tool` by the model and executed by the client.",
"properties":{
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Description and purpose of the function. Model uses it to decide how and whether to call the function.",
"title":"Description"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Must start with a letter or an underscore. Must be a-z, A-Z, 0-9, or contain underscores, dots and dashes, with a maximum length of 64.",
"title":"Name"
},
"parameters":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Describes the parameters to this function in JSON Schema Object format. Reflects the Open API 3.03 Parameter Object. string Key: the name of the parameter. Parameter names are case sensitive. Schema Value: the Schema defining the type used for the parameter. For function with no parameters, this can be left unset. Parameter names must start with a letter or an underscore and must only contain chars a-z, A-Z, 0-9, or underscores with a maximum length of 64. Example with 1 required and 1 optional parameter: type: OBJECT properties: param1: type: STRING param2: type: INTEGER required: - param1"
},
"response":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Describes the output from this function in JSON Schema format. Reflects the Open API 3.03 Response Object. The Schema defines the type used for the response value of the function."
}
},
"title":"FunctionDeclaration",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"GenerationConfig":{
"additionalProperties":false,
"description":"Generation config.",
"properties":{
"audioTimestamp":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If enabled, audio timestamp will be included in the request to the model.",
"title":"Audiotimestamp"
},
"candidateCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of candidates to generate.",
"title":"Candidatecount"
},
"frequencyPenalty":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Frequency penalties.",
"title":"Frequencypenalty"
},
"logprobs":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Logit probabilities.",
"title":"Logprobs"
},
"maxOutputTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The maximum number of output tokens to generate per message.",
"title":"Maxoutputtokens"
},
"mediaResolution":{
"anyOf":[
{
"$ref":"#/$defs/MediaResolution"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If specified, the media resolution specified will be used."
},
"presencePenalty":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Positive penalties.",
"title":"Presencepenalty"
},
"responseLogprobs":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If true, export the logprobs results in response.",
"title":"Responselogprobs"
},
"responseMimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Output response mimetype of the generated candidate text. Supported mimetype: - `text/plain`: (default) Text output. - `application/json`: JSON response in the candidates. The model needs to be prompted to output the appropriate response type, otherwise the behavior is undefined. This is a preview feature.",
"title":"Responsemimetype"
},
"responseSchema":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The `Schema` object allows the definition of input and output data types. These types can be objects, but also primitives and arrays. Represents a select subset of an [OpenAPI 3.0 schema object](https://spec.openapis.org/oas/v3.0.3#schema). If set, a compatible response_mime_type must also be set. Compatible mimetypes: `application/json`: Schema for JSON response."
},
"routingConfig":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Routing configuration."
},
"seed":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Seed.",
"title":"Seed"
},
"stopSequences":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Stop sequences.",
"title":"Stopsequences"
},
"temperature":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Controls the randomness of predictions.",
"title":"Temperature"
},
"topK":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If specified, top-k sampling will be used.",
"title":"Topk"
},
"topP":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If specified, nucleus sampling will be used.",
"title":"Topp"
}
},
"title":"GenerationConfig",
"type":"object"
},
"GenerationConfigRoutingConfig":{
"additionalProperties":false,
"description":"The configuration for routing the request to a specific model.",
"properties":{
"autoMode":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfigAutoRoutingMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Automated routing."
},
"manualMode":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfigManualRoutingMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Manual routing."
}
},
"title":"GenerationConfigRoutingConfig",
"type":"object"
},
"GenerationConfigRoutingConfigAutoRoutingMode":{
"additionalProperties":false,
"description":"When automated routing is specified, the routing will be determined by the pretrained routing model and customer provided model routing preference.",
"properties":{
"modelRoutingPreference":{
"anyOf":[
{
"enum":[
"UNKNOWN",
"PRIORITIZE_QUALITY",
"BALANCED",
"PRIORITIZE_COST"
],
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The model routing preference.",
"title":"Modelroutingpreference"
}
},
"title":"GenerationConfigRoutingConfigAutoRoutingMode",
"type":"object"
},
"GenerationConfigRoutingConfigManualRoutingMode":{
"additionalProperties":false,
"description":"When manual routing is set, the specified model will be used directly.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The model name to use. Only the public LLM models are accepted. e.g. 'gemini-1.5-pro-001'.",
"title":"Modelname"
}
},
"title":"GenerationConfigRoutingConfigManualRoutingMode",
"type":"object"
},
"GoogleMaps":{
"additionalProperties":false,
"description":"Tool to support Google Maps in Model.",
"properties":{
"authConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Auth config for the Google Maps tool."
}
},
"title":"GoogleMaps",
"type":"object"
},
"GoogleSearch":{
"additionalProperties":false,
"description":"Tool to support Google Search in Model. Powered by Google.",
"properties":{},
"title":"GoogleSearch",
"type":"object"
},
"GoogleSearchRetrieval":{
"additionalProperties":false,
"description":"Tool to retrieve public web data for grounding, powered by Google.",
"properties":{
"dynamicRetrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/DynamicRetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the dynamic retrieval configuration for the given source."
}
},
"title":"GoogleSearchRetrieval",
"type":"object"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"LiveClientContent":{
"additionalProperties":false,
"description":"Incremental update of the current conversation delivered from the client.\n\nAll the content here will unconditionally be appended to the conversation\nhistory and used as part of the prompt to the model to generate content.\n\nA message here will interrupt any current model generation.",
"properties":{
"turns":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Content"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The content appended to the current conversation with the model.\n\n      For single-turn queries, this is a single instance. For multi-turn\n      queries, this is a repeated field that contains conversation history and\n      latest request.\n      ",
"title":"Turns"
},
"turnComplete":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If true, indicates that the server content generation should start with\n  the currently accumulated prompt. Otherwise, the server will await\n  additional messages before starting generation.",
"title":"Turncomplete"
}
},
"title":"LiveClientContent",
"type":"object"
},
"LiveClientRealtimeInput":{
"additionalProperties":false,
"description":"User input that is sent in real time.\n\nThis is different from `LiveClientContent` in a few ways:\n\n  - Can be sent continuously without interruption to model generation.\n  - If there is a need to mix data interleaved across the\n    `LiveClientContent` and the `LiveClientRealtimeInput`, server attempts to\n    optimize for best response, but there are no guarantees.\n  - End of turn is not explicitly specified, but is rather derived from user\n    activity (for example, end of speech).\n  - Even before the end of turn, the data is processed incrementally\n    to optimize for a fast start of the response from the model.\n  - Is always assumed to be the user's input (cannot be used to populate\n    conversation history).",
"properties":{
"mediaChunks":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Blob"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Inlined bytes data for media input.",
"title":"Mediachunks"
},
"audio":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"The realtime audio input stream."
},
"audioStreamEnd":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"\nIndicates that the audio stream has ended, e.g. because the microphone was\nturned off.\n\nThis should only be sent when automatic activity detection is enabled\n(which is the default).\n\nThe client can reopen the stream by sending an audio message.\n",
"title":"Audiostreamend"
},
"video":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"The realtime video input stream."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The realtime text input stream.",
"title":"Text"
},
"activityStart":{
"anyOf":[
{
"$ref":"#/$defs/ActivityStart"
},
{
"type":"null"
}
],
"default":null,
"description":"Marks the start of user activity."
},
"activityEnd":{
"anyOf":[
{
"$ref":"#/$defs/ActivityEnd"
},
{
"type":"null"
}
],
"default":null,
"description":"Marks the end of user activity."
}
},
"title":"LiveClientRealtimeInput",
"type":"object"
},
"LiveClientSetup":{
"additionalProperties":false,
"description":"Message contains configuration that will apply for the duration of the streaming session.",
"properties":{
"model":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"\n      The fully qualified name of the publisher model or tuned model endpoint to\n      use.\n      ",
"title":"Model"
},
"generationConfig":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The generation configuration for the session.\n      Note: only a subset of fields are supported.\n      "
},
"systemInstruction":{
"anyOf":[
{
"$ref":"#/$defs/Content"
},
{
"items":{
"anyOf":[
{
"$ref":"#/$defs/File"
},
{
"$ref":"#/$defs/Part"
},
{
"type":"string"
}
]
},
"type":"array"
},
{
"$ref":"#/$defs/File"
},
{
"$ref":"#/$defs/Part"
},
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The user provided system instructions for the model.\n      Note: only text should be used in parts and content in each part will be\n      in a separate paragraph.",
"title":"Systeminstruction"
},
"tools":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Tool"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":" A list of `Tools` the model may use to generate the next response.\n\n      A `Tool` is a piece of code that enables the system to interact with\n      external systems to perform an action, or set of actions, outside of\n      knowledge and scope of the model.",
"title":"Tools"
},
"sessionResumption":{
"anyOf":[
{
"$ref":"#/$defs/SessionResumptionConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Configures session resumption mechanism.\n\n          If included server will send SessionResumptionUpdate messages."
},
"contextWindowCompression":{
"anyOf":[
{
"$ref":"#/$defs/ContextWindowCompressionConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Configures context window compression mechanism.\n\n      If included, server will compress context window to fit into given length."
},
"inputAudioTranscription":{
"anyOf":[
{
"$ref":"#/$defs/AudioTranscriptionConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The transcription of the input aligns with the input audio language.\n      "
},
"outputAudioTranscription":{
"anyOf":[
{
"$ref":"#/$defs/AudioTranscriptionConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The transcription of the output aligns with the language code\n      specified for the output audio.\n      "
}
},
"title":"LiveClientSetup",
"type":"object"
},
"LiveClientToolResponse":{
"additionalProperties":false,
"description":"Client generated response to a `ToolCall` received from the server.\n\nIndividual `FunctionResponse` objects are matched to the respective\n`FunctionCall` objects by the `id` field.\n\nNote that in the unary and server-streaming GenerateContent APIs function\ncalling happens by exchanging the `Content` parts, while in the bidi\nGenerateContent APIs function calling happens over this dedicated set of\nmessages.",
"properties":{
"functionResponses":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/FunctionResponse"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The response to the function calls.",
"title":"Functionresponses"
}
},
"title":"LiveClientToolResponse",
"type":"object"
},
"MediaResolution":{
"description":"The media resolution to use.",
"enum":[
"MEDIA_RESOLUTION_UNSPECIFIED",
"MEDIA_RESOLUTION_LOW",
"MEDIA_RESOLUTION_MEDIUM",
"MEDIA_RESOLUTION_HIGH"
],
"title":"MediaResolution",
"type":"string"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"RagRetrievalConfig":{
"additionalProperties":false,
"description":"Specifies the context retrieval config.",
"properties":{
"filter":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigFilter"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for filters."
},
"hybridSearch":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigHybridSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Hybrid Search."
},
"ranking":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRanking"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for ranking and reranking."
},
"topK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The number of contexts to retrieve.",
"title":"Topk"
}
},
"title":"RagRetrievalConfig",
"type":"object"
},
"RagRetrievalConfigFilter":{
"additionalProperties":false,
"description":"Config for filters.",
"properties":{
"metadataFilter":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. String for metadata filtering.",
"title":"Metadatafilter"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
},
"vectorSimilarityThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector similarity larger than the threshold.",
"title":"Vectorsimilaritythreshold"
}
},
"title":"RagRetrievalConfigFilter",
"type":"object"
},
"RagRetrievalConfigHybridSearch":{
"additionalProperties":false,
"description":"Config for Hybrid Search.",
"properties":{
"alpha":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally.",
"title":"Alpha"
}
},
"title":"RagRetrievalConfigHybridSearch",
"type":"object"
},
"RagRetrievalConfigRanking":{
"additionalProperties":false,
"description":"Config for ranking and reranking.",
"properties":{
"llmRanker":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingLlmRanker"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for LlmRanker."
},
"rankService":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingRankService"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Rank Service."
}
},
"title":"RagRetrievalConfigRanking",
"type":"object"
},
"RagRetrievalConfigRankingLlmRanker":{
"additionalProperties":false,
"description":"Config for LlmRanker.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name used for ranking. Format: `gemini-1.5-pro`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingLlmRanker",
"type":"object"
},
"RagRetrievalConfigRankingRankService":{
"additionalProperties":false,
"description":"Config for Rank Service.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name of the rank service. Format: `semantic-ranker-512@latest`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingRankService",
"type":"object"
},
"Retrieval":{
"additionalProperties":false,
"description":"Defines a retrieval tool that model can call to access external knowledge.",
"properties":{
"disableAttribution":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Deprecated. This option is no longer supported.",
"title":"Disableattribution"
},
"vertexAiSearch":{
"anyOf":[
{
"$ref":"#/$defs/VertexAISearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Set to use data source powered by Vertex AI Search."
},
"vertexRagStore":{
"anyOf":[
{
"$ref":"#/$defs/VertexRagStore"
},
{
"type":"null"
}
],
"default":null,
"description":"Set to use data source powered by Vertex RAG store. User data is uploaded via the VertexRagDataService."
}
},
"title":"Retrieval",
"type":"object"
},
"Schema":{
"additionalProperties":false,
"description":"Schema is used to define the format of input/output data.\n\nRepresents a select subset of an [OpenAPI 3.0 schema\nobject](https://spec.openapis.org/oas/v3.0.3#schema-object). More fields may\nbe added in the future as needed.",
"properties":{
"anyOf":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Schema"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The value should be validated against any (one or more) of the subschemas in the list.",
"title":"Anyof"
},
"default":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Default value of the data.",
"title":"Default"
},
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The description of the data.",
"title":"Description"
},
"enum":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Possible values of the element of primitive type with enum format. Examples: 1. We can define direction as : {type:STRING, format:enum, enum:[\"EAST\", NORTH\", \"SOUTH\", \"WEST\"]} 2. We can define apartment number as : {type:INTEGER, format:enum, enum:[\"101\", \"201\", \"301\"]}",
"title":"Enum"
},
"example":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Example of the object. Will only populated when the object is the root.",
"title":"Example"
},
"format":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The format of the data. Supported formats: for NUMBER type: \"float\", \"double\" for INTEGER type: \"int32\", \"int64\" for STRING type: \"email\", \"byte\", etc",
"title":"Format"
},
"items":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE ARRAY Schema of the elements of Type.ARRAY."
},
"maxItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the elements for Type.ARRAY.",
"title":"Maxitems"
},
"maxLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum length of the Type.STRING",
"title":"Maxlength"
},
"maxProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the properties for Type.OBJECT.",
"title":"Maxproperties"
},
"maximum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum value of the Type.INTEGER and Type.NUMBER",
"title":"Maximum"
},
"minItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the elements for Type.ARRAY.",
"title":"Minitems"
},
"minLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING",
"title":"Minlength"
},
"minProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the properties for Type.OBJECT.",
"title":"Minproperties"
},
"minimum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER Minimum value of the Type.INTEGER and Type.NUMBER",
"title":"Minimum"
},
"nullable":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Indicates if the value may be null.",
"title":"Nullable"
},
"pattern":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Pattern of the Type.STRING to restrict a string to a regular expression.",
"title":"Pattern"
},
"properties":{
"anyOf":[
{
"additionalProperties":{
"$ref":"#/$defs/Schema"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE OBJECT Properties of Type.OBJECT.",
"title":"Properties"
},
"propertyOrdering":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The order of the properties. Not a standard field in open api spec. Only used to support the order of the properties.",
"title":"Propertyordering"
},
"required":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required properties of Type.OBJECT.",
"title":"Required"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The title of the Schema.",
"title":"Title"
},
"type":{
"anyOf":[
{
"$ref":"#/$defs/Type"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The type of the data."
}
},
"title":"Schema",
"type":"object"
},
"SessionResumptionConfig":{
"additionalProperties":false,
"description":"Configuration of session resumption mechanism.\n\nIncluded in `LiveConnectConfig.session_resumption`. If included server\nwill send `LiveServerSessionResumptionUpdate` messages.",
"properties":{
"handle":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Session resumption handle of previous session (session to restore).\n\nIf not present new session will be started.",
"title":"Handle"
},
"transparent":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If set the server will send `last_consumed_client_message_index` in the `session_resumption_update` messages to allow for transparent reconnections.",
"title":"Transparent"
}
},
"title":"SessionResumptionConfig",
"type":"object"
},
"SlidingWindow":{
"additionalProperties":false,
"description":"Context window will be truncated by keeping only suffix of it.\n\nContext window will always be cut at start of USER role turn. System\ninstructions and `BidiGenerateContentSetup.prefix_turns` will not be\nsubject to the sliding window mechanism, they will always stay at the\nbeginning of context window.",
"properties":{
"targetTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Session reduction target -- how many tokens we should keep. Window shortening operation has some latency costs, so we should avoid running it on every turn. Should be < trigger_tokens. If not set, trigger_tokens/2 is assumed.",
"title":"Targettokens"
}
},
"title":"SlidingWindow",
"type":"object"
},
"Tool":{
"additionalProperties":false,
"description":"Tool details of a tool that the model may use to generate a response.",
"properties":{
"retrieval":{
"anyOf":[
{
"$ref":"#/$defs/Retrieval"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Retrieval tool type. System will always execute the provided retrieval tool(s) to get external knowledge to answer the prompt. Retrieval results are presented to the model for generation."
},
"googleSearch":{
"anyOf":[
{
"$ref":"#/$defs/GoogleSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google Search tool type. Specialized retrieval tool\n      that is powered by Google Search."
},
"googleSearchRetrieval":{
"anyOf":[
{
"$ref":"#/$defs/GoogleSearchRetrieval"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. GoogleSearchRetrieval tool type. Specialized retrieval tool that is powered by Google search."
},
"enterpriseWebSearch":{
"anyOf":[
{
"$ref":"#/$defs/EnterpriseWebSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Enterprise web search tool type. Specialized retrieval\n      tool that is powered by Vertex AI Search and Sec4 compliance."
},
"googleMaps":{
"anyOf":[
{
"$ref":"#/$defs/GoogleMaps"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google Maps tool type. Specialized retrieval tool\n      that is powered by Google Maps."
},
"codeExecution":{
"anyOf":[
{
"$ref":"#/$defs/ToolCodeExecution"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. CodeExecution tool type. Enables the model to execute code as part of generation. This field is only used by the Gemini Developer API services."
},
"functionDeclarations":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/FunctionDeclaration"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Function tool type. One or more function declarations to be passed to the model along with the current user query. Model may decide to call a subset of these functions by populating FunctionCall in the response. User should provide a FunctionResponse for each function call in the next turn. Based on the function responses, Model will generate the final response back to the user. Maximum 128 function declarations can be provided.",
"title":"Functiondeclarations"
}
},
"title":"Tool",
"type":"object"
},
"ToolCodeExecution":{
"additionalProperties":false,
"description":"Tool that executes code generated by the model, and automatically returns the result to the model.\n\nSee also [ExecutableCode]and [CodeExecutionResult] which are input and output\nto this tool.",
"properties":{},
"title":"ToolCodeExecution",
"type":"object"
},
"Type":{
"description":"Optional. The type of the data.",
"enum":[
"TYPE_UNSPECIFIED",
"STRING",
"NUMBER",
"INTEGER",
"BOOLEAN",
"ARRAY",
"OBJECT"
],
"title":"Type",
"type":"string"
},
"VertexAISearch":{
"additionalProperties":false,
"description":"Retrieve from Vertex AI Search datastore or engine for grounding.\n\ndatastore and engine are mutually exclusive. See\nhttps://cloud.google.com/products/agent-builder",
"properties":{
"datastore":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search data store resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`",
"title":"Datastore"
},
"engine":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search engine resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}`",
"title":"Engine"
}
},
"title":"VertexAISearch",
"type":"object"
},
"VertexRagStore":{
"additionalProperties":false,
"description":"Retrieve from Vertex RAG Store for grounding.",
"properties":{
"ragCorpora":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Deprecated. Please use rag_resources instead.",
"title":"Ragcorpora"
},
"ragResources":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/VertexRagStoreRagResource"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The representation of the rag source. It can be used to specify corpus only or ragfiles. Currently only support one corpus or multiple files from one corpus. In the future we may open up multiple corpora support.",
"title":"Ragresources"
},
"ragRetrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The retrieval config for the Rag query."
},
"similarityTopK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of top k results to return from the selected corpora.",
"title":"Similaritytopk"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only return results with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
}
},
"title":"VertexRagStore",
"type":"object"
},
"VertexRagStoreRagResource":{
"additionalProperties":false,
"description":"The definition of the Rag resource.",
"properties":{
"ragCorpus":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. RagCorpora resource name. Format: `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`",
"title":"Ragcorpus"
},
"ragFileIds":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus field.",
"title":"Ragfileids"
}
},
"title":"VertexRagStoreRagResource",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `client_content (genai.types.LiveClientContent | None)`
  * `realtime_input (genai.types.LiveClientRealtimeInput | None)`
  * `setup (genai.types.LiveClientSetup | None)`
  * `tool_response (genai.types.LiveClientToolResponse | None)`



_field_ client_content _:`Optional`[`LiveClientContent`]__= None_ _(alias 'clientContent')_¶ 
    
Incremental update of the current conversation delivered from the client. 

_field_ realtime_input _:`Optional`[`LiveClientRealtimeInput`]__= None_ _(alias 'realtimeInput')_¶ 
    
User input that is sent in real time. 

_field_ setup _:`Optional`[`LiveClientSetup`]__= None_¶ 
    
Message to be sent by the system when connecting to the API. SDK users should not send this message. 

_field_ tool_response _:`Optional`[`LiveClientToolResponse`]__= None_ _(alias 'toolResponse')_¶ 
    
Response to a ToolCallMessage received from the server. 

_class_ genai.types.LiveClientMessageDict¶ 
    
Bases: `TypedDict`
Messages sent by the client in the API call. 

client_content _:`Optional`[`LiveClientContentDict`]_¶ 
    
Incremental update of the current conversation delivered from the client. 

realtime_input _:`Optional`[`LiveClientRealtimeInputDict`]_¶ 
    
User input that is sent in real time. 

setup _:`Optional`[`LiveClientSetupDict`]_¶ 
    
Message to be sent by the system when connecting to the API. SDK users should not send this message. 

tool_response _:`Optional`[`LiveClientToolResponseDict`]_¶ 
    
Response to a ToolCallMessage received from the server. 

_pydantic model_genai.types.LiveClientRealtimeInput¶ 
    
Bases: `BaseModel`
User input that is sent in real time.
This is different from LiveClientContent in a few ways:
>   * Can be sent continuously without interruption to model generation.
>   * If there is a need to mix data interleaved across the LiveClientContent and the LiveClientRealtimeInput, server attempts to optimize for best response, but there are no guarantees.
>   * End of turn is not explicitly specified, but is rather derived from user activity (for example, end of speech).
>   * Even before the end of turn, the data is processed incrementally to optimize for a fast start of the response from the model.
>   * Is always assumed to be the user’s input (cannot be used to populate conversation history).
> 

Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"LiveClientRealtimeInput",
"description":"User input that is sent in real time.\n\nThis is different from `LiveClientContent` in a few ways:\n\n  - Can be sent continuously without interruption to model generation.\n  - If there is a need to mix data interleaved across the\n    `LiveClientContent` and the `LiveClientRealtimeInput`, server attempts to\n    optimize for best response, but there are no guarantees.\n  - End of turn is not explicitly specified, but is rather derived from user\n    activity (for example, end of speech).\n  - Even before the end of turn, the data is processed incrementally\n    to optimize for a fast start of the response from the model.\n  - Is always assumed to be the user's input (cannot be used to populate\n    conversation history).",
"type":"object",
"properties":{
"mediaChunks":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Blob"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Inlined bytes data for media input.",
"title":"Mediachunks"
},
"audio":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"The realtime audio input stream."
},
"audioStreamEnd":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"\nIndicates that the audio stream has ended, e.g. because the microphone was\nturned off.\n\nThis should only be sent when automatic activity detection is enabled\n(which is the default).\n\nThe client can reopen the stream by sending an audio message.\n",
"title":"Audiostreamend"
},
"video":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"The realtime video input stream."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The realtime text input stream.",
"title":"Text"
},
"activityStart":{
"anyOf":[
{
"$ref":"#/$defs/ActivityStart"
},
{
"type":"null"
}
],
"default":null,
"description":"Marks the start of user activity."
},
"activityEnd":{
"anyOf":[
{
"$ref":"#/$defs/ActivityEnd"
},
{
"type":"null"
}
],
"default":null,
"description":"Marks the end of user activity."
}
},
"$defs":{
"ActivityEnd":{
"additionalProperties":false,
"description":"Marks the end of user activity.\n\nThis can only be sent if automatic (i.e. server-side) activity detection is\ndisabled.",
"properties":{},
"title":"ActivityEnd",
"type":"object"
},
"ActivityStart":{
"additionalProperties":false,
"description":"Marks the start of user activity.\n\nThis can only be sent if automatic (i.e. server-side) activity detection is\ndisabled.",
"properties":{},
"title":"ActivityStart",
"type":"object"
},
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `activity_end (genai.types.ActivityEnd | None)`
  * `activity_start (genai.types.ActivityStart | None)`
  * `audio (genai.types.Blob | None)`
  * `audio_stream_end (bool | None)`
  * `media_chunks (list[genai.types.Blob] | None)`
  * `text (str | None)`
  * `video (genai.types.Blob | None)`



_field_ activity_end _:`Optional`[`ActivityEnd`]__= None_ _(alias 'activityEnd')_¶ 
    
Marks the end of user activity. 

_field_ activity_start _:`Optional`[`ActivityStart`]__= None_ _(alias 'activityStart')_¶ 
    
Marks the start of user activity. 

_field_ audio _:`Optional`[`Blob`]__= None_¶ 
    
The realtime audio input stream. 

_field_ audio_stream_end _:`Optional`[`bool`]__= None_ _(alias 'audioStreamEnd')_¶ 
    
Indicates that the audio stream has ended, e.g. because the microphone was turned off.
This should only be sent when automatic activity detection is enabled (which is the default).
The client can reopen the stream by sending an audio message. 

_field_ media_chunks _:`Optional`[`list`[`Blob`]]__= None_ _(alias 'mediaChunks')_¶ 
    
Inlined bytes data for media input. 

_field_ text _:`Optional`[`str`]__= None_¶ 
    
The realtime text input stream. 

_field_ video _:`Optional`[`Blob`]__= None_¶ 
    
The realtime video input stream. 

_class_ genai.types.LiveClientRealtimeInputDict¶ 
    
Bases: `TypedDict`
User input that is sent in real time.
This is different from LiveClientContent in a few ways:
>   * Can be sent continuously without interruption to model generation.
>   * If there is a need to mix data interleaved across the LiveClientContent and the LiveClientRealtimeInput, server attempts to optimize for best response, but there are no guarantees.
>   * End of turn is not explicitly specified, but is rather derived from user activity (for example, end of speech).
>   * Even before the end of turn, the data is processed incrementally to optimize for a fast start of the response from the model.
>   * Is always assumed to be the user’s input (cannot be used to populate conversation history).
> 


activity_end _:`Optional`[`ActivityEndDict`]_¶ 
    
Marks the end of user activity. 

activity_start _:`Optional`[`ActivityStartDict`]_¶ 
    
Marks the start of user activity. 

audio _:`Optional`[`BlobDict`]_¶ 
    
The realtime audio input stream. 

audio_stream_end _:`Optional`[`bool`]_¶ 
    
Indicates that the audio stream has ended, e.g. because the microphone was turned off.
This should only be sent when automatic activity detection is enabled (which is the default).
The client can reopen the stream by sending an audio message. 

media_chunks _:`Optional`[`list`[`BlobDict`]]_¶ 
    
Inlined bytes data for media input. 

text _:`Optional`[`str`]_¶ 
    
The realtime text input stream. 

video _:`Optional`[`BlobDict`]_¶ 
    
The realtime video input stream. 

_pydantic model_genai.types.LiveClientSetup¶ 
    
Bases: `BaseModel`
Message contains configuration that will apply for the duration of the streaming session.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"LiveClientSetup",
"description":"Message contains configuration that will apply for the duration of the streaming session.",
"type":"object",
"properties":{
"model":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"\n      The fully qualified name of the publisher model or tuned model endpoint to\n      use.\n      ",
"title":"Model"
},
"generationConfig":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The generation configuration for the session.\n      Note: only a subset of fields are supported.\n      "
},
"systemInstruction":{
"anyOf":[
{
"$ref":"#/$defs/Content"
},
{
"items":{
"anyOf":[
{
"$ref":"#/$defs/File"
},
{
"$ref":"#/$defs/Part"
},
{
"type":"string"
}
]
},
"type":"array"
},
{
"$ref":"#/$defs/File"
},
{
"$ref":"#/$defs/Part"
},
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The user provided system instructions for the model.\n      Note: only text should be used in parts and content in each part will be\n      in a separate paragraph.",
"title":"Systeminstruction"
},
"tools":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Tool"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":" A list of `Tools` the model may use to generate the next response.\n\n      A `Tool` is a piece of code that enables the system to interact with\n      external systems to perform an action, or set of actions, outside of\n      knowledge and scope of the model.",
"title":"Tools"
},
"sessionResumption":{
"anyOf":[
{
"$ref":"#/$defs/SessionResumptionConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Configures session resumption mechanism.\n\n          If included server will send SessionResumptionUpdate messages."
},
"contextWindowCompression":{
"anyOf":[
{
"$ref":"#/$defs/ContextWindowCompressionConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Configures context window compression mechanism.\n\n      If included, server will compress context window to fit into given length."
},
"inputAudioTranscription":{
"anyOf":[
{
"$ref":"#/$defs/AudioTranscriptionConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The transcription of the input aligns with the input audio language.\n      "
},
"outputAudioTranscription":{
"anyOf":[
{
"$ref":"#/$defs/AudioTranscriptionConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The transcription of the output aligns with the language code\n      specified for the output audio.\n      "
}
},
"$defs":{
"ApiKeyConfig":{
"additionalProperties":false,
"description":"Config for authentication with API key.",
"properties":{
"apiKeyString":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The API key to be used in the request directly.",
"title":"Apikeystring"
}
},
"title":"ApiKeyConfig",
"type":"object"
},
"AudioTranscriptionConfig":{
"additionalProperties":false,
"description":"The audio transcription configuration in Setup.",
"properties":{},
"title":"AudioTranscriptionConfig",
"type":"object"
},
"AuthConfig":{
"additionalProperties":false,
"description":"Auth configuration to run the extension.",
"properties":{
"apiKeyConfig":{
"anyOf":[
{
"$ref":"#/$defs/ApiKeyConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for API key auth."
},
"authType":{
"anyOf":[
{
"$ref":"#/$defs/AuthType"
},
{
"type":"null"
}
],
"default":null,
"description":"Type of auth scheme."
},
"googleServiceAccountConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigGoogleServiceAccountConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for Google Service Account auth."
},
"httpBasicAuthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigHttpBasicAuthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for HTTP Basic auth."
},
"oauthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOauthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user oauth."
},
"oidcConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOidcConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user OIDC auth."
}
},
"title":"AuthConfig",
"type":"object"
},
"AuthConfigGoogleServiceAccountConfig":{
"additionalProperties":false,
"description":"Config for Google Service Account Authentication.",
"properties":{
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The service account that the extension execution service runs as. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified service account. - If not specified, the Vertex AI Extension Service Agent will be used to execute the Extension.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigGoogleServiceAccountConfig",
"type":"object"
},
"AuthConfigHttpBasicAuthConfig":{
"additionalProperties":false,
"description":"Config for HTTP Basic Authentication.",
"properties":{
"credentialSecret":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the SecretManager secret version resource storing the base64 encoded credentials. Format: `projects/{project}/secrets/{secrete}/versions/{version}` - If specified, the `secretmanager.versions.access` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified resource.",
"title":"Credentialsecret"
}
},
"title":"AuthConfigHttpBasicAuthConfig",
"type":"object"
},
"AuthConfigOauthConfig":{
"additionalProperties":false,
"description":"Config for user oauth.",
"properties":{
"accessToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Access token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Accesstoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate access tokens for executing the Extension. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the provided service account.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOauthConfig",
"type":"object"
},
"AuthConfigOidcConfig":{
"additionalProperties":false,
"description":"Config for user OIDC auth.",
"properties":{
"idToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"OpenID Connect formatted ID token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Idtoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate an OpenID Connect (OIDC)-compatible JWT token signed by the Google OIDC Provider (accounts.google.com) for extension endpoint (https://cloud.google.com/iam/docs/create-short-lived-credentials-direct#sa-credentials-oidc). - The audience for the token will be set to the URL in the server url defined in the OpenApi spec. - If the service account is provided, the service account should grant `iam.serviceAccounts.getOpenIdToken` permission to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOidcConfig",
"type":"object"
},
"AuthType":{
"description":"Type of auth scheme.",
"enum":[
"AUTH_TYPE_UNSPECIFIED",
"NO_AUTH",
"API_KEY_AUTH",
"HTTP_BASIC_AUTH",
"GOOGLE_SERVICE_ACCOUNT_AUTH",
"OAUTH",
"OIDC_AUTH"
],
"title":"AuthType",
"type":"string"
},
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"Content":{
"additionalProperties":false,
"description":"Contains the multi-part content of a message.",
"properties":{
"parts":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Part"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of parts that constitute a single message. Each part may have\n      a different IANA MIME type.",
"title":"Parts"
},
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role.",
"title":"Role"
}
},
"title":"Content",
"type":"object"
},
"ContextWindowCompressionConfig":{
"additionalProperties":false,
"description":"Enables context window compression -- mechanism managing model context window so it does not exceed given length.",
"properties":{
"triggerTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens (before running turn) that triggers context window compression mechanism.",
"title":"Triggertokens"
},
"slidingWindow":{
"anyOf":[
{
"$ref":"#/$defs/SlidingWindow"
},
{
"type":"null"
}
],
"default":null,
"description":"Sliding window compression mechanism."
}
},
"title":"ContextWindowCompressionConfig",
"type":"object"
},
"DynamicRetrievalConfig":{
"additionalProperties":false,
"description":"Describes the options to customize dynamic retrieval.",
"properties":{
"mode":{
"anyOf":[
{
"$ref":"#/$defs/DynamicRetrievalConfigMode"
},
{
"type":"null"
}
],
"default":null,
"description":"The mode of the predictor to be used in dynamic retrieval."
},
"dynamicThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The threshold to be used in dynamic retrieval. If not set, a system default value is used.",
"title":"Dynamicthreshold"
}
},
"title":"DynamicRetrievalConfig",
"type":"object"
},
"DynamicRetrievalConfigMode":{
"description":"Config for the dynamic retrieval config mode.",
"enum":[
"MODE_UNSPECIFIED",
"MODE_DYNAMIC"
],
"title":"DynamicRetrievalConfigMode",
"type":"string"
},
"EnterpriseWebSearch":{
"additionalProperties":false,
"description":"Tool to search public web data, powered by Vertex AI Search and Sec4 compliance.",
"properties":{},
"title":"EnterpriseWebSearch",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"File":{
"additionalProperties":false,
"description":"A file uploaded to the API.",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The `File` resource name. The ID (name excluding the \"files/\" prefix) can contain up to 40 characters that are lowercase alphanumeric or dashes (-). The ID cannot start or end with a dash. If the name is empty on create, a unique name will be generated. Example: `files/123-456`",
"title":"Name"
},
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The human-readable display name for the `File`. The display name must be no more than 512 characters in length, including spaces. Example: 'Welcome Image'",
"title":"Displayname"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. MIME type of the file.",
"title":"Mimetype"
},
"sizeBytes":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Size of the file in bytes.",
"title":"Sizebytes"
},
"createTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` was created.",
"title":"Createtime"
},
"expirationTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` will be deleted. Only set if the `File` is scheduled to expire.",
"title":"Expirationtime"
},
"updateTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` was last updated.",
"title":"Updatetime"
},
"sha256Hash":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. SHA-256 hash of the uploaded bytes. The hash value is encoded in base64 format.",
"title":"Sha256Hash"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The URI of the `File`.",
"title":"Uri"
},
"downloadUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The URI of the `File`, only set for downloadable (generated) files.",
"title":"Downloaduri"
},
"state":{
"anyOf":[
{
"$ref":"#/$defs/FileState"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Processing state of the File."
},
"source":{
"anyOf":[
{
"$ref":"#/$defs/FileSource"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The source of the `File`."
},
"videoMetadata":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Metadata for a video.",
"title":"Videometadata"
},
"error":{
"anyOf":[
{
"$ref":"#/$defs/FileStatus"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Error status if File processing failed."
}
},
"title":"File",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FileSource":{
"description":"Source of the File.",
"enum":[
"SOURCE_UNSPECIFIED",
"UPLOADED",
"GENERATED"
],
"title":"FileSource",
"type":"string"
},
"FileState":{
"description":"State for the lifecycle of a File.",
"enum":[
"STATE_UNSPECIFIED",
"PROCESSING",
"ACTIVE",
"FAILED"
],
"title":"FileState",
"type":"string"
},
"FileStatus":{
"additionalProperties":false,
"description":"Status of a File that uses a common error model.",
"properties":{
"details":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Details"
},
"message":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Message"
},
"code":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The status code. 0 for OK, 1 for CANCELLED",
"title":"Code"
}
},
"title":"FileStatus",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionDeclaration":{
"additionalProperties":false,
"description":"Structured representation of a function declaration as defined by the [OpenAPI 3.0 specification](https://spec.openapis.org/oas/v3.0.3).\n\nIncluded in this declaration are the function name, description, parameters\nand response type. This FunctionDeclaration is a representation of a block of\ncode that can be used as a `Tool` by the model and executed by the client.",
"properties":{
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Description and purpose of the function. Model uses it to decide how and whether to call the function.",
"title":"Description"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Must start with a letter or an underscore. Must be a-z, A-Z, 0-9, or contain underscores, dots and dashes, with a maximum length of 64.",
"title":"Name"
},
"parameters":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Describes the parameters to this function in JSON Schema Object format. Reflects the Open API 3.03 Parameter Object. string Key: the name of the parameter. Parameter names are case sensitive. Schema Value: the Schema defining the type used for the parameter. For function with no parameters, this can be left unset. Parameter names must start with a letter or an underscore and must only contain chars a-z, A-Z, 0-9, or underscores with a maximum length of 64. Example with 1 required and 1 optional parameter: type: OBJECT properties: param1: type: STRING param2: type: INTEGER required: - param1"
},
"response":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Describes the output from this function in JSON Schema format. Reflects the Open API 3.03 Response Object. The Schema defines the type used for the response value of the function."
}
},
"title":"FunctionDeclaration",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"GenerationConfig":{
"additionalProperties":false,
"description":"Generation config.",
"properties":{
"audioTimestamp":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If enabled, audio timestamp will be included in the request to the model.",
"title":"Audiotimestamp"
},
"candidateCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of candidates to generate.",
"title":"Candidatecount"
},
"frequencyPenalty":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Frequency penalties.",
"title":"Frequencypenalty"
},
"logprobs":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Logit probabilities.",
"title":"Logprobs"
},
"maxOutputTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The maximum number of output tokens to generate per message.",
"title":"Maxoutputtokens"
},
"mediaResolution":{
"anyOf":[
{
"$ref":"#/$defs/MediaResolution"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If specified, the media resolution specified will be used."
},
"presencePenalty":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Positive penalties.",
"title":"Presencepenalty"
},
"responseLogprobs":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If true, export the logprobs results in response.",
"title":"Responselogprobs"
},
"responseMimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Output response mimetype of the generated candidate text. Supported mimetype: - `text/plain`: (default) Text output. - `application/json`: JSON response in the candidates. The model needs to be prompted to output the appropriate response type, otherwise the behavior is undefined. This is a preview feature.",
"title":"Responsemimetype"
},
"responseSchema":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The `Schema` object allows the definition of input and output data types. These types can be objects, but also primitives and arrays. Represents a select subset of an [OpenAPI 3.0 schema object](https://spec.openapis.org/oas/v3.0.3#schema). If set, a compatible response_mime_type must also be set. Compatible mimetypes: `application/json`: Schema for JSON response."
},
"routingConfig":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Routing configuration."
},
"seed":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Seed.",
"title":"Seed"
},
"stopSequences":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Stop sequences.",
"title":"Stopsequences"
},
"temperature":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Controls the randomness of predictions.",
"title":"Temperature"
},
"topK":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If specified, top-k sampling will be used.",
"title":"Topk"
},
"topP":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If specified, nucleus sampling will be used.",
"title":"Topp"
}
},
"title":"GenerationConfig",
"type":"object"
},
"GenerationConfigRoutingConfig":{
"additionalProperties":false,
"description":"The configuration for routing the request to a specific model.",
"properties":{
"autoMode":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfigAutoRoutingMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Automated routing."
},
"manualMode":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfigManualRoutingMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Manual routing."
}
},
"title":"GenerationConfigRoutingConfig",
"type":"object"
},
"GenerationConfigRoutingConfigAutoRoutingMode":{
"additionalProperties":false,
"description":"When automated routing is specified, the routing will be determined by the pretrained routing model and customer provided model routing preference.",
"properties":{
"modelRoutingPreference":{
"anyOf":[
{
"enum":[
"UNKNOWN",
"PRIORITIZE_QUALITY",
"BALANCED",
"PRIORITIZE_COST"
],
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The model routing preference.",
"title":"Modelroutingpreference"
}
},
"title":"GenerationConfigRoutingConfigAutoRoutingMode",
"type":"object"
},
"GenerationConfigRoutingConfigManualRoutingMode":{
"additionalProperties":false,
"description":"When manual routing is set, the specified model will be used directly.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The model name to use. Only the public LLM models are accepted. e.g. 'gemini-1.5-pro-001'.",
"title":"Modelname"
}
},
"title":"GenerationConfigRoutingConfigManualRoutingMode",
"type":"object"
},
"GoogleMaps":{
"additionalProperties":false,
"description":"Tool to support Google Maps in Model.",
"properties":{
"authConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Auth config for the Google Maps tool."
}
},
"title":"GoogleMaps",
"type":"object"
},
"GoogleSearch":{
"additionalProperties":false,
"description":"Tool to support Google Search in Model. Powered by Google.",
"properties":{},
"title":"GoogleSearch",
"type":"object"
},
"GoogleSearchRetrieval":{
"additionalProperties":false,
"description":"Tool to retrieve public web data for grounding, powered by Google.",
"properties":{
"dynamicRetrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/DynamicRetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the dynamic retrieval configuration for the given source."
}
},
"title":"GoogleSearchRetrieval",
"type":"object"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"MediaResolution":{
"description":"The media resolution to use.",
"enum":[
"MEDIA_RESOLUTION_UNSPECIFIED",
"MEDIA_RESOLUTION_LOW",
"MEDIA_RESOLUTION_MEDIUM",
"MEDIA_RESOLUTION_HIGH"
],
"title":"MediaResolution",
"type":"string"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"RagRetrievalConfig":{
"additionalProperties":false,
"description":"Specifies the context retrieval config.",
"properties":{
"filter":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigFilter"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for filters."
},
"hybridSearch":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigHybridSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Hybrid Search."
},
"ranking":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRanking"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for ranking and reranking."
},
"topK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The number of contexts to retrieve.",
"title":"Topk"
}
},
"title":"RagRetrievalConfig",
"type":"object"
},
"RagRetrievalConfigFilter":{
"additionalProperties":false,
"description":"Config for filters.",
"properties":{
"metadataFilter":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. String for metadata filtering.",
"title":"Metadatafilter"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
},
"vectorSimilarityThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector similarity larger than the threshold.",
"title":"Vectorsimilaritythreshold"
}
},
"title":"RagRetrievalConfigFilter",
"type":"object"
},
"RagRetrievalConfigHybridSearch":{
"additionalProperties":false,
"description":"Config for Hybrid Search.",
"properties":{
"alpha":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally.",
"title":"Alpha"
}
},
"title":"RagRetrievalConfigHybridSearch",
"type":"object"
},
"RagRetrievalConfigRanking":{
"additionalProperties":false,
"description":"Config for ranking and reranking.",
"properties":{
"llmRanker":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingLlmRanker"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for LlmRanker."
},
"rankService":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingRankService"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Rank Service."
}
},
"title":"RagRetrievalConfigRanking",
"type":"object"
},
"RagRetrievalConfigRankingLlmRanker":{
"additionalProperties":false,
"description":"Config for LlmRanker.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name used for ranking. Format: `gemini-1.5-pro`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingLlmRanker",
"type":"object"
},
"RagRetrievalConfigRankingRankService":{
"additionalProperties":false,
"description":"Config for Rank Service.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name of the rank service. Format: `semantic-ranker-512@latest`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingRankService",
"type":"object"
},
"Retrieval":{
"additionalProperties":false,
"description":"Defines a retrieval tool that model can call to access external knowledge.",
"properties":{
"disableAttribution":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Deprecated. This option is no longer supported.",
"title":"Disableattribution"
},
"vertexAiSearch":{
"anyOf":[
{
"$ref":"#/$defs/VertexAISearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Set to use data source powered by Vertex AI Search."
},
"vertexRagStore":{
"anyOf":[
{
"$ref":"#/$defs/VertexRagStore"
},
{
"type":"null"
}
],
"default":null,
"description":"Set to use data source powered by Vertex RAG store. User data is uploaded via the VertexRagDataService."
}
},
"title":"Retrieval",
"type":"object"
},
"Schema":{
"additionalProperties":false,
"description":"Schema is used to define the format of input/output data.\n\nRepresents a select subset of an [OpenAPI 3.0 schema\nobject](https://spec.openapis.org/oas/v3.0.3#schema-object). More fields may\nbe added in the future as needed.",
"properties":{
"anyOf":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Schema"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The value should be validated against any (one or more) of the subschemas in the list.",
"title":"Anyof"
},
"default":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Default value of the data.",
"title":"Default"
},
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The description of the data.",
"title":"Description"
},
"enum":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Possible values of the element of primitive type with enum format. Examples: 1. We can define direction as : {type:STRING, format:enum, enum:[\"EAST\", NORTH\", \"SOUTH\", \"WEST\"]} 2. We can define apartment number as : {type:INTEGER, format:enum, enum:[\"101\", \"201\", \"301\"]}",
"title":"Enum"
},
"example":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Example of the object. Will only populated when the object is the root.",
"title":"Example"
},
"format":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The format of the data. Supported formats: for NUMBER type: \"float\", \"double\" for INTEGER type: \"int32\", \"int64\" for STRING type: \"email\", \"byte\", etc",
"title":"Format"
},
"items":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE ARRAY Schema of the elements of Type.ARRAY."
},
"maxItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the elements for Type.ARRAY.",
"title":"Maxitems"
},
"maxLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum length of the Type.STRING",
"title":"Maxlength"
},
"maxProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the properties for Type.OBJECT.",
"title":"Maxproperties"
},
"maximum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum value of the Type.INTEGER and Type.NUMBER",
"title":"Maximum"
},
"minItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the elements for Type.ARRAY.",
"title":"Minitems"
},
"minLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING",
"title":"Minlength"
},
"minProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the properties for Type.OBJECT.",
"title":"Minproperties"
},
"minimum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER Minimum value of the Type.INTEGER and Type.NUMBER",
"title":"Minimum"
},
"nullable":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Indicates if the value may be null.",
"title":"Nullable"
},
"pattern":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Pattern of the Type.STRING to restrict a string to a regular expression.",
"title":"Pattern"
},
"properties":{
"anyOf":[
{
"additionalProperties":{
"$ref":"#/$defs/Schema"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE OBJECT Properties of Type.OBJECT.",
"title":"Properties"
},
"propertyOrdering":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The order of the properties. Not a standard field in open api spec. Only used to support the order of the properties.",
"title":"Propertyordering"
},
"required":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required properties of Type.OBJECT.",
"title":"Required"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The title of the Schema.",
"title":"Title"
},
"type":{
"anyOf":[
{
"$ref":"#/$defs/Type"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The type of the data."
}
},
"title":"Schema",
"type":"object"
},
"SessionResumptionConfig":{
"additionalProperties":false,
"description":"Configuration of session resumption mechanism.\n\nIncluded in `LiveConnectConfig.session_resumption`. If included server\nwill send `LiveServerSessionResumptionUpdate` messages.",
"properties":{
"handle":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Session resumption handle of previous session (session to restore).\n\nIf not present new session will be started.",
"title":"Handle"
},
"transparent":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If set the server will send `last_consumed_client_message_index` in the `session_resumption_update` messages to allow for transparent reconnections.",
"title":"Transparent"
}
},
"title":"SessionResumptionConfig",
"type":"object"
},
"SlidingWindow":{
"additionalProperties":false,
"description":"Context window will be truncated by keeping only suffix of it.\n\nContext window will always be cut at start of USER role turn. System\ninstructions and `BidiGenerateContentSetup.prefix_turns` will not be\nsubject to the sliding window mechanism, they will always stay at the\nbeginning of context window.",
"properties":{
"targetTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Session reduction target -- how many tokens we should keep. Window shortening operation has some latency costs, so we should avoid running it on every turn. Should be < trigger_tokens. If not set, trigger_tokens/2 is assumed.",
"title":"Targettokens"
}
},
"title":"SlidingWindow",
"type":"object"
},
"Tool":{
"additionalProperties":false,
"description":"Tool details of a tool that the model may use to generate a response.",
"properties":{
"retrieval":{
"anyOf":[
{
"$ref":"#/$defs/Retrieval"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Retrieval tool type. System will always execute the provided retrieval tool(s) to get external knowledge to answer the prompt. Retrieval results are presented to the model for generation."
},
"googleSearch":{
"anyOf":[
{
"$ref":"#/$defs/GoogleSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google Search tool type. Specialized retrieval tool\n      that is powered by Google Search."
},
"googleSearchRetrieval":{
"anyOf":[
{
"$ref":"#/$defs/GoogleSearchRetrieval"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. GoogleSearchRetrieval tool type. Specialized retrieval tool that is powered by Google search."
},
"enterpriseWebSearch":{
"anyOf":[
{
"$ref":"#/$defs/EnterpriseWebSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Enterprise web search tool type. Specialized retrieval\n      tool that is powered by Vertex AI Search and Sec4 compliance."
},
"googleMaps":{
"anyOf":[
{
"$ref":"#/$defs/GoogleMaps"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google Maps tool type. Specialized retrieval tool\n      that is powered by Google Maps."
},
"codeExecution":{
"anyOf":[
{
"$ref":"#/$defs/ToolCodeExecution"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. CodeExecution tool type. Enables the model to execute code as part of generation. This field is only used by the Gemini Developer API services."
},
"functionDeclarations":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/FunctionDeclaration"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Function tool type. One or more function declarations to be passed to the model along with the current user query. Model may decide to call a subset of these functions by populating FunctionCall in the response. User should provide a FunctionResponse for each function call in the next turn. Based on the function responses, Model will generate the final response back to the user. Maximum 128 function declarations can be provided.",
"title":"Functiondeclarations"
}
},
"title":"Tool",
"type":"object"
},
"ToolCodeExecution":{
"additionalProperties":false,
"description":"Tool that executes code generated by the model, and automatically returns the result to the model.\n\nSee also [ExecutableCode]and [CodeExecutionResult] which are input and output\nto this tool.",
"properties":{},
"title":"ToolCodeExecution",
"type":"object"
},
"Type":{
"description":"Optional. The type of the data.",
"enum":[
"TYPE_UNSPECIFIED",
"STRING",
"NUMBER",
"INTEGER",
"BOOLEAN",
"ARRAY",
"OBJECT"
],
"title":"Type",
"type":"string"
},
"VertexAISearch":{
"additionalProperties":false,
"description":"Retrieve from Vertex AI Search datastore or engine for grounding.\n\ndatastore and engine are mutually exclusive. See\nhttps://cloud.google.com/products/agent-builder",
"properties":{
"datastore":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search data store resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`",
"title":"Datastore"
},
"engine":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search engine resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}`",
"title":"Engine"
}
},
"title":"VertexAISearch",
"type":"object"
},
"VertexRagStore":{
"additionalProperties":false,
"description":"Retrieve from Vertex RAG Store for grounding.",
"properties":{
"ragCorpora":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Deprecated. Please use rag_resources instead.",
"title":"Ragcorpora"
},
"ragResources":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/VertexRagStoreRagResource"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The representation of the rag source. It can be used to specify corpus only or ragfiles. Currently only support one corpus or multiple files from one corpus. In the future we may open up multiple corpora support.",
"title":"Ragresources"
},
"ragRetrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The retrieval config for the Rag query."
},
"similarityTopK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of top k results to return from the selected corpora.",
"title":"Similaritytopk"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only return results with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
}
},
"title":"VertexRagStore",
"type":"object"
},
"VertexRagStoreRagResource":{
"additionalProperties":false,
"description":"The definition of the Rag resource.",
"properties":{
"ragCorpus":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. RagCorpora resource name. Format: `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`",
"title":"Ragcorpus"
},
"ragFileIds":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus field.",
"title":"Ragfileids"
}
},
"title":"VertexRagStoreRagResource",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `context_window_compression (genai.types.ContextWindowCompressionConfig | None)`
  * `generation_config (genai.types.GenerationConfig | None)`
  * `input_audio_transcription (genai.types.AudioTranscriptionConfig | None)`
  * `model (str | None)`
  * `output_audio_transcription (genai.types.AudioTranscriptionConfig | None)`
  * `session_resumption (genai.types.SessionResumptionConfig | None)`
  * `system_instruction (genai.types.Content | list[genai.types.File | genai.types.Part | PIL.Image.Image | str] | genai.types.File | genai.types.Part | PIL.Image.Image | str | None)`
  * `tools (list[genai.types.Tool | Callable[[...], Any]] | None)`



_field_ context_window_compression _:`Optional`[`ContextWindowCompressionConfig`]__= None_ _(alias 'contextWindowCompression')_¶ 
    
Configures context window compression mechanism.
If included, server will compress context window to fit into given length. 

_field_ generation_config _:`Optional`[`GenerationConfig`]__= None_ _(alias 'generationConfig')_¶ 
    
The generation configuration for the session. Note: only a subset of fields are supported. 

_field_ input_audio_transcription _:`Optional`[`AudioTranscriptionConfig`]__= None_ _(alias 'inputAudioTranscription')_¶ 
    
The transcription of the input aligns with the input audio language. 

_field_ model _:`Optional`[`str`]__= None_¶ 
    
The fully qualified name of the publisher model or tuned model endpoint to use. 

_field_ output_audio_transcription _:`Optional`[`AudioTranscriptionConfig`]__= None_ _(alias 'outputAudioTranscription')_¶ 
    
The transcription of the output aligns with the language code specified for the output audio. 

_field_ session_resumption _:`Optional`[`SessionResumptionConfig`]__= None_ _(alias 'sessionResumption')_¶ 
    
Configures session resumption mechanism.
If included server will send SessionResumptionUpdate messages. 

_field_ system_instruction _:`Union`[`Content`, `list`[`Union`[`File`, `Part`, `Image`, `str`]], `File`, `Part`, `Image`, `str`, `None`]__= None_ _(alias 'systemInstruction')_¶ 
    
The user provided system instructions for the model. Note: only text should be used in parts and content in each part will be in a separate paragraph. 

_field_ tools _:`Optional`[`list`[`Union`[`Tool`, `Callable`[`...`, `Any`]]]]__= None_¶ 
    
A list of Tools the model may use to generate the next response.
A Tool is a piece of code that enables the system to interact with external systems to perform an action, or set of actions, outside of knowledge and scope of the model. 

_class_ genai.types.LiveClientSetupDict¶ 
    
Bases: `TypedDict`
Message contains configuration that will apply for the duration of the streaming session. 

context_window_compression _:`Optional`[`ContextWindowCompressionConfigDict`]_¶ 
    
Configures context window compression mechanism.
If included, server will compress context window to fit into given length. 

generation_config _:`Optional`[`GenerationConfigDict`]_¶ 
    
The generation configuration for the session. Note: only a subset of fields are supported. 

input_audio_transcription _:`Optional`[`AudioTranscriptionConfigDict`]_¶ 
    
The transcription of the input aligns with the input audio language. 

model _:`Optional`[`str`]_¶ 
    
The fully qualified name of the publisher model or tuned model endpoint to use. 

output_audio_transcription _:`Optional`[`AudioTranscriptionConfigDict`]_¶ 
    
The transcription of the output aligns with the language code specified for the output audio. 

session_resumption _:`Optional`[`SessionResumptionConfigDict`]_¶ 
    
Configures session resumption mechanism.
If included server will send SessionResumptionUpdate messages. 

system_instruction _:`Union`[`Content`, `list`[`Union`[`File`, `Part`, `Image`, `str`]], `File`, `Part`, `Image`, `str`, `ContentDict`, `None`]_¶ 
    
The user provided system instructions for the model. Note: only text should be used in parts and content in each part will be in a separate paragraph. 

tools _:`Optional`[`list`[`Union`[`ToolDict`, `Callable`[`...`, `Any`]]]]_¶ 
    
A list of Tools the model may use to generate the next response.
A Tool is a piece of code that enables the system to interact with external systems to perform an action, or set of actions, outside of knowledge and scope of the model. 

_pydantic model_genai.types.LiveClientToolResponse¶ 
    
Bases: `BaseModel`
Client generated response to a ToolCall received from the server.
Individual FunctionResponse objects are matched to the respective FunctionCall objects by the id field.
Note that in the unary and server-streaming GenerateContent APIs function calling happens by exchanging the Content parts, while in the bidi GenerateContent APIs function calling happens over this dedicated set of messages.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"LiveClientToolResponse",
"description":"Client generated response to a `ToolCall` received from the server.\n\nIndividual `FunctionResponse` objects are matched to the respective\n`FunctionCall` objects by the `id` field.\n\nNote that in the unary and server-streaming GenerateContent APIs function\ncalling happens by exchanging the `Content` parts, while in the bidi\nGenerateContent APIs function calling happens over this dedicated set of\nmessages.",
"type":"object",
"properties":{
"functionResponses":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/FunctionResponse"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The response to the function calls.",
"title":"Functionresponses"
}
},
"$defs":{
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `function_responses (list[genai.types.FunctionResponse] | None)`



_field_ function_responses _:`Optional`[`list`[`FunctionResponse`]]__= None_ _(alias 'functionResponses')_¶ 
    
The response to the function calls. 

_class_ genai.types.LiveClientToolResponseDict¶ 
    
Bases: `TypedDict`
Client generated response to a ToolCall received from the server.
Individual FunctionResponse objects are matched to the respective FunctionCall objects by the id field.
Note that in the unary and server-streaming GenerateContent APIs function calling happens by exchanging the Content parts, while in the bidi GenerateContent APIs function calling happens over this dedicated set of messages. 

function_responses _:`Optional`[`list`[`FunctionResponseDict`]]_¶ 
    
The response to the function calls. 

_pydantic model_genai.types.LiveConnectConfig¶ 
    
Bases: `BaseModel`
Session config for the API connection.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"LiveConnectConfig",
"description":"Session config for the API connection.",
"type":"object",
"properties":{
"generationConfig":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The generation configuration for the session."
},
"responseModalities":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Modality"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The requested modalities of the response. Represents the set of\n      modalities that the model can return. Defaults to AUDIO if not specified.\n      ",
"title":"Responsemodalities"
},
"temperature":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Value that controls the degree of randomness in token selection.\n      Lower temperatures are good for prompts that require a less open-ended or\n      creative response, while higher temperatures can lead to more diverse or\n      creative results.\n      ",
"title":"Temperature"
},
"topP":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Tokens are selected from the most to least probable until the sum\n      of their probabilities equals this value. Use a lower value for less\n      random responses and a higher value for more random responses.\n      ",
"title":"Topp"
},
"topK":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"For each token selection step, the ``top_k`` tokens with the\n      highest probabilities are sampled. Then tokens are further filtered based\n      on ``top_p`` with the final token selected using temperature sampling. Use\n      a lower number for less random responses and a higher number for more\n      random responses.\n      ",
"title":"Topk"
},
"maxOutputTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Maximum number of tokens that can be generated in the response.\n      ",
"title":"Maxoutputtokens"
},
"mediaResolution":{
"anyOf":[
{
"$ref":"#/$defs/MediaResolution"
},
{
"type":"null"
}
],
"default":null,
"description":"If specified, the media resolution specified will be used.\n      "
},
"seed":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"When ``seed`` is fixed to a specific number, the model makes a best\n      effort to provide the same response for repeated requests. By default, a\n      random number is used.\n      ",
"title":"Seed"
},
"speechConfig":{
"anyOf":[
{
"$ref":"#/$defs/SpeechConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The speech generation configuration.\n      "
},
"systemInstruction":{
"anyOf":[
{
"$ref":"#/$defs/Content"
},
{
"items":{
"anyOf":[
{
"$ref":"#/$defs/File"
},
{
"$ref":"#/$defs/Part"
},
{
"type":"string"
}
]
},
"type":"array"
},
{
"$ref":"#/$defs/File"
},
{
"$ref":"#/$defs/Part"
},
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The user provided system instructions for the model.\n      Note: only text should be used in parts and content in each part will be\n      in a separate paragraph.",
"title":"Systeminstruction"
},
"tools":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Tool"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of `Tools` the model may use to generate the next response.\n\n      A `Tool` is a piece of code that enables the system to interact with\n      external systems to perform an action, or set of actions, outside of\n      knowledge and scope of the model.",
"title":"Tools"
},
"sessionResumption":{
"anyOf":[
{
"$ref":"#/$defs/SessionResumptionConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Configures session resumption mechanism.\n\nIf included the server will send SessionResumptionUpdate messages."
},
"inputAudioTranscription":{
"anyOf":[
{
"$ref":"#/$defs/AudioTranscriptionConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The transcription of the input aligns with the input audio language.\n      "
},
"outputAudioTranscription":{
"anyOf":[
{
"$ref":"#/$defs/AudioTranscriptionConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The transcription of the output aligns with the language code\n      specified for the output audio.\n      "
},
"realtimeInputConfig":{
"anyOf":[
{
"$ref":"#/$defs/RealtimeInputConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Configures the realtime input behavior in BidiGenerateContent."
},
"contextWindowCompression":{
"anyOf":[
{
"$ref":"#/$defs/ContextWindowCompressionConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Configures context window compression mechanism.\n\n      If included, server will compress context window to fit into given length."
}
},
"$defs":{
"ActivityHandling":{
"description":"The different ways of handling user activity.",
"enum":[
"ACTIVITY_HANDLING_UNSPECIFIED",
"START_OF_ACTIVITY_INTERRUPTS",
"NO_INTERRUPTION"
],
"title":"ActivityHandling",
"type":"string"
},
"ApiKeyConfig":{
"additionalProperties":false,
"description":"Config for authentication with API key.",
"properties":{
"apiKeyString":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The API key to be used in the request directly.",
"title":"Apikeystring"
}
},
"title":"ApiKeyConfig",
"type":"object"
},
"AudioTranscriptionConfig":{
"additionalProperties":false,
"description":"The audio transcription configuration in Setup.",
"properties":{},
"title":"AudioTranscriptionConfig",
"type":"object"
},
"AuthConfig":{
"additionalProperties":false,
"description":"Auth configuration to run the extension.",
"properties":{
"apiKeyConfig":{
"anyOf":[
{
"$ref":"#/$defs/ApiKeyConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for API key auth."
},
"authType":{
"anyOf":[
{
"$ref":"#/$defs/AuthType"
},
{
"type":"null"
}
],
"default":null,
"description":"Type of auth scheme."
},
"googleServiceAccountConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigGoogleServiceAccountConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for Google Service Account auth."
},
"httpBasicAuthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigHttpBasicAuthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for HTTP Basic auth."
},
"oauthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOauthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user oauth."
},
"oidcConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOidcConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user OIDC auth."
}
},
"title":"AuthConfig",
"type":"object"
},
"AuthConfigGoogleServiceAccountConfig":{
"additionalProperties":false,
"description":"Config for Google Service Account Authentication.",
"properties":{
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The service account that the extension execution service runs as. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified service account. - If not specified, the Vertex AI Extension Service Agent will be used to execute the Extension.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigGoogleServiceAccountConfig",
"type":"object"
},
"AuthConfigHttpBasicAuthConfig":{
"additionalProperties":false,
"description":"Config for HTTP Basic Authentication.",
"properties":{
"credentialSecret":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the SecretManager secret version resource storing the base64 encoded credentials. Format: `projects/{project}/secrets/{secrete}/versions/{version}` - If specified, the `secretmanager.versions.access` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified resource.",
"title":"Credentialsecret"
}
},
"title":"AuthConfigHttpBasicAuthConfig",
"type":"object"
},
"AuthConfigOauthConfig":{
"additionalProperties":false,
"description":"Config for user oauth.",
"properties":{
"accessToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Access token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Accesstoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate access tokens for executing the Extension. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the provided service account.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOauthConfig",
"type":"object"
},
"AuthConfigOidcConfig":{
"additionalProperties":false,
"description":"Config for user OIDC auth.",
"properties":{
"idToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"OpenID Connect formatted ID token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Idtoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate an OpenID Connect (OIDC)-compatible JWT token signed by the Google OIDC Provider (accounts.google.com) for extension endpoint (https://cloud.google.com/iam/docs/create-short-lived-credentials-direct#sa-credentials-oidc). - The audience for the token will be set to the URL in the server url defined in the OpenApi spec. - If the service account is provided, the service account should grant `iam.serviceAccounts.getOpenIdToken` permission to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOidcConfig",
"type":"object"
},
"AuthType":{
"description":"Type of auth scheme.",
"enum":[
"AUTH_TYPE_UNSPECIFIED",
"NO_AUTH",
"API_KEY_AUTH",
"HTTP_BASIC_AUTH",
"GOOGLE_SERVICE_ACCOUNT_AUTH",
"OAUTH",
"OIDC_AUTH"
],
"title":"AuthType",
"type":"string"
},
"AutomaticActivityDetection":{
"additionalProperties":false,
"description":"Configures automatic detection of activity.",
"properties":{
"disabled":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If enabled, detected voice and text input count as activity. If disabled, the client must send activity signals.",
"title":"Disabled"
},
"startOfSpeechSensitivity":{
"anyOf":[
{
"$ref":"#/$defs/StartSensitivity"
},
{
"type":"null"
}
],
"default":null,
"description":"Determines how likely speech is to be detected."
},
"endOfSpeechSensitivity":{
"anyOf":[
{
"$ref":"#/$defs/EndSensitivity"
},
{
"type":"null"
}
],
"default":null,
"description":"Determines how likely detected speech is ended."
},
"prefixPaddingMs":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The required duration of detected speech before start-of-speech is committed. The lower this value the more sensitive the start-of-speech detection is and the shorter speech can be recognized. However, this also increases the probability of false positives.",
"title":"Prefixpaddingms"
},
"silenceDurationMs":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The required duration of detected non-speech (e.g. silence) before end-of-speech is committed. The larger this value, the longer speech gaps can be without interrupting the user's activity but this will increase the model's latency.",
"title":"Silencedurationms"
}
},
"title":"AutomaticActivityDetection",
"type":"object"
},
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"Content":{
"additionalProperties":false,
"description":"Contains the multi-part content of a message.",
"properties":{
"parts":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Part"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of parts that constitute a single message. Each part may have\n      a different IANA MIME type.",
"title":"Parts"
},
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role.",
"title":"Role"
}
},
"title":"Content",
"type":"object"
},
"ContextWindowCompressionConfig":{
"additionalProperties":false,
"description":"Enables context window compression -- mechanism managing model context window so it does not exceed given length.",
"properties":{
"triggerTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens (before running turn) that triggers context window compression mechanism.",
"title":"Triggertokens"
},
"slidingWindow":{
"anyOf":[
{
"$ref":"#/$defs/SlidingWindow"
},
{
"type":"null"
}
],
"default":null,
"description":"Sliding window compression mechanism."
}
},
"title":"ContextWindowCompressionConfig",
"type":"object"
},
"DynamicRetrievalConfig":{
"additionalProperties":false,
"description":"Describes the options to customize dynamic retrieval.",
"properties":{
"mode":{
"anyOf":[
{
"$ref":"#/$defs/DynamicRetrievalConfigMode"
},
{
"type":"null"
}
],
"default":null,
"description":"The mode of the predictor to be used in dynamic retrieval."
},
"dynamicThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The threshold to be used in dynamic retrieval. If not set, a system default value is used.",
"title":"Dynamicthreshold"
}
},
"title":"DynamicRetrievalConfig",
"type":"object"
},
"DynamicRetrievalConfigMode":{
"description":"Config for the dynamic retrieval config mode.",
"enum":[
"MODE_UNSPECIFIED",
"MODE_DYNAMIC"
],
"title":"DynamicRetrievalConfigMode",
"type":"string"
},
"EndSensitivity":{
"description":"End of speech sensitivity.",
"enum":[
"END_SENSITIVITY_UNSPECIFIED",
"END_SENSITIVITY_HIGH",
"END_SENSITIVITY_LOW"
],
"title":"EndSensitivity",
"type":"string"
},
"EnterpriseWebSearch":{
"additionalProperties":false,
"description":"Tool to search public web data, powered by Vertex AI Search and Sec4 compliance.",
"properties":{},
"title":"EnterpriseWebSearch",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"File":{
"additionalProperties":false,
"description":"A file uploaded to the API.",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The `File` resource name. The ID (name excluding the \"files/\" prefix) can contain up to 40 characters that are lowercase alphanumeric or dashes (-). The ID cannot start or end with a dash. If the name is empty on create, a unique name will be generated. Example: `files/123-456`",
"title":"Name"
},
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The human-readable display name for the `File`. The display name must be no more than 512 characters in length, including spaces. Example: 'Welcome Image'",
"title":"Displayname"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. MIME type of the file.",
"title":"Mimetype"
},
"sizeBytes":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Size of the file in bytes.",
"title":"Sizebytes"
},
"createTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` was created.",
"title":"Createtime"
},
"expirationTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` will be deleted. Only set if the `File` is scheduled to expire.",
"title":"Expirationtime"
},
"updateTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` was last updated.",
"title":"Updatetime"
},
"sha256Hash":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. SHA-256 hash of the uploaded bytes. The hash value is encoded in base64 format.",
"title":"Sha256Hash"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The URI of the `File`.",
"title":"Uri"
},
"downloadUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The URI of the `File`, only set for downloadable (generated) files.",
"title":"Downloaduri"
},
"state":{
"anyOf":[
{
"$ref":"#/$defs/FileState"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Processing state of the File."
},
"source":{
"anyOf":[
{
"$ref":"#/$defs/FileSource"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The source of the `File`."
},
"videoMetadata":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Metadata for a video.",
"title":"Videometadata"
},
"error":{
"anyOf":[
{
"$ref":"#/$defs/FileStatus"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Error status if File processing failed."
}
},
"title":"File",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FileSource":{
"description":"Source of the File.",
"enum":[
"SOURCE_UNSPECIFIED",
"UPLOADED",
"GENERATED"
],
"title":"FileSource",
"type":"string"
},
"FileState":{
"description":"State for the lifecycle of a File.",
"enum":[
"STATE_UNSPECIFIED",
"PROCESSING",
"ACTIVE",
"FAILED"
],
"title":"FileState",
"type":"string"
},
"FileStatus":{
"additionalProperties":false,
"description":"Status of a File that uses a common error model.",
"properties":{
"details":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Details"
},
"message":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Message"
},
"code":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The status code. 0 for OK, 1 for CANCELLED",
"title":"Code"
}
},
"title":"FileStatus",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionDeclaration":{
"additionalProperties":false,
"description":"Structured representation of a function declaration as defined by the [OpenAPI 3.0 specification](https://spec.openapis.org/oas/v3.0.3).\n\nIncluded in this declaration are the function name, description, parameters\nand response type. This FunctionDeclaration is a representation of a block of\ncode that can be used as a `Tool` by the model and executed by the client.",
"properties":{
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Description and purpose of the function. Model uses it to decide how and whether to call the function.",
"title":"Description"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Must start with a letter or an underscore. Must be a-z, A-Z, 0-9, or contain underscores, dots and dashes, with a maximum length of 64.",
"title":"Name"
},
"parameters":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Describes the parameters to this function in JSON Schema Object format. Reflects the Open API 3.03 Parameter Object. string Key: the name of the parameter. Parameter names are case sensitive. Schema Value: the Schema defining the type used for the parameter. For function with no parameters, this can be left unset. Parameter names must start with a letter or an underscore and must only contain chars a-z, A-Z, 0-9, or underscores with a maximum length of 64. Example with 1 required and 1 optional parameter: type: OBJECT properties: param1: type: STRING param2: type: INTEGER required: - param1"
},
"response":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Describes the output from this function in JSON Schema format. Reflects the Open API 3.03 Response Object. The Schema defines the type used for the response value of the function."
}
},
"title":"FunctionDeclaration",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"GenerationConfig":{
"additionalProperties":false,
"description":"Generation config.",
"properties":{
"audioTimestamp":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If enabled, audio timestamp will be included in the request to the model.",
"title":"Audiotimestamp"
},
"candidateCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of candidates to generate.",
"title":"Candidatecount"
},
"frequencyPenalty":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Frequency penalties.",
"title":"Frequencypenalty"
},
"logprobs":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Logit probabilities.",
"title":"Logprobs"
},
"maxOutputTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The maximum number of output tokens to generate per message.",
"title":"Maxoutputtokens"
},
"mediaResolution":{
"anyOf":[
{
"$ref":"#/$defs/MediaResolution"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If specified, the media resolution specified will be used."
},
"presencePenalty":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Positive penalties.",
"title":"Presencepenalty"
},
"responseLogprobs":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If true, export the logprobs results in response.",
"title":"Responselogprobs"
},
"responseMimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Output response mimetype of the generated candidate text. Supported mimetype: - `text/plain`: (default) Text output. - `application/json`: JSON response in the candidates. The model needs to be prompted to output the appropriate response type, otherwise the behavior is undefined. This is a preview feature.",
"title":"Responsemimetype"
},
"responseSchema":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The `Schema` object allows the definition of input and output data types. These types can be objects, but also primitives and arrays. Represents a select subset of an [OpenAPI 3.0 schema object](https://spec.openapis.org/oas/v3.0.3#schema). If set, a compatible response_mime_type must also be set. Compatible mimetypes: `application/json`: Schema for JSON response."
},
"routingConfig":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Routing configuration."
},
"seed":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Seed.",
"title":"Seed"
},
"stopSequences":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Stop sequences.",
"title":"Stopsequences"
},
"temperature":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Controls the randomness of predictions.",
"title":"Temperature"
},
"topK":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If specified, top-k sampling will be used.",
"title":"Topk"
},
"topP":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If specified, nucleus sampling will be used.",
"title":"Topp"
}
},
"title":"GenerationConfig",
"type":"object"
},
"GenerationConfigRoutingConfig":{
"additionalProperties":false,
"description":"The configuration for routing the request to a specific model.",
"properties":{
"autoMode":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfigAutoRoutingMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Automated routing."
},
"manualMode":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfigManualRoutingMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Manual routing."
}
},
"title":"GenerationConfigRoutingConfig",
"type":"object"
},
"GenerationConfigRoutingConfigAutoRoutingMode":{
"additionalProperties":false,
"description":"When automated routing is specified, the routing will be determined by the pretrained routing model and customer provided model routing preference.",
"properties":{
"modelRoutingPreference":{
"anyOf":[
{
"enum":[
"UNKNOWN",
"PRIORITIZE_QUALITY",
"BALANCED",
"PRIORITIZE_COST"
],
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The model routing preference.",
"title":"Modelroutingpreference"
}
},
"title":"GenerationConfigRoutingConfigAutoRoutingMode",
"type":"object"
},
"GenerationConfigRoutingConfigManualRoutingMode":{
"additionalProperties":false,
"description":"When manual routing is set, the specified model will be used directly.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The model name to use. Only the public LLM models are accepted. e.g. 'gemini-1.5-pro-001'.",
"title":"Modelname"
}
},
"title":"GenerationConfigRoutingConfigManualRoutingMode",
"type":"object"
},
"GoogleMaps":{
"additionalProperties":false,
"description":"Tool to support Google Maps in Model.",
"properties":{
"authConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Auth config for the Google Maps tool."
}
},
"title":"GoogleMaps",
"type":"object"
},
"GoogleSearch":{
"additionalProperties":false,
"description":"Tool to support Google Search in Model. Powered by Google.",
"properties":{},
"title":"GoogleSearch",
"type":"object"
},
"GoogleSearchRetrieval":{
"additionalProperties":false,
"description":"Tool to retrieve public web data for grounding, powered by Google.",
"properties":{
"dynamicRetrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/DynamicRetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the dynamic retrieval configuration for the given source."
}
},
"title":"GoogleSearchRetrieval",
"type":"object"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"MediaResolution":{
"description":"The media resolution to use.",
"enum":[
"MEDIA_RESOLUTION_UNSPECIFIED",
"MEDIA_RESOLUTION_LOW",
"MEDIA_RESOLUTION_MEDIUM",
"MEDIA_RESOLUTION_HIGH"
],
"title":"MediaResolution",
"type":"string"
},
"Modality":{
"description":"Server content modalities.",
"enum":[
"MODALITY_UNSPECIFIED",
"TEXT",
"IMAGE",
"AUDIO"
],
"title":"Modality",
"type":"string"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"PrebuiltVoiceConfig":{
"additionalProperties":false,
"description":"The configuration for the prebuilt speaker to use.",
"properties":{
"voiceName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The name of the prebuilt voice to use.\n      ",
"title":"Voicename"
}
},
"title":"PrebuiltVoiceConfig",
"type":"object"
},
"RagRetrievalConfig":{
"additionalProperties":false,
"description":"Specifies the context retrieval config.",
"properties":{
"filter":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigFilter"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for filters."
},
"hybridSearch":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigHybridSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Hybrid Search."
},
"ranking":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRanking"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for ranking and reranking."
},
"topK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The number of contexts to retrieve.",
"title":"Topk"
}
},
"title":"RagRetrievalConfig",
"type":"object"
},
"RagRetrievalConfigFilter":{
"additionalProperties":false,
"description":"Config for filters.",
"properties":{
"metadataFilter":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. String for metadata filtering.",
"title":"Metadatafilter"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
},
"vectorSimilarityThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector similarity larger than the threshold.",
"title":"Vectorsimilaritythreshold"
}
},
"title":"RagRetrievalConfigFilter",
"type":"object"
},
"RagRetrievalConfigHybridSearch":{
"additionalProperties":false,
"description":"Config for Hybrid Search.",
"properties":{
"alpha":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally.",
"title":"Alpha"
}
},
"title":"RagRetrievalConfigHybridSearch",
"type":"object"
},
"RagRetrievalConfigRanking":{
"additionalProperties":false,
"description":"Config for ranking and reranking.",
"properties":{
"llmRanker":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingLlmRanker"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for LlmRanker."
},
"rankService":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingRankService"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Rank Service."
}
},
"title":"RagRetrievalConfigRanking",
"type":"object"
},
"RagRetrievalConfigRankingLlmRanker":{
"additionalProperties":false,
"description":"Config for LlmRanker.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name used for ranking. Format: `gemini-1.5-pro`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingLlmRanker",
"type":"object"
},
"RagRetrievalConfigRankingRankService":{
"additionalProperties":false,
"description":"Config for Rank Service.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name of the rank service. Format: `semantic-ranker-512@latest`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingRankService",
"type":"object"
},
"RealtimeInputConfig":{
"additionalProperties":false,
"description":"Marks the end of user activity.\n\nThis can only be sent if automatic (i.e. server-side) activity detection is\ndisabled.",
"properties":{
"automaticActivityDetection":{
"anyOf":[
{
"$ref":"#/$defs/AutomaticActivityDetection"
},
{
"type":"null"
}
],
"default":null,
"description":"If not set, automatic activity detection is enabled by default. If automatic voice detection is disabled, the client must send activity signals."
},
"activityHandling":{
"anyOf":[
{
"$ref":"#/$defs/ActivityHandling"
},
{
"type":"null"
}
],
"default":null,
"description":"Defines what effect activity has."
},
"turnCoverage":{
"anyOf":[
{
"$ref":"#/$defs/TurnCoverage"
},
{
"type":"null"
}
],
"default":null,
"description":"Defines which input is included in the user's turn."
}
},
"title":"RealtimeInputConfig",
"type":"object"
},
"Retrieval":{
"additionalProperties":false,
"description":"Defines a retrieval tool that model can call to access external knowledge.",
"properties":{
"disableAttribution":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Deprecated. This option is no longer supported.",
"title":"Disableattribution"
},
"vertexAiSearch":{
"anyOf":[
{
"$ref":"#/$defs/VertexAISearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Set to use data source powered by Vertex AI Search."
},
"vertexRagStore":{
"anyOf":[
{
"$ref":"#/$defs/VertexRagStore"
},
{
"type":"null"
}
],
"default":null,
"description":"Set to use data source powered by Vertex RAG store. User data is uploaded via the VertexRagDataService."
}
},
"title":"Retrieval",
"type":"object"
},
"Schema":{
"additionalProperties":false,
"description":"Schema is used to define the format of input/output data.\n\nRepresents a select subset of an [OpenAPI 3.0 schema\nobject](https://spec.openapis.org/oas/v3.0.3#schema-object). More fields may\nbe added in the future as needed.",
"properties":{
"anyOf":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Schema"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The value should be validated against any (one or more) of the subschemas in the list.",
"title":"Anyof"
},
"default":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Default value of the data.",
"title":"Default"
},
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The description of the data.",
"title":"Description"
},
"enum":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Possible values of the element of primitive type with enum format. Examples: 1. We can define direction as : {type:STRING, format:enum, enum:[\"EAST\", NORTH\", \"SOUTH\", \"WEST\"]} 2. We can define apartment number as : {type:INTEGER, format:enum, enum:[\"101\", \"201\", \"301\"]}",
"title":"Enum"
},
"example":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Example of the object. Will only populated when the object is the root.",
"title":"Example"
},
"format":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The format of the data. Supported formats: for NUMBER type: \"float\", \"double\" for INTEGER type: \"int32\", \"int64\" for STRING type: \"email\", \"byte\", etc",
"title":"Format"
},
"items":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE ARRAY Schema of the elements of Type.ARRAY."
},
"maxItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the elements for Type.ARRAY.",
"title":"Maxitems"
},
"maxLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum length of the Type.STRING",
"title":"Maxlength"
},
"maxProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the properties for Type.OBJECT.",
"title":"Maxproperties"
},
"maximum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum value of the Type.INTEGER and Type.NUMBER",
"title":"Maximum"
},
"minItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the elements for Type.ARRAY.",
"title":"Minitems"
},
"minLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING",
"title":"Minlength"
},
"minProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the properties for Type.OBJECT.",
"title":"Minproperties"
},
"minimum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER Minimum value of the Type.INTEGER and Type.NUMBER",
"title":"Minimum"
},
"nullable":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Indicates if the value may be null.",
"title":"Nullable"
},
"pattern":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Pattern of the Type.STRING to restrict a string to a regular expression.",
"title":"Pattern"
},
"properties":{
"anyOf":[
{
"additionalProperties":{
"$ref":"#/$defs/Schema"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE OBJECT Properties of Type.OBJECT.",
"title":"Properties"
},
"propertyOrdering":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The order of the properties. Not a standard field in open api spec. Only used to support the order of the properties.",
"title":"Propertyordering"
},
"required":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required properties of Type.OBJECT.",
"title":"Required"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The title of the Schema.",
"title":"Title"
},
"type":{
"anyOf":[
{
"$ref":"#/$defs/Type"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The type of the data."
}
},
"title":"Schema",
"type":"object"
},
"SessionResumptionConfig":{
"additionalProperties":false,
"description":"Configuration of session resumption mechanism.\n\nIncluded in `LiveConnectConfig.session_resumption`. If included server\nwill send `LiveServerSessionResumptionUpdate` messages.",
"properties":{
"handle":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Session resumption handle of previous session (session to restore).\n\nIf not present new session will be started.",
"title":"Handle"
},
"transparent":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If set the server will send `last_consumed_client_message_index` in the `session_resumption_update` messages to allow for transparent reconnections.",
"title":"Transparent"
}
},
"title":"SessionResumptionConfig",
"type":"object"
},
"SlidingWindow":{
"additionalProperties":false,
"description":"Context window will be truncated by keeping only suffix of it.\n\nContext window will always be cut at start of USER role turn. System\ninstructions and `BidiGenerateContentSetup.prefix_turns` will not be\nsubject to the sliding window mechanism, they will always stay at the\nbeginning of context window.",
"properties":{
"targetTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Session reduction target -- how many tokens we should keep. Window shortening operation has some latency costs, so we should avoid running it on every turn. Should be < trigger_tokens. If not set, trigger_tokens/2 is assumed.",
"title":"Targettokens"
}
},
"title":"SlidingWindow",
"type":"object"
},
"SpeechConfig":{
"additionalProperties":false,
"description":"The speech generation configuration.",
"properties":{
"voiceConfig":{
"anyOf":[
{
"$ref":"#/$defs/VoiceConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The configuration for the speaker to use.\n      "
},
"languageCode":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Language code (ISO 639. e.g. en-US) for the speech synthesization.\n      Only available for Live API.\n      ",
"title":"Languagecode"
}
},
"title":"SpeechConfig",
"type":"object"
},
"StartSensitivity":{
"description":"Start of speech sensitivity.",
"enum":[
"START_SENSITIVITY_UNSPECIFIED",
"START_SENSITIVITY_HIGH",
"START_SENSITIVITY_LOW"
],
"title":"StartSensitivity",
"type":"string"
},
"Tool":{
"additionalProperties":false,
"description":"Tool details of a tool that the model may use to generate a response.",
"properties":{
"retrieval":{
"anyOf":[
{
"$ref":"#/$defs/Retrieval"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Retrieval tool type. System will always execute the provided retrieval tool(s) to get external knowledge to answer the prompt. Retrieval results are presented to the model for generation."
},
"googleSearch":{
"anyOf":[
{
"$ref":"#/$defs/GoogleSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google Search tool type. Specialized retrieval tool\n      that is powered by Google Search."
},
"googleSearchRetrieval":{
"anyOf":[
{
"$ref":"#/$defs/GoogleSearchRetrieval"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. GoogleSearchRetrieval tool type. Specialized retrieval tool that is powered by Google search."
},
"enterpriseWebSearch":{
"anyOf":[
{
"$ref":"#/$defs/EnterpriseWebSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Enterprise web search tool type. Specialized retrieval\n      tool that is powered by Vertex AI Search and Sec4 compliance."
},
"googleMaps":{
"anyOf":[
{
"$ref":"#/$defs/GoogleMaps"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google Maps tool type. Specialized retrieval tool\n      that is powered by Google Maps."
},
"codeExecution":{
"anyOf":[
{
"$ref":"#/$defs/ToolCodeExecution"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. CodeExecution tool type. Enables the model to execute code as part of generation. This field is only used by the Gemini Developer API services."
},
"functionDeclarations":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/FunctionDeclaration"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Function tool type. One or more function declarations to be passed to the model along with the current user query. Model may decide to call a subset of these functions by populating FunctionCall in the response. User should provide a FunctionResponse for each function call in the next turn. Based on the function responses, Model will generate the final response back to the user. Maximum 128 function declarations can be provided.",
"title":"Functiondeclarations"
}
},
"title":"Tool",
"type":"object"
},
"ToolCodeExecution":{
"additionalProperties":false,
"description":"Tool that executes code generated by the model, and automatically returns the result to the model.\n\nSee also [ExecutableCode]and [CodeExecutionResult] which are input and output\nto this tool.",
"properties":{},
"title":"ToolCodeExecution",
"type":"object"
},
"TurnCoverage":{
"description":"Options about which input is included in the user's turn.",
"enum":[
"TURN_COVERAGE_UNSPECIFIED",
"TURN_INCLUDES_ONLY_ACTIVITY",
"TURN_INCLUDES_ALL_INPUT"
],
"title":"TurnCoverage",
"type":"string"
},
"Type":{
"description":"Optional. The type of the data.",
"enum":[
"TYPE_UNSPECIFIED",
"STRING",
"NUMBER",
"INTEGER",
"BOOLEAN",
"ARRAY",
"OBJECT"
],
"title":"Type",
"type":"string"
},
"VertexAISearch":{
"additionalProperties":false,
"description":"Retrieve from Vertex AI Search datastore or engine for grounding.\n\ndatastore and engine are mutually exclusive. See\nhttps://cloud.google.com/products/agent-builder",
"properties":{
"datastore":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search data store resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`",
"title":"Datastore"
},
"engine":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search engine resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}`",
"title":"Engine"
}
},
"title":"VertexAISearch",
"type":"object"
},
"VertexRagStore":{
"additionalProperties":false,
"description":"Retrieve from Vertex RAG Store for grounding.",
"properties":{
"ragCorpora":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Deprecated. Please use rag_resources instead.",
"title":"Ragcorpora"
},
"ragResources":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/VertexRagStoreRagResource"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The representation of the rag source. It can be used to specify corpus only or ragfiles. Currently only support one corpus or multiple files from one corpus. In the future we may open up multiple corpora support.",
"title":"Ragresources"
},
"ragRetrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The retrieval config for the Rag query."
},
"similarityTopK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of top k results to return from the selected corpora.",
"title":"Similaritytopk"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only return results with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
}
},
"title":"VertexRagStore",
"type":"object"
},
"VertexRagStoreRagResource":{
"additionalProperties":false,
"description":"The definition of the Rag resource.",
"properties":{
"ragCorpus":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. RagCorpora resource name. Format: `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`",
"title":"Ragcorpus"
},
"ragFileIds":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus field.",
"title":"Ragfileids"
}
},
"title":"VertexRagStoreRagResource",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
},
"VoiceConfig":{
"additionalProperties":false,
"description":"The configuration for the voice to use.",
"properties":{
"prebuiltVoiceConfig":{
"anyOf":[
{
"$ref":"#/$defs/PrebuiltVoiceConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The configuration for the speaker to use.\n      "
}
},
"title":"VoiceConfig",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `context_window_compression (genai.types.ContextWindowCompressionConfig | None)`
  * `generation_config (genai.types.GenerationConfig | None)`
  * `input_audio_transcription (genai.types.AudioTranscriptionConfig | None)`
  * `max_output_tokens (int | None)`
  * `media_resolution (genai.types.MediaResolution | None)`
  * `output_audio_transcription (genai.types.AudioTranscriptionConfig | None)`
  * `realtime_input_config (genai.types.RealtimeInputConfig | None)`
  * `response_modalities (list[genai.types.Modality] | None)`
  * `seed (int | None)`
  * `session_resumption (genai.types.SessionResumptionConfig | None)`
  * `speech_config (genai.types.SpeechConfig | None)`
  * `system_instruction (genai.types.Content | list[genai.types.File | genai.types.Part | PIL.Image.Image | str] | genai.types.File | genai.types.Part | PIL.Image.Image | str | None)`
  * `temperature (float | None)`
  * `tools (list[genai.types.Tool | Callable[[...], Any]] | None)`
  * `top_k (float | None)`
  * `top_p (float | None)`



_field_ context_window_compression _:`Optional`[`ContextWindowCompressionConfig`]__= None_ _(alias 'contextWindowCompression')_¶ 
    
Configures context window compression mechanism.
If included, server will compress context window to fit into given length. 

_field_ generation_config _:`Optional`[`GenerationConfig`]__= None_ _(alias 'generationConfig')_¶ 
    
The generation configuration for the session. 

_field_ input_audio_transcription _:`Optional`[`AudioTranscriptionConfig`]__= None_ _(alias 'inputAudioTranscription')_¶ 
    
The transcription of the input aligns with the input audio language. 

_field_ max_output_tokens _:`Optional`[`int`]__= None_ _(alias 'maxOutputTokens')_¶ 
    
Maximum number of tokens that can be generated in the response. 

_field_ media_resolution _:`Optional`[`MediaResolution`]__= None_ _(alias 'mediaResolution')_¶ 
    
If specified, the media resolution specified will be used. 

_field_ output_audio_transcription _:`Optional`[`AudioTranscriptionConfig`]__= None_ _(alias 'outputAudioTranscription')_¶ 
    
The transcription of the output aligns with the language code specified for the output audio. 

_field_ realtime_input_config _:`Optional`[`RealtimeInputConfig`]__= None_ _(alias 'realtimeInputConfig')_¶ 
    
Configures the realtime input behavior in BidiGenerateContent. 

_field_ response_modalities _:`Optional`[`list`[`Modality`]]__= None_ _(alias 'responseModalities')_¶ 
    
The requested modalities of the response. Represents the set of modalities that the model can return. Defaults to AUDIO if not specified. 

_field_ seed _:`Optional`[`int`]__= None_¶ 
    
When `seed` is fixed to a specific number, the model makes a best effort to provide the same response for repeated requests. By default, a random number is used. 

_field_ session_resumption _:`Optional`[`SessionResumptionConfig`]__= None_ _(alias 'sessionResumption')_¶ 
    
Configures session resumption mechanism.
If included the server will send SessionResumptionUpdate messages. 

_field_ speech_config _:`Optional`[`SpeechConfig`]__= None_ _(alias 'speechConfig')_¶ 
    
The speech generation configuration. 

_field_ system_instruction _:`Union`[`Content`, `list`[`Union`[`File`, `Part`, `Image`, `str`]], `File`, `Part`, `Image`, `str`, `None`]__= None_ _(alias 'systemInstruction')_¶ 
    
The user provided system instructions for the model. Note: only text should be used in parts and content in each part will be in a separate paragraph. 

_field_ temperature _:`Optional`[`float`]__= None_¶ 
    
Value that controls the degree of randomness in token selection. Lower temperatures are good for prompts that require a less open-ended or creative response, while higher temperatures can lead to more diverse or creative results. 

_field_ tools _:`Optional`[`list`[`Union`[`Tool`, `Callable`[`...`, `Any`]]]]__= None_¶ 
    
A list of Tools the model may use to generate the next response.
A Tool is a piece of code that enables the system to interact with external systems to perform an action, or set of actions, outside of knowledge and scope of the model. 

_field_ top_k _:`Optional`[`float`]__= None_ _(alias 'topK')_¶ 
    
For each token selection step, the `top_k` tokens with the highest probabilities are sampled. Then tokens are further filtered based on `top_p` with the final token selected using temperature sampling. Use a lower number for less random responses and a higher number for more random responses. 

_field_ top_p _:`Optional`[`float`]__= None_ _(alias 'topP')_¶ 
    
Tokens are selected from the most to least probable until the sum of their probabilities equals this value. Use a lower value for less random responses and a higher value for more random responses. 

_class_ genai.types.LiveConnectConfigDict¶ 
    
Bases: `TypedDict`
Session config for the API connection. 

context_window_compression _:`Optional`[`ContextWindowCompressionConfigDict`]_¶ 
    
Configures context window compression mechanism.
If included, server will compress context window to fit into given length. 

generation_config _:`Optional`[`GenerationConfigDict`]_¶ 
    
The generation configuration for the session. 

input_audio_transcription _:`Optional`[`AudioTranscriptionConfigDict`]_¶ 
    
The transcription of the input aligns with the input audio language. 

max_output_tokens _:`Optional`[`int`]_¶ 
    
Maximum number of tokens that can be generated in the response. 

media_resolution _:`Optional`[`MediaResolution`]_¶ 
    
If specified, the media resolution specified will be used. 

output_audio_transcription _:`Optional`[`AudioTranscriptionConfigDict`]_¶ 
    
The transcription of the output aligns with the language code specified for the output audio. 

realtime_input_config _:`Optional`[`RealtimeInputConfigDict`]_¶ 
    
Configures the realtime input behavior in BidiGenerateContent. 

response_modalities _:`Optional`[`list`[`Modality`]]_¶ 
    
The requested modalities of the response. Represents the set of modalities that the model can return. Defaults to AUDIO if not specified. 

seed _:`Optional`[`int`]_¶ 
    
When `seed` is fixed to a specific number, the model makes a best effort to provide the same response for repeated requests. By default, a random number is used. 

session_resumption _:`Optional`[`SessionResumptionConfigDict`]_¶ 
    
Configures session resumption mechanism.
If included the server will send SessionResumptionUpdate messages. 

speech_config _:`Optional`[`SpeechConfigDict`]_¶ 
    
The speech generation configuration. 

system_instruction _:`Union`[`Content`, `list`[`Union`[`File`, `Part`, `Image`, `str`]], `File`, `Part`, `Image`, `str`, `ContentDict`, `None`]_¶ 
    
The user provided system instructions for the model. Note: only text should be used in parts and content in each part will be in a separate paragraph. 

temperature _:`Optional`[`float`]_¶ 
    
Value that controls the degree of randomness in token selection. Lower temperatures are good for prompts that require a less open-ended or creative response, while higher temperatures can lead to more diverse or creative results. 

tools _:`Optional`[`list`[`Union`[`ToolDict`, `Callable`[`...`, `Any`]]]]_¶ 
    
A list of Tools the model may use to generate the next response.
A Tool is a piece of code that enables the system to interact with external systems to perform an action, or set of actions, outside of knowledge and scope of the model. 

top_k _:`Optional`[`float`]_¶ 
    
For each token selection step, the `top_k` tokens with the highest probabilities are sampled. Then tokens are further filtered based on `top_p` with the final token selected using temperature sampling. Use a lower number for less random responses and a higher number for more random responses. 

top_p _:`Optional`[`float`]_¶ 
    
Tokens are selected from the most to least probable until the sum of their probabilities equals this value. Use a lower value for less random responses and a higher value for more random responses. 

_pydantic model_genai.types.LiveConnectParameters¶ 
    
Bases: `BaseModel`
Parameters for connecting to the live API.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"LiveConnectParameters",
"description":"Parameters for connecting to the live API.",
"type":"object",
"properties":{
"model":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"ID of the model to use. For a list of models, see `Google models\n    <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models>`_.",
"title":"Model"
},
"config":{
"anyOf":[
{
"$ref":"#/$defs/LiveConnectConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional configuration parameters for the request.\n      "
}
},
"$defs":{
"ActivityHandling":{
"description":"The different ways of handling user activity.",
"enum":[
"ACTIVITY_HANDLING_UNSPECIFIED",
"START_OF_ACTIVITY_INTERRUPTS",
"NO_INTERRUPTION"
],
"title":"ActivityHandling",
"type":"string"
},
"ApiKeyConfig":{
"additionalProperties":false,
"description":"Config for authentication with API key.",
"properties":{
"apiKeyString":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The API key to be used in the request directly.",
"title":"Apikeystring"
}
},
"title":"ApiKeyConfig",
"type":"object"
},
"AudioTranscriptionConfig":{
"additionalProperties":false,
"description":"The audio transcription configuration in Setup.",
"properties":{},
"title":"AudioTranscriptionConfig",
"type":"object"
},
"AuthConfig":{
"additionalProperties":false,
"description":"Auth configuration to run the extension.",
"properties":{
"apiKeyConfig":{
"anyOf":[
{
"$ref":"#/$defs/ApiKeyConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for API key auth."
},
"authType":{
"anyOf":[
{
"$ref":"#/$defs/AuthType"
},
{
"type":"null"
}
],
"default":null,
"description":"Type of auth scheme."
},
"googleServiceAccountConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigGoogleServiceAccountConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for Google Service Account auth."
},
"httpBasicAuthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigHttpBasicAuthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for HTTP Basic auth."
},
"oauthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOauthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user oauth."
},
"oidcConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOidcConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user OIDC auth."
}
},
"title":"AuthConfig",
"type":"object"
},
"AuthConfigGoogleServiceAccountConfig":{
"additionalProperties":false,
"description":"Config for Google Service Account Authentication.",
"properties":{
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The service account that the extension execution service runs as. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified service account. - If not specified, the Vertex AI Extension Service Agent will be used to execute the Extension.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigGoogleServiceAccountConfig",
"type":"object"
},
"AuthConfigHttpBasicAuthConfig":{
"additionalProperties":false,
"description":"Config for HTTP Basic Authentication.",
"properties":{
"credentialSecret":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the SecretManager secret version resource storing the base64 encoded credentials. Format: `projects/{project}/secrets/{secrete}/versions/{version}` - If specified, the `secretmanager.versions.access` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified resource.",
"title":"Credentialsecret"
}
},
"title":"AuthConfigHttpBasicAuthConfig",
"type":"object"
},
"AuthConfigOauthConfig":{
"additionalProperties":false,
"description":"Config for user oauth.",
"properties":{
"accessToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Access token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Accesstoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate access tokens for executing the Extension. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the provided service account.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOauthConfig",
"type":"object"
},
"AuthConfigOidcConfig":{
"additionalProperties":false,
"description":"Config for user OIDC auth.",
"properties":{
"idToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"OpenID Connect formatted ID token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Idtoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate an OpenID Connect (OIDC)-compatible JWT token signed by the Google OIDC Provider (accounts.google.com) for extension endpoint (https://cloud.google.com/iam/docs/create-short-lived-credentials-direct#sa-credentials-oidc). - The audience for the token will be set to the URL in the server url defined in the OpenApi spec. - If the service account is provided, the service account should grant `iam.serviceAccounts.getOpenIdToken` permission to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOidcConfig",
"type":"object"
},
"AuthType":{
"description":"Type of auth scheme.",
"enum":[
"AUTH_TYPE_UNSPECIFIED",
"NO_AUTH",
"API_KEY_AUTH",
"HTTP_BASIC_AUTH",
"GOOGLE_SERVICE_ACCOUNT_AUTH",
"OAUTH",
"OIDC_AUTH"
],
"title":"AuthType",
"type":"string"
},
"AutomaticActivityDetection":{
"additionalProperties":false,
"description":"Configures automatic detection of activity.",
"properties":{
"disabled":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If enabled, detected voice and text input count as activity. If disabled, the client must send activity signals.",
"title":"Disabled"
},
"startOfSpeechSensitivity":{
"anyOf":[
{
"$ref":"#/$defs/StartSensitivity"
},
{
"type":"null"
}
],
"default":null,
"description":"Determines how likely speech is to be detected."
},
"endOfSpeechSensitivity":{
"anyOf":[
{
"$ref":"#/$defs/EndSensitivity"
},
{
"type":"null"
}
],
"default":null,
"description":"Determines how likely detected speech is ended."
},
"prefixPaddingMs":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The required duration of detected speech before start-of-speech is committed. The lower this value the more sensitive the start-of-speech detection is and the shorter speech can be recognized. However, this also increases the probability of false positives.",
"title":"Prefixpaddingms"
},
"silenceDurationMs":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The required duration of detected non-speech (e.g. silence) before end-of-speech is committed. The larger this value, the longer speech gaps can be without interrupting the user's activity but this will increase the model's latency.",
"title":"Silencedurationms"
}
},
"title":"AutomaticActivityDetection",
"type":"object"
},
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"Content":{
"additionalProperties":false,
"description":"Contains the multi-part content of a message.",
"properties":{
"parts":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Part"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of parts that constitute a single message. Each part may have\n      a different IANA MIME type.",
"title":"Parts"
},
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role.",
"title":"Role"
}
},
"title":"Content",
"type":"object"
},
"ContextWindowCompressionConfig":{
"additionalProperties":false,
"description":"Enables context window compression -- mechanism managing model context window so it does not exceed given length.",
"properties":{
"triggerTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens (before running turn) that triggers context window compression mechanism.",
"title":"Triggertokens"
},
"slidingWindow":{
"anyOf":[
{
"$ref":"#/$defs/SlidingWindow"
},
{
"type":"null"
}
],
"default":null,
"description":"Sliding window compression mechanism."
}
},
"title":"ContextWindowCompressionConfig",
"type":"object"
},
"DynamicRetrievalConfig":{
"additionalProperties":false,
"description":"Describes the options to customize dynamic retrieval.",
"properties":{
"mode":{
"anyOf":[
{
"$ref":"#/$defs/DynamicRetrievalConfigMode"
},
{
"type":"null"
}
],
"default":null,
"description":"The mode of the predictor to be used in dynamic retrieval."
},
"dynamicThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The threshold to be used in dynamic retrieval. If not set, a system default value is used.",
"title":"Dynamicthreshold"
}
},
"title":"DynamicRetrievalConfig",
"type":"object"
},
"DynamicRetrievalConfigMode":{
"description":"Config for the dynamic retrieval config mode.",
"enum":[
"MODE_UNSPECIFIED",
"MODE_DYNAMIC"
],
"title":"DynamicRetrievalConfigMode",
"type":"string"
},
"EndSensitivity":{
"description":"End of speech sensitivity.",
"enum":[
"END_SENSITIVITY_UNSPECIFIED",
"END_SENSITIVITY_HIGH",
"END_SENSITIVITY_LOW"
],
"title":"EndSensitivity",
"type":"string"
},
"EnterpriseWebSearch":{
"additionalProperties":false,
"description":"Tool to search public web data, powered by Vertex AI Search and Sec4 compliance.",
"properties":{},
"title":"EnterpriseWebSearch",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"File":{
"additionalProperties":false,
"description":"A file uploaded to the API.",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The `File` resource name. The ID (name excluding the \"files/\" prefix) can contain up to 40 characters that are lowercase alphanumeric or dashes (-). The ID cannot start or end with a dash. If the name is empty on create, a unique name will be generated. Example: `files/123-456`",
"title":"Name"
},
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The human-readable display name for the `File`. The display name must be no more than 512 characters in length, including spaces. Example: 'Welcome Image'",
"title":"Displayname"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. MIME type of the file.",
"title":"Mimetype"
},
"sizeBytes":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Size of the file in bytes.",
"title":"Sizebytes"
},
"createTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` was created.",
"title":"Createtime"
},
"expirationTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` will be deleted. Only set if the `File` is scheduled to expire.",
"title":"Expirationtime"
},
"updateTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The timestamp of when the `File` was last updated.",
"title":"Updatetime"
},
"sha256Hash":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. SHA-256 hash of the uploaded bytes. The hash value is encoded in base64 format.",
"title":"Sha256Hash"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The URI of the `File`.",
"title":"Uri"
},
"downloadUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The URI of the `File`, only set for downloadable (generated) files.",
"title":"Downloaduri"
},
"state":{
"anyOf":[
{
"$ref":"#/$defs/FileState"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Processing state of the File."
},
"source":{
"anyOf":[
{
"$ref":"#/$defs/FileSource"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The source of the `File`."
},
"videoMetadata":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Metadata for a video.",
"title":"Videometadata"
},
"error":{
"anyOf":[
{
"$ref":"#/$defs/FileStatus"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Error status if File processing failed."
}
},
"title":"File",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FileSource":{
"description":"Source of the File.",
"enum":[
"SOURCE_UNSPECIFIED",
"UPLOADED",
"GENERATED"
],
"title":"FileSource",
"type":"string"
},
"FileState":{
"description":"State for the lifecycle of a File.",
"enum":[
"STATE_UNSPECIFIED",
"PROCESSING",
"ACTIVE",
"FAILED"
],
"title":"FileState",
"type":"string"
},
"FileStatus":{
"additionalProperties":false,
"description":"Status of a File that uses a common error model.",
"properties":{
"details":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Details"
},
"message":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Message"
},
"code":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The status code. 0 for OK, 1 for CANCELLED",
"title":"Code"
}
},
"title":"FileStatus",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionDeclaration":{
"additionalProperties":false,
"description":"Structured representation of a function declaration as defined by the [OpenAPI 3.0 specification](https://spec.openapis.org/oas/v3.0.3).\n\nIncluded in this declaration are the function name, description, parameters\nand response type. This FunctionDeclaration is a representation of a block of\ncode that can be used as a `Tool` by the model and executed by the client.",
"properties":{
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Description and purpose of the function. Model uses it to decide how and whether to call the function.",
"title":"Description"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Must start with a letter or an underscore. Must be a-z, A-Z, 0-9, or contain underscores, dots and dashes, with a maximum length of 64.",
"title":"Name"
},
"parameters":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Describes the parameters to this function in JSON Schema Object format. Reflects the Open API 3.03 Parameter Object. string Key: the name of the parameter. Parameter names are case sensitive. Schema Value: the Schema defining the type used for the parameter. For function with no parameters, this can be left unset. Parameter names must start with a letter or an underscore and must only contain chars a-z, A-Z, 0-9, or underscores with a maximum length of 64. Example with 1 required and 1 optional parameter: type: OBJECT properties: param1: type: STRING param2: type: INTEGER required: - param1"
},
"response":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Describes the output from this function in JSON Schema format. Reflects the Open API 3.03 Response Object. The Schema defines the type used for the response value of the function."
}
},
"title":"FunctionDeclaration",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"GenerationConfig":{
"additionalProperties":false,
"description":"Generation config.",
"properties":{
"audioTimestamp":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If enabled, audio timestamp will be included in the request to the model.",
"title":"Audiotimestamp"
},
"candidateCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of candidates to generate.",
"title":"Candidatecount"
},
"frequencyPenalty":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Frequency penalties.",
"title":"Frequencypenalty"
},
"logprobs":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Logit probabilities.",
"title":"Logprobs"
},
"maxOutputTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The maximum number of output tokens to generate per message.",
"title":"Maxoutputtokens"
},
"mediaResolution":{
"anyOf":[
{
"$ref":"#/$defs/MediaResolution"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If specified, the media resolution specified will be used."
},
"presencePenalty":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Positive penalties.",
"title":"Presencepenalty"
},
"responseLogprobs":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If true, export the logprobs results in response.",
"title":"Responselogprobs"
},
"responseMimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Output response mimetype of the generated candidate text. Supported mimetype: - `text/plain`: (default) Text output. - `application/json`: JSON response in the candidates. The model needs to be prompted to output the appropriate response type, otherwise the behavior is undefined. This is a preview feature.",
"title":"Responsemimetype"
},
"responseSchema":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The `Schema` object allows the definition of input and output data types. These types can be objects, but also primitives and arrays. Represents a select subset of an [OpenAPI 3.0 schema object](https://spec.openapis.org/oas/v3.0.3#schema). If set, a compatible response_mime_type must also be set. Compatible mimetypes: `application/json`: Schema for JSON response."
},
"routingConfig":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Routing configuration."
},
"seed":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Seed.",
"title":"Seed"
},
"stopSequences":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Stop sequences.",
"title":"Stopsequences"
},
"temperature":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Controls the randomness of predictions.",
"title":"Temperature"
},
"topK":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If specified, top-k sampling will be used.",
"title":"Topk"
},
"topP":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If specified, nucleus sampling will be used.",
"title":"Topp"
}
},
"title":"GenerationConfig",
"type":"object"
},
"GenerationConfigRoutingConfig":{
"additionalProperties":false,
"description":"The configuration for routing the request to a specific model.",
"properties":{
"autoMode":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfigAutoRoutingMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Automated routing."
},
"manualMode":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfigRoutingConfigManualRoutingMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Manual routing."
}
},
"title":"GenerationConfigRoutingConfig",
"type":"object"
},
"GenerationConfigRoutingConfigAutoRoutingMode":{
"additionalProperties":false,
"description":"When automated routing is specified, the routing will be determined by the pretrained routing model and customer provided model routing preference.",
"properties":{
"modelRoutingPreference":{
"anyOf":[
{
"enum":[
"UNKNOWN",
"PRIORITIZE_QUALITY",
"BALANCED",
"PRIORITIZE_COST"
],
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The model routing preference.",
"title":"Modelroutingpreference"
}
},
"title":"GenerationConfigRoutingConfigAutoRoutingMode",
"type":"object"
},
"GenerationConfigRoutingConfigManualRoutingMode":{
"additionalProperties":false,
"description":"When manual routing is set, the specified model will be used directly.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The model name to use. Only the public LLM models are accepted. e.g. 'gemini-1.5-pro-001'.",
"title":"Modelname"
}
},
"title":"GenerationConfigRoutingConfigManualRoutingMode",
"type":"object"
},
"GoogleMaps":{
"additionalProperties":false,
"description":"Tool to support Google Maps in Model.",
"properties":{
"authConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Auth config for the Google Maps tool."
}
},
"title":"GoogleMaps",
"type":"object"
},
"GoogleSearch":{
"additionalProperties":false,
"description":"Tool to support Google Search in Model. Powered by Google.",
"properties":{},
"title":"GoogleSearch",
"type":"object"
},
"GoogleSearchRetrieval":{
"additionalProperties":false,
"description":"Tool to retrieve public web data for grounding, powered by Google.",
"properties":{
"dynamicRetrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/DynamicRetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the dynamic retrieval configuration for the given source."
}
},
"title":"GoogleSearchRetrieval",
"type":"object"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"LiveConnectConfig":{
"additionalProperties":false,
"description":"Session config for the API connection.",
"properties":{
"generationConfig":{
"anyOf":[
{
"$ref":"#/$defs/GenerationConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The generation configuration for the session."
},
"responseModalities":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Modality"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The requested modalities of the response. Represents the set of\n      modalities that the model can return. Defaults to AUDIO if not specified.\n      ",
"title":"Responsemodalities"
},
"temperature":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Value that controls the degree of randomness in token selection.\n      Lower temperatures are good for prompts that require a less open-ended or\n      creative response, while higher temperatures can lead to more diverse or\n      creative results.\n      ",
"title":"Temperature"
},
"topP":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Tokens are selected from the most to least probable until the sum\n      of their probabilities equals this value. Use a lower value for less\n      random responses and a higher value for more random responses.\n      ",
"title":"Topp"
},
"topK":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"For each token selection step, the ``top_k`` tokens with the\n      highest probabilities are sampled. Then tokens are further filtered based\n      on ``top_p`` with the final token selected using temperature sampling. Use\n      a lower number for less random responses and a higher number for more\n      random responses.\n      ",
"title":"Topk"
},
"maxOutputTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Maximum number of tokens that can be generated in the response.\n      ",
"title":"Maxoutputtokens"
},
"mediaResolution":{
"anyOf":[
{
"$ref":"#/$defs/MediaResolution"
},
{
"type":"null"
}
],
"default":null,
"description":"If specified, the media resolution specified will be used.\n      "
},
"seed":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"When ``seed`` is fixed to a specific number, the model makes a best\n      effort to provide the same response for repeated requests. By default, a\n      random number is used.\n      ",
"title":"Seed"
},
"speechConfig":{
"anyOf":[
{
"$ref":"#/$defs/SpeechConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The speech generation configuration.\n      "
},
"systemInstruction":{
"anyOf":[
{
"$ref":"#/$defs/Content"
},
{
"items":{
"anyOf":[
{
"$ref":"#/$defs/File"
},
{
"$ref":"#/$defs/Part"
},
{
"type":"string"
}
]
},
"type":"array"
},
{
"$ref":"#/$defs/File"
},
{
"$ref":"#/$defs/Part"
},
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The user provided system instructions for the model.\n      Note: only text should be used in parts and content in each part will be\n      in a separate paragraph.",
"title":"Systeminstruction"
},
"tools":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Tool"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of `Tools` the model may use to generate the next response.\n\n      A `Tool` is a piece of code that enables the system to interact with\n      external systems to perform an action, or set of actions, outside of\n      knowledge and scope of the model.",
"title":"Tools"
},
"sessionResumption":{
"anyOf":[
{
"$ref":"#/$defs/SessionResumptionConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Configures session resumption mechanism.\n\nIf included the server will send SessionResumptionUpdate messages."
},
"inputAudioTranscription":{
"anyOf":[
{
"$ref":"#/$defs/AudioTranscriptionConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The transcription of the input aligns with the input audio language.\n      "
},
"outputAudioTranscription":{
"anyOf":[
{
"$ref":"#/$defs/AudioTranscriptionConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The transcription of the output aligns with the language code\n      specified for the output audio.\n      "
},
"realtimeInputConfig":{
"anyOf":[
{
"$ref":"#/$defs/RealtimeInputConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Configures the realtime input behavior in BidiGenerateContent."
},
"contextWindowCompression":{
"anyOf":[
{
"$ref":"#/$defs/ContextWindowCompressionConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Configures context window compression mechanism.\n\n      If included, server will compress context window to fit into given length."
}
},
"title":"LiveConnectConfig",
"type":"object"
},
"MediaResolution":{
"description":"The media resolution to use.",
"enum":[
"MEDIA_RESOLUTION_UNSPECIFIED",
"MEDIA_RESOLUTION_LOW",
"MEDIA_RESOLUTION_MEDIUM",
"MEDIA_RESOLUTION_HIGH"
],
"title":"MediaResolution",
"type":"string"
},
"Modality":{
"description":"Server content modalities.",
"enum":[
"MODALITY_UNSPECIFIED",
"TEXT",
"IMAGE",
"AUDIO"
],
"title":"Modality",
"type":"string"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"PrebuiltVoiceConfig":{
"additionalProperties":false,
"description":"The configuration for the prebuilt speaker to use.",
"properties":{
"voiceName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The name of the prebuilt voice to use.\n      ",
"title":"Voicename"
}
},
"title":"PrebuiltVoiceConfig",
"type":"object"
},
"RagRetrievalConfig":{
"additionalProperties":false,
"description":"Specifies the context retrieval config.",
"properties":{
"filter":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigFilter"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for filters."
},
"hybridSearch":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigHybridSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Hybrid Search."
},
"ranking":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRanking"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for ranking and reranking."
},
"topK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The number of contexts to retrieve.",
"title":"Topk"
}
},
"title":"RagRetrievalConfig",
"type":"object"
},
"RagRetrievalConfigFilter":{
"additionalProperties":false,
"description":"Config for filters.",
"properties":{
"metadataFilter":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. String for metadata filtering.",
"title":"Metadatafilter"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
},
"vectorSimilarityThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector similarity larger than the threshold.",
"title":"Vectorsimilaritythreshold"
}
},
"title":"RagRetrievalConfigFilter",
"type":"object"
},
"RagRetrievalConfigHybridSearch":{
"additionalProperties":false,
"description":"Config for Hybrid Search.",
"properties":{
"alpha":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally.",
"title":"Alpha"
}
},
"title":"RagRetrievalConfigHybridSearch",
"type":"object"
},
"RagRetrievalConfigRanking":{
"additionalProperties":false,
"description":"Config for ranking and reranking.",
"properties":{
"llmRanker":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingLlmRanker"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for LlmRanker."
},
"rankService":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingRankService"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Rank Service."
}
},
"title":"RagRetrievalConfigRanking",
"type":"object"
},
"RagRetrievalConfigRankingLlmRanker":{
"additionalProperties":false,
"description":"Config for LlmRanker.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name used for ranking. Format: `gemini-1.5-pro`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingLlmRanker",
"type":"object"
},
"RagRetrievalConfigRankingRankService":{
"additionalProperties":false,
"description":"Config for Rank Service.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name of the rank service. Format: `semantic-ranker-512@latest`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingRankService",
"type":"object"
},
"RealtimeInputConfig":{
"additionalProperties":false,
"description":"Marks the end of user activity.\n\nThis can only be sent if automatic (i.e. server-side) activity detection is\ndisabled.",
"properties":{
"automaticActivityDetection":{
"anyOf":[
{
"$ref":"#/$defs/AutomaticActivityDetection"
},
{
"type":"null"
}
],
"default":null,
"description":"If not set, automatic activity detection is enabled by default. If automatic voice detection is disabled, the client must send activity signals."
},
"activityHandling":{
"anyOf":[
{
"$ref":"#/$defs/ActivityHandling"
},
{
"type":"null"
}
],
"default":null,
"description":"Defines what effect activity has."
},
"turnCoverage":{
"anyOf":[
{
"$ref":"#/$defs/TurnCoverage"
},
{
"type":"null"
}
],
"default":null,
"description":"Defines which input is included in the user's turn."
}
},
"title":"RealtimeInputConfig",
"type":"object"
},
"Retrieval":{
"additionalProperties":false,
"description":"Defines a retrieval tool that model can call to access external knowledge.",
"properties":{
"disableAttribution":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Deprecated. This option is no longer supported.",
"title":"Disableattribution"
},
"vertexAiSearch":{
"anyOf":[
{
"$ref":"#/$defs/VertexAISearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Set to use data source powered by Vertex AI Search."
},
"vertexRagStore":{
"anyOf":[
{
"$ref":"#/$defs/VertexRagStore"
},
{
"type":"null"
}
],
"default":null,
"description":"Set to use data source powered by Vertex RAG store. User data is uploaded via the VertexRagDataService."
}
},
"title":"Retrieval",
"type":"object"
},
"Schema":{
"additionalProperties":false,
"description":"Schema is used to define the format of input/output data.\n\nRepresents a select subset of an [OpenAPI 3.0 schema\nobject](https://spec.openapis.org/oas/v3.0.3#schema-object). More fields may\nbe added in the future as needed.",
"properties":{
"anyOf":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Schema"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The value should be validated against any (one or more) of the subschemas in the list.",
"title":"Anyof"
},
"default":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Default value of the data.",
"title":"Default"
},
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The description of the data.",
"title":"Description"
},
"enum":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Possible values of the element of primitive type with enum format. Examples: 1. We can define direction as : {type:STRING, format:enum, enum:[\"EAST\", NORTH\", \"SOUTH\", \"WEST\"]} 2. We can define apartment number as : {type:INTEGER, format:enum, enum:[\"101\", \"201\", \"301\"]}",
"title":"Enum"
},
"example":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Example of the object. Will only populated when the object is the root.",
"title":"Example"
},
"format":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The format of the data. Supported formats: for NUMBER type: \"float\", \"double\" for INTEGER type: \"int32\", \"int64\" for STRING type: \"email\", \"byte\", etc",
"title":"Format"
},
"items":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE ARRAY Schema of the elements of Type.ARRAY."
},
"maxItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the elements for Type.ARRAY.",
"title":"Maxitems"
},
"maxLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum length of the Type.STRING",
"title":"Maxlength"
},
"maxProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the properties for Type.OBJECT.",
"title":"Maxproperties"
},
"maximum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum value of the Type.INTEGER and Type.NUMBER",
"title":"Maximum"
},
"minItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the elements for Type.ARRAY.",
"title":"Minitems"
},
"minLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING",
"title":"Minlength"
},
"minProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the properties for Type.OBJECT.",
"title":"Minproperties"
},
"minimum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER Minimum value of the Type.INTEGER and Type.NUMBER",
"title":"Minimum"
},
"nullable":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Indicates if the value may be null.",
"title":"Nullable"
},
"pattern":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Pattern of the Type.STRING to restrict a string to a regular expression.",
"title":"Pattern"
},
"properties":{
"anyOf":[
{
"additionalProperties":{
"$ref":"#/$defs/Schema"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE OBJECT Properties of Type.OBJECT.",
"title":"Properties"
},
"propertyOrdering":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The order of the properties. Not a standard field in open api spec. Only used to support the order of the properties.",
"title":"Propertyordering"
},
"required":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required properties of Type.OBJECT.",
"title":"Required"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The title of the Schema.",
"title":"Title"
},
"type":{
"anyOf":[
{
"$ref":"#/$defs/Type"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The type of the data."
}
},
"title":"Schema",
"type":"object"
},
"SessionResumptionConfig":{
"additionalProperties":false,
"description":"Configuration of session resumption mechanism.\n\nIncluded in `LiveConnectConfig.session_resumption`. If included server\nwill send `LiveServerSessionResumptionUpdate` messages.",
"properties":{
"handle":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Session resumption handle of previous session (session to restore).\n\nIf not present new session will be started.",
"title":"Handle"
},
"transparent":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If set the server will send `last_consumed_client_message_index` in the `session_resumption_update` messages to allow for transparent reconnections.",
"title":"Transparent"
}
},
"title":"SessionResumptionConfig",
"type":"object"
},
"SlidingWindow":{
"additionalProperties":false,
"description":"Context window will be truncated by keeping only suffix of it.\n\nContext window will always be cut at start of USER role turn. System\ninstructions and `BidiGenerateContentSetup.prefix_turns` will not be\nsubject to the sliding window mechanism, they will always stay at the\nbeginning of context window.",
"properties":{
"targetTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Session reduction target -- how many tokens we should keep. Window shortening operation has some latency costs, so we should avoid running it on every turn. Should be < trigger_tokens. If not set, trigger_tokens/2 is assumed.",
"title":"Targettokens"
}
},
"title":"SlidingWindow",
"type":"object"
},
"SpeechConfig":{
"additionalProperties":false,
"description":"The speech generation configuration.",
"properties":{
"voiceConfig":{
"anyOf":[
{
"$ref":"#/$defs/VoiceConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The configuration for the speaker to use.\n      "
},
"languageCode":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Language code (ISO 639. e.g. en-US) for the speech synthesization.\n      Only available for Live API.\n      ",
"title":"Languagecode"
}
},
"title":"SpeechConfig",
"type":"object"
},
"StartSensitivity":{
"description":"Start of speech sensitivity.",
"enum":[
"START_SENSITIVITY_UNSPECIFIED",
"START_SENSITIVITY_HIGH",
"START_SENSITIVITY_LOW"
],
"title":"StartSensitivity",
"type":"string"
},
"Tool":{
"additionalProperties":false,
"description":"Tool details of a tool that the model may use to generate a response.",
"properties":{
"retrieval":{
"anyOf":[
{
"$ref":"#/$defs/Retrieval"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Retrieval tool type. System will always execute the provided retrieval tool(s) to get external knowledge to answer the prompt. Retrieval results are presented to the model for generation."
},
"googleSearch":{
"anyOf":[
{
"$ref":"#/$defs/GoogleSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google Search tool type. Specialized retrieval tool\n      that is powered by Google Search."
},
"googleSearchRetrieval":{
"anyOf":[
{
"$ref":"#/$defs/GoogleSearchRetrieval"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. GoogleSearchRetrieval tool type. Specialized retrieval tool that is powered by Google search."
},
"enterpriseWebSearch":{
"anyOf":[
{
"$ref":"#/$defs/EnterpriseWebSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Enterprise web search tool type. Specialized retrieval\n      tool that is powered by Vertex AI Search and Sec4 compliance."
},
"googleMaps":{
"anyOf":[
{
"$ref":"#/$defs/GoogleMaps"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google Maps tool type. Specialized retrieval tool\n      that is powered by Google Maps."
},
"codeExecution":{
"anyOf":[
{
"$ref":"#/$defs/ToolCodeExecution"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. CodeExecution tool type. Enables the model to execute code as part of generation. This field is only used by the Gemini Developer API services."
},
"functionDeclarations":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/FunctionDeclaration"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Function tool type. One or more function declarations to be passed to the model along with the current user query. Model may decide to call a subset of these functions by populating FunctionCall in the response. User should provide a FunctionResponse for each function call in the next turn. Based on the function responses, Model will generate the final response back to the user. Maximum 128 function declarations can be provided.",
"title":"Functiondeclarations"
}
},
"title":"Tool",
"type":"object"
},
"ToolCodeExecution":{
"additionalProperties":false,
"description":"Tool that executes code generated by the model, and automatically returns the result to the model.\n\nSee also [ExecutableCode]and [CodeExecutionResult] which are input and output\nto this tool.",
"properties":{},
"title":"ToolCodeExecution",
"type":"object"
},
"TurnCoverage":{
"description":"Options about which input is included in the user's turn.",
"enum":[
"TURN_COVERAGE_UNSPECIFIED",
"TURN_INCLUDES_ONLY_ACTIVITY",
"TURN_INCLUDES_ALL_INPUT"
],
"title":"TurnCoverage",
"type":"string"
},
"Type":{
"description":"Optional. The type of the data.",
"enum":[
"TYPE_UNSPECIFIED",
"STRING",
"NUMBER",
"INTEGER",
"BOOLEAN",
"ARRAY",
"OBJECT"
],
"title":"Type",
"type":"string"
},
"VertexAISearch":{
"additionalProperties":false,
"description":"Retrieve from Vertex AI Search datastore or engine for grounding.\n\ndatastore and engine are mutually exclusive. See\nhttps://cloud.google.com/products/agent-builder",
"properties":{
"datastore":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search data store resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`",
"title":"Datastore"
},
"engine":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search engine resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}`",
"title":"Engine"
}
},
"title":"VertexAISearch",
"type":"object"
},
"VertexRagStore":{
"additionalProperties":false,
"description":"Retrieve from Vertex RAG Store for grounding.",
"properties":{
"ragCorpora":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Deprecated. Please use rag_resources instead.",
"title":"Ragcorpora"
},
"ragResources":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/VertexRagStoreRagResource"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The representation of the rag source. It can be used to specify corpus only or ragfiles. Currently only support one corpus or multiple files from one corpus. In the future we may open up multiple corpora support.",
"title":"Ragresources"
},
"ragRetrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The retrieval config for the Rag query."
},
"similarityTopK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of top k results to return from the selected corpora.",
"title":"Similaritytopk"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only return results with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
}
},
"title":"VertexRagStore",
"type":"object"
},
"VertexRagStoreRagResource":{
"additionalProperties":false,
"description":"The definition of the Rag resource.",
"properties":{
"ragCorpus":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. RagCorpora resource name. Format: `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`",
"title":"Ragcorpus"
},
"ragFileIds":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus field.",
"title":"Ragfileids"
}
},
"title":"VertexRagStoreRagResource",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
},
"VoiceConfig":{
"additionalProperties":false,
"description":"The configuration for the voice to use.",
"properties":{
"prebuiltVoiceConfig":{
"anyOf":[
{
"$ref":"#/$defs/PrebuiltVoiceConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The configuration for the speaker to use.\n      "
}
},
"title":"VoiceConfig",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `config (genai.types.LiveConnectConfig | None)`
  * `model (str | None)`



_field_ config _:`Optional`[`LiveConnectConfig`]__= None_¶ 
    
Optional configuration parameters for the request. 

_field_ model _:`Optional`[`str`]__= None_¶ 
    
ID of the model to use. For a list of models, see Google models. 

_class_ genai.types.LiveConnectParametersDict¶ 
    
Bases: `TypedDict`
Parameters for connecting to the live API. 

config _:`Optional`[`LiveConnectConfigDict`]_¶ 
    
Optional configuration parameters for the request. 

model _:`Optional`[`str`]_¶ 
    
ID of the model to use. For a list of models, see Google models. 

_pydantic model_genai.types.LiveSendRealtimeInputParameters¶ 
    
Bases: `BaseModel`
Parameters for sending realtime input to the live API.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"LiveSendRealtimeInputParameters",
"description":"Parameters for sending realtime input to the live API.",
"type":"object",
"properties":{
"media":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Realtime input to send to the session.",
"title":"Media"
},
"audio":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"The realtime audio input stream."
},
"audioStreamEnd":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"\nIndicates that the audio stream has ended, e.g. because the microphone was\nturned off.\n\nThis should only be sent when automatic activity detection is enabled\n(which is the default).\n\nThe client can reopen the stream by sending an audio message.\n",
"title":"Audiostreamend"
},
"video":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"The realtime video input stream.",
"title":"Video"
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The realtime text input stream.",
"title":"Text"
},
"activityStart":{
"anyOf":[
{
"$ref":"#/$defs/ActivityStart"
},
{
"type":"null"
}
],
"default":null,
"description":"Marks the start of user activity."
},
"activityEnd":{
"anyOf":[
{
"$ref":"#/$defs/ActivityEnd"
},
{
"type":"null"
}
],
"default":null,
"description":"Marks the end of user activity."
}
},
"$defs":{
"ActivityEnd":{
"additionalProperties":false,
"description":"Marks the end of user activity.\n\nThis can only be sent if automatic (i.e. server-side) activity detection is\ndisabled.",
"properties":{},
"title":"ActivityEnd",
"type":"object"
},
"ActivityStart":{
"additionalProperties":false,
"description":"Marks the start of user activity.\n\nThis can only be sent if automatic (i.e. server-side) activity detection is\ndisabled.",
"properties":{},
"title":"ActivityStart",
"type":"object"
},
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `activity_end (genai.types.ActivityEnd | None)`
  * `activity_start (genai.types.ActivityStart | None)`
  * `audio (genai.types.Blob | None)`
  * `audio_stream_end (bool | None)`
  * `media (genai.types.Blob | PIL.Image.Image | None)`
  * `text (str | None)`
  * `video (genai.types.Blob | PIL.Image.Image | None)`



_field_ activity_end _:`Optional`[`ActivityEnd`]__= None_ _(alias 'activityEnd')_¶ 
    
Marks the end of user activity. 

_field_ activity_start _:`Optional`[`ActivityStart`]__= None_ _(alias 'activityStart')_¶ 
    
Marks the start of user activity. 

_field_ audio _:`Optional`[`Blob`]__= None_¶ 
    
The realtime audio input stream. 

_field_ audio_stream_end _:`Optional`[`bool`]__= None_ _(alias 'audioStreamEnd')_¶ 
    
Indicates that the audio stream has ended, e.g. because the microphone was turned off.
This should only be sent when automatic activity detection is enabled (which is the default).
The client can reopen the stream by sending an audio message. 

_field_ media _:`Union`[`Blob`, `Image`, `None`]__= None_¶ 
    
Realtime input to send to the session. 

_field_ text _:`Optional`[`str`]__= None_¶ 
    
The realtime text input stream. 

_field_ video _:`Union`[`Blob`, `Image`, `None`]__= None_¶ 
    
The realtime video input stream. 

_class_ genai.types.LiveSendRealtimeInputParametersDict¶ 
    
Bases: `TypedDict`
Parameters for sending realtime input to the live API. 

activity_end _:`Optional`[`ActivityEndDict`]_¶ 
    
Marks the end of user activity. 

activity_start _:`Optional`[`ActivityStartDict`]_¶ 
    
Marks the start of user activity. 

audio _:`Optional`[`BlobDict`]_¶ 
    
The realtime audio input stream. 

audio_stream_end _:`Optional`[`bool`]_¶ 
    
Indicates that the audio stream has ended, e.g. because the microphone was turned off.
This should only be sent when automatic activity detection is enabled (which is the default).
The client can reopen the stream by sending an audio message. 

media _:`Union`[`Blob`, `Image`, `BlobDict`, `None`]_¶ 
    
Realtime input to send to the session. 

text _:`Optional`[`str`]_¶ 
    
The realtime text input stream. 

video _:`Union`[`Blob`, `Image`, `BlobDict`, `None`]_¶ 
    
The realtime video input stream. 

_pydantic model_genai.types.LiveServerContent¶ 
    
Bases: `BaseModel`
Incremental server update generated by the model in response to client messages.
Content is generated as quickly as possible, and not in real time. Clients may choose to buffer and play it out in real time.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"LiveServerContent",
"description":"Incremental server update generated by the model in response to client messages.\n\nContent is generated as quickly as possible, and not in real time. Clients\nmay choose to buffer and play it out in real time.",
"type":"object",
"properties":{
"modelTurn":{
"anyOf":[
{
"$ref":"#/$defs/Content"
},
{
"type":"null"
}
],
"default":null,
"description":"The content that the model has generated as part of the current conversation with the user."
},
"turnComplete":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If true, indicates that the model is done generating. Generation will only start in response to additional client messages. Can be set alongside `content`, indicating that the `content` is the last in the turn.",
"title":"Turncomplete"
},
"interrupted":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If true, indicates that a client message has interrupted current model generation. If the client is playing out the content in realtime, this is a good signal to stop and empty the current queue.",
"title":"Interrupted"
},
"groundingMetadata":{
"anyOf":[
{
"$ref":"#/$defs/GroundingMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata returned to client when grounding is enabled."
},
"generationComplete":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If true, indicates that the model is done generating. When model is\n      interrupted while generating there will be no generation_complete message\n      in interrupted turn, it will go through interrupted > turn_complete.\n      When model assumes realtime playback there will be delay between\n      generation_complete and turn_complete that is caused by model\n      waiting for playback to finish. If true, indicates that the model\n      has finished generating all content. This is a signal to the client\n      that it can stop sending messages.",
"title":"Generationcomplete"
},
"inputTranscription":{
"anyOf":[
{
"$ref":"#/$defs/Transcription"
},
{
"type":"null"
}
],
"default":null,
"description":"Input transcription. The transcription is independent to the model\n      turn which means it doesn\u2019t imply any ordering between transcription and\n      model turn."
},
"outputTranscription":{
"anyOf":[
{
"$ref":"#/$defs/Transcription"
},
{
"type":"null"
}
],
"default":null,
"description":"Output transcription. The transcription is independent to the model\n      turn which means it doesn\u2019t imply any ordering between transcription and\n      model turn.\n      "
}
},
"$defs":{
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"Content":{
"additionalProperties":false,
"description":"Contains the multi-part content of a message.",
"properties":{
"parts":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Part"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of parts that constitute a single message. Each part may have\n      a different IANA MIME type.",
"title":"Parts"
},
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role.",
"title":"Role"
}
},
"title":"Content",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"GroundingChunk":{
"additionalProperties":false,
"description":"Grounding chunk.",
"properties":{
"retrievedContext":{
"anyOf":[
{
"$ref":"#/$defs/GroundingChunkRetrievedContext"
},
{
"type":"null"
}
],
"default":null,
"description":"Grounding chunk from context retrieved by the retrieval tools."
},
"web":{
"anyOf":[
{
"$ref":"#/$defs/GroundingChunkWeb"
},
{
"type":"null"
}
],
"default":null,
"description":"Grounding chunk from the web."
}
},
"title":"GroundingChunk",
"type":"object"
},
"GroundingChunkRetrievedContext":{
"additionalProperties":false,
"description":"Chunk from context retrieved by the retrieval tools.",
"properties":{
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Text of the attribution.",
"title":"Text"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Title of the attribution.",
"title":"Title"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"URI reference of the attribution.",
"title":"Uri"
}
},
"title":"GroundingChunkRetrievedContext",
"type":"object"
},
"GroundingChunkWeb":{
"additionalProperties":false,
"description":"Chunk from the web.",
"properties":{
"domain":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Domain of the (original) URI.",
"title":"Domain"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Title of the chunk.",
"title":"Title"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"URI reference of the chunk.",
"title":"Uri"
}
},
"title":"GroundingChunkWeb",
"type":"object"
},
"GroundingMetadata":{
"additionalProperties":false,
"description":"Metadata returned to client when grounding is enabled.",
"properties":{
"groundingChunks":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/GroundingChunk"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of supporting references retrieved from specified grounding source.",
"title":"Groundingchunks"
},
"groundingSupports":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/GroundingSupport"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. List of grounding support.",
"title":"Groundingsupports"
},
"retrievalMetadata":{
"anyOf":[
{
"$ref":"#/$defs/RetrievalMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Output only. Retrieval metadata."
},
"retrievalQueries":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Queries executed by the retrieval tools.",
"title":"Retrievalqueries"
},
"searchEntryPoint":{
"anyOf":[
{
"$ref":"#/$defs/SearchEntryPoint"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google search entry for the following-up web searches."
},
"webSearchQueries":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Web search queries for the following-up web search.",
"title":"Websearchqueries"
}
},
"title":"GroundingMetadata",
"type":"object"
},
"GroundingSupport":{
"additionalProperties":false,
"description":"Grounding support.",
"properties":{
"confidenceScores":{
"anyOf":[
{
"items":{
"type":"number"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Confidence score of the support references. Ranges from 0 to 1. 1 is the most confident. This list must have the same size as the grounding_chunk_indices.",
"title":"Confidencescores"
},
"groundingChunkIndices":{
"anyOf":[
{
"items":{
"type":"integer"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of indices (into 'grounding_chunk') specifying the citations associated with the claim. For instance [1,3,4] means that grounding_chunk[1], grounding_chunk[3], grounding_chunk[4] are the retrieved content attributed to the claim.",
"title":"Groundingchunkindices"
},
"segment":{
"anyOf":[
{
"$ref":"#/$defs/Segment"
},
{
"type":"null"
}
],
"default":null,
"description":"Segment of the content this support belongs to."
}
},
"title":"GroundingSupport",
"type":"object"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"RetrievalMetadata":{
"additionalProperties":false,
"description":"Metadata related to retrieval in the grounding flow.",
"properties":{
"googleSearchDynamicRetrievalScore":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Score indicating how likely information from Google Search could help answer the prompt. The score is in the range `[0, 1]`, where 0 is the least likely and 1 is the most likely. This score is only populated when Google Search grounding and dynamic retrieval is enabled. It will be compared to the threshold to determine whether to trigger Google Search.",
"title":"Googlesearchdynamicretrievalscore"
}
},
"title":"RetrievalMetadata",
"type":"object"
},
"SearchEntryPoint":{
"additionalProperties":false,
"description":"Google search entry point.",
"properties":{
"renderedContent":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Web content snippet that can be embedded in a web page or an app webview.",
"title":"Renderedcontent"
},
"sdkBlob":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Base64 encoded JSON representing array of tuple.",
"title":"Sdkblob"
}
},
"title":"SearchEntryPoint",
"type":"object"
},
"Segment":{
"additionalProperties":false,
"description":"Segment of the content.",
"properties":{
"endIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. End index in the given Part, measured in bytes. Offset from the start of the Part, exclusive, starting at zero.",
"title":"Endindex"
},
"partIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The index of a Part object within its parent Content object.",
"title":"Partindex"
},
"startIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Start index in the given Part, measured in bytes. Offset from the start of the Part, inclusive, starting at zero.",
"title":"Startindex"
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The text corresponding to the segment from the response.",
"title":"Text"
}
},
"title":"Segment",
"type":"object"
},
"Transcription":{
"additionalProperties":false,
"description":"Audio transcription in Server Conent.",
"properties":{
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Transcription text.\n      ",
"title":"Text"
},
"finished":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"The bool indicates the end of the transcription.\n      ",
"title":"Finished"
}
},
"title":"Transcription",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `generation_complete (bool | None)`
  * `grounding_metadata (genai.types.GroundingMetadata | None)`
  * `input_transcription (genai.types.Transcription | None)`
  * `interrupted (bool | None)`
  * `model_turn (genai.types.Content | None)`
  * `output_transcription (genai.types.Transcription | None)`
  * `turn_complete (bool | None)`



_field_ generation_complete _:`Optional`[`bool`]__= None_ _(alias 'generationComplete')_¶ 
    
If true, indicates that the model is done generating. When model is interrupted while generating there will be no generation_complete message in interrupted turn, it will go through interrupted > turn_complete. When model assumes realtime playback there will be delay between generation_complete and turn_complete that is caused by model waiting for playback to finish. If true, indicates that the model has finished generating all content. This is a signal to the client that it can stop sending messages. 

_field_ grounding_metadata _:`Optional`[`GroundingMetadata`]__= None_ _(alias 'groundingMetadata')_¶ 
    
Metadata returned to client when grounding is enabled. 

_field_ input_transcription _:`Optional`[`Transcription`]__= None_ _(alias 'inputTranscription')_¶ 
    
Input transcription. The transcription is independent to the model turn which means it doesn’t imply any ordering between transcription and model turn. 

_field_ interrupted _:`Optional`[`bool`]__= None_¶ 
    
If true, indicates that a client message has interrupted current model generation. If the client is playing out the content in realtime, this is a good signal to stop and empty the current queue. 

_field_ model_turn _:`Optional`[`Content`]__= None_ _(alias 'modelTurn')_¶ 
    
The content that the model has generated as part of the current conversation with the user. 

_field_ output_transcription _:`Optional`[`Transcription`]__= None_ _(alias 'outputTranscription')_¶ 
    
Output transcription. The transcription is independent to the model turn which means it doesn’t imply any ordering between transcription and model turn. 

_field_ turn_complete _:`Optional`[`bool`]__= None_ _(alias 'turnComplete')_¶ 
    
If true, indicates that the model is done generating. Generation will only start in response to additional client messages. Can be set alongside content, indicating that the content is the last in the turn. 

_class_ genai.types.LiveServerContentDict¶ 
    
Bases: `TypedDict`
Incremental server update generated by the model in response to client messages.
Content is generated as quickly as possible, and not in real time. Clients may choose to buffer and play it out in real time. 

generation_complete _:`Optional`[`bool`]_¶ 
    
If true, indicates that the model is done generating. When model is interrupted while generating there will be no generation_complete message in interrupted turn, it will go through interrupted > turn_complete. When model assumes realtime playback there will be delay between generation_complete and turn_complete that is caused by model waiting for playback to finish. If true, indicates that the model has finished generating all content. This is a signal to the client that it can stop sending messages. 

grounding_metadata _:`Optional`[`GroundingMetadataDict`]_¶ 
    
Metadata returned to client when grounding is enabled. 

input_transcription _:`Optional`[`TranscriptionDict`]_¶ 
    
Input transcription. The transcription is independent to the model turn which means it doesn’t imply any ordering between transcription and model turn. 

interrupted _:`Optional`[`bool`]_¶ 
    
If true, indicates that a client message has interrupted current model generation. If the client is playing out the content in realtime, this is a good signal to stop and empty the current queue. 

model_turn _:`Optional`[`ContentDict`]_¶ 
    
The content that the model has generated as part of the current conversation with the user. 

output_transcription _:`Optional`[`TranscriptionDict`]_¶ 
    
Output transcription. The transcription is independent to the model turn which means it doesn’t imply any ordering between transcription and model turn. 

turn_complete _:`Optional`[`bool`]_¶ 
    
If true, indicates that the model is done generating. Generation will only start in response to additional client messages. Can be set alongside content, indicating that the content is the last in the turn. 

_pydantic model_genai.types.LiveServerGoAway¶ 
    
Bases: `BaseModel`
Server will not be able to service client soon.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"LiveServerGoAway",
"description":"Server will not be able to service client soon.",
"type":"object",
"properties":{
"timeLeft":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The remaining time before the connection will be terminated as ABORTED. The minimal time returned here is specified differently together with the rate limits for a given model.",
"title":"Timeleft"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `time_left (str | None)`



_field_ time_left _:`Optional`[`str`]__= None_ _(alias 'timeLeft')_¶ 
    
The remaining time before the connection will be terminated as ABORTED. The minimal time returned here is specified differently together with the rate limits for a given model. 

_class_ genai.types.LiveServerGoAwayDict¶ 
    
Bases: `TypedDict`
Server will not be able to service client soon. 

time_left _:`Optional`[`str`]_¶ 
    
The remaining time before the connection will be terminated as ABORTED. The minimal time returned here is specified differently together with the rate limits for a given model. 

_pydantic model_genai.types.LiveServerMessage¶ 
    
Bases: `BaseModel`
Response message for API call.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"LiveServerMessage",
"description":"Response message for API call.",
"type":"object",
"properties":{
"setupComplete":{
"anyOf":[
{
"$ref":"#/$defs/LiveServerSetupComplete"
},
{
"type":"null"
}
],
"default":null,
"description":"Sent in response to a `LiveClientSetup` message from the client."
},
"serverContent":{
"anyOf":[
{
"$ref":"#/$defs/LiveServerContent"
},
{
"type":"null"
}
],
"default":null,
"description":"Content generated by the model in response to client messages."
},
"toolCall":{
"anyOf":[
{
"$ref":"#/$defs/LiveServerToolCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Request for the client to execute the `function_calls` and return the responses with the matching `id`s."
},
"toolCallCancellation":{
"anyOf":[
{
"$ref":"#/$defs/LiveServerToolCallCancellation"
},
{
"type":"null"
}
],
"default":null,
"description":"Notification for the client that a previously issued `ToolCallMessage` with the specified `id`s should have been not executed and should be cancelled."
},
"usageMetadata":{
"anyOf":[
{
"$ref":"#/$defs/UsageMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Usage metadata about model response(s)."
},
"goAway":{
"anyOf":[
{
"$ref":"#/$defs/LiveServerGoAway"
},
{
"type":"null"
}
],
"default":null,
"description":"Server will disconnect soon."
},
"sessionResumptionUpdate":{
"anyOf":[
{
"$ref":"#/$defs/LiveServerSessionResumptionUpdate"
},
{
"type":"null"
}
],
"default":null,
"description":"Update of the session resumption state."
}
},
"$defs":{
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"Content":{
"additionalProperties":false,
"description":"Contains the multi-part content of a message.",
"properties":{
"parts":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Part"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of parts that constitute a single message. Each part may have\n      a different IANA MIME type.",
"title":"Parts"
},
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role.",
"title":"Role"
}
},
"title":"Content",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"GroundingChunk":{
"additionalProperties":false,
"description":"Grounding chunk.",
"properties":{
"retrievedContext":{
"anyOf":[
{
"$ref":"#/$defs/GroundingChunkRetrievedContext"
},
{
"type":"null"
}
],
"default":null,
"description":"Grounding chunk from context retrieved by the retrieval tools."
},
"web":{
"anyOf":[
{
"$ref":"#/$defs/GroundingChunkWeb"
},
{
"type":"null"
}
],
"default":null,
"description":"Grounding chunk from the web."
}
},
"title":"GroundingChunk",
"type":"object"
},
"GroundingChunkRetrievedContext":{
"additionalProperties":false,
"description":"Chunk from context retrieved by the retrieval tools.",
"properties":{
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Text of the attribution.",
"title":"Text"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Title of the attribution.",
"title":"Title"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"URI reference of the attribution.",
"title":"Uri"
}
},
"title":"GroundingChunkRetrievedContext",
"type":"object"
},
"GroundingChunkWeb":{
"additionalProperties":false,
"description":"Chunk from the web.",
"properties":{
"domain":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Domain of the (original) URI.",
"title":"Domain"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Title of the chunk.",
"title":"Title"
},
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"URI reference of the chunk.",
"title":"Uri"
}
},
"title":"GroundingChunkWeb",
"type":"object"
},
"GroundingMetadata":{
"additionalProperties":false,
"description":"Metadata returned to client when grounding is enabled.",
"properties":{
"groundingChunks":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/GroundingChunk"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of supporting references retrieved from specified grounding source.",
"title":"Groundingchunks"
},
"groundingSupports":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/GroundingSupport"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. List of grounding support.",
"title":"Groundingsupports"
},
"retrievalMetadata":{
"anyOf":[
{
"$ref":"#/$defs/RetrievalMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Output only. Retrieval metadata."
},
"retrievalQueries":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Queries executed by the retrieval tools.",
"title":"Retrievalqueries"
},
"searchEntryPoint":{
"anyOf":[
{
"$ref":"#/$defs/SearchEntryPoint"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google search entry for the following-up web searches."
},
"webSearchQueries":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Web search queries for the following-up web search.",
"title":"Websearchqueries"
}
},
"title":"GroundingMetadata",
"type":"object"
},
"GroundingSupport":{
"additionalProperties":false,
"description":"Grounding support.",
"properties":{
"confidenceScores":{
"anyOf":[
{
"items":{
"type":"number"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Confidence score of the support references. Ranges from 0 to 1. 1 is the most confident. This list must have the same size as the grounding_chunk_indices.",
"title":"Confidencescores"
},
"groundingChunkIndices":{
"anyOf":[
{
"items":{
"type":"integer"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of indices (into 'grounding_chunk') specifying the citations associated with the claim. For instance [1,3,4] means that grounding_chunk[1], grounding_chunk[3], grounding_chunk[4] are the retrieved content attributed to the claim.",
"title":"Groundingchunkindices"
},
"segment":{
"anyOf":[
{
"$ref":"#/$defs/Segment"
},
{
"type":"null"
}
],
"default":null,
"description":"Segment of the content this support belongs to."
}
},
"title":"GroundingSupport",
"type":"object"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"LiveServerContent":{
"additionalProperties":false,
"description":"Incremental server update generated by the model in response to client messages.\n\nContent is generated as quickly as possible, and not in real time. Clients\nmay choose to buffer and play it out in real time.",
"properties":{
"modelTurn":{
"anyOf":[
{
"$ref":"#/$defs/Content"
},
{
"type":"null"
}
],
"default":null,
"description":"The content that the model has generated as part of the current conversation with the user."
},
"turnComplete":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If true, indicates that the model is done generating. Generation will only start in response to additional client messages. Can be set alongside `content`, indicating that the `content` is the last in the turn.",
"title":"Turncomplete"
},
"interrupted":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If true, indicates that a client message has interrupted current model generation. If the client is playing out the content in realtime, this is a good signal to stop and empty the current queue.",
"title":"Interrupted"
},
"groundingMetadata":{
"anyOf":[
{
"$ref":"#/$defs/GroundingMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata returned to client when grounding is enabled."
},
"generationComplete":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If true, indicates that the model is done generating. When model is\n      interrupted while generating there will be no generation_complete message\n      in interrupted turn, it will go through interrupted > turn_complete.\n      When model assumes realtime playback there will be delay between\n      generation_complete and turn_complete that is caused by model\n      waiting for playback to finish. If true, indicates that the model\n      has finished generating all content. This is a signal to the client\n      that it can stop sending messages.",
"title":"Generationcomplete"
},
"inputTranscription":{
"anyOf":[
{
"$ref":"#/$defs/Transcription"
},
{
"type":"null"
}
],
"default":null,
"description":"Input transcription. The transcription is independent to the model\n      turn which means it doesn\u2019t imply any ordering between transcription and\n      model turn."
},
"outputTranscription":{
"anyOf":[
{
"$ref":"#/$defs/Transcription"
},
{
"type":"null"
}
],
"default":null,
"description":"Output transcription. The transcription is independent to the model\n      turn which means it doesn\u2019t imply any ordering between transcription and\n      model turn.\n      "
}
},
"title":"LiveServerContent",
"type":"object"
},
"LiveServerGoAway":{
"additionalProperties":false,
"description":"Server will not be able to service client soon.",
"properties":{
"timeLeft":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The remaining time before the connection will be terminated as ABORTED. The minimal time returned here is specified differently together with the rate limits for a given model.",
"title":"Timeleft"
}
},
"title":"LiveServerGoAway",
"type":"object"
},
"LiveServerSessionResumptionUpdate":{
"additionalProperties":false,
"description":"Update of the session resumption state.\n\nOnly sent if `session_resumption` was set in the connection config.",
"properties":{
"newHandle":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"New handle that represents state that can be resumed. Empty if `resumable`=false.",
"title":"Newhandle"
},
"resumable":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"True if session can be resumed at this point. It might be not possible to resume session at some points. In that case we send update empty new_handle and resumable=false. Example of such case could be model executing function calls or just generating. Resuming session (using previous session token) in such state will result in some data loss.",
"title":"Resumable"
},
"lastConsumedClientMessageIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Index of last message sent by client that is included in state represented by this SessionResumptionToken. Only sent when `SessionResumptionConfig.transparent` is set.\n\nPresence of this index allows users to transparently reconnect and avoid issue of losing some part of realtime audio input/video. If client wishes to temporarily disconnect (for example as result of receiving GoAway) they can do it without losing state by buffering messages sent since last `SessionResmumptionTokenUpdate`. This field will enable them to limit buffering (avoid keeping all requests in RAM).\n\nNote: This should not be used for when resuming a session at some time later -- in those cases partial audio and video frames arelikely not needed.",
"title":"Lastconsumedclientmessageindex"
}
},
"title":"LiveServerSessionResumptionUpdate",
"type":"object"
},
"LiveServerSetupComplete":{
"additionalProperties":false,
"description":"Sent in response to a `LiveGenerateContentSetup` message from the client.",
"properties":{},
"title":"LiveServerSetupComplete",
"type":"object"
},
"LiveServerToolCall":{
"additionalProperties":false,
"description":"Request for the client to execute the `function_calls` and return the responses with the matching `id`s.",
"properties":{
"functionCalls":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/FunctionCall"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The function call to be executed.",
"title":"Functioncalls"
}
},
"title":"LiveServerToolCall",
"type":"object"
},
"LiveServerToolCallCancellation":{
"additionalProperties":false,
"description":"Notification for the client that a previously issued `ToolCallMessage` with the specified `id`s should have been not executed and should be cancelled.\n\nIf there were side-effects to those tool calls, clients may attempt to undo\nthe tool calls. This message occurs only in cases where the clients interrupt\nserver turns.",
"properties":{
"ids":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The ids of the tool calls to be cancelled.",
"title":"Ids"
}
},
"title":"LiveServerToolCallCancellation",
"type":"object"
},
"MediaModality":{
"description":"Server content modalities.",
"enum":[
"MODALITY_UNSPECIFIED",
"TEXT",
"IMAGE",
"VIDEO",
"AUDIO",
"DOCUMENT"
],
"title":"MediaModality",
"type":"string"
},
"ModalityTokenCount":{
"additionalProperties":false,
"description":"Represents token counting info for a single modality.",
"properties":{
"modality":{
"anyOf":[
{
"$ref":"#/$defs/MediaModality"
},
{
"type":"null"
}
],
"default":null,
"description":"The modality associated with this token count."
},
"tokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens.",
"title":"Tokencount"
}
},
"title":"ModalityTokenCount",
"type":"object"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"RetrievalMetadata":{
"additionalProperties":false,
"description":"Metadata related to retrieval in the grounding flow.",
"properties":{
"googleSearchDynamicRetrievalScore":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Score indicating how likely information from Google Search could help answer the prompt. The score is in the range `[0, 1]`, where 0 is the least likely and 1 is the most likely. This score is only populated when Google Search grounding and dynamic retrieval is enabled. It will be compared to the threshold to determine whether to trigger Google Search.",
"title":"Googlesearchdynamicretrievalscore"
}
},
"title":"RetrievalMetadata",
"type":"object"
},
"SearchEntryPoint":{
"additionalProperties":false,
"description":"Google search entry point.",
"properties":{
"renderedContent":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Web content snippet that can be embedded in a web page or an app webview.",
"title":"Renderedcontent"
},
"sdkBlob":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Base64 encoded JSON representing array of tuple.",
"title":"Sdkblob"
}
},
"title":"SearchEntryPoint",
"type":"object"
},
"Segment":{
"additionalProperties":false,
"description":"Segment of the content.",
"properties":{
"endIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. End index in the given Part, measured in bytes. Offset from the start of the Part, exclusive, starting at zero.",
"title":"Endindex"
},
"partIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The index of a Part object within its parent Content object.",
"title":"Partindex"
},
"startIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Start index in the given Part, measured in bytes. Offset from the start of the Part, inclusive, starting at zero.",
"title":"Startindex"
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The text corresponding to the segment from the response.",
"title":"Text"
}
},
"title":"Segment",
"type":"object"
},
"TrafficType":{
"description":"Output only.\n\nTraffic type. This shows whether a request consumes Pay-As-You-Go or\nProvisioned Throughput quota.",
"enum":[
"TRAFFIC_TYPE_UNSPECIFIED",
"ON_DEMAND",
"PROVISIONED_THROUGHPUT"
],
"title":"TrafficType",
"type":"string"
},
"Transcription":{
"additionalProperties":false,
"description":"Audio transcription in Server Conent.",
"properties":{
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Transcription text.\n      ",
"title":"Text"
},
"finished":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"The bool indicates the end of the transcription.\n      ",
"title":"Finished"
}
},
"title":"Transcription",
"type":"object"
},
"UsageMetadata":{
"additionalProperties":false,
"description":"Usage metadata about response(s).",
"properties":{
"promptTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens in the prompt. When `cached_content` is set, this is still the total effective prompt size meaning this includes the number of tokens in the cached content.",
"title":"Prompttokencount"
},
"cachedContentTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens in the cached part of the prompt (the cached content).",
"title":"Cachedcontenttokencount"
},
"responseTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Total number of tokens across all the generated response candidates.",
"title":"Responsetokencount"
},
"toolUsePromptTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens present in tool-use prompt(s).",
"title":"Tooluseprompttokencount"
},
"thoughtsTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens of thoughts for thinking models.",
"title":"Thoughtstokencount"
},
"totalTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Total token count for prompt, response candidates, and tool-use prompts(if present).",
"title":"Totaltokencount"
},
"promptTokensDetails":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/ModalityTokenCount"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of modalities that were processed in the request input.",
"title":"Prompttokensdetails"
},
"cacheTokensDetails":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/ModalityTokenCount"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of modalities that were processed in the cache input.",
"title":"Cachetokensdetails"
},
"responseTokensDetails":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/ModalityTokenCount"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of modalities that were returned in the response.",
"title":"Responsetokensdetails"
},
"toolUsePromptTokensDetails":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/ModalityTokenCount"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of modalities that were processed in the tool-use prompt.",
"title":"Tooluseprompttokensdetails"
},
"trafficType":{
"anyOf":[
{
"$ref":"#/$defs/TrafficType"
},
{
"type":"null"
}
],
"default":null,
"description":"Traffic type. This shows whether a request consumes Pay-As-You-Go\n or Provisioned Throughput quota."
}
},
"title":"UsageMetadata",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `go_away (genai.types.LiveServerGoAway | None)`
  * `server_content (genai.types.LiveServerContent | None)`
  * `session_resumption_update (genai.types.LiveServerSessionResumptionUpdate | None)`
  * `setup_complete (genai.types.LiveServerSetupComplete | None)`
  * `tool_call (genai.types.LiveServerToolCall | None)`
  * `tool_call_cancellation (genai.types.LiveServerToolCallCancellation | None)`
  * `usage_metadata (genai.types.UsageMetadata | None)`



_field_ go_away _:`Optional`[`LiveServerGoAway`]__= None_ _(alias 'goAway')_¶ 
    
Server will disconnect soon. 

_field_ server_content _:`Optional`[`LiveServerContent`]__= None_ _(alias 'serverContent')_¶ 
    
Content generated by the model in response to client messages. 

_field_ session_resumption_update _:`Optional`[`LiveServerSessionResumptionUpdate`]__= None_ _(alias 'sessionResumptionUpdate')_¶ 
    
Update of the session resumption state. 

_field_ setup_complete _:`Optional`[`LiveServerSetupComplete`]__= None_ _(alias 'setupComplete')_¶ 
    
Sent in response to a LiveClientSetup message from the client. 

_field_ tool_call _:`Optional`[`LiveServerToolCall`]__= None_ _(alias 'toolCall')_¶ 
    
Request for the client to execute the function_calls and return the responses with the matching `id`s. 

_field_ tool_call_cancellation _:`Optional`[`LiveServerToolCallCancellation`]__= None_ _(alias 'toolCallCancellation')_¶ 
    
Notification for the client that a previously issued ToolCallMessage with the specified `id`s should have been not executed and should be cancelled. 

_field_ usage_metadata _:`Optional`[`UsageMetadata`]__= None_ _(alias 'usageMetadata')_¶ 
    
Usage metadata about model response(s). 

_property_ data _: bytes|None_¶ 
    
Returns the concatenation of all inline data parts in the response. 

_property_ text _: str|None_¶ 
    
Returns the concatenation of all text parts in the response. 

_class_ genai.types.LiveServerMessageDict¶ 
    
Bases: `TypedDict`
Response message for API call. 

go_away _:`Optional`[`LiveServerGoAwayDict`]_¶ 
    
Server will disconnect soon. 

server_content _:`Optional`[`LiveServerContentDict`]_¶ 
    
Content generated by the model in response to client messages. 

session_resumption_update _:`Optional`[`LiveServerSessionResumptionUpdateDict`]_¶ 
    
Update of the session resumption state. 

setup_complete _:`Optional`[`LiveServerSetupCompleteDict`]_¶ 
    
Sent in response to a LiveClientSetup message from the client. 

tool_call _:`Optional`[`LiveServerToolCallDict`]_¶ 
    
Request for the client to execute the function_calls and return the responses with the matching `id`s. 

tool_call_cancellation _:`Optional`[`LiveServerToolCallCancellationDict`]_¶ 
    
Notification for the client that a previously issued ToolCallMessage with the specified `id`s should have been not executed and should be cancelled. 

usage_metadata _:`Optional`[`UsageMetadataDict`]_¶ 
    
Usage metadata about model response(s). 

_pydantic model_genai.types.LiveServerSessionResumptionUpdate¶ 
    
Bases: `BaseModel`
Update of the session resumption state.
Only sent if session_resumption was set in the connection config.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"LiveServerSessionResumptionUpdate",
"description":"Update of the session resumption state.\n\nOnly sent if `session_resumption` was set in the connection config.",
"type":"object",
"properties":{
"newHandle":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"New handle that represents state that can be resumed. Empty if `resumable`=false.",
"title":"Newhandle"
},
"resumable":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"True if session can be resumed at this point. It might be not possible to resume session at some points. In that case we send update empty new_handle and resumable=false. Example of such case could be model executing function calls or just generating. Resuming session (using previous session token) in such state will result in some data loss.",
"title":"Resumable"
},
"lastConsumedClientMessageIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Index of last message sent by client that is included in state represented by this SessionResumptionToken. Only sent when `SessionResumptionConfig.transparent` is set.\n\nPresence of this index allows users to transparently reconnect and avoid issue of losing some part of realtime audio input/video. If client wishes to temporarily disconnect (for example as result of receiving GoAway) they can do it without losing state by buffering messages sent since last `SessionResmumptionTokenUpdate`. This field will enable them to limit buffering (avoid keeping all requests in RAM).\n\nNote: This should not be used for when resuming a session at some time later -- in those cases partial audio and video frames arelikely not needed.",
"title":"Lastconsumedclientmessageindex"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `last_consumed_client_message_index (int | None)`
  * `new_handle (str | None)`
  * `resumable (bool | None)`



_field_ last_consumed_client_message_index _:`Optional`[`int`]__= None_ _(alias 'lastConsumedClientMessageIndex')_¶ 
    
Index of last message sent by client that is included in state represented by this SessionResumptionToken. Only sent when SessionResumptionConfig.transparent is set.
Presence of this index allows users to transparently reconnect and avoid issue of losing some part of realtime audio input/video. If client wishes to temporarily disconnect (for example as result of receiving GoAway) they can do it without losing state by buffering messages sent since last SessionResmumptionTokenUpdate. This field will enable them to limit buffering (avoid keeping all requests in RAM).
Note: This should not be used for when resuming a session at some time later – in those cases partial audio and video frames arelikely not needed. 

_field_ new_handle _:`Optional`[`str`]__= None_ _(alias 'newHandle')_¶ 
    
New handle that represents state that can be resumed. Empty if `resumable`=false. 

_field_ resumable _:`Optional`[`bool`]__= None_¶ 
    
True if session can be resumed at this point. It might be not possible to resume session at some points. In that case we send update empty new_handle and resumable=false. Example of such case could be model executing function calls or just generating. Resuming session (using previous session token) in such state will result in some data loss. 

_class_ genai.types.LiveServerSessionResumptionUpdateDict¶ 
    
Bases: `TypedDict`
Update of the session resumption state.
Only sent if session_resumption was set in the connection config. 

last_consumed_client_message_index _:`Optional`[`int`]_¶ 
    
Index of last message sent by client that is included in state represented by this SessionResumptionToken. Only sent when SessionResumptionConfig.transparent is set.
Presence of this index allows users to transparently reconnect and avoid issue of losing some part of realtime audio input/video. If client wishes to temporarily disconnect (for example as result of receiving GoAway) they can do it without losing state by buffering messages sent since last SessionResmumptionTokenUpdate. This field will enable them to limit buffering (avoid keeping all requests in RAM).
Note: This should not be used for when resuming a session at some time later – in those cases partial audio and video frames arelikely not needed. 

new_handle _:`Optional`[`str`]_¶ 
    
New handle that represents state that can be resumed. Empty if `resumable`=false. 

resumable _:`Optional`[`bool`]_¶ 
    
True if session can be resumed at this point. It might be not possible to resume session at some points. In that case we send update empty new_handle and resumable=false. Example of such case could be model executing function calls or just generating. Resuming session (using previous session token) in such state will result in some data loss. 

_pydantic model_genai.types.LiveServerSetupComplete¶ 
    
Bases: `BaseModel`
Sent in response to a LiveGenerateContentSetup message from the client.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"LiveServerSetupComplete",
"description":"Sent in response to a `LiveGenerateContentSetup` message from the client.",
"type":"object",
"properties":{},
"additionalProperties":false
}

```


_class_ genai.types.LiveServerSetupCompleteDict¶ 
    
Bases: `TypedDict`
Sent in response to a LiveGenerateContentSetup message from the client. 

_pydantic model_genai.types.LiveServerToolCall¶ 
    
Bases: `BaseModel`
Request for the client to execute the function_calls and return the responses with the matching `id`s.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"LiveServerToolCall",
"description":"Request for the client to execute the `function_calls` and return the responses with the matching `id`s.",
"type":"object",
"properties":{
"functionCalls":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/FunctionCall"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The function call to be executed.",
"title":"Functioncalls"
}
},
"$defs":{
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `function_calls (list[genai.types.FunctionCall] | None)`



_field_ function_calls _:`Optional`[`list`[`FunctionCall`]]__= None_ _(alias 'functionCalls')_¶ 
    
The function call to be executed. 

_pydantic model_genai.types.LiveServerToolCallCancellation¶ 
    
Bases: `BaseModel`
Notification for the client that a previously issued ToolCallMessage with the specified `id`s should have been not executed and should be cancelled.
If there were side-effects to those tool calls, clients may attempt to undo the tool calls. This message occurs only in cases where the clients interrupt server turns.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"LiveServerToolCallCancellation",
"description":"Notification for the client that a previously issued `ToolCallMessage` with the specified `id`s should have been not executed and should be cancelled.\n\nIf there were side-effects to those tool calls, clients may attempt to undo\nthe tool calls. This message occurs only in cases where the clients interrupt\nserver turns.",
"type":"object",
"properties":{
"ids":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The ids of the tool calls to be cancelled.",
"title":"Ids"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `ids (list[str] | None)`



_field_ ids _:`Optional`[`list`[`str`]]__= None_¶ 
    
The ids of the tool calls to be cancelled. 

_class_ genai.types.LiveServerToolCallCancellationDict¶ 
    
Bases: `TypedDict`
Notification for the client that a previously issued ToolCallMessage with the specified `id`s should have been not executed and should be cancelled.
If there were side-effects to those tool calls, clients may attempt to undo the tool calls. This message occurs only in cases where the clients interrupt server turns. 

ids _:`Optional`[`list`[`str`]]_¶ 
    
The ids of the tool calls to be cancelled. 

_class_ genai.types.LiveServerToolCallDict¶ 
    
Bases: `TypedDict`
Request for the client to execute the function_calls and return the responses with the matching `id`s. 

function_calls _:`Optional`[`list`[`FunctionCallDict`]]_¶ 
    
The function call to be executed. 

_pydantic model_genai.types.LogprobsResult¶ 
    
Bases: `BaseModel`
Logprobs Result
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"LogprobsResult",
"description":"Logprobs Result",
"type":"object",
"properties":{
"chosenCandidates":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/LogprobsResultCandidate"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Length = total number of decoding steps. The chosen candidates may or may not be in top_candidates.",
"title":"Chosencandidates"
},
"topCandidates":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/LogprobsResultTopCandidates"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Length = total number of decoding steps.",
"title":"Topcandidates"
}
},
"$defs":{
"LogprobsResultCandidate":{
"additionalProperties":false,
"description":"Candidate for the logprobs token and score.",
"properties":{
"logProbability":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"The candidate's log probability.",
"title":"Logprobability"
},
"token":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The candidate's token string value.",
"title":"Token"
},
"tokenId":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The candidate's token id value.",
"title":"Tokenid"
}
},
"title":"LogprobsResultCandidate",
"type":"object"
},
"LogprobsResultTopCandidates":{
"additionalProperties":false,
"description":"Candidates with top log probabilities at each decoding step.",
"properties":{
"candidates":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/LogprobsResultCandidate"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Sorted by log probability in descending order.",
"title":"Candidates"
}
},
"title":"LogprobsResultTopCandidates",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `chosen_candidates (list[genai.types.LogprobsResultCandidate] | None)`
  * `top_candidates (list[genai.types.LogprobsResultTopCandidates] | None)`



_field_ chosen_candidates _:`Optional`[`list`[`LogprobsResultCandidate`]]__= None_ _(alias 'chosenCandidates')_¶ 
    
Length = total number of decoding steps. The chosen candidates may or may not be in top_candidates. 

_field_ top_candidates _:`Optional`[`list`[`LogprobsResultTopCandidates`]]__= None_ _(alias 'topCandidates')_¶ 
    
Length = total number of decoding steps. 

_pydantic model_genai.types.LogprobsResultCandidate¶ 
    
Bases: `BaseModel`
Candidate for the logprobs token and score.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"LogprobsResultCandidate",
"description":"Candidate for the logprobs token and score.",
"type":"object",
"properties":{
"logProbability":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"The candidate's log probability.",
"title":"Logprobability"
},
"token":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The candidate's token string value.",
"title":"Token"
},
"tokenId":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The candidate's token id value.",
"title":"Tokenid"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `log_probability (float | None)`
  * `token (str | None)`
  * `token_id (int | None)`



_field_ log_probability _:`Optional`[`float`]__= None_ _(alias 'logProbability')_¶ 
    
The candidate’s log probability. 

_field_ token _:`Optional`[`str`]__= None_¶ 
    
The candidate’s token string value. 

_field_ token_id _:`Optional`[`int`]__= None_ _(alias 'tokenId')_¶ 
    
The candidate’s token id value. 

_class_ genai.types.LogprobsResultCandidateDict¶ 
    
Bases: `TypedDict`
Candidate for the logprobs token and score. 

log_probability _:`Optional`[`float`]_¶ 
    
The candidate’s log probability. 

token _:`Optional`[`str`]_¶ 
    
The candidate’s token string value. 

token_id _:`Optional`[`int`]_¶ 
    
The candidate’s token id value. 

_class_ genai.types.LogprobsResultDict¶ 
    
Bases: `TypedDict`
Logprobs Result 

chosen_candidates _:`Optional`[`list`[`LogprobsResultCandidateDict`]]_¶ 
    
Length = total number of decoding steps. The chosen candidates may or may not be in top_candidates. 

top_candidates _:`Optional`[`list`[`LogprobsResultTopCandidatesDict`]]_¶ 
    
Length = total number of decoding steps. 

_pydantic model_genai.types.LogprobsResultTopCandidates¶ 
    
Bases: `BaseModel`
Candidates with top log probabilities at each decoding step.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"LogprobsResultTopCandidates",
"description":"Candidates with top log probabilities at each decoding step.",
"type":"object",
"properties":{
"candidates":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/LogprobsResultCandidate"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Sorted by log probability in descending order.",
"title":"Candidates"
}
},
"$defs":{
"LogprobsResultCandidate":{
"additionalProperties":false,
"description":"Candidate for the logprobs token and score.",
"properties":{
"logProbability":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"The candidate's log probability.",
"title":"Logprobability"
},
"token":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The candidate's token string value.",
"title":"Token"
},
"tokenId":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The candidate's token id value.",
"title":"Tokenid"
}
},
"title":"LogprobsResultCandidate",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `candidates (list[genai.types.LogprobsResultCandidate] | None)`



_field_ candidates _:`Optional`[`list`[`LogprobsResultCandidate`]]__= None_¶ 
    
Sorted by log probability in descending order. 

_class_ genai.types.LogprobsResultTopCandidatesDict¶ 
    
Bases: `TypedDict`
Candidates with top log probabilities at each decoding step. 

candidates _:`Optional`[`list`[`LogprobsResultCandidateDict`]]_¶ 
    
Sorted by log probability in descending order. 

_pydantic model_genai.types.MaskReferenceConfig¶ 
    
Bases: `BaseModel`
Configuration for a Mask reference image.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"MaskReferenceConfig",
"description":"Configuration for a Mask reference image.",
"type":"object",
"properties":{
"maskMode":{
"anyOf":[
{
"$ref":"#/$defs/MaskReferenceMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Prompts the model to generate a mask instead of you needing to\n      provide one (unless MASK_MODE_USER_PROVIDED is used)."
},
"segmentationClasses":{
"anyOf":[
{
"items":{
"type":"integer"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of up to 5 class ids to use for semantic segmentation.\n      Automatically creates an image mask based on specific objects.",
"title":"Segmentationclasses"
},
"maskDilation":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Dilation percentage of the mask provided.\n      Float between 0 and 1.",
"title":"Maskdilation"
}
},
"$defs":{
"MaskReferenceMode":{
"description":"Enum representing the mask mode of a mask reference image.",
"enum":[
"MASK_MODE_DEFAULT",
"MASK_MODE_USER_PROVIDED",
"MASK_MODE_BACKGROUND",
"MASK_MODE_FOREGROUND",
"MASK_MODE_SEMANTIC"
],
"title":"MaskReferenceMode",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `mask_dilation (float | None)`
  * `mask_mode (genai.types.MaskReferenceMode | None)`
  * `segmentation_classes (list[int] | None)`



_field_ mask_dilation _:`Optional`[`float`]__= None_ _(alias 'maskDilation')_¶ 
    
Dilation percentage of the mask provided. Float between 0 and 1. 

_field_ mask_mode _:`Optional`[`MaskReferenceMode`]__= None_ _(alias 'maskMode')_¶ 
    
Prompts the model to generate a mask instead of you needing to provide one (unless MASK_MODE_USER_PROVIDED is used). 

_field_ segmentation_classes _:`Optional`[`list`[`int`]]__= None_ _(alias 'segmentationClasses')_¶ 
    
A list of up to 5 class ids to use for semantic segmentation. Automatically creates an image mask based on specific objects. 

_class_ genai.types.MaskReferenceConfigDict¶ 
    
Bases: `TypedDict`
Configuration for a Mask reference image. 

mask_dilation _:`Optional`[`float`]_¶ 
    
Dilation percentage of the mask provided. Float between 0 and 1. 

mask_mode _:`Optional`[`MaskReferenceMode`]_¶ 
    
Prompts the model to generate a mask instead of you needing to provide one (unless MASK_MODE_USER_PROVIDED is used). 

segmentation_classes _:`Optional`[`list`[`int`]]_¶ 
    
A list of up to 5 class ids to use for semantic segmentation. Automatically creates an image mask based on specific objects. 

_pydantic model_genai.types.MaskReferenceImage¶ 
    
Bases: `BaseModel`
A mask reference image.
This encapsulates either a mask image provided by the user and configs for the user provided mask, or only config parameters for the model to generate a mask.
A mask image is an image whose non-zero values indicate where to edit the base image. If the user provides a mask image, the mask must be in the same dimensions as the raw image.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"MaskReferenceImage",
"description":"A mask reference image.\n\nThis encapsulates either a mask image provided by the user and configs for\nthe user provided mask, or only config parameters for the model to generate\na mask.\n\nA mask image is an image whose non-zero values indicate where to edit the base\nimage. If the user provides a mask image, the mask must be in the same\ndimensions as the raw image.",
"type":"object",
"properties":{
"referenceImage":{
"anyOf":[
{
"$ref":"#/$defs/Image"
},
{
"type":"null"
}
],
"default":null,
"description":"The reference image for the editing operation."
},
"referenceId":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the reference image.",
"title":"Referenceid"
},
"referenceType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The type of the reference image. Only set by the SDK.",
"title":"Referencetype"
},
"config":{
"anyOf":[
{
"$ref":"#/$defs/MaskReferenceConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Configuration for the mask reference image."
},
"maskImageConfig":{
"anyOf":[
{
"$ref":"#/$defs/MaskReferenceConfig"
},
{
"type":"null"
}
],
"default":null,
"description":""
}
},
"$defs":{
"Image":{
"additionalProperties":false,
"description":"An image.",
"properties":{
"gcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The Cloud Storage URI of the image. ``Image`` can contain a value\n      for this field or the ``image_bytes`` field but not both.\n      ",
"title":"Gcsuri"
},
"imageBytes":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The image bytes data. ``Image`` can contain a value for this field\n      or the ``gcs_uri`` field but not both.\n      ",
"title":"Imagebytes"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The MIME type of the image.",
"title":"Mimetype"
}
},
"title":"Image",
"type":"object"
},
"MaskReferenceConfig":{
"additionalProperties":false,
"description":"Configuration for a Mask reference image.",
"properties":{
"maskMode":{
"anyOf":[
{
"$ref":"#/$defs/MaskReferenceMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Prompts the model to generate a mask instead of you needing to\n      provide one (unless MASK_MODE_USER_PROVIDED is used)."
},
"segmentationClasses":{
"anyOf":[
{
"items":{
"type":"integer"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of up to 5 class ids to use for semantic segmentation.\n      Automatically creates an image mask based on specific objects.",
"title":"Segmentationclasses"
},
"maskDilation":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Dilation percentage of the mask provided.\n      Float between 0 and 1.",
"title":"Maskdilation"
}
},
"title":"MaskReferenceConfig",
"type":"object"
},
"MaskReferenceMode":{
"description":"Enum representing the mask mode of a mask reference image.",
"enum":[
"MASK_MODE_DEFAULT",
"MASK_MODE_USER_PROVIDED",
"MASK_MODE_BACKGROUND",
"MASK_MODE_FOREGROUND",
"MASK_MODE_SEMANTIC"
],
"title":"MaskReferenceMode",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `config (genai.types.MaskReferenceConfig | None)`
  * `mask_image_config (genai.types.MaskReferenceConfig | None)`
  * `reference_id (int | None)`
  * `reference_image (genai.types.Image | None)`
  * `reference_type (str | None)`



Validators: 
    
  * `_validate_mask_image_config` » `all fields`



_field_ config _:`Optional`[`MaskReferenceConfig`]__= None_¶ 
    
Re-map config to mask_reference_config to send to API.
Configuration for the mask reference image. 

Validated by: 
    
  * `_validate_mask_image_config`



_field_ mask_image_config _:`Optional`[MaskReferenceConfig]__= None_ _(alias 'maskImageConfig')_¶ 
     

Validated by: 
    
  * `_validate_mask_image_config`



_field_ reference_id _:`Optional`[`int`]__= None_ _(alias 'referenceId')_¶ 
    
The id of the reference image. 

Validated by: 
    
  * `_validate_mask_image_config`



_field_ reference_image _:`Optional`[`Image`]__= None_ _(alias 'referenceImage')_¶ 
    
The reference image for the editing operation. 

Validated by: 
    
  * `_validate_mask_image_config`



_field_ reference_type _:`Optional`[`str`]__= None_ _(alias 'referenceType')_¶ 
    
The type of the reference image. Only set by the SDK. 

Validated by: 
    
  * `_validate_mask_image_config`



_class_ genai.types.MaskReferenceImageDict¶ 
    
Bases: `TypedDict`
A mask reference image.
This encapsulates either a mask image provided by the user and configs for the user provided mask, or only config parameters for the model to generate a mask.
A mask image is an image whose non-zero values indicate where to edit the base image. If the user provides a mask image, the mask must be in the same dimensions as the raw image. 

config _:`Optional`[`MaskReferenceConfigDict`]_¶ 
    
Configuration for the mask reference image. 

reference_id _:`Optional`[`int`]_¶ 
    
The id of the reference image. 

reference_image _:`Optional`[`ImageDict`]_¶ 
    
The reference image for the editing operation. 

reference_type _:`Optional`[`str`]_¶ 
    
The type of the reference image. Only set by the SDK. 

_class_ genai.types.MaskReferenceMode(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Enum representing the mask mode of a mask reference image. 

MASK_MODE_BACKGROUND _= 'MASK_MODE_BACKGROUND'_¶ 


MASK_MODE_DEFAULT _= 'MASK_MODE_DEFAULT'_¶ 


MASK_MODE_FOREGROUND _= 'MASK_MODE_FOREGROUND'_¶ 


MASK_MODE_SEMANTIC _= 'MASK_MODE_SEMANTIC'_¶ 


MASK_MODE_USER_PROVIDED _= 'MASK_MODE_USER_PROVIDED'_¶ 


_class_ genai.types.MediaModality(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Server content modalities. 

AUDIO _= 'AUDIO'_¶ 


DOCUMENT _= 'DOCUMENT'_¶ 


IMAGE _= 'IMAGE'_¶ 


MODALITY_UNSPECIFIED _= 'MODALITY_UNSPECIFIED'_¶ 


TEXT _= 'TEXT'_¶ 


VIDEO _= 'VIDEO'_¶ 


_class_ genai.types.MediaResolution(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
The media resolution to use. 

MEDIA_RESOLUTION_HIGH _= 'MEDIA_RESOLUTION_HIGH'_¶ 


MEDIA_RESOLUTION_LOW _= 'MEDIA_RESOLUTION_LOW'_¶ 


MEDIA_RESOLUTION_MEDIUM _= 'MEDIA_RESOLUTION_MEDIUM'_¶ 


MEDIA_RESOLUTION_UNSPECIFIED _= 'MEDIA_RESOLUTION_UNSPECIFIED'_¶ 


_class_ genai.types.Modality(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Server content modalities. 

AUDIO _= 'AUDIO'_¶ 


IMAGE _= 'IMAGE'_¶ 


MODALITY_UNSPECIFIED _= 'MODALITY_UNSPECIFIED'_¶ 


TEXT _= 'TEXT'_¶ 


_pydantic model_genai.types.ModalityTokenCount¶ 
    
Bases: `BaseModel`
Represents token counting info for a single modality.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ModalityTokenCount",
"description":"Represents token counting info for a single modality.",
"type":"object",
"properties":{
"modality":{
"anyOf":[
{
"$ref":"#/$defs/MediaModality"
},
{
"type":"null"
}
],
"default":null,
"description":"The modality associated with this token count."
},
"tokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens.",
"title":"Tokencount"
}
},
"$defs":{
"MediaModality":{
"description":"Server content modalities.",
"enum":[
"MODALITY_UNSPECIFIED",
"TEXT",
"IMAGE",
"VIDEO",
"AUDIO",
"DOCUMENT"
],
"title":"MediaModality",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `modality (genai.types.MediaModality | None)`
  * `token_count (int | None)`



_field_ modality _:`Optional`[`MediaModality`]__= None_¶ 
    
The modality associated with this token count. 

_field_ token_count _:`Optional`[`int`]__= None_ _(alias 'tokenCount')_¶ 
    
Number of tokens. 

_class_ genai.types.ModalityTokenCountDict¶ 
    
Bases: `TypedDict`
Represents token counting info for a single modality. 

modality _:`Optional`[`MediaModality`]_¶ 
    
The modality associated with this token count. 

token_count _:`Optional`[`int`]_¶ 
    
Number of tokens. 

_class_ genai.types.Mode(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
The mode of the predictor to be used in dynamic retrieval. 

MODE_DYNAMIC _= 'MODE_DYNAMIC'_¶ 


MODE_UNSPECIFIED _= 'MODE_UNSPECIFIED'_¶ 


_pydantic model_genai.types.Model¶ 
    
Bases: `BaseModel`
A trained machine learning model.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"Model",
"description":"A trained machine learning model.",
"type":"object",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Resource name of the model.",
"title":"Name"
},
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Display name of the model.",
"title":"Displayname"
},
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Description of the model.",
"title":"Description"
},
"version":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Version ID of the model. A new version is committed when a new\n      model version is uploaded or trained under an existing model ID. The\n      version ID is an auto-incrementing decimal number in string\n      representation.",
"title":"Version"
},
"endpoints":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Endpoint"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of deployed models created from this base model. Note that a\n      model could have been deployed to endpoints in different locations.",
"title":"Endpoints"
},
"labels":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Labels with user-defined metadata to organize your models.",
"title":"Labels"
},
"tunedModelInfo":{
"anyOf":[
{
"$ref":"#/$defs/TunedModelInfo"
},
{
"type":"null"
}
],
"default":null,
"description":"Information about the tuned model from the base model."
},
"inputTokenLimit":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The maximum number of input tokens that the model can handle.",
"title":"Inputtokenlimit"
},
"outputTokenLimit":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The maximum number of output tokens that the model can generate.",
"title":"Outputtokenlimit"
},
"supportedActions":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of actions that are supported by the model.",
"title":"Supportedactions"
},
"defaultCheckpointId":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The default checkpoint id of a model version.\n      ",
"title":"Defaultcheckpointid"
},
"checkpoints":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Checkpoint"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The checkpoints of the model.",
"title":"Checkpoints"
}
},
"$defs":{
"Checkpoint":{
"additionalProperties":false,
"description":"Describes the machine learning model version checkpoint.",
"properties":{
"checkpointId":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The ID of the checkpoint.\n      ",
"title":"Checkpointid"
},
"epoch":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The epoch of the checkpoint.\n      ",
"title":"Epoch"
},
"step":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The step of the checkpoint.\n      ",
"title":"Step"
}
},
"title":"Checkpoint",
"type":"object"
},
"Endpoint":{
"additionalProperties":false,
"description":"An endpoint where you deploy models.",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Resource name of the endpoint.",
"title":"Name"
},
"deployedModelId":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"ID of the model that's deployed to the endpoint.",
"title":"Deployedmodelid"
}
},
"title":"Endpoint",
"type":"object"
},
"TunedModelInfo":{
"additionalProperties":false,
"description":"A tuned machine learning model.",
"properties":{
"baseModel":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"ID of the base model that you want to tune.",
"title":"Basemodel"
},
"createTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Date and time when the base model was created.",
"title":"Createtime"
},
"updateTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Date and time when the base model was last updated.",
"title":"Updatetime"
}
},
"title":"TunedModelInfo",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `checkpoints (list[genai.types.Checkpoint] | None)`
  * `default_checkpoint_id (str | None)`
  * `description (str | None)`
  * `display_name (str | None)`
  * `endpoints (list[genai.types.Endpoint] | None)`
  * `input_token_limit (int | None)`
  * `labels (dict[str, str] | None)`
  * `name (str | None)`
  * `output_token_limit (int | None)`
  * `supported_actions (list[str] | None)`
  * `tuned_model_info (genai.types.TunedModelInfo | None)`
  * `version (str | None)`



_field_ checkpoints _:`Optional`[`list`[`Checkpoint`]]__= None_¶ 
    
The checkpoints of the model. 

_field_ default_checkpoint_id _:`Optional`[`str`]__= None_ _(alias 'defaultCheckpointId')_¶ 
    
The default checkpoint id of a model version. 

_field_ description _:`Optional`[`str`]__= None_¶ 
    
Description of the model. 

_field_ display_name _:`Optional`[`str`]__= None_ _(alias 'displayName')_¶ 
    
Display name of the model. 

_field_ endpoints _:`Optional`[`list`[`Endpoint`]]__= None_¶ 
    
List of deployed models created from this base model. Note that a model could have been deployed to endpoints in different locations. 

_field_ input_token_limit _:`Optional`[`int`]__= None_ _(alias 'inputTokenLimit')_¶ 
    
The maximum number of input tokens that the model can handle. 

_field_ labels _:`Optional`[`dict`[`str`, `str`]]__= None_¶ 
    
Labels with user-defined metadata to organize your models. 

_field_ name _:`Optional`[`str`]__= None_¶ 
    
Resource name of the model. 

_field_ output_token_limit _:`Optional`[`int`]__= None_ _(alias 'outputTokenLimit')_¶ 
    
The maximum number of output tokens that the model can generate. 

_field_ supported_actions _:`Optional`[`list`[`str`]]__= None_ _(alias 'supportedActions')_¶ 
    
List of actions that are supported by the model. 

_field_ tuned_model_info _:`Optional`[`TunedModelInfo`]__= None_ _(alias 'tunedModelInfo')_¶ 
    
Information about the tuned model from the base model. 

_field_ version _:`Optional`[`str`]__= None_¶ 
    
Version ID of the model. A new version is committed when a new model version is uploaded or trained under an existing model ID. The version ID is an auto-incrementing decimal number in string representation. 

_pydantic model_genai.types.ModelContent¶ 
    
Bases: `Content`
ModelContent facilitates the creation of a Content object with a model role.
Example usages:
  * Create a model Content object with a string: model_content = ModelContent(“Why is the sky blue?”)
  * Create a model Content object with a file data Part object: model_content = ModelContent(Part.from_uri(file_uril=”gs://bucket/file.txt”, mime_type=”text/plain”))
  * Create a model Content object with byte data Part object: model_content = ModelContent(Part.from_bytes(data=b”Hello, World!”, mime_type=”text/plain”))
You can create a model Content object using other classmethods in the Part class as well. You can also create a model Content using a list of Part objects or strings.


Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ModelContent",
"description":"ModelContent facilitates the creation of a Content object with a model role.\n\nExample usages:\n\n- Create a model Content object with a string:\n  model_content = ModelContent(\"Why is the sky blue?\")\n- Create a model Content object with a file data Part object:\n  model_content = ModelContent(Part.from_uri(file_uril=\"gs://bucket/file.txt\",\n  mime_type=\"text/plain\"))\n- Create a model Content object with byte data Part object:\n  model_content = ModelContent(Part.from_bytes(data=b\"Hello, World!\",\n  mime_type=\"text/plain\"))\n\n  You can create a model Content object using other classmethods in the Part\n  class as well.\n  You can also create a model Content using a list of Part objects or strings.",
"type":"object",
"properties":{
"parts":{
"items":{
"$ref":"#/$defs/Part"
},
"title":"Parts",
"type":"array"
},
"role":{
"const":"model",
"default":"model",
"enum":[
"model"
],
"title":"Role",
"type":"string"
}
},
"$defs":{
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
}
},
"additionalProperties":false,
"required":[
"parts"
]
}

```


Fields: 
    
  * `parts (list[genai.types.Part])`
  * `role (Literal['model'])`



_field_ parts _:`list`[`Part`]__[Required]_¶ 


_field_ role _:`Literal`[`'model'`]__= 'model'_¶ 


_class_ genai.types.ModelDict¶ 
    
Bases: `TypedDict`
A trained machine learning model. 

checkpoints _:`Optional`[`list`[`CheckpointDict`]]_¶ 
    
The checkpoints of the model. 

default_checkpoint_id _:`Optional`[`str`]_¶ 
    
The default checkpoint id of a model version. 

description _:`Optional`[`str`]_¶ 
    
Description of the model. 

display_name _:`Optional`[`str`]_¶ 
    
Display name of the model. 

endpoints _:`Optional`[`list`[`EndpointDict`]]_¶ 
    
List of deployed models created from this base model. Note that a model could have been deployed to endpoints in different locations. 

input_token_limit _:`Optional`[`int`]_¶ 
    
The maximum number of input tokens that the model can handle. 

labels _:`Optional`[`dict`[`str`, `str`]]_¶ 
    
Labels with user-defined metadata to organize your models. 

name _:`Optional`[`str`]_¶ 
    
Resource name of the model. 

output_token_limit _:`Optional`[`int`]_¶ 
    
The maximum number of output tokens that the model can generate. 

supported_actions _:`Optional`[`list`[`str`]]_¶ 
    
List of actions that are supported by the model. 

tuned_model_info _:`Optional`[`TunedModelInfoDict`]_¶ 
    
Information about the tuned model from the base model. 

version _:`Optional`[`str`]_¶ 
    
Version ID of the model. A new version is committed when a new model version is uploaded or trained under an existing model ID. The version ID is an auto-incrementing decimal number in string representation. 

_pydantic model_genai.types.ModelSelectionConfig¶ 
    
Bases: `BaseModel`
Config for model selection.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ModelSelectionConfig",
"description":"Config for model selection.",
"type":"object",
"properties":{
"featureSelectionPreference":{
"anyOf":[
{
"$ref":"#/$defs/FeatureSelectionPreference"
},
{
"type":"null"
}
],
"default":null,
"description":"Options for feature selection preference."
}
},
"$defs":{
"FeatureSelectionPreference":{
"description":"Options for feature selection preference.",
"enum":[
"FEATURE_SELECTION_PREFERENCE_UNSPECIFIED",
"PRIORITIZE_QUALITY",
"BALANCED",
"PRIORITIZE_COST"
],
"title":"FeatureSelectionPreference",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `feature_selection_preference (genai.types.FeatureSelectionPreference | None)`



_field_ feature_selection_preference _:`Optional`[`FeatureSelectionPreference`]__= None_ _(alias 'featureSelectionPreference')_¶ 
    
Options for feature selection preference. 

_class_ genai.types.ModelSelectionConfigDict¶ 
    
Bases: `TypedDict`
Config for model selection. 

feature_selection_preference _:`Optional`[`FeatureSelectionPreference`]_¶ 
    
Options for feature selection preference. 

_pydantic model_genai.types.Operation¶ 
    
Bases: `BaseModel`
A long-running operation.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"Operation",
"description":"A long-running operation.",
"type":"object",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`.",
"title":"Name"
},
"metadata":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata.  Any method that returns a long-running operation should document the metadata type, if any.",
"title":"Metadata"
},
"done":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available.",
"title":"Done"
},
"error":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"The error result of the operation in case of failure or cancellation.",
"title":"Error"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `done (bool | None)`
  * `error (dict[str, Any] | None)`
  * `metadata (dict[str, Any] | None)`
  * `name (str | None)`



_field_ done _:`Optional`[`bool`]__= None_¶ 
    
If the value is false, it means the operation is still in progress. If true, the operation is completed, and either error or response is available. 

_field_ error _:`Optional`[`dict`[`str`, `Any`]]__= None_¶ 
    
The error result of the operation in case of failure or cancellation. 

_field_ metadata _:`Optional`[`dict`[`str`, `Any`]]__= None_¶ 
    
Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any. 

_field_ name _:`Optional`[`str`]__= None_¶ 
    
The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the name should be a resource name ending with operations/{unique_id}. 

_class_ genai.types.OperationDict¶ 
    
Bases: `TypedDict`
A long-running operation. 

done _:`Optional`[`bool`]_¶ 
    
If the value is false, it means the operation is still in progress. If true, the operation is completed, and either error or response is available. 

error _:`Optional`[`dict`[`str`, `Any`]]_¶ 
    
The error result of the operation in case of failure or cancellation. 

metadata _:`Optional`[`dict`[`str`, `Any`]]_¶ 
    
Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any. 

name _:`Optional`[`str`]_¶ 
    
The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the name should be a resource name ending with operations/{unique_id}. 

_class_ genai.types.Outcome(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Required. Outcome of the code execution. 

OUTCOME_DEADLINE_EXCEEDED _= 'OUTCOME_DEADLINE_EXCEEDED'_¶ 


OUTCOME_FAILED _= 'OUTCOME_FAILED'_¶ 


OUTCOME_OK _= 'OUTCOME_OK'_¶ 


OUTCOME_UNSPECIFIED _= 'OUTCOME_UNSPECIFIED'_¶ 


_pydantic model_genai.types.Part¶ 
    
Bases: `BaseModel`
A datatype containing media content.
Exactly one field within a Part should be set, representing the specific type of content being conveyed. Using multiple fields within the same Part instance is considered invalid.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"Part",
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"type":"object",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"$defs":{
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `code_execution_result (genai.types.CodeExecutionResult | None)`
  * `executable_code (genai.types.ExecutableCode | None)`
  * `file_data (genai.types.FileData | None)`
  * `function_call (genai.types.FunctionCall | None)`
  * `function_response (genai.types.FunctionResponse | None)`
  * `inline_data (genai.types.Blob | None)`
  * `text (str | None)`
  * `thought (bool | None)`
  * `video_metadata (genai.types.VideoMetadata | None)`



_field_ code_execution_result _:`Optional`[`CodeExecutionResult`]__= None_ _(alias 'codeExecutionResult')_¶ 
    
Optional. Result of executing the [ExecutableCode]. 

_field_ executable_code _:`Optional`[`ExecutableCode`]__= None_ _(alias 'executableCode')_¶ 
    
Optional. Code generated by the model that is meant to be executed. 

_field_ file_data _:`Optional`[`FileData`]__= None_ _(alias 'fileData')_¶ 
    
Optional. URI based data. 

_field_ function_call _:`Optional`[`FunctionCall`]__= None_ _(alias 'functionCall')_¶ 
    
Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values. 

_field_ function_response _:`Optional`[`FunctionResponse`]__= None_ _(alias 'functionResponse')_¶ 
    
Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model. 

_field_ inline_data _:`Optional`[`Blob`]__= None_ _(alias 'inlineData')_¶ 
    
Optional. Inlined bytes data. 

_field_ text _:`Optional`[`str`]__= None_¶ 
    
Optional. Text part (can be code). 

_field_ thought _:`Optional`[`bool`]__= None_¶ 
    
Indicates if the part is thought from the model. 

_field_ video_metadata _:`Optional`[`VideoMetadata`]__= None_ _(alias 'videoMetadata')_¶ 
    
Metadata for a given video. 

_classmethod_ from_bytes(_*_ , _data_ , _mime_type_)¶ 
     

Return type: 
    
`Part` 

_classmethod_ from_code_execution_result(_*_ , _outcome_ , _output_)¶ 
     

Return type: 
    
`Part` 

_classmethod_ from_executable_code(_*_ , _code_ , _language_)¶ 
     

Return type: 
    
`Part` 

_classmethod_ from_function_call(_*_ , _name_ , _args_)¶ 
     

Return type: 
    
`Part` 

_classmethod_ from_function_response(_*_ , _name_ , _response_)¶ 
     

Return type: 
    
`Part` 

_classmethod_ from_text(_*_ , _text_)¶ 
     

Return type: 
    
`Part` 

_classmethod_ from_uri(_*_ , _file_uri_ , _mime_type =None_)¶ 
    
Creates a Part from a file uri. 

Return type: 
    
`Part` 

Parameters: 
    
  * **file_uri** (_str_) – The uri of the file
  * **mime_type** (_str_) – mime_type: The MIME type of the image. If not provided, the MIME type will be automatically determined.



_class_ genai.types.PartDict¶ 
    
Bases: `TypedDict`
A datatype containing media content.
Exactly one field within a Part should be set, representing the specific type of content being conveyed. Using multiple fields within the same Part instance is considered invalid. 

code_execution_result _:`Optional`[`CodeExecutionResultDict`]_¶ 
    
Optional. Result of executing the [ExecutableCode]. 

executable_code _:`Optional`[`ExecutableCodeDict`]_¶ 
    
Optional. Code generated by the model that is meant to be executed. 

file_data _:`Optional`[`FileDataDict`]_¶ 
    
Optional. URI based data. 

function_call _:`Optional`[`FunctionCallDict`]_¶ 
    
Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values. 

function_response _:`Optional`[`FunctionResponseDict`]_¶ 
    
Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model. 

inline_data _:`Optional`[`BlobDict`]_¶ 
    
Optional. Inlined bytes data. 

text _:`Optional`[`str`]_¶ 
    
Optional. Text part (can be code). 

thought _:`Optional`[`bool`]_¶ 
    
Indicates if the part is thought from the model. 

video_metadata _:`Optional`[`VideoMetadataDict`]_¶ 
    
Metadata for a given video. 

_pydantic model_genai.types.PartnerModelTuningSpec¶ 
    
Bases: `BaseModel`
Tuning spec for Partner models.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"PartnerModelTuningSpec",
"description":"Tuning spec for Partner models.",
"type":"object",
"properties":{
"hyperParameters":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Hyperparameters for tuning. The accepted hyper_parameters and their valid range of values will differ depending on the base model.",
"title":"Hyperparameters"
},
"trainingDatasetUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file.",
"title":"Trainingdataseturi"
},
"validationDatasetUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Cloud Storage path to file containing validation dataset for tuning. The dataset must be formatted as a JSONL file.",
"title":"Validationdataseturi"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `hyper_parameters (dict[str, Any] | None)`
  * `training_dataset_uri (str | None)`
  * `validation_dataset_uri (str | None)`



_field_ hyper_parameters _:`Optional`[`dict`[`str`, `Any`]]__= None_ _(alias 'hyperParameters')_¶ 
    
Hyperparameters for tuning. The accepted hyper_parameters and their valid range of values will differ depending on the base model. 

_field_ training_dataset_uri _:`Optional`[`str`]__= None_ _(alias 'trainingDatasetUri')_¶ 
    
Required. Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file. 

_field_ validation_dataset_uri _:`Optional`[`str`]__= None_ _(alias 'validationDatasetUri')_¶ 
    
Optional. Cloud Storage path to file containing validation dataset for tuning. The dataset must be formatted as a JSONL file. 

_class_ genai.types.PartnerModelTuningSpecDict¶ 
    
Bases: `TypedDict`
Tuning spec for Partner models. 

hyper_parameters _:`Optional`[`dict`[`str`, `Any`]]_¶ 
    
Hyperparameters for tuning. The accepted hyper_parameters and their valid range of values will differ depending on the base model. 

training_dataset_uri _:`Optional`[`str`]_¶ 
    
Required. Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file. 

validation_dataset_uri _:`Optional`[`str`]_¶ 
    
Optional. Cloud Storage path to file containing validation dataset for tuning. The dataset must be formatted as a JSONL file. 

_class_ genai.types.PersonGeneration(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Enum that controls the generation of people. 

ALLOW_ADULT _= 'ALLOW_ADULT'_¶ 


ALLOW_ALL _= 'ALLOW_ALL'_¶ 


DONT_ALLOW _= 'DONT_ALLOW'_¶ 


_pydantic model_genai.types.PrebuiltVoiceConfig¶ 
    
Bases: `BaseModel`
The configuration for the prebuilt speaker to use.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"PrebuiltVoiceConfig",
"description":"The configuration for the prebuilt speaker to use.",
"type":"object",
"properties":{
"voiceName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The name of the prebuilt voice to use.\n      ",
"title":"Voicename"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `voice_name (str | None)`



_field_ voice_name _:`Optional`[`str`]__= None_ _(alias 'voiceName')_¶ 
    
The name of the prebuilt voice to use. 

_class_ genai.types.PrebuiltVoiceConfigDict¶ 
    
Bases: `TypedDict`
The configuration for the prebuilt speaker to use. 

voice_name _:`Optional`[`str`]_¶ 
    
The name of the prebuilt voice to use. 

_pydantic model_genai.types.RagRetrievalConfig¶ 
    
Bases: `BaseModel`
Specifies the context retrieval config.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"RagRetrievalConfig",
"description":"Specifies the context retrieval config.",
"type":"object",
"properties":{
"filter":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigFilter"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for filters."
},
"hybridSearch":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigHybridSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Hybrid Search."
},
"ranking":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRanking"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for ranking and reranking."
},
"topK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The number of contexts to retrieve.",
"title":"Topk"
}
},
"$defs":{
"RagRetrievalConfigFilter":{
"additionalProperties":false,
"description":"Config for filters.",
"properties":{
"metadataFilter":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. String for metadata filtering.",
"title":"Metadatafilter"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
},
"vectorSimilarityThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector similarity larger than the threshold.",
"title":"Vectorsimilaritythreshold"
}
},
"title":"RagRetrievalConfigFilter",
"type":"object"
},
"RagRetrievalConfigHybridSearch":{
"additionalProperties":false,
"description":"Config for Hybrid Search.",
"properties":{
"alpha":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally.",
"title":"Alpha"
}
},
"title":"RagRetrievalConfigHybridSearch",
"type":"object"
},
"RagRetrievalConfigRanking":{
"additionalProperties":false,
"description":"Config for ranking and reranking.",
"properties":{
"llmRanker":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingLlmRanker"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for LlmRanker."
},
"rankService":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingRankService"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Rank Service."
}
},
"title":"RagRetrievalConfigRanking",
"type":"object"
},
"RagRetrievalConfigRankingLlmRanker":{
"additionalProperties":false,
"description":"Config for LlmRanker.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name used for ranking. Format: `gemini-1.5-pro`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingLlmRanker",
"type":"object"
},
"RagRetrievalConfigRankingRankService":{
"additionalProperties":false,
"description":"Config for Rank Service.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name of the rank service. Format: `semantic-ranker-512@latest`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingRankService",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `filter (genai.types.RagRetrievalConfigFilter | None)`
  * `hybrid_search (genai.types.RagRetrievalConfigHybridSearch | None)`
  * `ranking (genai.types.RagRetrievalConfigRanking | None)`
  * `top_k (int | None)`



_field_ filter _:`Optional`[`RagRetrievalConfigFilter`]__= None_¶ 
    
Optional. Config for filters. 

_field_ hybrid_search _:`Optional`[`RagRetrievalConfigHybridSearch`]__= None_ _(alias 'hybridSearch')_¶ 
    
Optional. Config for Hybrid Search. 

_field_ ranking _:`Optional`[`RagRetrievalConfigRanking`]__= None_¶ 
    
Optional. Config for ranking and reranking. 

_field_ top_k _:`Optional`[`int`]__= None_ _(alias 'topK')_¶ 
    
Optional. The number of contexts to retrieve. 

_class_ genai.types.RagRetrievalConfigDict¶ 
    
Bases: `TypedDict`
Specifies the context retrieval config. 

filter _:`Optional`[`RagRetrievalConfigFilterDict`]_¶ 
    
Optional. Config for filters. 

hybrid_search _:`Optional`[`RagRetrievalConfigHybridSearchDict`]_¶ 
    
Optional. Config for Hybrid Search. 

ranking _:`Optional`[`RagRetrievalConfigRankingDict`]_¶ 
    
Optional. Config for ranking and reranking. 

top_k _:`Optional`[`int`]_¶ 
    
Optional. The number of contexts to retrieve. 

_pydantic model_genai.types.RagRetrievalConfigFilter¶ 
    
Bases: `BaseModel`
Config for filters.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"RagRetrievalConfigFilter",
"description":"Config for filters.",
"type":"object",
"properties":{
"metadataFilter":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. String for metadata filtering.",
"title":"Metadatafilter"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
},
"vectorSimilarityThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector similarity larger than the threshold.",
"title":"Vectorsimilaritythreshold"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `metadata_filter (str | None)`
  * `vector_distance_threshold (float | None)`
  * `vector_similarity_threshold (float | None)`



_field_ metadata_filter _:`Optional`[`str`]__= None_ _(alias 'metadataFilter')_¶ 
    
Optional. String for metadata filtering. 

_field_ vector_distance_threshold _:`Optional`[`float`]__= None_ _(alias 'vectorDistanceThreshold')_¶ 
    
Optional. Only returns contexts with vector distance smaller than the threshold. 

_field_ vector_similarity_threshold _:`Optional`[`float`]__= None_ _(alias 'vectorSimilarityThreshold')_¶ 
    
Optional. Only returns contexts with vector similarity larger than the threshold. 

_class_ genai.types.RagRetrievalConfigFilterDict¶ 
    
Bases: `TypedDict`
Config for filters. 

metadata_filter _:`Optional`[`str`]_¶ 
    
Optional. String for metadata filtering. 

vector_distance_threshold _:`Optional`[`float`]_¶ 
    
Optional. Only returns contexts with vector distance smaller than the threshold. 

vector_similarity_threshold _:`Optional`[`float`]_¶ 
    
Optional. Only returns contexts with vector similarity larger than the threshold. 

_pydantic model_genai.types.RagRetrievalConfigHybridSearch¶ 
    
Bases: `BaseModel`
Config for Hybrid Search.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"RagRetrievalConfigHybridSearch",
"description":"Config for Hybrid Search.",
"type":"object",
"properties":{
"alpha":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally.",
"title":"Alpha"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `alpha (float | None)`



_field_ alpha _:`Optional`[`float`]__= None_¶ 
    
Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally. 

_class_ genai.types.RagRetrievalConfigHybridSearchDict¶ 
    
Bases: `TypedDict`
Config for Hybrid Search. 

alpha _:`Optional`[`float`]_¶ 
    
Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally. 

_pydantic model_genai.types.RagRetrievalConfigRanking¶ 
    
Bases: `BaseModel`
Config for ranking and reranking.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"RagRetrievalConfigRanking",
"description":"Config for ranking and reranking.",
"type":"object",
"properties":{
"llmRanker":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingLlmRanker"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for LlmRanker."
},
"rankService":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingRankService"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Rank Service."
}
},
"$defs":{
"RagRetrievalConfigRankingLlmRanker":{
"additionalProperties":false,
"description":"Config for LlmRanker.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name used for ranking. Format: `gemini-1.5-pro`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingLlmRanker",
"type":"object"
},
"RagRetrievalConfigRankingRankService":{
"additionalProperties":false,
"description":"Config for Rank Service.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name of the rank service. Format: `semantic-ranker-512@latest`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingRankService",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `llm_ranker (genai.types.RagRetrievalConfigRankingLlmRanker | None)`
  * `rank_service (genai.types.RagRetrievalConfigRankingRankService | None)`



_field_ llm_ranker _:`Optional`[`RagRetrievalConfigRankingLlmRanker`]__= None_ _(alias 'llmRanker')_¶ 
    
Optional. Config for LlmRanker. 

_field_ rank_service _:`Optional`[`RagRetrievalConfigRankingRankService`]__= None_ _(alias 'rankService')_¶ 
    
Optional. Config for Rank Service. 

_class_ genai.types.RagRetrievalConfigRankingDict¶ 
    
Bases: `TypedDict`
Config for ranking and reranking. 

llm_ranker _:`Optional`[`RagRetrievalConfigRankingLlmRankerDict`]_¶ 
    
Optional. Config for LlmRanker. 

rank_service _:`Optional`[`RagRetrievalConfigRankingRankServiceDict`]_¶ 
    
Optional. Config for Rank Service. 

_pydantic model_genai.types.RagRetrievalConfigRankingLlmRanker¶ 
    
Bases: `BaseModel`
Config for LlmRanker.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"RagRetrievalConfigRankingLlmRanker",
"description":"Config for LlmRanker.",
"type":"object",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name used for ranking. Format: `gemini-1.5-pro`",
"title":"Modelname"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `model_name (str | None)`



_field_ model_name _:`Optional`[`str`]__= None_ _(alias 'modelName')_¶ 
    
Optional. The model name used for ranking. Format: gemini-1.5-pro 

_class_ genai.types.RagRetrievalConfigRankingLlmRankerDict¶ 
    
Bases: `TypedDict`
Config for LlmRanker. 

model_name _:`Optional`[`str`]_¶ 
    
gemini-1.5-pro 

Type: 
    
Optional. The model name used for ranking. Format 

_pydantic model_genai.types.RagRetrievalConfigRankingRankService¶ 
    
Bases: `BaseModel`
Config for Rank Service.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"RagRetrievalConfigRankingRankService",
"description":"Config for Rank Service.",
"type":"object",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name of the rank service. Format: `semantic-ranker-512@latest`",
"title":"Modelname"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `model_name (str | None)`



_field_ model_name _:`Optional`[`str`]__= None_ _(alias 'modelName')_¶ 
    
Optional. The model name of the rank service. Format: semantic-ranker-512@latest 

_class_ genai.types.RagRetrievalConfigRankingRankServiceDict¶ 
    
Bases: `TypedDict`
Config for Rank Service. 

model_name _:`Optional`[`str`]_¶ 
    
semantic-ranker-512@latest 

Type: 
    
Optional. The model name of the rank service. Format 

_pydantic model_genai.types.RawReferenceImage¶ 
    
Bases: `BaseModel`
A raw reference image.
A raw reference image represents the base image to edit, provided by the user. It can optionally be provided in addition to a mask reference image or a style reference image.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"RawReferenceImage",
"description":"A raw reference image.\n\nA raw reference image represents the base image to edit, provided by the user.\nIt can optionally be provided in addition to a mask reference image or\na style reference image.",
"type":"object",
"properties":{
"referenceImage":{
"anyOf":[
{
"$ref":"#/$defs/Image"
},
{
"type":"null"
}
],
"default":null,
"description":"The reference image for the editing operation."
},
"referenceId":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the reference image.",
"title":"Referenceid"
},
"referenceType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The type of the reference image. Only set by the SDK.",
"title":"Referencetype"
}
},
"$defs":{
"Image":{
"additionalProperties":false,
"description":"An image.",
"properties":{
"gcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The Cloud Storage URI of the image. ``Image`` can contain a value\n      for this field or the ``image_bytes`` field but not both.\n      ",
"title":"Gcsuri"
},
"imageBytes":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The image bytes data. ``Image`` can contain a value for this field\n      or the ``gcs_uri`` field but not both.\n      ",
"title":"Imagebytes"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The MIME type of the image.",
"title":"Mimetype"
}
},
"title":"Image",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `reference_id (int | None)`
  * `reference_image (genai.types.Image | None)`
  * `reference_type (str | None)`



Validators: 
    
  * `_validate_mask_image_config` » `all fields`



_field_ reference_id _:`Optional`[`int`]__= None_ _(alias 'referenceId')_¶ 
    
The id of the reference image. 

Validated by: 
    
  * `_validate_mask_image_config`



_field_ reference_image _:`Optional`[`Image`]__= None_ _(alias 'referenceImage')_¶ 
    
The reference image for the editing operation. 

Validated by: 
    
  * `_validate_mask_image_config`



_field_ reference_type _:`Optional`[`str`]__= None_ _(alias 'referenceType')_¶ 
    
The type of the reference image. Only set by the SDK. 

Validated by: 
    
  * `_validate_mask_image_config`



_class_ genai.types.RawReferenceImageDict¶ 
    
Bases: `TypedDict`
A raw reference image.
A raw reference image represents the base image to edit, provided by the user. It can optionally be provided in addition to a mask reference image or a style reference image. 

reference_id _:`Optional`[`int`]_¶ 
    
The id of the reference image. 

reference_image _:`Optional`[`ImageDict`]_¶ 
    
The reference image for the editing operation. 

reference_type _:`Optional`[`str`]_¶ 
    
The type of the reference image. Only set by the SDK. 

_pydantic model_genai.types.RealtimeInputConfig¶ 
    
Bases: `BaseModel`
Marks the end of user activity.
This can only be sent if automatic (i.e. server-side) activity detection is disabled.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"RealtimeInputConfig",
"description":"Marks the end of user activity.\n\nThis can only be sent if automatic (i.e. server-side) activity detection is\ndisabled.",
"type":"object",
"properties":{
"automaticActivityDetection":{
"anyOf":[
{
"$ref":"#/$defs/AutomaticActivityDetection"
},
{
"type":"null"
}
],
"default":null,
"description":"If not set, automatic activity detection is enabled by default. If automatic voice detection is disabled, the client must send activity signals."
},
"activityHandling":{
"anyOf":[
{
"$ref":"#/$defs/ActivityHandling"
},
{
"type":"null"
}
],
"default":null,
"description":"Defines what effect activity has."
},
"turnCoverage":{
"anyOf":[
{
"$ref":"#/$defs/TurnCoverage"
},
{
"type":"null"
}
],
"default":null,
"description":"Defines which input is included in the user's turn."
}
},
"$defs":{
"ActivityHandling":{
"description":"The different ways of handling user activity.",
"enum":[
"ACTIVITY_HANDLING_UNSPECIFIED",
"START_OF_ACTIVITY_INTERRUPTS",
"NO_INTERRUPTION"
],
"title":"ActivityHandling",
"type":"string"
},
"AutomaticActivityDetection":{
"additionalProperties":false,
"description":"Configures automatic detection of activity.",
"properties":{
"disabled":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If enabled, detected voice and text input count as activity. If disabled, the client must send activity signals.",
"title":"Disabled"
},
"startOfSpeechSensitivity":{
"anyOf":[
{
"$ref":"#/$defs/StartSensitivity"
},
{
"type":"null"
}
],
"default":null,
"description":"Determines how likely speech is to be detected."
},
"endOfSpeechSensitivity":{
"anyOf":[
{
"$ref":"#/$defs/EndSensitivity"
},
{
"type":"null"
}
],
"default":null,
"description":"Determines how likely detected speech is ended."
},
"prefixPaddingMs":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The required duration of detected speech before start-of-speech is committed. The lower this value the more sensitive the start-of-speech detection is and the shorter speech can be recognized. However, this also increases the probability of false positives.",
"title":"Prefixpaddingms"
},
"silenceDurationMs":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The required duration of detected non-speech (e.g. silence) before end-of-speech is committed. The larger this value, the longer speech gaps can be without interrupting the user's activity but this will increase the model's latency.",
"title":"Silencedurationms"
}
},
"title":"AutomaticActivityDetection",
"type":"object"
},
"EndSensitivity":{
"description":"End of speech sensitivity.",
"enum":[
"END_SENSITIVITY_UNSPECIFIED",
"END_SENSITIVITY_HIGH",
"END_SENSITIVITY_LOW"
],
"title":"EndSensitivity",
"type":"string"
},
"StartSensitivity":{
"description":"Start of speech sensitivity.",
"enum":[
"START_SENSITIVITY_UNSPECIFIED",
"START_SENSITIVITY_HIGH",
"START_SENSITIVITY_LOW"
],
"title":"StartSensitivity",
"type":"string"
},
"TurnCoverage":{
"description":"Options about which input is included in the user's turn.",
"enum":[
"TURN_COVERAGE_UNSPECIFIED",
"TURN_INCLUDES_ONLY_ACTIVITY",
"TURN_INCLUDES_ALL_INPUT"
],
"title":"TurnCoverage",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `activity_handling (genai.types.ActivityHandling | None)`
  * `automatic_activity_detection (genai.types.AutomaticActivityDetection | None)`
  * `turn_coverage (genai.types.TurnCoverage | None)`



_field_ activity_handling _:`Optional`[`ActivityHandling`]__= None_ _(alias 'activityHandling')_¶ 
    
Defines what effect activity has. 

_field_ automatic_activity_detection _:`Optional`[`AutomaticActivityDetection`]__= None_ _(alias 'automaticActivityDetection')_¶ 
    
If not set, automatic activity detection is enabled by default. If automatic voice detection is disabled, the client must send activity signals. 

_field_ turn_coverage _:`Optional`[`TurnCoverage`]__= None_ _(alias 'turnCoverage')_¶ 
    
Defines which input is included in the user’s turn. 

_class_ genai.types.RealtimeInputConfigDict¶ 
    
Bases: `TypedDict`
Marks the end of user activity.
This can only be sent if automatic (i.e. server-side) activity detection is disabled. 

activity_handling _:`Optional`[`ActivityHandling`]_¶ 
    
Defines what effect activity has. 

automatic_activity_detection _:`Optional`[`AutomaticActivityDetectionDict`]_¶ 
    
If not set, automatic activity detection is enabled by default. If automatic voice detection is disabled, the client must send activity signals. 

turn_coverage _:`Optional`[`TurnCoverage`]_¶ 
    
Defines which input is included in the user’s turn. 

_pydantic model_genai.types.ReplayFile¶ 
    
Bases: `BaseModel`
Represents a recorded session.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ReplayFile",
"description":"Represents a recorded session.",
"type":"object",
"properties":{
"replayId":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Replayid"
},
"interactions":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/ReplayInteraction"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Interactions"
}
},
"$defs":{
"ReplayInteraction":{
"additionalProperties":false,
"description":"Represents a single interaction, request and response in a replay.",
"properties":{
"request":{
"anyOf":[
{
"$ref":"#/$defs/ReplayRequest"
},
{
"type":"null"
}
],
"default":null,
"description":""
},
"response":{
"anyOf":[
{
"$ref":"#/$defs/ReplayResponse"
},
{
"type":"null"
}
],
"default":null,
"description":""
}
},
"title":"ReplayInteraction",
"type":"object"
},
"ReplayRequest":{
"additionalProperties":false,
"description":"Represents a single request in a replay.",
"properties":{
"method":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Method"
},
"url":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Url"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Headers"
},
"bodySegments":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Bodysegments"
}
},
"title":"ReplayRequest",
"type":"object"
},
"ReplayResponse":{
"additionalProperties":false,
"description":"Represents a single response in a replay.",
"properties":{
"statusCode":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Statuscode"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Headers"
},
"bodySegments":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Bodysegments"
},
"sdkResponseSegments":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Sdkresponsesegments"
}
},
"title":"ReplayResponse",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `interactions (list[genai.types.ReplayInteraction] | None)`
  * `replay_id (str | None)`



_field_ interactions _:`Optional`[`list`[`ReplayInteraction`]]__= None_¶ 


_field_ replay_id _:`Optional`[`str`]__= None_ _(alias 'replayId')_¶ 


_class_ genai.types.ReplayFileDict¶ 
    
Bases: `TypedDict`
Represents a recorded session. 

interactions _:`Optional`[`list`[`ReplayInteractionDict`]]_¶ 


replay_id _:`Optional`[`str`]_¶ 


_pydantic model_genai.types.ReplayInteraction¶ 
    
Bases: `BaseModel`
Represents a single interaction, request and response in a replay.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ReplayInteraction",
"description":"Represents a single interaction, request and response in a replay.",
"type":"object",
"properties":{
"request":{
"anyOf":[
{
"$ref":"#/$defs/ReplayRequest"
},
{
"type":"null"
}
],
"default":null,
"description":""
},
"response":{
"anyOf":[
{
"$ref":"#/$defs/ReplayResponse"
},
{
"type":"null"
}
],
"default":null,
"description":""
}
},
"$defs":{
"ReplayRequest":{
"additionalProperties":false,
"description":"Represents a single request in a replay.",
"properties":{
"method":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Method"
},
"url":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Url"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Headers"
},
"bodySegments":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Bodysegments"
}
},
"title":"ReplayRequest",
"type":"object"
},
"ReplayResponse":{
"additionalProperties":false,
"description":"Represents a single response in a replay.",
"properties":{
"statusCode":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Statuscode"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Headers"
},
"bodySegments":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Bodysegments"
},
"sdkResponseSegments":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Sdkresponsesegments"
}
},
"title":"ReplayResponse",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `request (genai.types.ReplayRequest | None)`
  * `response (genai.types.ReplayResponse | None)`



_field_ request _:`Optional`[`ReplayRequest`]__= None_¶ 


_field_ response _:`Optional`[`ReplayResponse`]__= None_¶ 


_class_ genai.types.ReplayInteractionDict¶ 
    
Bases: `TypedDict`
Represents a single interaction, request and response in a replay. 

request _:`Optional`[`ReplayRequestDict`]_¶ 


response _:`Optional`[`ReplayResponseDict`]_¶ 


_pydantic model_genai.types.ReplayRequest¶ 
    
Bases: `BaseModel`
Represents a single request in a replay.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ReplayRequest",
"description":"Represents a single request in a replay.",
"type":"object",
"properties":{
"method":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Method"
},
"url":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Url"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Headers"
},
"bodySegments":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Bodysegments"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `body_segments (list[dict[str, Any]] | None)`
  * `headers (dict[str, str] | None)`
  * `method (str | None)`
  * `url (str | None)`



_field_ body_segments _:`Optional`[`list`[`dict`[`str`, `Any`]]]__= None_ _(alias 'bodySegments')_¶ 


_field_ headers _:`Optional`[`dict`[`str`, `str`]]__= None_¶ 


_field_ method _:`Optional`[`str`]__= None_¶ 


_field_ url _:`Optional`[`str`]__= None_¶ 


_class_ genai.types.ReplayRequestDict¶ 
    
Bases: `TypedDict`
Represents a single request in a replay. 

body_segments _:`Optional`[`list`[`dict`[`str`, `Any`]]]_¶ 


headers _:`Optional`[`dict`[`str`, `str`]]_¶ 


method _:`Optional`[`str`]_¶ 


url _:`Optional`[`str`]_¶ 


_pydantic model_genai.types.ReplayResponse¶ 
    
Bases: `BaseModel`
Represents a single response in a replay.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ReplayResponse",
"description":"Represents a single response in a replay.",
"type":"object",
"properties":{
"statusCode":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Statuscode"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Headers"
},
"bodySegments":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Bodysegments"
},
"sdkResponseSegments":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Sdkresponsesegments"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `body_segments (list[dict[str, Any]] | None)`
  * `headers (dict[str, str] | None)`
  * `sdk_response_segments (list[dict[str, Any]] | None)`
  * `status_code (int | None)`



_field_ body_segments _:`Optional`[`list`[`dict`[`str`, `Any`]]]__= None_ _(alias 'bodySegments')_¶ 


_field_ headers _:`Optional`[`dict`[`str`, `str`]]__= None_¶ 


_field_ sdk_response_segments _:`Optional`[`list`[`dict`[`str`, `Any`]]]__= None_ _(alias 'sdkResponseSegments')_¶ 


_field_ status_code _:`Optional`[`int`]__= None_ _(alias 'statusCode')_¶ 


_class_ genai.types.ReplayResponseDict¶ 
    
Bases: `TypedDict`
Represents a single response in a replay. 

body_segments _:`Optional`[`list`[`dict`[`str`, `Any`]]]_¶ 


headers _:`Optional`[`dict`[`str`, `str`]]_¶ 


sdk_response_segments _:`Optional`[`list`[`dict`[`str`, `Any`]]]_¶ 


status_code _:`Optional`[`int`]_¶ 


_pydantic model_genai.types.Retrieval¶ 
    
Bases: `BaseModel`
Defines a retrieval tool that model can call to access external knowledge.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"Retrieval",
"description":"Defines a retrieval tool that model can call to access external knowledge.",
"type":"object",
"properties":{
"disableAttribution":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Deprecated. This option is no longer supported.",
"title":"Disableattribution"
},
"vertexAiSearch":{
"anyOf":[
{
"$ref":"#/$defs/VertexAISearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Set to use data source powered by Vertex AI Search."
},
"vertexRagStore":{
"anyOf":[
{
"$ref":"#/$defs/VertexRagStore"
},
{
"type":"null"
}
],
"default":null,
"description":"Set to use data source powered by Vertex RAG store. User data is uploaded via the VertexRagDataService."
}
},
"$defs":{
"RagRetrievalConfig":{
"additionalProperties":false,
"description":"Specifies the context retrieval config.",
"properties":{
"filter":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigFilter"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for filters."
},
"hybridSearch":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigHybridSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Hybrid Search."
},
"ranking":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRanking"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for ranking and reranking."
},
"topK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The number of contexts to retrieve.",
"title":"Topk"
}
},
"title":"RagRetrievalConfig",
"type":"object"
},
"RagRetrievalConfigFilter":{
"additionalProperties":false,
"description":"Config for filters.",
"properties":{
"metadataFilter":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. String for metadata filtering.",
"title":"Metadatafilter"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
},
"vectorSimilarityThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector similarity larger than the threshold.",
"title":"Vectorsimilaritythreshold"
}
},
"title":"RagRetrievalConfigFilter",
"type":"object"
},
"RagRetrievalConfigHybridSearch":{
"additionalProperties":false,
"description":"Config for Hybrid Search.",
"properties":{
"alpha":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally.",
"title":"Alpha"
}
},
"title":"RagRetrievalConfigHybridSearch",
"type":"object"
},
"RagRetrievalConfigRanking":{
"additionalProperties":false,
"description":"Config for ranking and reranking.",
"properties":{
"llmRanker":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingLlmRanker"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for LlmRanker."
},
"rankService":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingRankService"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Rank Service."
}
},
"title":"RagRetrievalConfigRanking",
"type":"object"
},
"RagRetrievalConfigRankingLlmRanker":{
"additionalProperties":false,
"description":"Config for LlmRanker.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name used for ranking. Format: `gemini-1.5-pro`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingLlmRanker",
"type":"object"
},
"RagRetrievalConfigRankingRankService":{
"additionalProperties":false,
"description":"Config for Rank Service.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name of the rank service. Format: `semantic-ranker-512@latest`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingRankService",
"type":"object"
},
"VertexAISearch":{
"additionalProperties":false,
"description":"Retrieve from Vertex AI Search datastore or engine for grounding.\n\ndatastore and engine are mutually exclusive. See\nhttps://cloud.google.com/products/agent-builder",
"properties":{
"datastore":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search data store resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`",
"title":"Datastore"
},
"engine":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search engine resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}`",
"title":"Engine"
}
},
"title":"VertexAISearch",
"type":"object"
},
"VertexRagStore":{
"additionalProperties":false,
"description":"Retrieve from Vertex RAG Store for grounding.",
"properties":{
"ragCorpora":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Deprecated. Please use rag_resources instead.",
"title":"Ragcorpora"
},
"ragResources":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/VertexRagStoreRagResource"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The representation of the rag source. It can be used to specify corpus only or ragfiles. Currently only support one corpus or multiple files from one corpus. In the future we may open up multiple corpora support.",
"title":"Ragresources"
},
"ragRetrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The retrieval config for the Rag query."
},
"similarityTopK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of top k results to return from the selected corpora.",
"title":"Similaritytopk"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only return results with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
}
},
"title":"VertexRagStore",
"type":"object"
},
"VertexRagStoreRagResource":{
"additionalProperties":false,
"description":"The definition of the Rag resource.",
"properties":{
"ragCorpus":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. RagCorpora resource name. Format: `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`",
"title":"Ragcorpus"
},
"ragFileIds":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus field.",
"title":"Ragfileids"
}
},
"title":"VertexRagStoreRagResource",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `disable_attribution (bool | None)`
  * `vertex_ai_search (genai.types.VertexAISearch | None)`
  * `vertex_rag_store (genai.types.VertexRagStore | None)`



_field_ disable_attribution _:`Optional`[`bool`]__= None_ _(alias 'disableAttribution')_¶ 
    
Optional. Deprecated. This option is no longer supported. 

_field_ vertex_ai_search _:`Optional`[`VertexAISearch`]__= None_ _(alias 'vertexAiSearch')_¶ 
    
Set to use data source powered by Vertex AI Search. 

_field_ vertex_rag_store _:`Optional`[`VertexRagStore`]__= None_ _(alias 'vertexRagStore')_¶ 
    
Set to use data source powered by Vertex RAG store. User data is uploaded via the VertexRagDataService. 

_pydantic model_genai.types.RetrievalConfig¶ 
    
Bases: `BaseModel`
Retrieval config.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"RetrievalConfig",
"description":"Retrieval config.",
"type":"object",
"properties":{
"latLng":{
"anyOf":[
{
"$ref":"#/$defs/LatLng"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The location of the user."
}
},
"$defs":{
"LatLng":{
"additionalProperties":false,
"description":"An object that represents a latitude/longitude pair.\n\nThis is expressed as a pair of doubles to represent degrees latitude and\ndegrees longitude. Unless specified otherwise, this object must conform to the\n<a href=\"https://en.wikipedia.org/wiki/World_Geodetic_System#1984_version\">\nWGS84 standard</a>. Values must be within normalized ranges.",
"properties":{
"latitude":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"The latitude in degrees. It must be in the range [-90.0, +90.0].",
"title":"Latitude"
},
"longitude":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"The longitude in degrees. It must be in the range [-180.0, +180.0]",
"title":"Longitude"
}
},
"title":"LatLng",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `lat_lng (genai.types.LatLng | None)`



_field_ lat_lng _:`Optional`[`LatLng`]__= None_ _(alias 'latLng')_¶ 
    
Optional. The location of the user. 

_class_ genai.types.RetrievalConfigDict¶ 
    
Bases: `TypedDict`
Retrieval config. 

lat_lng _:`Optional`[`LatLngDict`]_¶ 
    
Optional. The location of the user. 

_class_ genai.types.RetrievalDict¶ 
    
Bases: `TypedDict`
Defines a retrieval tool that model can call to access external knowledge. 

disable_attribution _:`Optional`[`bool`]_¶ 
    
Optional. Deprecated. This option is no longer supported. 

vertex_ai_search _:`Optional`[`VertexAISearchDict`]_¶ 
    
Set to use data source powered by Vertex AI Search. 

vertex_rag_store _:`Optional`[`VertexRagStoreDict`]_¶ 
    
Set to use data source powered by Vertex RAG store. User data is uploaded via the VertexRagDataService. 

_pydantic model_genai.types.RetrievalMetadata¶ 
    
Bases: `BaseModel`
Metadata related to retrieval in the grounding flow.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"RetrievalMetadata",
"description":"Metadata related to retrieval in the grounding flow.",
"type":"object",
"properties":{
"googleSearchDynamicRetrievalScore":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Score indicating how likely information from Google Search could help answer the prompt. The score is in the range `[0, 1]`, where 0 is the least likely and 1 is the most likely. This score is only populated when Google Search grounding and dynamic retrieval is enabled. It will be compared to the threshold to determine whether to trigger Google Search.",
"title":"Googlesearchdynamicretrievalscore"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `google_search_dynamic_retrieval_score (float | None)`



_field_ google_search_dynamic_retrieval_score _:`Optional`[`float`]__= None_ _(alias 'googleSearchDynamicRetrievalScore')_¶ 
    
Optional. Score indicating how likely information from Google Search could help answer the prompt. The score is in the range [0, 1], where 0 is the least likely and 1 is the most likely. This score is only populated when Google Search grounding and dynamic retrieval is enabled. It will be compared to the threshold to determine whether to trigger Google Search. 

_class_ genai.types.RetrievalMetadataDict¶ 
    
Bases: `TypedDict`
Metadata related to retrieval in the grounding flow. 

google_search_dynamic_retrieval_score _:`Optional`[`float`]_¶ 
    
Optional. Score indicating how likely information from Google Search could help answer the prompt. The score is in the range [0, 1], where 0 is the least likely and 1 is the most likely. This score is only populated when Google Search grounding and dynamic retrieval is enabled. It will be compared to the threshold to determine whether to trigger Google Search. 

_pydantic model_genai.types.SafetyAttributes¶ 
    
Bases: `BaseModel`
Safety attributes of a GeneratedImage or the user-provided prompt.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"SafetyAttributes",
"description":"Safety attributes of a GeneratedImage or the user-provided prompt.",
"type":"object",
"properties":{
"categories":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of RAI categories.\n      ",
"title":"Categories"
},
"scores":{
"anyOf":[
{
"items":{
"type":"number"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of scores of each categories.\n      ",
"title":"Scores"
},
"contentType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Internal use only.\n      ",
"title":"Contenttype"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `categories (list[str] | None)`
  * `content_type (str | None)`
  * `scores (list[float] | None)`



_field_ categories _:`Optional`[`list`[`str`]]__= None_¶ 
    
List of RAI categories. 

_field_ content_type _:`Optional`[`str`]__= None_ _(alias 'contentType')_¶ 
    
Internal use only. 

_field_ scores _:`Optional`[`list`[`float`]]__= None_¶ 
    
List of scores of each categories. 

_class_ genai.types.SafetyAttributesDict¶ 
    
Bases: `TypedDict`
Safety attributes of a GeneratedImage or the user-provided prompt. 

categories _:`Optional`[`list`[`str`]]_¶ 
    
List of RAI categories. 

content_type _:`Optional`[`str`]_¶ 
    
Internal use only. 

scores _:`Optional`[`list`[`float`]]_¶ 
    
List of scores of each categories. 

_class_ genai.types.SafetyFilterLevel(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Enum that controls the safety filter level for objectionable content. 

BLOCK_LOW_AND_ABOVE _= 'BLOCK_LOW_AND_ABOVE'_¶ 


BLOCK_MEDIUM_AND_ABOVE _= 'BLOCK_MEDIUM_AND_ABOVE'_¶ 


BLOCK_NONE _= 'BLOCK_NONE'_¶ 


BLOCK_ONLY_HIGH _= 'BLOCK_ONLY_HIGH'_¶ 


_pydantic model_genai.types.SafetyRating¶ 
    
Bases: `BaseModel`
Safety rating corresponding to the generated content.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"SafetyRating",
"description":"Safety rating corresponding to the generated content.",
"type":"object",
"properties":{
"blocked":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Indicates whether the content was filtered out because of this rating.",
"title":"Blocked"
},
"category":{
"anyOf":[
{
"$ref":"#/$defs/HarmCategory"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm category."
},
"probability":{
"anyOf":[
{
"$ref":"#/$defs/HarmProbability"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm probability levels in the content."
},
"probabilityScore":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm probability score.",
"title":"Probabilityscore"
},
"severity":{
"anyOf":[
{
"$ref":"#/$defs/HarmSeverity"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm severity levels in the content."
},
"severityScore":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Harm severity score.",
"title":"Severityscore"
}
},
"$defs":{
"HarmCategory":{
"description":"Required. Harm category.",
"enum":[
"HARM_CATEGORY_UNSPECIFIED",
"HARM_CATEGORY_HATE_SPEECH",
"HARM_CATEGORY_DANGEROUS_CONTENT",
"HARM_CATEGORY_HARASSMENT",
"HARM_CATEGORY_SEXUALLY_EXPLICIT",
"HARM_CATEGORY_CIVIC_INTEGRITY"
],
"title":"HarmCategory",
"type":"string"
},
"HarmProbability":{
"description":"Output only. Harm probability levels in the content.",
"enum":[
"HARM_PROBABILITY_UNSPECIFIED",
"NEGLIGIBLE",
"LOW",
"MEDIUM",
"HIGH"
],
"title":"HarmProbability",
"type":"string"
},
"HarmSeverity":{
"description":"Output only. Harm severity levels in the content.",
"enum":[
"HARM_SEVERITY_UNSPECIFIED",
"HARM_SEVERITY_NEGLIGIBLE",
"HARM_SEVERITY_LOW",
"HARM_SEVERITY_MEDIUM",
"HARM_SEVERITY_HIGH"
],
"title":"HarmSeverity",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `blocked (bool | None)`
  * `category (genai.types.HarmCategory | None)`
  * `probability (genai.types.HarmProbability | None)`
  * `probability_score (float | None)`
  * `severity (genai.types.HarmSeverity | None)`
  * `severity_score (float | None)`



_field_ blocked _:`Optional`[`bool`]__= None_¶ 
    
Output only. Indicates whether the content was filtered out because of this rating. 

_field_ category _:`Optional`[`HarmCategory`]__= None_¶ 
    
Output only. Harm category. 

_field_ probability _:`Optional`[`HarmProbability`]__= None_¶ 
    
Output only. Harm probability levels in the content. 

_field_ probability_score _:`Optional`[`float`]__= None_ _(alias 'probabilityScore')_¶ 
    
Output only. Harm probability score. 

_field_ severity _:`Optional`[`HarmSeverity`]__= None_¶ 
    
Output only. Harm severity levels in the content. 

_field_ severity_score _:`Optional`[`float`]__= None_ _(alias 'severityScore')_¶ 
    
Output only. Harm severity score. 

_class_ genai.types.SafetyRatingDict¶ 
    
Bases: `TypedDict`
Safety rating corresponding to the generated content. 

blocked _:`Optional`[`bool`]_¶ 
    
Output only. Indicates whether the content was filtered out because of this rating. 

category _:`Optional`[`HarmCategory`]_¶ 
    
Output only. Harm category. 

probability _:`Optional`[`HarmProbability`]_¶ 
    
Output only. Harm probability levels in the content. 

probability_score _:`Optional`[`float`]_¶ 
    
Output only. Harm probability score. 

severity _:`Optional`[`HarmSeverity`]_¶ 
    
Output only. Harm severity levels in the content. 

severity_score _:`Optional`[`float`]_¶ 
    
Output only. Harm severity score. 

_pydantic model_genai.types.SafetySetting¶ 
    
Bases: `BaseModel`
Safety settings.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"SafetySetting",
"description":"Safety settings.",
"type":"object",
"properties":{
"method":{
"anyOf":[
{
"$ref":"#/$defs/HarmBlockMethod"
},
{
"type":"null"
}
],
"default":null,
"description":"Determines if the harm block method uses probability or probability\n      and severity scores."
},
"category":{
"anyOf":[
{
"$ref":"#/$defs/HarmCategory"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Harm category."
},
"threshold":{
"anyOf":[
{
"$ref":"#/$defs/HarmBlockThreshold"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The harm block threshold."
}
},
"$defs":{
"HarmBlockMethod":{
"description":"Optional.\n\nSpecify if the threshold is used for probability or severity score. If not\nspecified, the threshold is used for probability score.",
"enum":[
"HARM_BLOCK_METHOD_UNSPECIFIED",
"SEVERITY",
"PROBABILITY"
],
"title":"HarmBlockMethod",
"type":"string"
},
"HarmBlockThreshold":{
"description":"Required. The harm block threshold.",
"enum":[
"HARM_BLOCK_THRESHOLD_UNSPECIFIED",
"BLOCK_LOW_AND_ABOVE",
"BLOCK_MEDIUM_AND_ABOVE",
"BLOCK_ONLY_HIGH",
"BLOCK_NONE",
"OFF"
],
"title":"HarmBlockThreshold",
"type":"string"
},
"HarmCategory":{
"description":"Required. Harm category.",
"enum":[
"HARM_CATEGORY_UNSPECIFIED",
"HARM_CATEGORY_HATE_SPEECH",
"HARM_CATEGORY_DANGEROUS_CONTENT",
"HARM_CATEGORY_HARASSMENT",
"HARM_CATEGORY_SEXUALLY_EXPLICIT",
"HARM_CATEGORY_CIVIC_INTEGRITY"
],
"title":"HarmCategory",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `category (genai.types.HarmCategory | None)`
  * `method (genai.types.HarmBlockMethod | None)`
  * `threshold (genai.types.HarmBlockThreshold | None)`



_field_ category _:`Optional`[`HarmCategory`]__= None_¶ 
    
Required. Harm category. 

_field_ method _:`Optional`[`HarmBlockMethod`]__= None_¶ 
    
Determines if the harm block method uses probability or probability and severity scores. 

_field_ threshold _:`Optional`[`HarmBlockThreshold`]__= None_¶ 
    
Required. The harm block threshold. 

_class_ genai.types.SafetySettingDict¶ 
    
Bases: `TypedDict`
Safety settings. 

category _:`Optional`[`HarmCategory`]_¶ 
    
Required. Harm category. 

method _:`Optional`[`HarmBlockMethod`]_¶ 
    
Determines if the harm block method uses probability or probability and severity scores. 

threshold _:`Optional`[`HarmBlockThreshold`]_¶ 
    
Required. The harm block threshold. 

_pydantic model_genai.types.Schema¶ 
    
Bases: `BaseModel`
Schema is used to define the format of input/output data.
Represents a select subset of an [OpenAPI 3.0 schema object](https://spec.openapis.org/oas/v3.0.3#schema-object). More fields may be added in the future as needed.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"$defs":{
"Schema":{
"additionalProperties":false,
"description":"Schema is used to define the format of input/output data.\n\nRepresents a select subset of an [OpenAPI 3.0 schema\nobject](https://spec.openapis.org/oas/v3.0.3#schema-object). More fields may\nbe added in the future as needed.",
"properties":{
"anyOf":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Schema"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The value should be validated against any (one or more) of the subschemas in the list.",
"title":"Anyof"
},
"default":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Default value of the data.",
"title":"Default"
},
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The description of the data.",
"title":"Description"
},
"enum":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Possible values of the element of primitive type with enum format. Examples: 1. We can define direction as : {type:STRING, format:enum, enum:[\"EAST\", NORTH\", \"SOUTH\", \"WEST\"]} 2. We can define apartment number as : {type:INTEGER, format:enum, enum:[\"101\", \"201\", \"301\"]}",
"title":"Enum"
},
"example":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Example of the object. Will only populated when the object is the root.",
"title":"Example"
},
"format":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The format of the data. Supported formats: for NUMBER type: \"float\", \"double\" for INTEGER type: \"int32\", \"int64\" for STRING type: \"email\", \"byte\", etc",
"title":"Format"
},
"items":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE ARRAY Schema of the elements of Type.ARRAY."
},
"maxItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the elements for Type.ARRAY.",
"title":"Maxitems"
},
"maxLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum length of the Type.STRING",
"title":"Maxlength"
},
"maxProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the properties for Type.OBJECT.",
"title":"Maxproperties"
},
"maximum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum value of the Type.INTEGER and Type.NUMBER",
"title":"Maximum"
},
"minItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the elements for Type.ARRAY.",
"title":"Minitems"
},
"minLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING",
"title":"Minlength"
},
"minProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the properties for Type.OBJECT.",
"title":"Minproperties"
},
"minimum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER Minimum value of the Type.INTEGER and Type.NUMBER",
"title":"Minimum"
},
"nullable":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Indicates if the value may be null.",
"title":"Nullable"
},
"pattern":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Pattern of the Type.STRING to restrict a string to a regular expression.",
"title":"Pattern"
},
"properties":{
"anyOf":[
{
"additionalProperties":{
"$ref":"#/$defs/Schema"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE OBJECT Properties of Type.OBJECT.",
"title":"Properties"
},
"propertyOrdering":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The order of the properties. Not a standard field in open api spec. Only used to support the order of the properties.",
"title":"Propertyordering"
},
"required":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required properties of Type.OBJECT.",
"title":"Required"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The title of the Schema.",
"title":"Title"
},
"type":{
"anyOf":[
{
"$ref":"#/$defs/Type"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The type of the data."
}
},
"title":"Schema",
"type":"object"
},
"Type":{
"description":"Optional. The type of the data.",
"enum":[
"TYPE_UNSPECIFIED",
"STRING",
"NUMBER",
"INTEGER",
"BOOLEAN",
"ARRAY",
"OBJECT"
],
"title":"Type",
"type":"string"
}
},
"$ref":"#/$defs/Schema"
}

```


Fields: 
    
  * `any_of (list[genai.types.Schema] | None)`
  * `default (Any | None)`
  * `description (str | None)`
  * `enum (list[str] | None)`
  * `example (Any | None)`
  * `format (str | None)`
  * `items (genai.types.Schema | None)`
  * `max_items (int | None)`
  * `max_length (int | None)`
  * `max_properties (int | None)`
  * `maximum (float | None)`
  * `min_items (int | None)`
  * `min_length (int | None)`
  * `min_properties (int | None)`
  * `minimum (float | None)`
  * `nullable (bool | None)`
  * `pattern (str | None)`
  * `properties (dict[str, genai.types.Schema] | None)`
  * `property_ordering (list[str] | None)`
  * `required (list[str] | None)`
  * `title (str | None)`
  * `type (genai.types.Type | None)`



_field_ any_of _:`Optional`[`list`[Schema]]__= None_ _(alias 'anyOf')_¶ 
    
Optional. The value should be validated against any (one or more) of the subschemas in the list. 

_field_ default _:`Optional`[`Any`]__= None_¶ 
    
Optional. Default value of the data. 

_field_ description _:`Optional`[`str`]__= None_¶ 
    
Optional. The description of the data. 

_field_ enum _:`Optional`[`list`[`str`]]__= None_¶ 
    
Optional. Possible values of the element of primitive type with enum format. Examples: 1. We can define direction as : {type:STRING, format:enum, enum:[“EAST”, NORTH”, “SOUTH”, “WEST”]} 2. We can define apartment number as : {type:INTEGER, format:enum, enum:[“101”, “201”, “301”]} 

_field_ example _:`Optional`[`Any`]__= None_¶ 
    
Optional. Example of the object. Will only populated when the object is the root. 

_field_ format _:`Optional`[`str`]__= None_¶ 
    
Optional. The format of the data. Supported formats: for NUMBER type: “float”, “double” for INTEGER type: “int32”, “int64” for STRING type: “email”, “byte”, etc 

_field_ items _:`Optional`[Schema]__= None_¶ 
    
Optional. SCHEMA FIELDS FOR TYPE ARRAY Schema of the elements of Type.ARRAY. 

_field_ max_items _:`Optional`[`int`]__= None_ _(alias 'maxItems')_¶ 
    
Optional. Maximum number of the elements for Type.ARRAY. 

_field_ max_length _:`Optional`[`int`]__= None_ _(alias 'maxLength')_¶ 
    
Optional. Maximum length of the Type.STRING 

_field_ max_properties _:`Optional`[`int`]__= None_ _(alias 'maxProperties')_¶ 
    
Optional. Maximum number of the properties for Type.OBJECT. 

_field_ maximum _:`Optional`[`float`]__= None_¶ 
    
Optional. Maximum value of the Type.INTEGER and Type.NUMBER 

_field_ min_items _:`Optional`[`int`]__= None_ _(alias 'minItems')_¶ 
    
Optional. Minimum number of the elements for Type.ARRAY. 

_field_ min_length _:`Optional`[`int`]__= None_ _(alias 'minLength')_¶ 
    
Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING 

_field_ min_properties _:`Optional`[`int`]__= None_ _(alias 'minProperties')_¶ 
    
Optional. Minimum number of the properties for Type.OBJECT. 

_field_ minimum _:`Optional`[`float`]__= None_¶ 
    
Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER Minimum value of the Type.INTEGER and Type.NUMBER 

_field_ nullable _:`Optional`[`bool`]__= None_¶ 
    
Optional. Indicates if the value may be null. 

_field_ pattern _:`Optional`[`str`]__= None_¶ 
    
Optional. Pattern of the Type.STRING to restrict a string to a regular expression. 

_field_ properties _:`Optional`[`dict`[`str`, Schema]]__= None_¶ 
    
Optional. SCHEMA FIELDS FOR TYPE OBJECT Properties of Type.OBJECT. 

_field_ property_ordering _:`Optional`[`list`[`str`]]__= None_ _(alias 'propertyOrdering')_¶ 
    
Optional. The order of the properties. Not a standard field in open api spec. Only used to support the order of the properties. 

_field_ required _:`Optional`[`list`[`str`]]__= None_¶ 
    
Optional. Required properties of Type.OBJECT. 

_field_ title _:`Optional`[`str`]__= None_¶ 
    
Optional. The title of the Schema. 

_field_ type _:`Optional`[`Type`]__= None_¶ 
    
Optional. The type of the data. 

_classmethod_ from_json_schema(_*_ , _json_schema_ , _api_option ='GEMINI_API'_, _raise_error_on_unsupported_field =False_)¶ 
    
Converts a JSONSchema object to a Schema object.
The JSONSchema is compatible with 2020-12 JSON Schema draft, specified by OpenAPI 3.1. 

Return type: 
    
`Schema` 

Parameters: 
    
  * **json_schema** – JSONSchema object to be converted.
  * **api_option** – API option to be used. If set to ‘VERTEX_AI’, the JSONSchema will be converted to a Schema object that is compatible with Vertex AI API. If set to ‘GEMINI_API’, the JSONSchema will be converted to a Schema object that is compatible with Gemini API. Default is ‘GEMINI_API’.
  * **raise_error_on_unsupported_field** – If set to True, an error will be raised if the JSONSchema contains any unsupported fields. Default is False.



Returns: 
    
Schema object that is compatible with the specified API option. 

Raises: 
    
**ValueError** – If the JSONSchema contains any unsupported fields and raise_error_on_unsupported_field is set to True. Or if the JSONSchema is not compatible with the specified API option. 

_property_ json_schema _: JSONSchema_¶ 
    
Converts the Schema object to a JSONSchema object, that is compatible with 2020-12 JSON Schema draft.
If a Schema field is not supported by JSONSchema, it will be ignored. 

_class_ genai.types.SchemaDict¶ 
    
Bases: `TypedDict`
Schema is used to define the format of input/output data.
Represents a select subset of an [OpenAPI 3.0 schema object](https://spec.openapis.org/oas/v3.0.3#schema-object). More fields may be added in the future as needed. 

any_of _:`Optional`[`list`[`SchemaDict`]]_¶ 
    
Optional. The value should be validated against any (one or more) of the subschemas in the list. 

default _:`Optional`[`Any`]_¶ 
    
Optional. Default value of the data. 

description _:`Optional`[`str`]_¶ 
    
Optional. The description of the data. 

enum _:`Optional`[`list`[`str`]]_¶ 
    
{type:STRING, format:enum, enum:[“EAST”, NORTH”, “SOUTH”, “WEST”]} 2. We can define apartment number as : {type:INTEGER, format:enum, enum:[“101”, “201”, “301”]} 

Type: 
    
Optional. Possible values of the element of primitive type with enum format. Examples 

Type: 
    
  1. We can define direction as



example _:`Optional`[`Any`]_¶ 
    
Optional. Example of the object. Will only populated when the object is the root. 

format _:`Optional`[`str`]_¶ 
    
“float”, “double” for INTEGER type: “int32”, “int64” for STRING type: “email”, “byte”, etc 

Type: 
    
Optional. The format of the data. Supported formats 

Type: 
    
for NUMBER type 

max_items _:`Optional`[`int`]_¶ 
    
Optional. Maximum number of the elements for Type.ARRAY. 

max_length _:`Optional`[`int`]_¶ 
    
Optional. Maximum length of the Type.STRING 

max_properties _:`Optional`[`int`]_¶ 
    
Optional. Maximum number of the properties for Type.OBJECT. 

maximum _:`Optional`[`float`]_¶ 
    
Optional. Maximum value of the Type.INTEGER and Type.NUMBER 

min_items _:`Optional`[`int`]_¶ 
    
Optional. Minimum number of the elements for Type.ARRAY. 

min_length _:`Optional`[`int`]_¶ 
    
Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING 

min_properties _:`Optional`[`int`]_¶ 
    
Optional. Minimum number of the properties for Type.OBJECT. 

minimum _:`Optional`[`float`]_¶ 
    
Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER Minimum value of the Type.INTEGER and Type.NUMBER 

nullable _:`Optional`[`bool`]_¶ 
    
Optional. Indicates if the value may be null. 

pattern _:`Optional`[`str`]_¶ 
    
Optional. Pattern of the Type.STRING to restrict a string to a regular expression. 

properties _:`Optional`[`dict`[`str`, `SchemaDict`]]_¶ 
    
Optional. SCHEMA FIELDS FOR TYPE OBJECT Properties of Type.OBJECT. 

property_ordering _:`Optional`[`list`[`str`]]_¶ 
    
Optional. The order of the properties. Not a standard field in open api spec. Only used to support the order of the properties. 

required _:`Optional`[`list`[`str`]]_¶ 
    
Optional. Required properties of Type.OBJECT. 

title _:`Optional`[`str`]_¶ 
    
Optional. The title of the Schema. 

type _:`Optional`[`Type`]_¶ 
    
Optional. The type of the data. 

_pydantic model_genai.types.SearchEntryPoint¶ 
    
Bases: `BaseModel`
Google search entry point.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"SearchEntryPoint",
"description":"Google search entry point.",
"type":"object",
"properties":{
"renderedContent":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Web content snippet that can be embedded in a web page or an app webview.",
"title":"Renderedcontent"
},
"sdkBlob":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Base64 encoded JSON representing array of tuple.",
"title":"Sdkblob"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `rendered_content (str | None)`
  * `sdk_blob (bytes | None)`



_field_ rendered_content _:`Optional`[`str`]__= None_ _(alias 'renderedContent')_¶ 
    
Optional. Web content snippet that can be embedded in a web page or an app webview. 

_field_ sdk_blob _:`Optional`[`bytes`]__= None_ _(alias 'sdkBlob')_¶ 
    
Optional. Base64 encoded JSON representing array of tuple. 

_class_ genai.types.SearchEntryPointDict¶ 
    
Bases: `TypedDict`
Google search entry point. 

rendered_content _:`Optional`[`str`]_¶ 
    
Optional. Web content snippet that can be embedded in a web page or an app webview. 

sdk_blob _:`Optional`[`bytes`]_¶ 
    
Optional. Base64 encoded JSON representing array of tuple. 

_pydantic model_genai.types.Segment¶ 
    
Bases: `BaseModel`
Segment of the content.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"Segment",
"description":"Segment of the content.",
"type":"object",
"properties":{
"endIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. End index in the given Part, measured in bytes. Offset from the start of the Part, exclusive, starting at zero.",
"title":"Endindex"
},
"partIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The index of a Part object within its parent Content object.",
"title":"Partindex"
},
"startIndex":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Start index in the given Part, measured in bytes. Offset from the start of the Part, inclusive, starting at zero.",
"title":"Startindex"
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The text corresponding to the segment from the response.",
"title":"Text"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `end_index (int | None)`
  * `part_index (int | None)`
  * `start_index (int | None)`
  * `text (str | None)`



_field_ end_index _:`Optional`[`int`]__= None_ _(alias 'endIndex')_¶ 
    
Output only. End index in the given Part, measured in bytes. Offset from the start of the Part, exclusive, starting at zero. 

_field_ part_index _:`Optional`[`int`]__= None_ _(alias 'partIndex')_¶ 
    
Output only. The index of a Part object within its parent Content object. 

_field_ start_index _:`Optional`[`int`]__= None_ _(alias 'startIndex')_¶ 
    
Output only. Start index in the given Part, measured in bytes. Offset from the start of the Part, inclusive, starting at zero. 

_field_ text _:`Optional`[`str`]__= None_¶ 
    
Output only. The text corresponding to the segment from the response. 

_class_ genai.types.SegmentDict¶ 
    
Bases: `TypedDict`
Segment of the content. 

end_index _:`Optional`[`int`]_¶ 
    
Output only. End index in the given Part, measured in bytes. Offset from the start of the Part, exclusive, starting at zero. 

part_index _:`Optional`[`int`]_¶ 
    
Output only. The index of a Part object within its parent Content object. 

start_index _:`Optional`[`int`]_¶ 
    
Output only. Start index in the given Part, measured in bytes. Offset from the start of the Part, inclusive, starting at zero. 

text _:`Optional`[`str`]_¶ 
    
Output only. The text corresponding to the segment from the response. 

_pydantic model_genai.types.SessionResumptionConfig¶ 
    
Bases: `BaseModel`
Configuration of session resumption mechanism.
Included in LiveConnectConfig.session_resumption. If included server will send LiveServerSessionResumptionUpdate messages.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"SessionResumptionConfig",
"description":"Configuration of session resumption mechanism.\n\nIncluded in `LiveConnectConfig.session_resumption`. If included server\nwill send `LiveServerSessionResumptionUpdate` messages.",
"type":"object",
"properties":{
"handle":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Session resumption handle of previous session (session to restore).\n\nIf not present new session will be started.",
"title":"Handle"
},
"transparent":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"If set the server will send `last_consumed_client_message_index` in the `session_resumption_update` messages to allow for transparent reconnections.",
"title":"Transparent"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `handle (str | None)`
  * `transparent (bool | None)`



_field_ handle _:`Optional`[`str`]__= None_¶ 
    
Session resumption handle of previous session (session to restore).
If not present new session will be started. 

_field_ transparent _:`Optional`[`bool`]__= None_¶ 
    
If set the server will send last_consumed_client_message_index in the session_resumption_update messages to allow for transparent reconnections. 

_class_ genai.types.SessionResumptionConfigDict¶ 
    
Bases: `TypedDict`
Configuration of session resumption mechanism.
Included in LiveConnectConfig.session_resumption. If included server will send LiveServerSessionResumptionUpdate messages. 

handle _:`Optional`[`str`]_¶ 
    
Session resumption handle of previous session (session to restore).
If not present new session will be started. 

transparent _:`Optional`[`bool`]_¶ 
    
If set the server will send last_consumed_client_message_index in the session_resumption_update messages to allow for transparent reconnections. 

_pydantic model_genai.types.SlidingWindow¶ 
    
Bases: `BaseModel`
Context window will be truncated by keeping only suffix of it.
Context window will always be cut at start of USER role turn. System instructions and BidiGenerateContentSetup.prefix_turns will not be subject to the sliding window mechanism, they will always stay at the beginning of context window.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"SlidingWindow",
"description":"Context window will be truncated by keeping only suffix of it.\n\nContext window will always be cut at start of USER role turn. System\ninstructions and `BidiGenerateContentSetup.prefix_turns` will not be\nsubject to the sliding window mechanism, they will always stay at the\nbeginning of context window.",
"type":"object",
"properties":{
"targetTokens":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Session reduction target -- how many tokens we should keep. Window shortening operation has some latency costs, so we should avoid running it on every turn. Should be < trigger_tokens. If not set, trigger_tokens/2 is assumed.",
"title":"Targettokens"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `target_tokens (int | None)`



_field_ target_tokens _:`Optional`[`int`]__= None_ _(alias 'targetTokens')_¶ 
    
Session reduction target – how many tokens we should keep. Window shortening operation has some latency costs, so we should avoid running it on every turn. Should be < trigger_tokens. If not set, trigger_tokens/2 is assumed. 

_class_ genai.types.SlidingWindowDict¶ 
    
Bases: `TypedDict`
Context window will be truncated by keeping only suffix of it.
Context window will always be cut at start of USER role turn. System instructions and BidiGenerateContentSetup.prefix_turns will not be subject to the sliding window mechanism, they will always stay at the beginning of context window. 

target_tokens _:`Optional`[`int`]_¶ 
    
Session reduction target – how many tokens we should keep. Window shortening operation has some latency costs, so we should avoid running it on every turn. Should be < trigger_tokens. If not set, trigger_tokens/2 is assumed. 

_pydantic model_genai.types.SpeechConfig¶ 
    
Bases: `BaseModel`
The speech generation configuration.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"SpeechConfig",
"description":"The speech generation configuration.",
"type":"object",
"properties":{
"voiceConfig":{
"anyOf":[
{
"$ref":"#/$defs/VoiceConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The configuration for the speaker to use.\n      "
},
"languageCode":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Language code (ISO 639. e.g. en-US) for the speech synthesization.\n      Only available for Live API.\n      ",
"title":"Languagecode"
}
},
"$defs":{
"PrebuiltVoiceConfig":{
"additionalProperties":false,
"description":"The configuration for the prebuilt speaker to use.",
"properties":{
"voiceName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The name of the prebuilt voice to use.\n      ",
"title":"Voicename"
}
},
"title":"PrebuiltVoiceConfig",
"type":"object"
},
"VoiceConfig":{
"additionalProperties":false,
"description":"The configuration for the voice to use.",
"properties":{
"prebuiltVoiceConfig":{
"anyOf":[
{
"$ref":"#/$defs/PrebuiltVoiceConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The configuration for the speaker to use.\n      "
}
},
"title":"VoiceConfig",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `language_code (str | None)`
  * `voice_config (genai.types.VoiceConfig | None)`



_field_ language_code _:`Optional`[`str`]__= None_ _(alias 'languageCode')_¶ 
    
Language code (ISO 639. e.g. en-US) for the speech synthesization. Only available for Live API. 

_field_ voice_config _:`Optional`[`VoiceConfig`]__= None_ _(alias 'voiceConfig')_¶ 
    
The configuration for the speaker to use. 

_class_ genai.types.SpeechConfigDict¶ 
    
Bases: `TypedDict`
The speech generation configuration. 

language_code _:`Optional`[`str`]_¶ 
    
Language code (ISO 639. e.g. en-US) for the speech synthesization. Only available for Live API. 

voice_config _:`Optional`[`VoiceConfigDict`]_¶ 
    
The configuration for the speaker to use. 

_class_ genai.types.StartSensitivity(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Start of speech sensitivity. 

START_SENSITIVITY_HIGH _= 'START_SENSITIVITY_HIGH'_¶ 


START_SENSITIVITY_LOW _= 'START_SENSITIVITY_LOW'_¶ 


START_SENSITIVITY_UNSPECIFIED _= 'START_SENSITIVITY_UNSPECIFIED'_¶ 


_pydantic model_genai.types.StyleReferenceConfig¶ 
    
Bases: `BaseModel`
Configuration for a Style reference image.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"StyleReferenceConfig",
"description":"Configuration for a Style reference image.",
"type":"object",
"properties":{
"styleDescription":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A text description of the style to use for the generated image.",
"title":"Styledescription"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `style_description (str | None)`



_field_ style_description _:`Optional`[`str`]__= None_ _(alias 'styleDescription')_¶ 
    
A text description of the style to use for the generated image. 

_class_ genai.types.StyleReferenceConfigDict¶ 
    
Bases: `TypedDict`
Configuration for a Style reference image. 

style_description _:`Optional`[`str`]_¶ 
    
A text description of the style to use for the generated image. 

_pydantic model_genai.types.StyleReferenceImage¶ 
    
Bases: `BaseModel`
A style reference image.
This encapsulates a style reference image provided by the user, and additionally optional config parameters for the style reference image.
A raw reference image can also be provided as a destination for the style to be applied to.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"StyleReferenceImage",
"description":"A style reference image.\n\nThis encapsulates a style reference image provided by the user, and\nadditionally optional config parameters for the style reference image.\n\nA raw reference image can also be provided as a destination for the style to\nbe applied to.",
"type":"object",
"properties":{
"referenceImage":{
"anyOf":[
{
"$ref":"#/$defs/Image"
},
{
"type":"null"
}
],
"default":null,
"description":"The reference image for the editing operation."
},
"referenceId":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the reference image.",
"title":"Referenceid"
},
"referenceType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The type of the reference image. Only set by the SDK.",
"title":"Referencetype"
},
"config":{
"anyOf":[
{
"$ref":"#/$defs/StyleReferenceConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Configuration for the style reference image."
},
"styleImageConfig":{
"anyOf":[
{
"$ref":"#/$defs/StyleReferenceConfig"
},
{
"type":"null"
}
],
"default":null,
"description":""
}
},
"$defs":{
"Image":{
"additionalProperties":false,
"description":"An image.",
"properties":{
"gcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The Cloud Storage URI of the image. ``Image`` can contain a value\n      for this field or the ``image_bytes`` field but not both.\n      ",
"title":"Gcsuri"
},
"imageBytes":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The image bytes data. ``Image`` can contain a value for this field\n      or the ``gcs_uri`` field but not both.\n      ",
"title":"Imagebytes"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The MIME type of the image.",
"title":"Mimetype"
}
},
"title":"Image",
"type":"object"
},
"StyleReferenceConfig":{
"additionalProperties":false,
"description":"Configuration for a Style reference image.",
"properties":{
"styleDescription":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A text description of the style to use for the generated image.",
"title":"Styledescription"
}
},
"title":"StyleReferenceConfig",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `config (genai.types.StyleReferenceConfig | None)`
  * `reference_id (int | None)`
  * `reference_image (genai.types.Image | None)`
  * `reference_type (str | None)`
  * `style_image_config (genai.types.StyleReferenceConfig | None)`



Validators: 
    
  * `_validate_mask_image_config` » `all fields`



_field_ config _:`Optional`[`StyleReferenceConfig`]__= None_¶ 
    
Re-map config to style_reference_config to send to API.
Configuration for the style reference image. 

Validated by: 
    
  * `_validate_mask_image_config`



_field_ reference_id _:`Optional`[`int`]__= None_ _(alias 'referenceId')_¶ 
    
The id of the reference image. 

Validated by: 
    
  * `_validate_mask_image_config`



_field_ reference_image _:`Optional`[`Image`]__= None_ _(alias 'referenceImage')_¶ 
    
The reference image for the editing operation. 

Validated by: 
    
  * `_validate_mask_image_config`



_field_ reference_type _:`Optional`[`str`]__= None_ _(alias 'referenceType')_¶ 
    
The type of the reference image. Only set by the SDK. 

Validated by: 
    
  * `_validate_mask_image_config`



_field_ style_image_config _:`Optional`[StyleReferenceConfig]__= None_ _(alias 'styleImageConfig')_¶ 
     

Validated by: 
    
  * `_validate_mask_image_config`



_class_ genai.types.StyleReferenceImageDict¶ 
    
Bases: `TypedDict`
A style reference image.
This encapsulates a style reference image provided by the user, and additionally optional config parameters for the style reference image.
A raw reference image can also be provided as a destination for the style to be applied to. 

config _:`Optional`[`StyleReferenceConfigDict`]_¶ 
    
Configuration for the style reference image. 

reference_id _:`Optional`[`int`]_¶ 
    
The id of the reference image. 

reference_image _:`Optional`[`ImageDict`]_¶ 
    
The reference image for the editing operation. 

reference_type _:`Optional`[`str`]_¶ 
    
The type of the reference image. Only set by the SDK. 

_pydantic model_genai.types.SubjectReferenceConfig¶ 
    
Bases: `BaseModel`
Configuration for a Subject reference image.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"SubjectReferenceConfig",
"description":"Configuration for a Subject reference image.",
"type":"object",
"properties":{
"subjectType":{
"anyOf":[
{
"$ref":"#/$defs/SubjectReferenceType"
},
{
"type":"null"
}
],
"default":null,
"description":"The subject type of a subject reference image."
},
"subjectDescription":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Subject description for the image.",
"title":"Subjectdescription"
}
},
"$defs":{
"SubjectReferenceType":{
"description":"Enum representing the subject type of a subject reference image.",
"enum":[
"SUBJECT_TYPE_DEFAULT",
"SUBJECT_TYPE_PERSON",
"SUBJECT_TYPE_ANIMAL",
"SUBJECT_TYPE_PRODUCT"
],
"title":"SubjectReferenceType",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `subject_description (str | None)`
  * `subject_type (genai.types.SubjectReferenceType | None)`



_field_ subject_description _:`Optional`[`str`]__= None_ _(alias 'subjectDescription')_¶ 
    
Subject description for the image. 

_field_ subject_type _:`Optional`[`SubjectReferenceType`]__= None_ _(alias 'subjectType')_¶ 
    
The subject type of a subject reference image. 

_class_ genai.types.SubjectReferenceConfigDict¶ 
    
Bases: `TypedDict`
Configuration for a Subject reference image. 

subject_description _:`Optional`[`str`]_¶ 
    
Subject description for the image. 

subject_type _:`Optional`[`SubjectReferenceType`]_¶ 
    
The subject type of a subject reference image. 

_pydantic model_genai.types.SubjectReferenceImage¶ 
    
Bases: `BaseModel`
A subject reference image.
This encapsulates a subject reference image provided by the user, and additionally optional config parameters for the subject reference image.
A raw reference image can also be provided as a destination for the subject to be applied to.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"SubjectReferenceImage",
"description":"A subject reference image.\n\nThis encapsulates a subject reference image provided by the user, and\nadditionally optional config parameters for the subject reference image.\n\nA raw reference image can also be provided as a destination for the subject to\nbe applied to.",
"type":"object",
"properties":{
"referenceImage":{
"anyOf":[
{
"$ref":"#/$defs/Image"
},
{
"type":"null"
}
],
"default":null,
"description":"The reference image for the editing operation."
},
"referenceId":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the reference image.",
"title":"Referenceid"
},
"referenceType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The type of the reference image. Only set by the SDK.",
"title":"Referencetype"
},
"config":{
"anyOf":[
{
"$ref":"#/$defs/SubjectReferenceConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Configuration for the subject reference image."
},
"subjectImageConfig":{
"anyOf":[
{
"$ref":"#/$defs/SubjectReferenceConfig"
},
{
"type":"null"
}
],
"default":null,
"description":""
}
},
"$defs":{
"Image":{
"additionalProperties":false,
"description":"An image.",
"properties":{
"gcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The Cloud Storage URI of the image. ``Image`` can contain a value\n      for this field or the ``image_bytes`` field but not both.\n      ",
"title":"Gcsuri"
},
"imageBytes":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The image bytes data. ``Image`` can contain a value for this field\n      or the ``gcs_uri`` field but not both.\n      ",
"title":"Imagebytes"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The MIME type of the image.",
"title":"Mimetype"
}
},
"title":"Image",
"type":"object"
},
"SubjectReferenceConfig":{
"additionalProperties":false,
"description":"Configuration for a Subject reference image.",
"properties":{
"subjectType":{
"anyOf":[
{
"$ref":"#/$defs/SubjectReferenceType"
},
{
"type":"null"
}
],
"default":null,
"description":"The subject type of a subject reference image."
},
"subjectDescription":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Subject description for the image.",
"title":"Subjectdescription"
}
},
"title":"SubjectReferenceConfig",
"type":"object"
},
"SubjectReferenceType":{
"description":"Enum representing the subject type of a subject reference image.",
"enum":[
"SUBJECT_TYPE_DEFAULT",
"SUBJECT_TYPE_PERSON",
"SUBJECT_TYPE_ANIMAL",
"SUBJECT_TYPE_PRODUCT"
],
"title":"SubjectReferenceType",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `config (genai.types.SubjectReferenceConfig | None)`
  * `reference_id (int | None)`
  * `reference_image (genai.types.Image | None)`
  * `reference_type (str | None)`
  * `subject_image_config (genai.types.SubjectReferenceConfig | None)`



Validators: 
    
  * `_validate_mask_image_config` » `all fields`



_field_ config _:`Optional`[`SubjectReferenceConfig`]__= None_¶ 
    
Re-map config to subject_reference_config to send to API.
Configuration for the subject reference image. 

Validated by: 
    
  * `_validate_mask_image_config`



_field_ reference_id _:`Optional`[`int`]__= None_ _(alias 'referenceId')_¶ 
    
The id of the reference image. 

Validated by: 
    
  * `_validate_mask_image_config`



_field_ reference_image _:`Optional`[`Image`]__= None_ _(alias 'referenceImage')_¶ 
    
The reference image for the editing operation. 

Validated by: 
    
  * `_validate_mask_image_config`



_field_ reference_type _:`Optional`[`str`]__= None_ _(alias 'referenceType')_¶ 
    
The type of the reference image. Only set by the SDK. 

Validated by: 
    
  * `_validate_mask_image_config`



_field_ subject_image_config _:`Optional`[SubjectReferenceConfig]__= None_ _(alias 'subjectImageConfig')_¶ 
     

Validated by: 
    
  * `_validate_mask_image_config`



_class_ genai.types.SubjectReferenceImageDict¶ 
    
Bases: `TypedDict`
A subject reference image.
This encapsulates a subject reference image provided by the user, and additionally optional config parameters for the subject reference image.
A raw reference image can also be provided as a destination for the subject to be applied to. 

config _:`Optional`[`SubjectReferenceConfigDict`]_¶ 
    
Configuration for the subject reference image. 

reference_id _:`Optional`[`int`]_¶ 
    
The id of the reference image. 

reference_image _:`Optional`[`ImageDict`]_¶ 
    
The reference image for the editing operation. 

reference_type _:`Optional`[`str`]_¶ 
    
The type of the reference image. Only set by the SDK. 

_class_ genai.types.SubjectReferenceType(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Enum representing the subject type of a subject reference image. 

SUBJECT_TYPE_ANIMAL _= 'SUBJECT_TYPE_ANIMAL'_¶ 


SUBJECT_TYPE_DEFAULT _= 'SUBJECT_TYPE_DEFAULT'_¶ 


SUBJECT_TYPE_PERSON _= 'SUBJECT_TYPE_PERSON'_¶ 


SUBJECT_TYPE_PRODUCT _= 'SUBJECT_TYPE_PRODUCT'_¶ 


_pydantic model_genai.types.SupervisedHyperParameters¶ 
    
Bases: `BaseModel`
Hyperparameters for SFT.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"SupervisedHyperParameters",
"description":"Hyperparameters for SFT.",
"type":"object",
"properties":{
"adapterSize":{
"anyOf":[
{
"$ref":"#/$defs/AdapterSize"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Adapter size for tuning."
},
"epochCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of complete passes the model makes over the entire training dataset during training.",
"title":"Epochcount"
},
"learningRateMultiplier":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Multiplier for adjusting the default learning rate.",
"title":"Learningratemultiplier"
}
},
"$defs":{
"AdapterSize":{
"description":"Optional. Adapter size for tuning.",
"enum":[
"ADAPTER_SIZE_UNSPECIFIED",
"ADAPTER_SIZE_ONE",
"ADAPTER_SIZE_TWO",
"ADAPTER_SIZE_FOUR",
"ADAPTER_SIZE_EIGHT",
"ADAPTER_SIZE_SIXTEEN",
"ADAPTER_SIZE_THIRTY_TWO"
],
"title":"AdapterSize",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `adapter_size (genai.types.AdapterSize | None)`
  * `epoch_count (int | None)`
  * `learning_rate_multiplier (float | None)`



_field_ adapter_size _:`Optional`[`AdapterSize`]__= None_ _(alias 'adapterSize')_¶ 
    
Optional. Adapter size for tuning. 

_field_ epoch_count _:`Optional`[`int`]__= None_ _(alias 'epochCount')_¶ 
    
Optional. Number of complete passes the model makes over the entire training dataset during training. 

_field_ learning_rate_multiplier _:`Optional`[`float`]__= None_ _(alias 'learningRateMultiplier')_¶ 
    
Optional. Multiplier for adjusting the default learning rate. 

_class_ genai.types.SupervisedHyperParametersDict¶ 
    
Bases: `TypedDict`
Hyperparameters for SFT. 

adapter_size _:`Optional`[`AdapterSize`]_¶ 
    
Optional. Adapter size for tuning. 

epoch_count _:`Optional`[`int`]_¶ 
    
Optional. Number of complete passes the model makes over the entire training dataset during training. 

learning_rate_multiplier _:`Optional`[`float`]_¶ 
    
Optional. Multiplier for adjusting the default learning rate. 

_pydantic model_genai.types.SupervisedTuningDataStats¶ 
    
Bases: `BaseModel`
Tuning data statistics for Supervised Tuning.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"SupervisedTuningDataStats",
"description":"Tuning data statistics for Supervised Tuning.",
"type":"object",
"properties":{
"totalBillableCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of billable characters in the tuning dataset.",
"title":"Totalbillablecharactercount"
},
"totalBillableTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of billable tokens in the tuning dataset.",
"title":"Totalbillabletokencount"
},
"totalTruncatedExampleCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The number of examples in the dataset that have been truncated by any amount.",
"title":"Totaltruncatedexamplecount"
},
"totalTuningCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tuning characters in the tuning dataset.",
"title":"Totaltuningcharactercount"
},
"truncatedExampleIndices":{
"anyOf":[
{
"items":{
"type":"integer"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A partial sample of the indices (starting from 1) of the truncated examples.",
"title":"Truncatedexampleindices"
},
"tuningDatasetExampleCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of examples in the tuning dataset.",
"title":"Tuningdatasetexamplecount"
},
"tuningStepCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tuning steps for this Tuning Job.",
"title":"Tuningstepcount"
},
"userDatasetExamples":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Content"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sample user messages in the training dataset uri.",
"title":"Userdatasetexamples"
},
"userInputTokenDistribution":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedTuningDatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the user input tokens."
},
"userMessagePerExampleDistribution":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedTuningDatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the messages per example."
},
"userOutputTokenDistribution":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedTuningDatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the user output tokens."
}
},
"$defs":{
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"Content":{
"additionalProperties":false,
"description":"Contains the multi-part content of a message.",
"properties":{
"parts":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Part"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of parts that constitute a single message. Each part may have\n      a different IANA MIME type.",
"title":"Parts"
},
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role.",
"title":"Role"
}
},
"title":"Content",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"SupervisedTuningDatasetDistribution":{
"additionalProperties":false,
"description":"Dataset distribution for Supervised Tuning.",
"properties":{
"billableSum":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sum of a given population of values that are billable.",
"title":"Billablesum"
},
"buckets":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/SupervisedTuningDatasetDistributionDatasetBucket"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Defines the histogram bucket.",
"title":"Buckets"
},
"max":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The maximum of the population values.",
"title":"Max"
},
"mean":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The arithmetic mean of the values in the population.",
"title":"Mean"
},
"median":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The median of the values in the population.",
"title":"Median"
},
"min":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The minimum of the population values.",
"title":"Min"
},
"p5":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 5th percentile of the values in the population.",
"title":"P5"
},
"p95":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 95th percentile of the values in the population.",
"title":"P95"
},
"sum":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sum of a given population of values.",
"title":"Sum"
}
},
"title":"SupervisedTuningDatasetDistribution",
"type":"object"
},
"SupervisedTuningDatasetDistributionDatasetBucket":{
"additionalProperties":false,
"description":"Dataset bucket used to create a histogram for the distribution given a population of values.",
"properties":{
"count":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of values in the bucket.",
"title":"Count"
},
"left":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Left bound of the bucket.",
"title":"Left"
},
"right":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Right bound of the bucket.",
"title":"Right"
}
},
"title":"SupervisedTuningDatasetDistributionDatasetBucket",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `total_billable_character_count (int | None)`
  * `total_billable_token_count (int | None)`
  * `total_truncated_example_count (int | None)`
  * `total_tuning_character_count (int | None)`
  * `truncated_example_indices (list[int] | None)`
  * `tuning_dataset_example_count (int | None)`
  * `tuning_step_count (int | None)`
  * `user_dataset_examples (list[genai.types.Content] | None)`
  * `user_input_token_distribution (genai.types.SupervisedTuningDatasetDistribution | None)`
  * `user_message_per_example_distribution (genai.types.SupervisedTuningDatasetDistribution | None)`
  * `user_output_token_distribution (genai.types.SupervisedTuningDatasetDistribution | None)`



_field_ total_billable_character_count _:`Optional`[`int`]__= None_ _(alias 'totalBillableCharacterCount')_¶ 
    
Output only. Number of billable characters in the tuning dataset. 

_field_ total_billable_token_count _:`Optional`[`int`]__= None_ _(alias 'totalBillableTokenCount')_¶ 
    
Output only. Number of billable tokens in the tuning dataset. 

_field_ total_truncated_example_count _:`Optional`[`int`]__= None_ _(alias 'totalTruncatedExampleCount')_¶ 
    
The number of examples in the dataset that have been truncated by any amount. 

_field_ total_tuning_character_count _:`Optional`[`int`]__= None_ _(alias 'totalTuningCharacterCount')_¶ 
    
Output only. Number of tuning characters in the tuning dataset. 

_field_ truncated_example_indices _:`Optional`[`list`[`int`]]__= None_ _(alias 'truncatedExampleIndices')_¶ 
    
A partial sample of the indices (starting from 1) of the truncated examples. 

_field_ tuning_dataset_example_count _:`Optional`[`int`]__= None_ _(alias 'tuningDatasetExampleCount')_¶ 
    
Output only. Number of examples in the tuning dataset. 

_field_ tuning_step_count _:`Optional`[`int`]__= None_ _(alias 'tuningStepCount')_¶ 
    
Output only. Number of tuning steps for this Tuning Job. 

_field_ user_dataset_examples _:`Optional`[`list`[`Content`]]__= None_ _(alias 'userDatasetExamples')_¶ 
    
Output only. Sample user messages in the training dataset uri. 

_field_ user_input_token_distribution _:`Optional`[`SupervisedTuningDatasetDistribution`]__= None_ _(alias 'userInputTokenDistribution')_¶ 
    
Output only. Dataset distributions for the user input tokens. 

_field_ user_message_per_example_distribution _:`Optional`[`SupervisedTuningDatasetDistribution`]__= None_ _(alias 'userMessagePerExampleDistribution')_¶ 
    
Output only. Dataset distributions for the messages per example. 

_field_ user_output_token_distribution _:`Optional`[`SupervisedTuningDatasetDistribution`]__= None_ _(alias 'userOutputTokenDistribution')_¶ 
    
Output only. Dataset distributions for the user output tokens. 

_class_ genai.types.SupervisedTuningDataStatsDict¶ 
    
Bases: `TypedDict`
Tuning data statistics for Supervised Tuning. 

total_billable_character_count _:`Optional`[`int`]_¶ 
    
Output only. Number of billable characters in the tuning dataset. 

total_billable_token_count _:`Optional`[`int`]_¶ 
    
Output only. Number of billable tokens in the tuning dataset. 

total_truncated_example_count _:`Optional`[`int`]_¶ 
    
The number of examples in the dataset that have been truncated by any amount. 

total_tuning_character_count _:`Optional`[`int`]_¶ 
    
Output only. Number of tuning characters in the tuning dataset. 

truncated_example_indices _:`Optional`[`list`[`int`]]_¶ 
    
A partial sample of the indices (starting from 1) of the truncated examples. 

tuning_dataset_example_count _:`Optional`[`int`]_¶ 
    
Output only. Number of examples in the tuning dataset. 

tuning_step_count _:`Optional`[`int`]_¶ 
    
Output only. Number of tuning steps for this Tuning Job. 

user_dataset_examples _:`Optional`[`list`[`ContentDict`]]_¶ 
    
Output only. Sample user messages in the training dataset uri. 

user_input_token_distribution _:`Optional`[`SupervisedTuningDatasetDistributionDict`]_¶ 
    
Output only. Dataset distributions for the user input tokens. 

user_message_per_example_distribution _:`Optional`[`SupervisedTuningDatasetDistributionDict`]_¶ 
    
Output only. Dataset distributions for the messages per example. 

user_output_token_distribution _:`Optional`[`SupervisedTuningDatasetDistributionDict`]_¶ 
    
Output only. Dataset distributions for the user output tokens. 

_pydantic model_genai.types.SupervisedTuningDatasetDistribution¶ 
    
Bases: `BaseModel`
Dataset distribution for Supervised Tuning.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"SupervisedTuningDatasetDistribution",
"description":"Dataset distribution for Supervised Tuning.",
"type":"object",
"properties":{
"billableSum":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sum of a given population of values that are billable.",
"title":"Billablesum"
},
"buckets":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/SupervisedTuningDatasetDistributionDatasetBucket"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Defines the histogram bucket.",
"title":"Buckets"
},
"max":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The maximum of the population values.",
"title":"Max"
},
"mean":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The arithmetic mean of the values in the population.",
"title":"Mean"
},
"median":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The median of the values in the population.",
"title":"Median"
},
"min":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The minimum of the population values.",
"title":"Min"
},
"p5":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 5th percentile of the values in the population.",
"title":"P5"
},
"p95":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 95th percentile of the values in the population.",
"title":"P95"
},
"sum":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sum of a given population of values.",
"title":"Sum"
}
},
"$defs":{
"SupervisedTuningDatasetDistributionDatasetBucket":{
"additionalProperties":false,
"description":"Dataset bucket used to create a histogram for the distribution given a population of values.",
"properties":{
"count":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of values in the bucket.",
"title":"Count"
},
"left":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Left bound of the bucket.",
"title":"Left"
},
"right":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Right bound of the bucket.",
"title":"Right"
}
},
"title":"SupervisedTuningDatasetDistributionDatasetBucket",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `billable_sum (int | None)`
  * `buckets (list[genai.types.SupervisedTuningDatasetDistributionDatasetBucket] | None)`
  * `max (float | None)`
  * `mean (float | None)`
  * `median (float | None)`
  * `min (float | None)`
  * `p5 (float | None)`
  * `p95 (float | None)`
  * `sum (int | None)`



_field_ billable_sum _:`Optional`[`int`]__= None_ _(alias 'billableSum')_¶ 
    
Output only. Sum of a given population of values that are billable. 

_field_ buckets _:`Optional`[`list`[`SupervisedTuningDatasetDistributionDatasetBucket`]]__= None_¶ 
    
Output only. Defines the histogram bucket. 

_field_ max _:`Optional`[`float`]__= None_¶ 
    
Output only. The maximum of the population values. 

_field_ mean _:`Optional`[`float`]__= None_¶ 
    
Output only. The arithmetic mean of the values in the population. 

_field_ median _:`Optional`[`float`]__= None_¶ 
    
Output only. The median of the values in the population. 

_field_ min _:`Optional`[`float`]__= None_¶ 
    
Output only. The minimum of the population values. 

_field_ p5 _:`Optional`[`float`]__= None_¶ 
    
Output only. The 5th percentile of the values in the population. 

_field_ p95 _:`Optional`[`float`]__= None_¶ 
    
Output only. The 95th percentile of the values in the population. 

_field_ sum _:`Optional`[`int`]__= None_¶ 
    
Output only. Sum of a given population of values. 

_pydantic model_genai.types.SupervisedTuningDatasetDistributionDatasetBucket¶ 
    
Bases: `BaseModel`
Dataset bucket used to create a histogram for the distribution given a population of values.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"SupervisedTuningDatasetDistributionDatasetBucket",
"description":"Dataset bucket used to create a histogram for the distribution given a population of values.",
"type":"object",
"properties":{
"count":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of values in the bucket.",
"title":"Count"
},
"left":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Left bound of the bucket.",
"title":"Left"
},
"right":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Right bound of the bucket.",
"title":"Right"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `count (float | None)`
  * `left (float | None)`
  * `right (float | None)`



_field_ count _:`Optional`[`float`]__= None_¶ 
    
Output only. Number of values in the bucket. 

_field_ left _:`Optional`[`float`]__= None_¶ 
    
Output only. Left bound of the bucket. 

_field_ right _:`Optional`[`float`]__= None_¶ 
    
Output only. Right bound of the bucket. 

_class_ genai.types.SupervisedTuningDatasetDistributionDatasetBucketDict¶ 
    
Bases: `TypedDict`
Dataset bucket used to create a histogram for the distribution given a population of values. 

count _:`Optional`[`float`]_¶ 
    
Output only. Number of values in the bucket. 

left _:`Optional`[`float`]_¶ 
    
Output only. Left bound of the bucket. 

right _:`Optional`[`float`]_¶ 
    
Output only. Right bound of the bucket. 

_class_ genai.types.SupervisedTuningDatasetDistributionDict¶ 
    
Bases: `TypedDict`
Dataset distribution for Supervised Tuning. 

billable_sum _:`Optional`[`int`]_¶ 
    
Output only. Sum of a given population of values that are billable. 

buckets _:`Optional`[`list`[`SupervisedTuningDatasetDistributionDatasetBucketDict`]]_¶ 
    
Output only. Defines the histogram bucket. 

max _:`Optional`[`float`]_¶ 
    
Output only. The maximum of the population values. 

mean _:`Optional`[`float`]_¶ 
    
Output only. The arithmetic mean of the values in the population. 

median _:`Optional`[`float`]_¶ 
    
Output only. The median of the values in the population. 

min _:`Optional`[`float`]_¶ 
    
Output only. The minimum of the population values. 

p5 _:`Optional`[`float`]_¶ 
    
Output only. The 5th percentile of the values in the population. 

p95 _:`Optional`[`float`]_¶ 
    
Output only. The 95th percentile of the values in the population. 

sum _:`Optional`[`int`]_¶ 
    
Output only. Sum of a given population of values. 

_pydantic model_genai.types.SupervisedTuningSpec¶ 
    
Bases: `BaseModel`
Tuning Spec for Supervised Tuning for first party models.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"SupervisedTuningSpec",
"description":"Tuning Spec for Supervised Tuning for first party models.",
"type":"object",
"properties":{
"hyperParameters":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedHyperParameters"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Hyperparameters for SFT."
},
"trainingDatasetUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file.",
"title":"Trainingdataseturi"
},
"validationDatasetUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Cloud Storage path to file containing validation dataset for tuning. The dataset must be formatted as a JSONL file.",
"title":"Validationdataseturi"
},
"exportLastCheckpointOnly":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If set to true, disable intermediate checkpoints for SFT and only the last checkpoint will be exported.",
"title":"Exportlastcheckpointonly"
}
},
"$defs":{
"AdapterSize":{
"description":"Optional. Adapter size for tuning.",
"enum":[
"ADAPTER_SIZE_UNSPECIFIED",
"ADAPTER_SIZE_ONE",
"ADAPTER_SIZE_TWO",
"ADAPTER_SIZE_FOUR",
"ADAPTER_SIZE_EIGHT",
"ADAPTER_SIZE_SIXTEEN",
"ADAPTER_SIZE_THIRTY_TWO"
],
"title":"AdapterSize",
"type":"string"
},
"SupervisedHyperParameters":{
"additionalProperties":false,
"description":"Hyperparameters for SFT.",
"properties":{
"adapterSize":{
"anyOf":[
{
"$ref":"#/$defs/AdapterSize"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Adapter size for tuning."
},
"epochCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of complete passes the model makes over the entire training dataset during training.",
"title":"Epochcount"
},
"learningRateMultiplier":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Multiplier for adjusting the default learning rate.",
"title":"Learningratemultiplier"
}
},
"title":"SupervisedHyperParameters",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `export_last_checkpoint_only (bool | None)`
  * `hyper_parameters (genai.types.SupervisedHyperParameters | None)`
  * `training_dataset_uri (str | None)`
  * `validation_dataset_uri (str | None)`



_field_ export_last_checkpoint_only _:`Optional`[`bool`]__= None_ _(alias 'exportLastCheckpointOnly')_¶ 
    
Optional. If set to true, disable intermediate checkpoints for SFT and only the last checkpoint will be exported. 

_field_ hyper_parameters _:`Optional`[`SupervisedHyperParameters`]__= None_ _(alias 'hyperParameters')_¶ 
    
Optional. Hyperparameters for SFT. 

_field_ training_dataset_uri _:`Optional`[`str`]__= None_ _(alias 'trainingDatasetUri')_¶ 
    
Required. Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file. 

_field_ validation_dataset_uri _:`Optional`[`str`]__= None_ _(alias 'validationDatasetUri')_¶ 
    
Optional. Cloud Storage path to file containing validation dataset for tuning. The dataset must be formatted as a JSONL file. 

_class_ genai.types.SupervisedTuningSpecDict¶ 
    
Bases: `TypedDict`
Tuning Spec for Supervised Tuning for first party models. 

export_last_checkpoint_only _:`Optional`[`bool`]_¶ 
    
Optional. If set to true, disable intermediate checkpoints for SFT and only the last checkpoint will be exported. 

hyper_parameters _:`Optional`[`SupervisedHyperParametersDict`]_¶ 
    
Optional. Hyperparameters for SFT. 

training_dataset_uri _:`Optional`[`str`]_¶ 
    
Required. Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file. 

validation_dataset_uri _:`Optional`[`str`]_¶ 
    
Optional. Cloud Storage path to file containing validation dataset for tuning. The dataset must be formatted as a JSONL file. 

_pydantic model_genai.types.TestTableFile¶ 
    
Bases: `BaseModel`
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"TestTableFile",
"type":"object",
"properties":{
"comment":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Comment"
},
"testMethod":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Testmethod"
},
"parameterNames":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Parameternames"
},
"testTable":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/TestTableItem"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Testtable"
}
},
"$defs":{
"TestTableItem":{
"additionalProperties":false,
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The name of the test. This is used to derive the replay id.",
"title":"Name"
},
"parameters":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"The parameters to the test. Use pydantic models.",
"title":"Parameters"
},
"exceptionIfMldev":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Expects an exception for MLDev matching the string.",
"title":"Exceptionifmldev"
},
"exceptionIfVertex":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Expects an exception for Vertex matching the string.",
"title":"Exceptionifvertex"
},
"overrideReplayId":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Use if you don't want to use the default replay id which is derived from the test name.",
"title":"Overridereplayid"
},
"hasUnion":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"True if the parameters contain an unsupported union type. This test  will be skipped for languages that do not support the union type.",
"title":"Hasunion"
},
"skipInApiMode":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"When set to a reason string, this test will be skipped in the API mode. Use this flag for tests that can not be reproduced with the real API. E.g. a test that deletes a resource.",
"title":"Skipinapimode"
},
"ignoreKeys":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Keys to ignore when comparing the request and response. This is useful for tests that are not deterministic.",
"title":"Ignorekeys"
}
},
"title":"TestTableItem",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `comment (str | None)`
  * `parameter_names (list[str] | None)`
  * `test_method (str | None)`
  * `test_table (list[genai.types.TestTableItem] | None)`



_field_ comment _:`Optional`[`str`]__= None_¶ 


_field_ parameter_names _:`Optional`[`list`[`str`]]__= None_ _(alias 'parameterNames')_¶ 


_field_ test_method _:`Optional`[`str`]__= None_ _(alias 'testMethod')_¶ 


_field_ test_table _:`Optional`[`list`[`TestTableItem`]]__= None_ _(alias 'testTable')_¶ 


_class_ genai.types.TestTableFileDict¶ 
    
Bases: `TypedDict` 

comment _:`Optional`[`str`]_¶ 


parameter_names _:`Optional`[`list`[`str`]]_¶ 


test_method _:`Optional`[`str`]_¶ 


test_table _:`Optional`[`list`[`TestTableItemDict`]]_¶ 


_pydantic model_genai.types.TestTableItem¶ 
    
Bases: `BaseModel`
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"TestTableItem",
"type":"object",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The name of the test. This is used to derive the replay id.",
"title":"Name"
},
"parameters":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"The parameters to the test. Use pydantic models.",
"title":"Parameters"
},
"exceptionIfMldev":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Expects an exception for MLDev matching the string.",
"title":"Exceptionifmldev"
},
"exceptionIfVertex":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Expects an exception for Vertex matching the string.",
"title":"Exceptionifvertex"
},
"overrideReplayId":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Use if you don't want to use the default replay id which is derived from the test name.",
"title":"Overridereplayid"
},
"hasUnion":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"True if the parameters contain an unsupported union type. This test  will be skipped for languages that do not support the union type.",
"title":"Hasunion"
},
"skipInApiMode":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"When set to a reason string, this test will be skipped in the API mode. Use this flag for tests that can not be reproduced with the real API. E.g. a test that deletes a resource.",
"title":"Skipinapimode"
},
"ignoreKeys":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Keys to ignore when comparing the request and response. This is useful for tests that are not deterministic.",
"title":"Ignorekeys"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `exception_if_mldev (str | None)`
  * `exception_if_vertex (str | None)`
  * `has_union (bool | None)`
  * `ignore_keys (list[str] | None)`
  * `name (str | None)`
  * `override_replay_id (str | None)`
  * `parameters (dict[str, Any] | None)`
  * `skip_in_api_mode (str | None)`



_field_ exception_if_mldev _:`Optional`[`str`]__= None_ _(alias 'exceptionIfMldev')_¶ 
    
Expects an exception for MLDev matching the string. 

_field_ exception_if_vertex _:`Optional`[`str`]__= None_ _(alias 'exceptionIfVertex')_¶ 
    
Expects an exception for Vertex matching the string. 

_field_ has_union _:`Optional`[`bool`]__= None_ _(alias 'hasUnion')_¶ 
    
True if the parameters contain an unsupported union type. This test will be skipped for languages that do not support the union type. 

_field_ ignore_keys _:`Optional`[`list`[`str`]]__= None_ _(alias 'ignoreKeys')_¶ 
    
Keys to ignore when comparing the request and response. This is useful for tests that are not deterministic. 

_field_ name _:`Optional`[`str`]__= None_¶ 
    
The name of the test. This is used to derive the replay id. 

_field_ override_replay_id _:`Optional`[`str`]__= None_ _(alias 'overrideReplayId')_¶ 
    
Use if you don’t want to use the default replay id which is derived from the test name. 

_field_ parameters _:`Optional`[`dict`[`str`, `Any`]]__= None_¶ 
    
The parameters to the test. Use pydantic models. 

_field_ skip_in_api_mode _:`Optional`[`str`]__= None_ _(alias 'skipInApiMode')_¶ 
    
When set to a reason string, this test will be skipped in the API mode. Use this flag for tests that can not be reproduced with the real API. E.g. a test that deletes a resource. 

_class_ genai.types.TestTableItemDict¶ 
    
Bases: `TypedDict` 

exception_if_mldev _:`Optional`[`str`]_¶ 
    
Expects an exception for MLDev matching the string. 

exception_if_vertex _:`Optional`[`str`]_¶ 
    
Expects an exception for Vertex matching the string. 

has_union _:`Optional`[`bool`]_¶ 
    
True if the parameters contain an unsupported union type. This test will be skipped for languages that do not support the union type. 

ignore_keys _:`Optional`[`list`[`str`]]_¶ 
    
Keys to ignore when comparing the request and response. This is useful for tests that are not deterministic. 

name _:`Optional`[`str`]_¶ 
    
The name of the test. This is used to derive the replay id. 

override_replay_id _:`Optional`[`str`]_¶ 
    
Use if you don’t want to use the default replay id which is derived from the test name. 

parameters _:`Optional`[`dict`[`str`, `Any`]]_¶ 
    
The parameters to the test. Use pydantic models. 

skip_in_api_mode _:`Optional`[`str`]_¶ 
    
When set to a reason string, this test will be skipped in the API mode. Use this flag for tests that can not be reproduced with the real API. E.g. a test that deletes a resource. 

_pydantic model_genai.types.ThinkingConfig¶ 
    
Bases: `BaseModel`
The thinking features configuration.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ThinkingConfig",
"description":"The thinking features configuration.",
"type":"object",
"properties":{
"includeThoughts":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates whether to include thoughts in the response. If true, thoughts are returned only if the model supports thought and thoughts are available.\n      ",
"title":"Includethoughts"
},
"thinkingBudget":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates the thinking budget in tokens.\n      ",
"title":"Thinkingbudget"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `include_thoughts (bool | None)`
  * `thinking_budget (int | None)`



_field_ include_thoughts _:`Optional`[`bool`]__= None_ _(alias 'includeThoughts')_¶ 
    
Indicates whether to include thoughts in the response. If true, thoughts are returned only if the model supports thought and thoughts are available. 

_field_ thinking_budget _:`Optional`[`int`]__= None_ _(alias 'thinkingBudget')_¶ 
    
Indicates the thinking budget in tokens. 

_class_ genai.types.ThinkingConfigDict¶ 
    
Bases: `TypedDict`
The thinking features configuration. 

include_thoughts _:`Optional`[`bool`]_¶ 
    
Indicates whether to include thoughts in the response. If true, thoughts are returned only if the model supports thought and thoughts are available. 

thinking_budget _:`Optional`[`int`]_¶ 
    
Indicates the thinking budget in tokens. 

_pydantic model_genai.types.TokensInfo¶ 
    
Bases: `BaseModel`
Tokens info with a list of tokens and the corresponding list of token ids.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"TokensInfo",
"description":"Tokens info with a list of tokens and the corresponding list of token ids.",
"type":"object",
"properties":{
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Optional fields for the role from the corresponding Content.",
"title":"Role"
},
"tokenIds":{
"anyOf":[
{
"items":{
"type":"integer"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of token ids from the input.",
"title":"Tokenids"
},
"tokens":{
"anyOf":[
{
"items":{
"format":"base64url",
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of tokens from the input.",
"title":"Tokens"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `role (str | None)`
  * `token_ids (list[int] | None)`
  * `tokens (list[bytes] | None)`



_field_ role _:`Optional`[`str`]__= None_¶ 
    
Optional. Optional fields for the role from the corresponding Content. 

_field_ token_ids _:`Optional`[`list`[`int`]]__= None_ _(alias 'tokenIds')_¶ 
    
A list of token ids from the input. 

_field_ tokens _:`Optional`[`list`[`bytes`]]__= None_¶ 
    
A list of tokens from the input. 

_class_ genai.types.TokensInfoDict¶ 
    
Bases: `TypedDict`
Tokens info with a list of tokens and the corresponding list of token ids. 

role _:`Optional`[`str`]_¶ 
    
Optional. Optional fields for the role from the corresponding Content. 

token_ids _:`Optional`[`list`[`int`]]_¶ 
    
A list of token ids from the input. 

tokens _:`Optional`[`list`[`bytes`]]_¶ 
    
A list of tokens from the input. 

_pydantic model_genai.types.Tool¶ 
    
Bases: `BaseModel`
Tool details of a tool that the model may use to generate a response.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"Tool",
"description":"Tool details of a tool that the model may use to generate a response.",
"type":"object",
"properties":{
"retrieval":{
"anyOf":[
{
"$ref":"#/$defs/Retrieval"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Retrieval tool type. System will always execute the provided retrieval tool(s) to get external knowledge to answer the prompt. Retrieval results are presented to the model for generation."
},
"googleSearch":{
"anyOf":[
{
"$ref":"#/$defs/GoogleSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google Search tool type. Specialized retrieval tool\n      that is powered by Google Search."
},
"googleSearchRetrieval":{
"anyOf":[
{
"$ref":"#/$defs/GoogleSearchRetrieval"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. GoogleSearchRetrieval tool type. Specialized retrieval tool that is powered by Google search."
},
"enterpriseWebSearch":{
"anyOf":[
{
"$ref":"#/$defs/EnterpriseWebSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Enterprise web search tool type. Specialized retrieval\n      tool that is powered by Vertex AI Search and Sec4 compliance."
},
"googleMaps":{
"anyOf":[
{
"$ref":"#/$defs/GoogleMaps"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Google Maps tool type. Specialized retrieval tool\n      that is powered by Google Maps."
},
"codeExecution":{
"anyOf":[
{
"$ref":"#/$defs/ToolCodeExecution"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. CodeExecution tool type. Enables the model to execute code as part of generation. This field is only used by the Gemini Developer API services."
},
"functionDeclarations":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/FunctionDeclaration"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Function tool type. One or more function declarations to be passed to the model along with the current user query. Model may decide to call a subset of these functions by populating FunctionCall in the response. User should provide a FunctionResponse for each function call in the next turn. Based on the function responses, Model will generate the final response back to the user. Maximum 128 function declarations can be provided.",
"title":"Functiondeclarations"
}
},
"$defs":{
"ApiKeyConfig":{
"additionalProperties":false,
"description":"Config for authentication with API key.",
"properties":{
"apiKeyString":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The API key to be used in the request directly.",
"title":"Apikeystring"
}
},
"title":"ApiKeyConfig",
"type":"object"
},
"AuthConfig":{
"additionalProperties":false,
"description":"Auth configuration to run the extension.",
"properties":{
"apiKeyConfig":{
"anyOf":[
{
"$ref":"#/$defs/ApiKeyConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for API key auth."
},
"authType":{
"anyOf":[
{
"$ref":"#/$defs/AuthType"
},
{
"type":"null"
}
],
"default":null,
"description":"Type of auth scheme."
},
"googleServiceAccountConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigGoogleServiceAccountConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for Google Service Account auth."
},
"httpBasicAuthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigHttpBasicAuthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for HTTP Basic auth."
},
"oauthConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOauthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user oauth."
},
"oidcConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfigOidcConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Config for user OIDC auth."
}
},
"title":"AuthConfig",
"type":"object"
},
"AuthConfigGoogleServiceAccountConfig":{
"additionalProperties":false,
"description":"Config for Google Service Account Authentication.",
"properties":{
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The service account that the extension execution service runs as. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified service account. - If not specified, the Vertex AI Extension Service Agent will be used to execute the Extension.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigGoogleServiceAccountConfig",
"type":"object"
},
"AuthConfigHttpBasicAuthConfig":{
"additionalProperties":false,
"description":"Config for HTTP Basic Authentication.",
"properties":{
"credentialSecret":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the SecretManager secret version resource storing the base64 encoded credentials. Format: `projects/{project}/secrets/{secrete}/versions/{version}` - If specified, the `secretmanager.versions.access` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified resource.",
"title":"Credentialsecret"
}
},
"title":"AuthConfigHttpBasicAuthConfig",
"type":"object"
},
"AuthConfigOauthConfig":{
"additionalProperties":false,
"description":"Config for user oauth.",
"properties":{
"accessToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Access token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Accesstoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate access tokens for executing the Extension. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the provided service account.",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOauthConfig",
"type":"object"
},
"AuthConfigOidcConfig":{
"additionalProperties":false,
"description":"Config for user OIDC auth.",
"properties":{
"idToken":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"OpenID Connect formatted ID token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.",
"title":"Idtoken"
},
"serviceAccount":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The service account used to generate an OpenID Connect (OIDC)-compatible JWT token signed by the Google OIDC Provider (accounts.google.com) for extension endpoint (https://cloud.google.com/iam/docs/create-short-lived-credentials-direct#sa-credentials-oidc). - The audience for the token will be set to the URL in the server url defined in the OpenApi spec. - If the service account is provided, the service account should grant `iam.serviceAccounts.getOpenIdToken` permission to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).",
"title":"Serviceaccount"
}
},
"title":"AuthConfigOidcConfig",
"type":"object"
},
"AuthType":{
"description":"Type of auth scheme.",
"enum":[
"AUTH_TYPE_UNSPECIFIED",
"NO_AUTH",
"API_KEY_AUTH",
"HTTP_BASIC_AUTH",
"GOOGLE_SERVICE_ACCOUNT_AUTH",
"OAUTH",
"OIDC_AUTH"
],
"title":"AuthType",
"type":"string"
},
"DynamicRetrievalConfig":{
"additionalProperties":false,
"description":"Describes the options to customize dynamic retrieval.",
"properties":{
"mode":{
"anyOf":[
{
"$ref":"#/$defs/DynamicRetrievalConfigMode"
},
{
"type":"null"
}
],
"default":null,
"description":"The mode of the predictor to be used in dynamic retrieval."
},
"dynamicThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The threshold to be used in dynamic retrieval. If not set, a system default value is used.",
"title":"Dynamicthreshold"
}
},
"title":"DynamicRetrievalConfig",
"type":"object"
},
"DynamicRetrievalConfigMode":{
"description":"Config for the dynamic retrieval config mode.",
"enum":[
"MODE_UNSPECIFIED",
"MODE_DYNAMIC"
],
"title":"DynamicRetrievalConfigMode",
"type":"string"
},
"EnterpriseWebSearch":{
"additionalProperties":false,
"description":"Tool to search public web data, powered by Vertex AI Search and Sec4 compliance.",
"properties":{},
"title":"EnterpriseWebSearch",
"type":"object"
},
"FunctionDeclaration":{
"additionalProperties":false,
"description":"Structured representation of a function declaration as defined by the [OpenAPI 3.0 specification](https://spec.openapis.org/oas/v3.0.3).\n\nIncluded in this declaration are the function name, description, parameters\nand response type. This FunctionDeclaration is a representation of a block of\ncode that can be used as a `Tool` by the model and executed by the client.",
"properties":{
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Description and purpose of the function. Model uses it to decide how and whether to call the function.",
"title":"Description"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Must start with a letter or an underscore. Must be a-z, A-Z, 0-9, or contain underscores, dots and dashes, with a maximum length of 64.",
"title":"Name"
},
"parameters":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Describes the parameters to this function in JSON Schema Object format. Reflects the Open API 3.03 Parameter Object. string Key: the name of the parameter. Parameter names are case sensitive. Schema Value: the Schema defining the type used for the parameter. For function with no parameters, this can be left unset. Parameter names must start with a letter or an underscore and must only contain chars a-z, A-Z, 0-9, or underscores with a maximum length of 64. Example with 1 required and 1 optional parameter: type: OBJECT properties: param1: type: STRING param2: type: INTEGER required: - param1"
},
"response":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Describes the output from this function in JSON Schema format. Reflects the Open API 3.03 Response Object. The Schema defines the type used for the response value of the function."
}
},
"title":"FunctionDeclaration",
"type":"object"
},
"GoogleMaps":{
"additionalProperties":false,
"description":"Tool to support Google Maps in Model.",
"properties":{
"authConfig":{
"anyOf":[
{
"$ref":"#/$defs/AuthConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Auth config for the Google Maps tool."
}
},
"title":"GoogleMaps",
"type":"object"
},
"GoogleSearch":{
"additionalProperties":false,
"description":"Tool to support Google Search in Model. Powered by Google.",
"properties":{},
"title":"GoogleSearch",
"type":"object"
},
"GoogleSearchRetrieval":{
"additionalProperties":false,
"description":"Tool to retrieve public web data for grounding, powered by Google.",
"properties":{
"dynamicRetrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/DynamicRetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the dynamic retrieval configuration for the given source."
}
},
"title":"GoogleSearchRetrieval",
"type":"object"
},
"RagRetrievalConfig":{
"additionalProperties":false,
"description":"Specifies the context retrieval config.",
"properties":{
"filter":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigFilter"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for filters."
},
"hybridSearch":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigHybridSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Hybrid Search."
},
"ranking":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRanking"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for ranking and reranking."
},
"topK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The number of contexts to retrieve.",
"title":"Topk"
}
},
"title":"RagRetrievalConfig",
"type":"object"
},
"RagRetrievalConfigFilter":{
"additionalProperties":false,
"description":"Config for filters.",
"properties":{
"metadataFilter":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. String for metadata filtering.",
"title":"Metadatafilter"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
},
"vectorSimilarityThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector similarity larger than the threshold.",
"title":"Vectorsimilaritythreshold"
}
},
"title":"RagRetrievalConfigFilter",
"type":"object"
},
"RagRetrievalConfigHybridSearch":{
"additionalProperties":false,
"description":"Config for Hybrid Search.",
"properties":{
"alpha":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally.",
"title":"Alpha"
}
},
"title":"RagRetrievalConfigHybridSearch",
"type":"object"
},
"RagRetrievalConfigRanking":{
"additionalProperties":false,
"description":"Config for ranking and reranking.",
"properties":{
"llmRanker":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingLlmRanker"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for LlmRanker."
},
"rankService":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingRankService"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Rank Service."
}
},
"title":"RagRetrievalConfigRanking",
"type":"object"
},
"RagRetrievalConfigRankingLlmRanker":{
"additionalProperties":false,
"description":"Config for LlmRanker.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name used for ranking. Format: `gemini-1.5-pro`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingLlmRanker",
"type":"object"
},
"RagRetrievalConfigRankingRankService":{
"additionalProperties":false,
"description":"Config for Rank Service.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name of the rank service. Format: `semantic-ranker-512@latest`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingRankService",
"type":"object"
},
"Retrieval":{
"additionalProperties":false,
"description":"Defines a retrieval tool that model can call to access external knowledge.",
"properties":{
"disableAttribution":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Deprecated. This option is no longer supported.",
"title":"Disableattribution"
},
"vertexAiSearch":{
"anyOf":[
{
"$ref":"#/$defs/VertexAISearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Set to use data source powered by Vertex AI Search."
},
"vertexRagStore":{
"anyOf":[
{
"$ref":"#/$defs/VertexRagStore"
},
{
"type":"null"
}
],
"default":null,
"description":"Set to use data source powered by Vertex RAG store. User data is uploaded via the VertexRagDataService."
}
},
"title":"Retrieval",
"type":"object"
},
"Schema":{
"additionalProperties":false,
"description":"Schema is used to define the format of input/output data.\n\nRepresents a select subset of an [OpenAPI 3.0 schema\nobject](https://spec.openapis.org/oas/v3.0.3#schema-object). More fields may\nbe added in the future as needed.",
"properties":{
"anyOf":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Schema"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The value should be validated against any (one or more) of the subschemas in the list.",
"title":"Anyof"
},
"default":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Default value of the data.",
"title":"Default"
},
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The description of the data.",
"title":"Description"
},
"enum":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Possible values of the element of primitive type with enum format. Examples: 1. We can define direction as : {type:STRING, format:enum, enum:[\"EAST\", NORTH\", \"SOUTH\", \"WEST\"]} 2. We can define apartment number as : {type:INTEGER, format:enum, enum:[\"101\", \"201\", \"301\"]}",
"title":"Enum"
},
"example":{
"anyOf":[
{},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Example of the object. Will only populated when the object is the root.",
"title":"Example"
},
"format":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The format of the data. Supported formats: for NUMBER type: \"float\", \"double\" for INTEGER type: \"int32\", \"int64\" for STRING type: \"email\", \"byte\", etc",
"title":"Format"
},
"items":{
"anyOf":[
{
"$ref":"#/$defs/Schema"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE ARRAY Schema of the elements of Type.ARRAY."
},
"maxItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the elements for Type.ARRAY.",
"title":"Maxitems"
},
"maxLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum length of the Type.STRING",
"title":"Maxlength"
},
"maxProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum number of the properties for Type.OBJECT.",
"title":"Maxproperties"
},
"maximum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Maximum value of the Type.INTEGER and Type.NUMBER",
"title":"Maximum"
},
"minItems":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the elements for Type.ARRAY.",
"title":"Minitems"
},
"minLength":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING",
"title":"Minlength"
},
"minProperties":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Minimum number of the properties for Type.OBJECT.",
"title":"Minproperties"
},
"minimum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER Minimum value of the Type.INTEGER and Type.NUMBER",
"title":"Minimum"
},
"nullable":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Indicates if the value may be null.",
"title":"Nullable"
},
"pattern":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Pattern of the Type.STRING to restrict a string to a regular expression.",
"title":"Pattern"
},
"properties":{
"anyOf":[
{
"additionalProperties":{
"$ref":"#/$defs/Schema"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. SCHEMA FIELDS FOR TYPE OBJECT Properties of Type.OBJECT.",
"title":"Properties"
},
"propertyOrdering":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The order of the properties. Not a standard field in open api spec. Only used to support the order of the properties.",
"title":"Propertyordering"
},
"required":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required properties of Type.OBJECT.",
"title":"Required"
},
"title":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The title of the Schema.",
"title":"Title"
},
"type":{
"anyOf":[
{
"$ref":"#/$defs/Type"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The type of the data."
}
},
"title":"Schema",
"type":"object"
},
"ToolCodeExecution":{
"additionalProperties":false,
"description":"Tool that executes code generated by the model, and automatically returns the result to the model.\n\nSee also [ExecutableCode]and [CodeExecutionResult] which are input and output\nto this tool.",
"properties":{},
"title":"ToolCodeExecution",
"type":"object"
},
"Type":{
"description":"Optional. The type of the data.",
"enum":[
"TYPE_UNSPECIFIED",
"STRING",
"NUMBER",
"INTEGER",
"BOOLEAN",
"ARRAY",
"OBJECT"
],
"title":"Type",
"type":"string"
},
"VertexAISearch":{
"additionalProperties":false,
"description":"Retrieve from Vertex AI Search datastore or engine for grounding.\n\ndatastore and engine are mutually exclusive. See\nhttps://cloud.google.com/products/agent-builder",
"properties":{
"datastore":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search data store resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`",
"title":"Datastore"
},
"engine":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search engine resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}`",
"title":"Engine"
}
},
"title":"VertexAISearch",
"type":"object"
},
"VertexRagStore":{
"additionalProperties":false,
"description":"Retrieve from Vertex RAG Store for grounding.",
"properties":{
"ragCorpora":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Deprecated. Please use rag_resources instead.",
"title":"Ragcorpora"
},
"ragResources":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/VertexRagStoreRagResource"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The representation of the rag source. It can be used to specify corpus only or ragfiles. Currently only support one corpus or multiple files from one corpus. In the future we may open up multiple corpora support.",
"title":"Ragresources"
},
"ragRetrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The retrieval config for the Rag query."
},
"similarityTopK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of top k results to return from the selected corpora.",
"title":"Similaritytopk"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only return results with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
}
},
"title":"VertexRagStore",
"type":"object"
},
"VertexRagStoreRagResource":{
"additionalProperties":false,
"description":"The definition of the Rag resource.",
"properties":{
"ragCorpus":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. RagCorpora resource name. Format: `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`",
"title":"Ragcorpus"
},
"ragFileIds":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus field.",
"title":"Ragfileids"
}
},
"title":"VertexRagStoreRagResource",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `code_execution (genai.types.ToolCodeExecution | None)`
  * `enterprise_web_search (genai.types.EnterpriseWebSearch | None)`
  * `function_declarations (list[genai.types.FunctionDeclaration] | None)`
  * `google_maps (genai.types.GoogleMaps | None)`
  * `google_search (genai.types.GoogleSearch | None)`
  * `google_search_retrieval (genai.types.GoogleSearchRetrieval | None)`
  * `retrieval (genai.types.Retrieval | None)`



_field_ code_execution _:`Optional`[`ToolCodeExecution`]__= None_ _(alias 'codeExecution')_¶ 
    
Optional. CodeExecution tool type. Enables the model to execute code as part of generation. This field is only used by the Gemini Developer API services. 

_field_ enterprise_web_search _:`Optional`[`EnterpriseWebSearch`]__= None_ _(alias 'enterpriseWebSearch')_¶ 
    
Optional. Enterprise web search tool type. Specialized retrieval tool that is powered by Vertex AI Search and Sec4 compliance. 

_field_ function_declarations _:`Optional`[`list`[`FunctionDeclaration`]]__= None_ _(alias 'functionDeclarations')_¶ 
    
Optional. Function tool type. One or more function declarations to be passed to the model along with the current user query. Model may decide to call a subset of these functions by populating FunctionCall in the response. User should provide a FunctionResponse for each function call in the next turn. Based on the function responses, Model will generate the final response back to the user. Maximum 128 function declarations can be provided. 

_field_ google_maps _:`Optional`[`GoogleMaps`]__= None_ _(alias 'googleMaps')_¶ 
    
Optional. Google Maps tool type. Specialized retrieval tool that is powered by Google Maps. 

_field_ google_search _:`Optional`[`GoogleSearch`]__= None_ _(alias 'googleSearch')_¶ 
    
Optional. Google Search tool type. Specialized retrieval tool that is powered by Google Search. 

_field_ google_search_retrieval _:`Optional`[`GoogleSearchRetrieval`]__= None_ _(alias 'googleSearchRetrieval')_¶ 
    
Optional. GoogleSearchRetrieval tool type. Specialized retrieval tool that is powered by Google search. 

_field_ retrieval _:`Optional`[`Retrieval`]__= None_¶ 
    
Optional. Retrieval tool type. System will always execute the provided retrieval tool(s) to get external knowledge to answer the prompt. Retrieval results are presented to the model for generation. 

_pydantic model_genai.types.ToolCodeExecution¶ 
    
Bases: `BaseModel`
Tool that executes code generated by the model, and automatically returns the result to the model.
See also [ExecutableCode]and [CodeExecutionResult] which are input and output to this tool.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ToolCodeExecution",
"description":"Tool that executes code generated by the model, and automatically returns the result to the model.\n\nSee also [ExecutableCode]and [CodeExecutionResult] which are input and output\nto this tool.",
"type":"object",
"properties":{},
"additionalProperties":false
}

```


_class_ genai.types.ToolCodeExecutionDict¶ 
    
Bases: `TypedDict`
Tool that executes code generated by the model, and automatically returns the result to the model.
See also [ExecutableCode]and [CodeExecutionResult] which are input and output to this tool. 

_pydantic model_genai.types.ToolConfig¶ 
    
Bases: `BaseModel`
Tool config.
This config is shared for all tools provided in the request.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"ToolConfig",
"description":"Tool config.\n\nThis config is shared for all tools provided in the request.",
"type":"object",
"properties":{
"functionCallingConfig":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCallingConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Function calling config."
},
"retrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/RetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Retrieval config."
}
},
"$defs":{
"FunctionCallingConfig":{
"additionalProperties":false,
"description":"Function calling config.",
"properties":{
"mode":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCallingConfigMode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Function calling mode."
},
"allowedFunctionNames":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Function names to call. Only set when the Mode is ANY. Function names should match [FunctionDeclaration.name]. With mode set to ANY, model will predict a function call from the set of function names provided.",
"title":"Allowedfunctionnames"
}
},
"title":"FunctionCallingConfig",
"type":"object"
},
"FunctionCallingConfigMode":{
"description":"Config for the function calling config mode.",
"enum":[
"MODE_UNSPECIFIED",
"AUTO",
"ANY",
"NONE"
],
"title":"FunctionCallingConfigMode",
"type":"string"
},
"LatLng":{
"additionalProperties":false,
"description":"An object that represents a latitude/longitude pair.\n\nThis is expressed as a pair of doubles to represent degrees latitude and\ndegrees longitude. Unless specified otherwise, this object must conform to the\n<a href=\"https://en.wikipedia.org/wiki/World_Geodetic_System#1984_version\">\nWGS84 standard</a>. Values must be within normalized ranges.",
"properties":{
"latitude":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"The latitude in degrees. It must be in the range [-90.0, +90.0].",
"title":"Latitude"
},
"longitude":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"The longitude in degrees. It must be in the range [-180.0, +180.0]",
"title":"Longitude"
}
},
"title":"LatLng",
"type":"object"
},
"RetrievalConfig":{
"additionalProperties":false,
"description":"Retrieval config.",
"properties":{
"latLng":{
"anyOf":[
{
"$ref":"#/$defs/LatLng"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The location of the user."
}
},
"title":"RetrievalConfig",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `function_calling_config (genai.types.FunctionCallingConfig | None)`
  * `retrieval_config (genai.types.RetrievalConfig | None)`



_field_ function_calling_config _:`Optional`[`FunctionCallingConfig`]__= None_ _(alias 'functionCallingConfig')_¶ 
    
Optional. Function calling config. 

_field_ retrieval_config _:`Optional`[`RetrievalConfig`]__= None_ _(alias 'retrievalConfig')_¶ 
    
Optional. Retrieval config. 

_class_ genai.types.ToolConfigDict¶ 
    
Bases: `TypedDict`
Tool config.
This config is shared for all tools provided in the request. 

function_calling_config _:`Optional`[`FunctionCallingConfigDict`]_¶ 
    
Optional. Function calling config. 

retrieval_config _:`Optional`[`RetrievalConfigDict`]_¶ 
    
Optional. Retrieval config. 

_class_ genai.types.ToolDict¶ 
    
Bases: `TypedDict`
Tool details of a tool that the model may use to generate a response. 

code_execution _:`Optional`[`ToolCodeExecutionDict`]_¶ 
    
Optional. CodeExecution tool type. Enables the model to execute code as part of generation. This field is only used by the Gemini Developer API services. 

enterprise_web_search _:`Optional`[`EnterpriseWebSearchDict`]_¶ 
    
Optional. Enterprise web search tool type. Specialized retrieval tool that is powered by Vertex AI Search and Sec4 compliance. 

function_declarations _:`Optional`[`list`[`FunctionDeclarationDict`]]_¶ 
    
Optional. Function tool type. One or more function declarations to be passed to the model along with the current user query. Model may decide to call a subset of these functions by populating FunctionCall in the response. User should provide a FunctionResponse for each function call in the next turn. Based on the function responses, Model will generate the final response back to the user. Maximum 128 function declarations can be provided. 

google_maps _:`Optional`[`GoogleMapsDict`]_¶ 
    
Optional. Google Maps tool type. Specialized retrieval tool that is powered by Google Maps. 

google_search _:`Optional`[`GoogleSearchDict`]_¶ 
    
Optional. Google Search tool type. Specialized retrieval tool that is powered by Google Search. 

google_search_retrieval _:`Optional`[`GoogleSearchRetrievalDict`]_¶ 
    
Optional. GoogleSearchRetrieval tool type. Specialized retrieval tool that is powered by Google search. 

retrieval _:`Optional`[`RetrievalDict`]_¶ 
    
Optional. Retrieval tool type. System will always execute the provided retrieval tool(s) to get external knowledge to answer the prompt. Retrieval results are presented to the model for generation. 

_class_ genai.types.TrafficType(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Output only.
Traffic type. This shows whether a request consumes Pay-As-You-Go or Provisioned Throughput quota. 

ON_DEMAND _= 'ON_DEMAND'_¶ 


PROVISIONED_THROUGHPUT _= 'PROVISIONED_THROUGHPUT'_¶ 


TRAFFIC_TYPE_UNSPECIFIED _= 'TRAFFIC_TYPE_UNSPECIFIED'_¶ 


_pydantic model_genai.types.Transcription¶ 
    
Bases: `BaseModel`
Audio transcription in Server Conent.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"Transcription",
"description":"Audio transcription in Server Conent.",
"type":"object",
"properties":{
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Transcription text.\n      ",
"title":"Text"
},
"finished":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"The bool indicates the end of the transcription.\n      ",
"title":"Finished"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `finished (bool | None)`
  * `text (str | None)`



_field_ finished _:`Optional`[`bool`]__= None_¶ 
    
The bool indicates the end of the transcription. 

_field_ text _:`Optional`[`str`]__= None_¶ 
    
Transcription text. 

_class_ genai.types.TranscriptionDict¶ 
    
Bases: `TypedDict`
Audio transcription in Server Conent. 

finished _:`Optional`[`bool`]_¶ 
    
The bool indicates the end of the transcription. 

text _:`Optional`[`str`]_¶ 
    
Transcription text. 

_pydantic model_genai.types.TunedModel¶ 
    
Bases: `BaseModel`
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"TunedModel",
"type":"object",
"properties":{
"model":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The resource name of the TunedModel. Format: `projects/{project}/locations/{location}/models/{model}`.",
"title":"Model"
},
"endpoint":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. A resource name of an Endpoint. Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`.",
"title":"Endpoint"
},
"checkpoints":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/TunedModelCheckpoint"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The checkpoints associated with this TunedModel.\n      This field is only populated for tuning jobs that enable intermediate\n      checkpoints.",
"title":"Checkpoints"
}
},
"$defs":{
"TunedModelCheckpoint":{
"additionalProperties":false,
"description":"TunedModelCheckpoint for the Tuned Model of a Tuning Job.",
"properties":{
"checkpointId":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The ID of the checkpoint.\n      ",
"title":"Checkpointid"
},
"epoch":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The epoch of the checkpoint.\n      ",
"title":"Epoch"
},
"step":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The step of the checkpoint.\n      ",
"title":"Step"
},
"endpoint":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The Endpoint resource name that the checkpoint is deployed to.\n      Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`.\n      ",
"title":"Endpoint"
}
},
"title":"TunedModelCheckpoint",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `checkpoints (list[genai.types.TunedModelCheckpoint] | None)`
  * `endpoint (str | None)`
  * `model (str | None)`



_field_ checkpoints _:`Optional`[`list`[`TunedModelCheckpoint`]]__= None_¶ 
    
The checkpoints associated with this TunedModel. This field is only populated for tuning jobs that enable intermediate checkpoints. 

_field_ endpoint _:`Optional`[`str`]__= None_¶ 
    
Output only. A resource name of an Endpoint. Format: projects/{project}/locations/{location}/endpoints/{endpoint}. 

_field_ model _:`Optional`[`str`]__= None_¶ 
    
Output only. The resource name of the TunedModel. Format: projects/{project}/locations/{location}/models/{model}. 

_pydantic model_genai.types.TunedModelCheckpoint¶ 
    
Bases: `BaseModel`
TunedModelCheckpoint for the Tuned Model of a Tuning Job.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"TunedModelCheckpoint",
"description":"TunedModelCheckpoint for the Tuned Model of a Tuning Job.",
"type":"object",
"properties":{
"checkpointId":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The ID of the checkpoint.\n      ",
"title":"Checkpointid"
},
"epoch":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The epoch of the checkpoint.\n      ",
"title":"Epoch"
},
"step":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The step of the checkpoint.\n      ",
"title":"Step"
},
"endpoint":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The Endpoint resource name that the checkpoint is deployed to.\n      Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`.\n      ",
"title":"Endpoint"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `checkpoint_id (str | None)`
  * `endpoint (str | None)`
  * `epoch (int | None)`
  * `step (int | None)`



_field_ checkpoint_id _:`Optional`[`str`]__= None_ _(alias 'checkpointId')_¶ 
    
The ID of the checkpoint. 

_field_ endpoint _:`Optional`[`str`]__= None_¶ 
    
The Endpoint resource name that the checkpoint is deployed to. Format: projects/{project}/locations/{location}/endpoints/{endpoint}. 

_field_ epoch _:`Optional`[`int`]__= None_¶ 
    
The epoch of the checkpoint. 

_field_ step _:`Optional`[`int`]__= None_¶ 
    
The step of the checkpoint. 

_class_ genai.types.TunedModelCheckpointDict¶ 
    
Bases: `TypedDict`
TunedModelCheckpoint for the Tuned Model of a Tuning Job. 

checkpoint_id _:`Optional`[`str`]_¶ 
    
The ID of the checkpoint. 

endpoint _:`Optional`[`str`]_¶ 
    
The Endpoint resource name that the checkpoint is deployed to. Format: projects/{project}/locations/{location}/endpoints/{endpoint}. 

epoch _:`Optional`[`int`]_¶ 
    
The epoch of the checkpoint. 

step _:`Optional`[`int`]_¶ 
    
The step of the checkpoint. 

_class_ genai.types.TunedModelDict¶ 
    
Bases: `TypedDict` 

checkpoints _:`Optional`[`list`[`TunedModelCheckpointDict`]]_¶ 
    
The checkpoints associated with this TunedModel. This field is only populated for tuning jobs that enable intermediate checkpoints. 

endpoint _:`Optional`[`str`]_¶ 
    
projects/{project}/locations/{location}/endpoints/{endpoint}. 

Type: 
    
Output only. A resource name of an Endpoint. Format 

model _:`Optional`[`str`]_¶ 
    
projects/{project}/locations/{location}/models/{model}. 

Type: 
    
Output only. The resource name of the TunedModel. Format 

_pydantic model_genai.types.TunedModelInfo¶ 
    
Bases: `BaseModel`
A tuned machine learning model.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"TunedModelInfo",
"description":"A tuned machine learning model.",
"type":"object",
"properties":{
"baseModel":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"ID of the base model that you want to tune.",
"title":"Basemodel"
},
"createTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Date and time when the base model was created.",
"title":"Createtime"
},
"updateTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Date and time when the base model was last updated.",
"title":"Updatetime"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `base_model (str | None)`
  * `create_time (datetime.datetime | None)`
  * `update_time (datetime.datetime | None)`



_field_ base_model _:`Optional`[`str`]__= None_ _(alias 'baseModel')_¶ 
    
ID of the base model that you want to tune. 

_field_ create_time _:`Optional`[`datetime`]__= None_ _(alias 'createTime')_¶ 
    
Date and time when the base model was created. 

_field_ update_time _:`Optional`[`datetime`]__= None_ _(alias 'updateTime')_¶ 
    
Date and time when the base model was last updated. 

_class_ genai.types.TunedModelInfoDict¶ 
    
Bases: `TypedDict`
A tuned machine learning model. 

base_model _:`Optional`[`str`]_¶ 
    
ID of the base model that you want to tune. 

create_time _:`Optional`[`datetime`]_¶ 
    
Date and time when the base model was created. 

update_time _:`Optional`[`datetime`]_¶ 
    
Date and time when the base model was last updated. 

_pydantic model_genai.types.TuningDataStats¶ 
    
Bases: `BaseModel`
The tuning data statistic values for TuningJob.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"TuningDataStats",
"description":"The tuning data statistic values for TuningJob.",
"type":"object",
"properties":{
"distillationDataStats":{
"anyOf":[
{
"$ref":"#/$defs/DistillationDataStats"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Statistics for distillation."
},
"supervisedTuningDataStats":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedTuningDataStats"
},
{
"type":"null"
}
],
"default":null,
"description":"The SFT Tuning data stats."
}
},
"$defs":{
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"Content":{
"additionalProperties":false,
"description":"Contains the multi-part content of a message.",
"properties":{
"parts":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Part"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of parts that constitute a single message. Each part may have\n      a different IANA MIME type.",
"title":"Parts"
},
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role.",
"title":"Role"
}
},
"title":"Content",
"type":"object"
},
"DatasetDistribution":{
"additionalProperties":false,
"description":"Distribution computed over a tuning dataset.",
"properties":{
"buckets":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/DatasetDistributionDistributionBucket"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Defines the histogram bucket.",
"title":"Buckets"
},
"max":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The maximum of the population values.",
"title":"Max"
},
"mean":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The arithmetic mean of the values in the population.",
"title":"Mean"
},
"median":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The median of the values in the population.",
"title":"Median"
},
"min":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The minimum of the population values.",
"title":"Min"
},
"p5":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 5th percentile of the values in the population.",
"title":"P5"
},
"p95":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 95th percentile of the values in the population.",
"title":"P95"
},
"sum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sum of a given population of values.",
"title":"Sum"
}
},
"title":"DatasetDistribution",
"type":"object"
},
"DatasetDistributionDistributionBucket":{
"additionalProperties":false,
"description":"Dataset bucket used to create a histogram for the distribution given a population of values.",
"properties":{
"count":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of values in the bucket.",
"title":"Count"
},
"left":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Left bound of the bucket.",
"title":"Left"
},
"right":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Right bound of the bucket.",
"title":"Right"
}
},
"title":"DatasetDistributionDistributionBucket",
"type":"object"
},
"DatasetStats":{
"additionalProperties":false,
"description":"Statistics computed over a tuning dataset.",
"properties":{
"totalBillableCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of billable characters in the tuning dataset.",
"title":"Totalbillablecharactercount"
},
"totalTuningCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tuning characters in the tuning dataset.",
"title":"Totaltuningcharactercount"
},
"tuningDatasetExampleCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of examples in the tuning dataset.",
"title":"Tuningdatasetexamplecount"
},
"tuningStepCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tuning steps for this Tuning Job.",
"title":"Tuningstepcount"
},
"userDatasetExamples":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Content"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sample user messages in the training dataset uri.",
"title":"Userdatasetexamples"
},
"userInputTokenDistribution":{
"anyOf":[
{
"$ref":"#/$defs/DatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the user input tokens."
},
"userMessagePerExampleDistribution":{
"anyOf":[
{
"$ref":"#/$defs/DatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the messages per example."
},
"userOutputTokenDistribution":{
"anyOf":[
{
"$ref":"#/$defs/DatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the user output tokens."
}
},
"title":"DatasetStats",
"type":"object"
},
"DistillationDataStats":{
"additionalProperties":false,
"description":"Statistics computed for datasets used for distillation.",
"properties":{
"trainingDatasetStats":{
"anyOf":[
{
"$ref":"#/$defs/DatasetStats"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Statistics computed for the training dataset."
}
},
"title":"DistillationDataStats",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"SupervisedTuningDataStats":{
"additionalProperties":false,
"description":"Tuning data statistics for Supervised Tuning.",
"properties":{
"totalBillableCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of billable characters in the tuning dataset.",
"title":"Totalbillablecharactercount"
},
"totalBillableTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of billable tokens in the tuning dataset.",
"title":"Totalbillabletokencount"
},
"totalTruncatedExampleCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The number of examples in the dataset that have been truncated by any amount.",
"title":"Totaltruncatedexamplecount"
},
"totalTuningCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tuning characters in the tuning dataset.",
"title":"Totaltuningcharactercount"
},
"truncatedExampleIndices":{
"anyOf":[
{
"items":{
"type":"integer"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A partial sample of the indices (starting from 1) of the truncated examples.",
"title":"Truncatedexampleindices"
},
"tuningDatasetExampleCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of examples in the tuning dataset.",
"title":"Tuningdatasetexamplecount"
},
"tuningStepCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tuning steps for this Tuning Job.",
"title":"Tuningstepcount"
},
"userDatasetExamples":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Content"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sample user messages in the training dataset uri.",
"title":"Userdatasetexamples"
},
"userInputTokenDistribution":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedTuningDatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the user input tokens."
},
"userMessagePerExampleDistribution":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedTuningDatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the messages per example."
},
"userOutputTokenDistribution":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedTuningDatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the user output tokens."
}
},
"title":"SupervisedTuningDataStats",
"type":"object"
},
"SupervisedTuningDatasetDistribution":{
"additionalProperties":false,
"description":"Dataset distribution for Supervised Tuning.",
"properties":{
"billableSum":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sum of a given population of values that are billable.",
"title":"Billablesum"
},
"buckets":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/SupervisedTuningDatasetDistributionDatasetBucket"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Defines the histogram bucket.",
"title":"Buckets"
},
"max":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The maximum of the population values.",
"title":"Max"
},
"mean":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The arithmetic mean of the values in the population.",
"title":"Mean"
},
"median":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The median of the values in the population.",
"title":"Median"
},
"min":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The minimum of the population values.",
"title":"Min"
},
"p5":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 5th percentile of the values in the population.",
"title":"P5"
},
"p95":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 95th percentile of the values in the population.",
"title":"P95"
},
"sum":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sum of a given population of values.",
"title":"Sum"
}
},
"title":"SupervisedTuningDatasetDistribution",
"type":"object"
},
"SupervisedTuningDatasetDistributionDatasetBucket":{
"additionalProperties":false,
"description":"Dataset bucket used to create a histogram for the distribution given a population of values.",
"properties":{
"count":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of values in the bucket.",
"title":"Count"
},
"left":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Left bound of the bucket.",
"title":"Left"
},
"right":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Right bound of the bucket.",
"title":"Right"
}
},
"title":"SupervisedTuningDatasetDistributionDatasetBucket",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `distillation_data_stats (genai.types.DistillationDataStats | None)`
  * `supervised_tuning_data_stats (genai.types.SupervisedTuningDataStats | None)`



_field_ distillation_data_stats _:`Optional`[`DistillationDataStats`]__= None_ _(alias 'distillationDataStats')_¶ 
    
Output only. Statistics for distillation. 

_field_ supervised_tuning_data_stats _:`Optional`[`SupervisedTuningDataStats`]__= None_ _(alias 'supervisedTuningDataStats')_¶ 
    
The SFT Tuning data stats. 

_class_ genai.types.TuningDataStatsDict¶ 
    
Bases: `TypedDict`
The tuning data statistic values for TuningJob. 

distillation_data_stats _:`Optional`[`DistillationDataStatsDict`]_¶ 
    
Output only. Statistics for distillation. 

supervised_tuning_data_stats _:`Optional`[`SupervisedTuningDataStatsDict`]_¶ 
    
The SFT Tuning data stats. 

_pydantic model_genai.types.TuningDataset¶ 
    
Bases: `BaseModel`
Supervised fine-tuning training dataset.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"TuningDataset",
"description":"Supervised fine-tuning training dataset.",
"type":"object",
"properties":{
"gcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"GCS URI of the file containing training dataset in JSONL format.",
"title":"Gcsuri"
},
"examples":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/TuningExample"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Inline examples with simple input/output text.",
"title":"Examples"
}
},
"$defs":{
"TuningExample":{
"additionalProperties":false,
"properties":{
"textInput":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Text model input.",
"title":"Textinput"
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The expected model output.",
"title":"Output"
}
},
"title":"TuningExample",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `examples (list[genai.types.TuningExample] | None)`
  * `gcs_uri (str | None)`



_field_ examples _:`Optional`[`list`[`TuningExample`]]__= None_¶ 
    
Inline examples with simple input/output text. 

_field_ gcs_uri _:`Optional`[`str`]__= None_ _(alias 'gcsUri')_¶ 
    
GCS URI of the file containing training dataset in JSONL format. 

_class_ genai.types.TuningDatasetDict¶ 
    
Bases: `TypedDict`
Supervised fine-tuning training dataset. 

examples _:`Optional`[`list`[`TuningExampleDict`]]_¶ 
    
Inline examples with simple input/output text. 

gcs_uri _:`Optional`[`str`]_¶ 
    
GCS URI of the file containing training dataset in JSONL format. 

_pydantic model_genai.types.TuningExample¶ 
    
Bases: `BaseModel`
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"TuningExample",
"type":"object",
"properties":{
"textInput":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Text model input.",
"title":"Textinput"
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The expected model output.",
"title":"Output"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `output (str | None)`
  * `text_input (str | None)`



_field_ output _:`Optional`[`str`]__= None_¶ 
    
The expected model output. 

_field_ text_input _:`Optional`[`str`]__= None_ _(alias 'textInput')_¶ 
    
Text model input. 

_class_ genai.types.TuningExampleDict¶ 
    
Bases: `TypedDict` 

output _:`Optional`[`str`]_¶ 
    
The expected model output. 

text_input _:`Optional`[`str`]_¶ 
    
Text model input. 

_pydantic model_genai.types.TuningJob¶ 
    
Bases: `BaseModel`
A tuning job.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"TuningJob",
"description":"A tuning job.",
"type":"object",
"properties":{
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Identifier. Resource name of a TuningJob. Format: `projects/{project}/locations/{location}/tuningJobs/{tuning_job}`",
"title":"Name"
},
"state":{
"anyOf":[
{
"$ref":"#/$defs/JobState"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The detailed state of the job."
},
"createTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Time when the TuningJob was created.",
"title":"Createtime"
},
"startTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Time when the TuningJob for the first time entered the `JOB_STATE_RUNNING` state.",
"title":"Starttime"
},
"endTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Time when the TuningJob entered any of the following JobStates: `JOB_STATE_SUCCEEDED`, `JOB_STATE_FAILED`, `JOB_STATE_CANCELLED`, `JOB_STATE_EXPIRED`.",
"title":"Endtime"
},
"updateTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Time when the TuningJob was most recently updated.",
"title":"Updatetime"
},
"error":{
"anyOf":[
{
"$ref":"#/$defs/GoogleRpcStatus"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Only populated when job's state is `JOB_STATE_FAILED` or `JOB_STATE_CANCELLED`."
},
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The description of the TuningJob.",
"title":"Description"
},
"baseModel":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base model that is being tuned, e.g., \"gemini-1.0-pro-002\". .",
"title":"Basemodel"
},
"tunedModel":{
"anyOf":[
{
"$ref":"#/$defs/TunedModel"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The tuned model resources associated with this TuningJob."
},
"supervisedTuningSpec":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedTuningSpec"
},
{
"type":"null"
}
],
"default":null,
"description":"Tuning Spec for Supervised Fine Tuning."
},
"tuningDataStats":{
"anyOf":[
{
"$ref":"#/$defs/TuningDataStats"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The tuning data statistics associated with this TuningJob."
},
"encryptionSpec":{
"anyOf":[
{
"$ref":"#/$defs/EncryptionSpec"
},
{
"type":"null"
}
],
"default":null,
"description":"Customer-managed encryption key options for a TuningJob. If this is set, then all resources created by the TuningJob will be encrypted with the provided encryption key."
},
"partnerModelTuningSpec":{
"anyOf":[
{
"$ref":"#/$defs/PartnerModelTuningSpec"
},
{
"type":"null"
}
],
"default":null,
"description":"Tuning Spec for open sourced and third party Partner models."
},
"distillationSpec":{
"anyOf":[
{
"$ref":"#/$defs/DistillationSpec"
},
{
"type":"null"
}
],
"default":null,
"description":"Tuning Spec for Distillation."
},
"experiment":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The Experiment associated with this TuningJob.",
"title":"Experiment"
},
"labels":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The labels with user-defined metadata to organize TuningJob and generated resources such as Model and Endpoint. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.",
"title":"Labels"
},
"pipelineJob":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The resource name of the PipelineJob associated with the TuningJob. Format: `projects/{project}/locations/{location}/pipelineJobs/{pipeline_job}`.",
"title":"Pipelinejob"
},
"tunedModelDisplayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The display name of the TunedModel. The name can be up to 128 characters long and can consist of any UTF-8 characters.",
"title":"Tunedmodeldisplayname"
}
},
"$defs":{
"AdapterSize":{
"description":"Optional. Adapter size for tuning.",
"enum":[
"ADAPTER_SIZE_UNSPECIFIED",
"ADAPTER_SIZE_ONE",
"ADAPTER_SIZE_TWO",
"ADAPTER_SIZE_FOUR",
"ADAPTER_SIZE_EIGHT",
"ADAPTER_SIZE_SIXTEEN",
"ADAPTER_SIZE_THIRTY_TWO"
],
"title":"AdapterSize",
"type":"string"
},
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"Content":{
"additionalProperties":false,
"description":"Contains the multi-part content of a message.",
"properties":{
"parts":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Part"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of parts that constitute a single message. Each part may have\n      a different IANA MIME type.",
"title":"Parts"
},
"role":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role.",
"title":"Role"
}
},
"title":"Content",
"type":"object"
},
"DatasetDistribution":{
"additionalProperties":false,
"description":"Distribution computed over a tuning dataset.",
"properties":{
"buckets":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/DatasetDistributionDistributionBucket"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Defines the histogram bucket.",
"title":"Buckets"
},
"max":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The maximum of the population values.",
"title":"Max"
},
"mean":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The arithmetic mean of the values in the population.",
"title":"Mean"
},
"median":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The median of the values in the population.",
"title":"Median"
},
"min":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The minimum of the population values.",
"title":"Min"
},
"p5":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 5th percentile of the values in the population.",
"title":"P5"
},
"p95":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 95th percentile of the values in the population.",
"title":"P95"
},
"sum":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sum of a given population of values.",
"title":"Sum"
}
},
"title":"DatasetDistribution",
"type":"object"
},
"DatasetDistributionDistributionBucket":{
"additionalProperties":false,
"description":"Dataset bucket used to create a histogram for the distribution given a population of values.",
"properties":{
"count":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of values in the bucket.",
"title":"Count"
},
"left":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Left bound of the bucket.",
"title":"Left"
},
"right":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Right bound of the bucket.",
"title":"Right"
}
},
"title":"DatasetDistributionDistributionBucket",
"type":"object"
},
"DatasetStats":{
"additionalProperties":false,
"description":"Statistics computed over a tuning dataset.",
"properties":{
"totalBillableCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of billable characters in the tuning dataset.",
"title":"Totalbillablecharactercount"
},
"totalTuningCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tuning characters in the tuning dataset.",
"title":"Totaltuningcharactercount"
},
"tuningDatasetExampleCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of examples in the tuning dataset.",
"title":"Tuningdatasetexamplecount"
},
"tuningStepCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tuning steps for this Tuning Job.",
"title":"Tuningstepcount"
},
"userDatasetExamples":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Content"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sample user messages in the training dataset uri.",
"title":"Userdatasetexamples"
},
"userInputTokenDistribution":{
"anyOf":[
{
"$ref":"#/$defs/DatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the user input tokens."
},
"userMessagePerExampleDistribution":{
"anyOf":[
{
"$ref":"#/$defs/DatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the messages per example."
},
"userOutputTokenDistribution":{
"anyOf":[
{
"$ref":"#/$defs/DatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the user output tokens."
}
},
"title":"DatasetStats",
"type":"object"
},
"DistillationDataStats":{
"additionalProperties":false,
"description":"Statistics computed for datasets used for distillation.",
"properties":{
"trainingDatasetStats":{
"anyOf":[
{
"$ref":"#/$defs/DatasetStats"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Statistics computed for the training dataset."
}
},
"title":"DistillationDataStats",
"type":"object"
},
"DistillationHyperParameters":{
"additionalProperties":false,
"description":"Hyperparameters for Distillation.",
"properties":{
"adapterSize":{
"anyOf":[
{
"$ref":"#/$defs/AdapterSize"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Adapter size for distillation."
},
"epochCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of complete passes the model makes over the entire training dataset during training.",
"title":"Epochcount"
},
"learningRateMultiplier":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Multiplier for adjusting the default learning rate.",
"title":"Learningratemultiplier"
}
},
"title":"DistillationHyperParameters",
"type":"object"
},
"DistillationSpec":{
"additionalProperties":false,
"description":"Tuning Spec for Distillation.",
"properties":{
"baseTeacherModel":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base teacher model that is being distilled, e.g., \"gemini-1.0-pro-002\".",
"title":"Baseteachermodel"
},
"hyperParameters":{
"anyOf":[
{
"$ref":"#/$defs/DistillationHyperParameters"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Hyperparameters for Distillation."
},
"pipelineRootDirectory":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. A path in a Cloud Storage bucket, which will be treated as the root output directory of the distillation pipeline. It is used by the system to generate the paths of output artifacts.",
"title":"Pipelinerootdirectory"
},
"studentModel":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The student model that is being tuned, e.g., \"google/gemma-2b-1.1-it\".",
"title":"Studentmodel"
},
"trainingDatasetUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file.",
"title":"Trainingdataseturi"
},
"tunedTeacherModelSource":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The resource name of the Tuned teacher model. Format: `projects/{project}/locations/{location}/models/{model}`.",
"title":"Tunedteachermodelsource"
},
"validationDatasetUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Cloud Storage path to file containing validation dataset for tuning. The dataset must be formatted as a JSONL file.",
"title":"Validationdataseturi"
}
},
"title":"DistillationSpec",
"type":"object"
},
"EncryptionSpec":{
"additionalProperties":false,
"description":"Represents a customer-managed encryption key spec that can be applied to a top-level resource.",
"properties":{
"kmsKeyName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.",
"title":"Kmskeyname"
}
},
"title":"EncryptionSpec",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"GoogleRpcStatus":{
"additionalProperties":false,
"description":"The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs.\n\nIt is used by [gRPC](https://github.com/grpc). Each `Status` message contains\nthree pieces of data: error code, error message, and error details. You can\nfind out more about this error model and how to work with it in the [API\nDesign Guide](https://cloud.google.com/apis/design/errors).",
"properties":{
"code":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The status code, which should be an enum value of google.rpc.Code.",
"title":"Code"
},
"details":{
"anyOf":[
{
"items":{
"type":"object"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A list of messages that carry the error details. There is a common set of message types for APIs to use.",
"title":"Details"
},
"message":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.",
"title":"Message"
}
},
"title":"GoogleRpcStatus",
"type":"object"
},
"JobState":{
"description":"Job state.",
"enum":[
"JOB_STATE_UNSPECIFIED",
"JOB_STATE_QUEUED",
"JOB_STATE_PENDING",
"JOB_STATE_RUNNING",
"JOB_STATE_SUCCEEDED",
"JOB_STATE_FAILED",
"JOB_STATE_CANCELLING",
"JOB_STATE_CANCELLED",
"JOB_STATE_PAUSED",
"JOB_STATE_EXPIRED",
"JOB_STATE_UPDATING",
"JOB_STATE_PARTIALLY_SUCCEEDED"
],
"title":"JobState",
"type":"string"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"PartnerModelTuningSpec":{
"additionalProperties":false,
"description":"Tuning spec for Partner models.",
"properties":{
"hyperParameters":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Hyperparameters for tuning. The accepted hyper_parameters and their valid range of values will differ depending on the base model.",
"title":"Hyperparameters"
},
"trainingDatasetUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file.",
"title":"Trainingdataseturi"
},
"validationDatasetUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Cloud Storage path to file containing validation dataset for tuning. The dataset must be formatted as a JSONL file.",
"title":"Validationdataseturi"
}
},
"title":"PartnerModelTuningSpec",
"type":"object"
},
"SupervisedHyperParameters":{
"additionalProperties":false,
"description":"Hyperparameters for SFT.",
"properties":{
"adapterSize":{
"anyOf":[
{
"$ref":"#/$defs/AdapterSize"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Adapter size for tuning."
},
"epochCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of complete passes the model makes over the entire training dataset during training.",
"title":"Epochcount"
},
"learningRateMultiplier":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Multiplier for adjusting the default learning rate.",
"title":"Learningratemultiplier"
}
},
"title":"SupervisedHyperParameters",
"type":"object"
},
"SupervisedTuningDataStats":{
"additionalProperties":false,
"description":"Tuning data statistics for Supervised Tuning.",
"properties":{
"totalBillableCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of billable characters in the tuning dataset.",
"title":"Totalbillablecharactercount"
},
"totalBillableTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of billable tokens in the tuning dataset.",
"title":"Totalbillabletokencount"
},
"totalTruncatedExampleCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The number of examples in the dataset that have been truncated by any amount.",
"title":"Totaltruncatedexamplecount"
},
"totalTuningCharacterCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tuning characters in the tuning dataset.",
"title":"Totaltuningcharactercount"
},
"truncatedExampleIndices":{
"anyOf":[
{
"items":{
"type":"integer"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"A partial sample of the indices (starting from 1) of the truncated examples.",
"title":"Truncatedexampleindices"
},
"tuningDatasetExampleCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of examples in the tuning dataset.",
"title":"Tuningdatasetexamplecount"
},
"tuningStepCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of tuning steps for this Tuning Job.",
"title":"Tuningstepcount"
},
"userDatasetExamples":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/Content"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sample user messages in the training dataset uri.",
"title":"Userdatasetexamples"
},
"userInputTokenDistribution":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedTuningDatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the user input tokens."
},
"userMessagePerExampleDistribution":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedTuningDatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the messages per example."
},
"userOutputTokenDistribution":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedTuningDatasetDistribution"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Dataset distributions for the user output tokens."
}
},
"title":"SupervisedTuningDataStats",
"type":"object"
},
"SupervisedTuningDatasetDistribution":{
"additionalProperties":false,
"description":"Dataset distribution for Supervised Tuning.",
"properties":{
"billableSum":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sum of a given population of values that are billable.",
"title":"Billablesum"
},
"buckets":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/SupervisedTuningDatasetDistributionDatasetBucket"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Defines the histogram bucket.",
"title":"Buckets"
},
"max":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The maximum of the population values.",
"title":"Max"
},
"mean":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The arithmetic mean of the values in the population.",
"title":"Mean"
},
"median":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The median of the values in the population.",
"title":"Median"
},
"min":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The minimum of the population values.",
"title":"Min"
},
"p5":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 5th percentile of the values in the population.",
"title":"P5"
},
"p95":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The 95th percentile of the values in the population.",
"title":"P95"
},
"sum":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Sum of a given population of values.",
"title":"Sum"
}
},
"title":"SupervisedTuningDatasetDistribution",
"type":"object"
},
"SupervisedTuningDatasetDistributionDatasetBucket":{
"additionalProperties":false,
"description":"Dataset bucket used to create a histogram for the distribution given a population of values.",
"properties":{
"count":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Number of values in the bucket.",
"title":"Count"
},
"left":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Left bound of the bucket.",
"title":"Left"
},
"right":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Right bound of the bucket.",
"title":"Right"
}
},
"title":"SupervisedTuningDatasetDistributionDatasetBucket",
"type":"object"
},
"SupervisedTuningSpec":{
"additionalProperties":false,
"description":"Tuning Spec for Supervised Tuning for first party models.",
"properties":{
"hyperParameters":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedHyperParameters"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Hyperparameters for SFT."
},
"trainingDatasetUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file.",
"title":"Trainingdataseturi"
},
"validationDatasetUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Cloud Storage path to file containing validation dataset for tuning. The dataset must be formatted as a JSONL file.",
"title":"Validationdataseturi"
},
"exportLastCheckpointOnly":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. If set to true, disable intermediate checkpoints for SFT and only the last checkpoint will be exported.",
"title":"Exportlastcheckpointonly"
}
},
"title":"SupervisedTuningSpec",
"type":"object"
},
"TunedModel":{
"additionalProperties":false,
"properties":{
"model":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. The resource name of the TunedModel. Format: `projects/{project}/locations/{location}/models/{model}`.",
"title":"Model"
},
"endpoint":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. A resource name of an Endpoint. Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`.",
"title":"Endpoint"
},
"checkpoints":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/TunedModelCheckpoint"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"The checkpoints associated with this TunedModel.\n      This field is only populated for tuning jobs that enable intermediate\n      checkpoints.",
"title":"Checkpoints"
}
},
"title":"TunedModel",
"type":"object"
},
"TunedModelCheckpoint":{
"additionalProperties":false,
"description":"TunedModelCheckpoint for the Tuned Model of a Tuning Job.",
"properties":{
"checkpointId":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The ID of the checkpoint.\n      ",
"title":"Checkpointid"
},
"epoch":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The epoch of the checkpoint.\n      ",
"title":"Epoch"
},
"step":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The step of the checkpoint.\n      ",
"title":"Step"
},
"endpoint":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The Endpoint resource name that the checkpoint is deployed to.\n      Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`.\n      ",
"title":"Endpoint"
}
},
"title":"TunedModelCheckpoint",
"type":"object"
},
"TuningDataStats":{
"additionalProperties":false,
"description":"The tuning data statistic values for TuningJob.",
"properties":{
"distillationDataStats":{
"anyOf":[
{
"$ref":"#/$defs/DistillationDataStats"
},
{
"type":"null"
}
],
"default":null,
"description":"Output only. Statistics for distillation."
},
"supervisedTuningDataStats":{
"anyOf":[
{
"$ref":"#/$defs/SupervisedTuningDataStats"
},
{
"type":"null"
}
],
"default":null,
"description":"The SFT Tuning data stats."
}
},
"title":"TuningDataStats",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `base_model (str | None)`
  * `create_time (datetime.datetime | None)`
  * `description (str | None)`
  * `distillation_spec (genai.types.DistillationSpec | None)`
  * `encryption_spec (genai.types.EncryptionSpec | None)`
  * `end_time (datetime.datetime | None)`
  * `error (genai.types.GoogleRpcStatus | None)`
  * `experiment (str | None)`
  * `labels (dict[str, str] | None)`
  * `name (str | None)`
  * `partner_model_tuning_spec (genai.types.PartnerModelTuningSpec | None)`
  * `pipeline_job (str | None)`
  * `start_time (datetime.datetime | None)`
  * `state (genai.types.JobState | None)`
  * `supervised_tuning_spec (genai.types.SupervisedTuningSpec | None)`
  * `tuned_model (genai.types.TunedModel | None)`
  * `tuned_model_display_name (str | None)`
  * `tuning_data_stats (genai.types.TuningDataStats | None)`
  * `update_time (datetime.datetime | None)`



_field_ base_model _:`Optional`[`str`]__= None_ _(alias 'baseModel')_¶ 
    
The base model that is being tuned, e.g., “gemini-1.0-pro-002”. . 

_field_ create_time _:`Optional`[`datetime`]__= None_ _(alias 'createTime')_¶ 
    
Output only. Time when the TuningJob was created. 

_field_ description _:`Optional`[`str`]__= None_¶ 
    
Optional. The description of the TuningJob. 

_field_ distillation_spec _:`Optional`[`DistillationSpec`]__= None_ _(alias 'distillationSpec')_¶ 
    
Tuning Spec for Distillation. 

_field_ encryption_spec _:`Optional`[`EncryptionSpec`]__= None_ _(alias 'encryptionSpec')_¶ 
    
Customer-managed encryption key options for a TuningJob. If this is set, then all resources created by the TuningJob will be encrypted with the provided encryption key. 

_field_ end_time _:`Optional`[`datetime`]__= None_ _(alias 'endTime')_¶ 
    
Output only. Time when the TuningJob entered any of the following JobStates: JOB_STATE_SUCCEEDED, JOB_STATE_FAILED, JOB_STATE_CANCELLED, JOB_STATE_EXPIRED. 

_field_ error _:`Optional`[`GoogleRpcStatus`]__= None_¶ 
    
Output only. Only populated when job’s state is JOB_STATE_FAILED or JOB_STATE_CANCELLED. 

_field_ experiment _:`Optional`[`str`]__= None_¶ 
    
Output only. The Experiment associated with this TuningJob. 

_field_ labels _:`Optional`[`dict`[`str`, `str`]]__= None_¶ 
    
Optional. The labels with user-defined metadata to organize TuningJob and generated resources such as Model and Endpoint. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels. 

_field_ name _:`Optional`[`str`]__= None_¶ 
    
Output only. Identifier. Resource name of a TuningJob. Format: projects/{project}/locations/{location}/tuningJobs/{tuning_job} 

_field_ partner_model_tuning_spec _:`Optional`[`PartnerModelTuningSpec`]__= None_ _(alias 'partnerModelTuningSpec')_¶ 
    
Tuning Spec for open sourced and third party Partner models. 

_field_ pipeline_job _:`Optional`[`str`]__= None_ _(alias 'pipelineJob')_¶ 
    
Output only. The resource name of the PipelineJob associated with the TuningJob. Format: projects/{project}/locations/{location}/pipelineJobs/{pipeline_job}. 

_field_ start_time _:`Optional`[`datetime`]__= None_ _(alias 'startTime')_¶ 
    
Output only. Time when the TuningJob for the first time entered the JOB_STATE_RUNNING state. 

_field_ state _:`Optional`[`JobState`]__= None_¶ 
    
Output only. The detailed state of the job. 

_field_ supervised_tuning_spec _:`Optional`[`SupervisedTuningSpec`]__= None_ _(alias 'supervisedTuningSpec')_¶ 
    
Tuning Spec for Supervised Fine Tuning. 

_field_ tuned_model _:`Optional`[`TunedModel`]__= None_ _(alias 'tunedModel')_¶ 
    
Output only. The tuned model resources associated with this TuningJob. 

_field_ tuned_model_display_name _:`Optional`[`str`]__= None_ _(alias 'tunedModelDisplayName')_¶ 
    
Optional. The display name of the TunedModel. The name can be up to 128 characters long and can consist of any UTF-8 characters. 

_field_ tuning_data_stats _:`Optional`[`TuningDataStats`]__= None_ _(alias 'tuningDataStats')_¶ 
    
Output only. The tuning data statistics associated with this TuningJob. 

_field_ update_time _:`Optional`[`datetime`]__= None_ _(alias 'updateTime')_¶ 
    
Output only. Time when the TuningJob was most recently updated. 

_property_ has_ended _: bool_¶ 
    
Whether the tuning job has ended. 

_property_ has_succeeded _: bool_¶ 
    
Whether the tuning job has succeeded. 

_class_ genai.types.TuningJobDict¶ 
    
Bases: `TypedDict`
A tuning job. 

base_model _:`Optional`[`str`]_¶ 
    
The base model that is being tuned, e.g., “gemini-1.0-pro-002”. . 

create_time _:`Optional`[`datetime`]_¶ 
    
Output only. Time when the TuningJob was created. 

description _:`Optional`[`str`]_¶ 
    
Optional. The description of the TuningJob. 

distillation_spec _:`Optional`[`DistillationSpecDict`]_¶ 
    
Tuning Spec for Distillation. 

encryption_spec _:`Optional`[`EncryptionSpecDict`]_¶ 
    
Customer-managed encryption key options for a TuningJob. If this is set, then all resources created by the TuningJob will be encrypted with the provided encryption key. 

end_time _:`Optional`[`datetime`]_¶ 
    
JOB_STATE_SUCCEEDED, JOB_STATE_FAILED, JOB_STATE_CANCELLED, JOB_STATE_EXPIRED. 

Type: 
    
Output only. Time when the TuningJob entered any of the following JobStates 

error _:`Optional`[`GoogleRpcStatusDict`]_¶ 
    
Output only. Only populated when job’s state is JOB_STATE_FAILED or JOB_STATE_CANCELLED. 

experiment _:`Optional`[`str`]_¶ 
    
Output only. The Experiment associated with this TuningJob. 

labels _:`Optional`[`dict`[`str`, `str`]]_¶ 
    
//goo.gl/xmQnxf for more information and examples of labels. 

Type: 
    
Optional. The labels with user-defined metadata to organize TuningJob and generated resources such as Model and Endpoint. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https 

name _:`Optional`[`str`]_¶ 
    
projects/{project}/locations/{location}/tuningJobs/{tuning_job} 

Type: 
    
Output only. Identifier. Resource name of a TuningJob. Format 

partner_model_tuning_spec _:`Optional`[`PartnerModelTuningSpecDict`]_¶ 
    
Tuning Spec for open sourced and third party Partner models. 

pipeline_job _:`Optional`[`str`]_¶ 
    
projects/{project}/locations/{location}/pipelineJobs/{pipeline_job}. 

Type: 
    
Output only. The resource name of the PipelineJob associated with the TuningJob. Format 

start_time _:`Optional`[`datetime`]_¶ 
    
Output only. Time when the TuningJob for the first time entered the JOB_STATE_RUNNING state. 

state _:`Optional`[`JobState`]_¶ 
    
Output only. The detailed state of the job. 

supervised_tuning_spec _:`Optional`[`SupervisedTuningSpecDict`]_¶ 
    
Tuning Spec for Supervised Fine Tuning. 

tuned_model _:`Optional`[`TunedModelDict`]_¶ 
    
Output only. The tuned model resources associated with this TuningJob. 

tuned_model_display_name _:`Optional`[`str`]_¶ 
    
Optional. The display name of the TunedModel. The name can be up to 128 characters long and can consist of any UTF-8 characters. 

tuning_data_stats _:`Optional`[`TuningDataStatsDict`]_¶ 
    
Output only. The tuning data statistics associated with this TuningJob. 

update_time _:`Optional`[`datetime`]_¶ 
    
Output only. Time when the TuningJob was most recently updated. 

_pydantic model_genai.types.TuningValidationDataset¶ 
    
Bases: `BaseModel`
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"TuningValidationDataset",
"type":"object",
"properties":{
"gcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"GCS URI of the file containing validation dataset in JSONL format.",
"title":"Gcsuri"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `gcs_uri (str | None)`



_field_ gcs_uri _:`Optional`[`str`]__= None_ _(alias 'gcsUri')_¶ 
    
GCS URI of the file containing validation dataset in JSONL format. 

_class_ genai.types.TuningValidationDatasetDict¶ 
    
Bases: `TypedDict` 

gcs_uri _:`Optional`[`str`]_¶ 
    
GCS URI of the file containing validation dataset in JSONL format. 

_class_ genai.types.TurnCoverage(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Options about which input is included in the user’s turn. 

TURN_COVERAGE_UNSPECIFIED _= 'TURN_COVERAGE_UNSPECIFIED'_¶ 


TURN_INCLUDES_ALL_INPUT _= 'TURN_INCLUDES_ALL_INPUT'_¶ 


TURN_INCLUDES_ONLY_ACTIVITY _= 'TURN_INCLUDES_ONLY_ACTIVITY'_¶ 


_class_ genai.types.Type(_* values_)¶ 
    
Bases: `CaseInSensitiveEnum`
Optional. The type of the data. 

ARRAY _= 'ARRAY'_¶ 


BOOLEAN _= 'BOOLEAN'_¶ 


INTEGER _= 'INTEGER'_¶ 


NUMBER _= 'NUMBER'_¶ 


OBJECT _= 'OBJECT'_¶ 


STRING _= 'STRING'_¶ 


TYPE_UNSPECIFIED _= 'TYPE_UNSPECIFIED'_¶ 


_pydantic model_genai.types.UpdateCachedContentConfig¶ 
    
Bases: `BaseModel`
Optional parameters for caches.update method.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"UpdateCachedContentConfig",
"description":"Optional parameters for caches.update method.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
},
"ttl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The TTL for this resource. The expiration time is computed: now + TTL. It is a duration string, with up to nine fractional digits, terminated by 's'. Example: \"3.5s\".",
"title":"Ttl"
},
"expireTime":{
"anyOf":[
{
"format":"date-time",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Timestamp of when this resource is considered expired. Uses RFC 3339 format, Example: 2014-10-02T15:01:23Z.",
"title":"Expiretime"
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `expire_time (datetime.datetime | None)`
  * `http_options (genai.types.HttpOptions | None)`
  * `ttl (str | None)`



_field_ expire_time _:`Optional`[`datetime`]__= None_ _(alias 'expireTime')_¶ 
    
Timestamp of when this resource is considered expired. Uses RFC 3339 format, Example: 2014-10-02T15:01:23Z. 

_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_field_ ttl _:`Optional`[`str`]__= None_¶ 
    
The TTL for this resource. The expiration time is computed: now + TTL. It is a duration string, with up to nine fractional digits, terminated by ‘s’. Example: “3.5s”. 

_class_ genai.types.UpdateCachedContentConfigDict¶ 
    
Bases: `TypedDict`
Optional parameters for caches.update method. 

expire_time _:`Optional`[`datetime`]_¶ 
    
01:23Z. 

Type: 
    
Timestamp of when this resource is considered expired. Uses RFC 3339 format, Example 

Type: 
    
2014-10-02T15 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

ttl _:`Optional`[`str`]_¶ 
    
“3.5s”. 

Type: 
    
The TTL for this resource. The expiration time is computed 

Type: 
    
now + TTL. It is a duration string, with up to nine fractional digits, terminated by ‘s’. Example 

_pydantic model_genai.types.UpdateModelConfig¶ 
    
Bases: `BaseModel`
Configuration for updating a tuned model.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"UpdateModelConfig",
"description":"Configuration for updating a tuned model.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
},
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Displayname"
},
"description":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Description"
},
"defaultCheckpointId":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"",
"title":"Defaultcheckpointid"
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `default_checkpoint_id (str | None)`
  * `description (str | None)`
  * `display_name (str | None)`
  * `http_options (genai.types.HttpOptions | None)`



_field_ default_checkpoint_id _:`Optional`[`str`]__= None_ _(alias 'defaultCheckpointId')_¶ 


_field_ description _:`Optional`[`str`]__= None_¶ 


_field_ display_name _:`Optional`[`str`]__= None_ _(alias 'displayName')_¶ 


_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_class_ genai.types.UpdateModelConfigDict¶ 
    
Bases: `TypedDict`
Configuration for updating a tuned model. 

default_checkpoint_id _:`Optional`[`str`]_¶ 


description _:`Optional`[`str`]_¶ 


display_name _:`Optional`[`str`]_¶ 


http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

_pydantic model_genai.types.UploadFileConfig¶ 
    
Bases: `BaseModel`
Used to override the default configuration.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"UploadFileConfig",
"description":"Used to override the default configuration.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The name of the file in the destination (e.g., 'files/sample-image'. If not provided one will be generated.",
"title":"Name"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"mime_type: The MIME type of the file. If not provided, it will be inferred from the file extension.",
"title":"Mimetype"
},
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional display name of the file.",
"title":"Displayname"
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `display_name (str | None)`
  * `http_options (genai.types.HttpOptions | None)`
  * `mime_type (str | None)`
  * `name (str | None)`



_field_ display_name _:`Optional`[`str`]__= None_ _(alias 'displayName')_¶ 
    
Optional display name of the file. 

_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_field_ mime_type _:`Optional`[`str`]__= None_ _(alias 'mimeType')_¶ 
    
mime_type: The MIME type of the file. If not provided, it will be inferred from the file extension. 

_field_ name _:`Optional`[`str`]__= None_¶ 
    
The name of the file in the destination (e.g., ‘files/sample-image’. If not provided one will be generated. 

_class_ genai.types.UploadFileConfigDict¶ 
    
Bases: `TypedDict`
Used to override the default configuration. 

display_name _:`Optional`[`str`]_¶ 
    
Optional display name of the file. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

mime_type _:`Optional`[`str`]_¶ 
    
The MIME type of the file. If not provided, it will be inferred from the file extension. 

Type: 
    
mime_type 

name _:`Optional`[`str`]_¶ 
    
The name of the file in the destination (e.g., ‘files/sample-image’. If not provided one will be generated. 

_pydantic model_genai.types.UpscaleImageConfig¶ 
    
Bases: `BaseModel`
Configuration for upscaling an image.
For more information on this configuration, refer to the Imagen API reference documentation.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"UpscaleImageConfig",
"description":"Configuration for upscaling an image.\n\nFor more information on this configuration, refer to\nthe `Imagen API reference documentation\n<https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/imagen-api>`_.",
"type":"object",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
},
"includeRaiReason":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Whether to include a reason for filtered-out images in the\n      response.",
"title":"Includeraireason"
},
"outputMimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The image format that the output should be saved as.",
"title":"Outputmimetype"
},
"outputCompressionQuality":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The level of compression if the ``output_mime_type`` is\n      ``image/jpeg``.",
"title":"Outputcompressionquality"
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `http_options (genai.types.HttpOptions | None)`
  * `include_rai_reason (bool | None)`
  * `output_compression_quality (int | None)`
  * `output_mime_type (str | None)`



_field_ http_options _:`Optional`[`HttpOptions`]__= None_ _(alias 'httpOptions')_¶ 
    
Used to override HTTP request options. 

_field_ include_rai_reason _:`Optional`[`bool`]__= None_ _(alias 'includeRaiReason')_¶ 
    
Whether to include a reason for filtered-out images in the response. 

_field_ output_compression_quality _:`Optional`[`int`]__= None_ _(alias 'outputCompressionQuality')_¶ 
    
The level of compression if the `output_mime_type` is `image/jpeg`. 

_field_ output_mime_type _:`Optional`[`str`]__= None_ _(alias 'outputMimeType')_¶ 
    
The image format that the output should be saved as. 

_class_ genai.types.UpscaleImageConfigDict¶ 
    
Bases: `TypedDict`
Configuration for upscaling an image.
For more information on this configuration, refer to the Imagen API reference documentation. 

http_options _:`Optional`[`HttpOptionsDict`]_¶ 
    
Used to override HTTP request options. 

include_rai_reason _:`Optional`[`bool`]_¶ 
    
Whether to include a reason for filtered-out images in the response. 

output_compression_quality _:`Optional`[`int`]_¶ 
    
The level of compression if the `output_mime_type` is `image/jpeg`. 

output_mime_type _:`Optional`[`str`]_¶ 
    
The image format that the output should be saved as. 

_pydantic model_genai.types.UpscaleImageParameters¶ 
    
Bases: `BaseModel`
User-facing config UpscaleImageParameters.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"UpscaleImageParameters",
"description":"User-facing config UpscaleImageParameters.",
"type":"object",
"properties":{
"model":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The model to use.",
"title":"Model"
},
"image":{
"anyOf":[
{
"$ref":"#/$defs/Image"
},
{
"type":"null"
}
],
"default":null,
"description":"The input image to upscale."
},
"upscaleFactor":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The factor to upscale the image (x2 or x4).",
"title":"Upscalefactor"
},
"config":{
"anyOf":[
{
"$ref":"#/$defs/UpscaleImageConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Configuration for upscaling."
}
},
"$defs":{
"HttpOptions":{
"additionalProperties":false,
"description":"HTTP options to be used in each of the requests.",
"properties":{
"baseUrl":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The base URL for the AI platform service endpoint.",
"title":"Baseurl"
},
"apiVersion":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Specifies the version of the API to use.",
"title":"Apiversion"
},
"headers":{
"anyOf":[
{
"additionalProperties":{
"type":"string"
},
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Additional HTTP headers to be sent with the request.",
"title":"Headers"
},
"timeout":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Timeout for the request in milliseconds.",
"title":"Timeout"
},
"clientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the HTTP client.",
"title":"Clientargs"
},
"asyncClientArgs":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Args passed to the async HTTP client.",
"title":"Asyncclientargs"
}
},
"title":"HttpOptions",
"type":"object"
},
"Image":{
"additionalProperties":false,
"description":"An image.",
"properties":{
"gcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The Cloud Storage URI of the image. ``Image`` can contain a value\n      for this field or the ``image_bytes`` field but not both.\n      ",
"title":"Gcsuri"
},
"imageBytes":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The image bytes data. ``Image`` can contain a value for this field\n      or the ``gcs_uri`` field but not both.\n      ",
"title":"Imagebytes"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The MIME type of the image.",
"title":"Mimetype"
}
},
"title":"Image",
"type":"object"
},
"UpscaleImageConfig":{
"additionalProperties":false,
"description":"Configuration for upscaling an image.\n\nFor more information on this configuration, refer to\nthe `Imagen API reference documentation\n<https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/imagen-api>`_.",
"properties":{
"httpOptions":{
"anyOf":[
{
"$ref":"#/$defs/HttpOptions"
},
{
"type":"null"
}
],
"default":null,
"description":"Used to override HTTP request options."
},
"includeRaiReason":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Whether to include a reason for filtered-out images in the\n      response.",
"title":"Includeraireason"
},
"outputMimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The image format that the output should be saved as.",
"title":"Outputmimetype"
},
"outputCompressionQuality":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"The level of compression if the ``output_mime_type`` is\n      ``image/jpeg``.",
"title":"Outputcompressionquality"
}
},
"title":"UpscaleImageConfig",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `config (genai.types.UpscaleImageConfig | None)`
  * `image (genai.types.Image | None)`
  * `model (str | None)`
  * `upscale_factor (str | None)`



_field_ config _:`Optional`[`UpscaleImageConfig`]__= None_¶ 
    
Configuration for upscaling. 

_field_ image _:`Optional`[`Image`]__= None_¶ 
    
The input image to upscale. 

_field_ model _:`Optional`[`str`]__= None_¶ 
    
The model to use. 

_field_ upscale_factor _:`Optional`[`str`]__= None_ _(alias 'upscaleFactor')_¶ 
    
The factor to upscale the image (x2 or x4). 

_class_ genai.types.UpscaleImageParametersDict¶ 
    
Bases: `TypedDict`
User-facing config UpscaleImageParameters. 

config _:`Optional`[`UpscaleImageConfigDict`]_¶ 
    
Configuration for upscaling. 

image _:`Optional`[`ImageDict`]_¶ 
    
The input image to upscale. 

model _:`Optional`[`str`]_¶ 
    
The model to use. 

upscale_factor _:`Optional`[`str`]_¶ 
    
The factor to upscale the image (x2 or x4). 

_pydantic model_genai.types.UpscaleImageResponse¶ 
    
Bases: `BaseModel`
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"UpscaleImageResponse",
"type":"object",
"properties":{
"generatedImages":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/GeneratedImage"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Generated images.",
"title":"Generatedimages"
}
},
"$defs":{
"GeneratedImage":{
"additionalProperties":false,
"description":"An output image.",
"properties":{
"image":{
"anyOf":[
{
"$ref":"#/$defs/Image"
},
{
"type":"null"
}
],
"default":null,
"description":"The output image data.\n      "
},
"raiFilteredReason":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Responsible AI filter reason if the image is filtered out of the\n      response.\n      ",
"title":"Raifilteredreason"
},
"safetyAttributes":{
"anyOf":[
{
"$ref":"#/$defs/SafetyAttributes"
},
{
"type":"null"
}
],
"default":null,
"description":"Safety attributes of the image. Lists of RAI categories and their\n      scores of each content.\n      "
},
"enhancedPrompt":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The rewritten prompt used for the image generation if the prompt\n      enhancer is enabled.\n      ",
"title":"Enhancedprompt"
}
},
"title":"GeneratedImage",
"type":"object"
},
"Image":{
"additionalProperties":false,
"description":"An image.",
"properties":{
"gcsUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The Cloud Storage URI of the image. ``Image`` can contain a value\n      for this field or the ``image_bytes`` field but not both.\n      ",
"title":"Gcsuri"
},
"imageBytes":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The image bytes data. ``Image`` can contain a value for this field\n      or the ``gcs_uri`` field but not both.\n      ",
"title":"Imagebytes"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The MIME type of the image.",
"title":"Mimetype"
}
},
"title":"Image",
"type":"object"
},
"SafetyAttributes":{
"additionalProperties":false,
"description":"Safety attributes of a GeneratedImage or the user-provided prompt.",
"properties":{
"categories":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of RAI categories.\n      ",
"title":"Categories"
},
"scores":{
"anyOf":[
{
"items":{
"type":"number"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of scores of each categories.\n      ",
"title":"Scores"
},
"contentType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Internal use only.\n      ",
"title":"Contenttype"
}
},
"title":"SafetyAttributes",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `generated_images (list[genai.types.GeneratedImage] | None)`



_field_ generated_images _:`Optional`[`list`[`GeneratedImage`]]__= None_ _(alias 'generatedImages')_¶ 
    
Generated images. 

_class_ genai.types.UpscaleImageResponseDict¶ 
    
Bases: `TypedDict` 

generated_images _:`Optional`[`list`[`GeneratedImageDict`]]_¶ 
    
Generated images. 

_pydantic model_genai.types.UsageMetadata¶ 
    
Bases: `BaseModel`
Usage metadata about response(s).
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"UsageMetadata",
"description":"Usage metadata about response(s).",
"type":"object",
"properties":{
"promptTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens in the prompt. When `cached_content` is set, this is still the total effective prompt size meaning this includes the number of tokens in the cached content.",
"title":"Prompttokencount"
},
"cachedContentTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens in the cached part of the prompt (the cached content).",
"title":"Cachedcontenttokencount"
},
"responseTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Total number of tokens across all the generated response candidates.",
"title":"Responsetokencount"
},
"toolUsePromptTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens present in tool-use prompt(s).",
"title":"Tooluseprompttokencount"
},
"thoughtsTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens of thoughts for thinking models.",
"title":"Thoughtstokencount"
},
"totalTokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Total token count for prompt, response candidates, and tool-use prompts(if present).",
"title":"Totaltokencount"
},
"promptTokensDetails":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/ModalityTokenCount"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of modalities that were processed in the request input.",
"title":"Prompttokensdetails"
},
"cacheTokensDetails":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/ModalityTokenCount"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of modalities that were processed in the cache input.",
"title":"Cachetokensdetails"
},
"responseTokensDetails":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/ModalityTokenCount"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of modalities that were returned in the response.",
"title":"Responsetokensdetails"
},
"toolUsePromptTokensDetails":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/ModalityTokenCount"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"List of modalities that were processed in the tool-use prompt.",
"title":"Tooluseprompttokensdetails"
},
"trafficType":{
"anyOf":[
{
"$ref":"#/$defs/TrafficType"
},
{
"type":"null"
}
],
"default":null,
"description":"Traffic type. This shows whether a request consumes Pay-As-You-Go\n or Provisioned Throughput quota."
}
},
"$defs":{
"MediaModality":{
"description":"Server content modalities.",
"enum":[
"MODALITY_UNSPECIFIED",
"TEXT",
"IMAGE",
"VIDEO",
"AUDIO",
"DOCUMENT"
],
"title":"MediaModality",
"type":"string"
},
"ModalityTokenCount":{
"additionalProperties":false,
"description":"Represents token counting info for a single modality.",
"properties":{
"modality":{
"anyOf":[
{
"$ref":"#/$defs/MediaModality"
},
{
"type":"null"
}
],
"default":null,
"description":"The modality associated with this token count."
},
"tokenCount":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Number of tokens.",
"title":"Tokencount"
}
},
"title":"ModalityTokenCount",
"type":"object"
},
"TrafficType":{
"description":"Output only.\n\nTraffic type. This shows whether a request consumes Pay-As-You-Go or\nProvisioned Throughput quota.",
"enum":[
"TRAFFIC_TYPE_UNSPECIFIED",
"ON_DEMAND",
"PROVISIONED_THROUGHPUT"
],
"title":"TrafficType",
"type":"string"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `cache_tokens_details (list[genai.types.ModalityTokenCount] | None)`
  * `cached_content_token_count (int | None)`
  * `prompt_token_count (int | None)`
  * `prompt_tokens_details (list[genai.types.ModalityTokenCount] | None)`
  * `response_token_count (int | None)`
  * `response_tokens_details (list[genai.types.ModalityTokenCount] | None)`
  * `thoughts_token_count (int | None)`
  * `tool_use_prompt_token_count (int | None)`
  * `tool_use_prompt_tokens_details (list[genai.types.ModalityTokenCount] | None)`
  * `total_token_count (int | None)`
  * `traffic_type (genai.types.TrafficType | None)`



_field_ cache_tokens_details _:`Optional`[`list`[`ModalityTokenCount`]]__= None_ _(alias 'cacheTokensDetails')_¶ 
    
List of modalities that were processed in the cache input. 

_field_ cached_content_token_count _:`Optional`[`int`]__= None_ _(alias 'cachedContentTokenCount')_¶ 
    
Number of tokens in the cached part of the prompt (the cached content). 

_field_ prompt_token_count _:`Optional`[`int`]__= None_ _(alias 'promptTokenCount')_¶ 
    
Number of tokens in the prompt. When cached_content is set, this is still the total effective prompt size meaning this includes the number of tokens in the cached content. 

_field_ prompt_tokens_details _:`Optional`[`list`[`ModalityTokenCount`]]__= None_ _(alias 'promptTokensDetails')_¶ 
    
List of modalities that were processed in the request input. 

_field_ response_token_count _:`Optional`[`int`]__= None_ _(alias 'responseTokenCount')_¶ 
    
Total number of tokens across all the generated response candidates. 

_field_ response_tokens_details _:`Optional`[`list`[`ModalityTokenCount`]]__= None_ _(alias 'responseTokensDetails')_¶ 
    
List of modalities that were returned in the response. 

_field_ thoughts_token_count _:`Optional`[`int`]__= None_ _(alias 'thoughtsTokenCount')_¶ 
    
Number of tokens of thoughts for thinking models. 

_field_ tool_use_prompt_token_count _:`Optional`[`int`]__= None_ _(alias 'toolUsePromptTokenCount')_¶ 
    
Number of tokens present in tool-use prompt(s). 

_field_ tool_use_prompt_tokens_details _:`Optional`[`list`[`ModalityTokenCount`]]__= None_ _(alias 'toolUsePromptTokensDetails')_¶ 
    
List of modalities that were processed in the tool-use prompt. 

_field_ total_token_count _:`Optional`[`int`]__= None_ _(alias 'totalTokenCount')_¶ 
    
Total token count for prompt, response candidates, and tool-use prompts(if present). 

_field_ traffic_type _:`Optional`[`TrafficType`]__= None_ _(alias 'trafficType')_¶ 
    
Traffic type. This shows whether a request consumes Pay-As-You-Go or Provisioned Throughput quota. 

_class_ genai.types.UsageMetadataDict¶ 
    
Bases: `TypedDict`
Usage metadata about response(s). 

cache_tokens_details _:`Optional`[`list`[`ModalityTokenCountDict`]]_¶ 
    
List of modalities that were processed in the cache input. 

cached_content_token_count _:`Optional`[`int`]_¶ 
    
Number of tokens in the cached part of the prompt (the cached content). 

prompt_token_count _:`Optional`[`int`]_¶ 
    
Number of tokens in the prompt. When cached_content is set, this is still the total effective prompt size meaning this includes the number of tokens in the cached content. 

prompt_tokens_details _:`Optional`[`list`[`ModalityTokenCountDict`]]_¶ 
    
List of modalities that were processed in the request input. 

response_token_count _:`Optional`[`int`]_¶ 
    
Total number of tokens across all the generated response candidates. 

response_tokens_details _:`Optional`[`list`[`ModalityTokenCountDict`]]_¶ 
    
List of modalities that were returned in the response. 

thoughts_token_count _:`Optional`[`int`]_¶ 
    
Number of tokens of thoughts for thinking models. 

tool_use_prompt_token_count _:`Optional`[`int`]_¶ 
    
Number of tokens present in tool-use prompt(s). 

tool_use_prompt_tokens_details _:`Optional`[`list`[`ModalityTokenCountDict`]]_¶ 
    
List of modalities that were processed in the tool-use prompt. 

total_token_count _:`Optional`[`int`]_¶ 
    
Total token count for prompt, response candidates, and tool-use prompts(if present). 

traffic_type _:`Optional`[`TrafficType`]_¶ 
    
Traffic type. This shows whether a request consumes Pay-As-You-Go or Provisioned Throughput quota. 

_pydantic model_genai.types.UserContent¶ 
    
Bases: `Content`
UserContent facilitates the creation of a Content object with a user role.
Example usages:
  * Create a user Content object with a string: user_content = UserContent(“Why is the sky blue?”)
  * Create a user Content object with a file data Part object: user_content = UserContent(Part.from_uri(file_uril=”gs://bucket/file.txt”, mime_type=”text/plain”))
  * Create a user Content object with byte data Part object: user_content = UserContent(Part.from_bytes(data=b”Hello, World!”, mime_type=”text/plain”))
You can create a user Content object using other classmethods in the Part class as well. You can also create a user Content using a list of Part objects or strings.


Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"UserContent",
"description":"UserContent facilitates the creation of a Content object with a user role.\n\nExample usages:\n\n\n- Create a user Content object with a string:\n  user_content = UserContent(\"Why is the sky blue?\")\n- Create a user Content object with a file data Part object:\n  user_content = UserContent(Part.from_uri(file_uril=\"gs://bucket/file.txt\",\n  mime_type=\"text/plain\"))\n- Create a user Content object with byte data Part object:\n  user_content = UserContent(Part.from_bytes(data=b\"Hello, World!\",\n  mime_type=\"text/plain\"))\n\n  You can create a user Content object using other classmethods in the Part\n  class as well.\n  You can also create a user Content using a list of Part objects or strings.",
"type":"object",
"properties":{
"parts":{
"items":{
"$ref":"#/$defs/Part"
},
"title":"Parts",
"type":"array"
},
"role":{
"const":"user",
"default":"user",
"enum":[
"user"
],
"title":"Role",
"type":"string"
}
},
"$defs":{
"Blob":{
"additionalProperties":false,
"description":"Content blob.",
"properties":{
"displayName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.",
"title":"Displayname"
},
"data":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Raw bytes.",
"title":"Data"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"Blob",
"type":"object"
},
"CodeExecutionResult":{
"additionalProperties":false,
"description":"Result of executing the [ExecutableCode].\n\nAlways follows a `part` containing the [ExecutableCode].",
"properties":{
"outcome":{
"anyOf":[
{
"$ref":"#/$defs/Outcome"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Outcome of the code execution."
},
"output":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.",
"title":"Output"
}
},
"title":"CodeExecutionResult",
"type":"object"
},
"ExecutableCode":{
"additionalProperties":false,
"description":"Code generated by the model that is meant to be executed, and the result returned to the model.\n\nGenerated when using the [FunctionDeclaration] tool and\n[FunctionCallingConfig] mode is set to [Mode.CODE].",
"properties":{
"code":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The code to be executed.",
"title":"Code"
},
"language":{
"anyOf":[
{
"$ref":"#/$defs/Language"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. Programming language of the `code`."
}
},
"title":"ExecutableCode",
"type":"object"
},
"FileData":{
"additionalProperties":false,
"description":"URI based data.",
"properties":{
"fileUri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. URI.",
"title":"Fileuri"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The IANA standard MIME type of the source data.",
"title":"Mimetype"
}
},
"title":"FileData",
"type":"object"
},
"FunctionCall":{
"additionalProperties":false,
"description":"A function call.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`.",
"title":"Id"
},
"args":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.",
"title":"Args"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name].",
"title":"Name"
}
},
"title":"FunctionCall",
"type":"object"
},
"FunctionResponse":{
"additionalProperties":false,
"description":"A function response.",
"properties":{
"id":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The id of the function call this response is for. Populated by the client\n   to match the corresponding function call `id`.",
"title":"Id"
},
"name":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].",
"title":"Name"
},
"response":{
"anyOf":[
{
"type":"object"
},
{
"type":"null"
}
],
"default":null,
"description":"Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output.",
"title":"Response"
}
},
"title":"FunctionResponse",
"type":"object"
},
"Language":{
"description":"Required. Programming language of the `code`.",
"enum":[
"LANGUAGE_UNSPECIFIED",
"PYTHON"
],
"title":"Language",
"type":"string"
},
"Outcome":{
"description":"Required. Outcome of the code execution.",
"enum":[
"OUTCOME_UNSPECIFIED",
"OUTCOME_OK",
"OUTCOME_FAILED",
"OUTCOME_DEADLINE_EXCEEDED"
],
"title":"Outcome",
"type":"string"
},
"Part":{
"additionalProperties":false,
"description":"A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid.",
"properties":{
"videoMetadata":{
"anyOf":[
{
"$ref":"#/$defs/VideoMetadata"
},
{
"type":"null"
}
],
"default":null,
"description":"Metadata for a given video."
},
"thought":{
"anyOf":[
{
"type":"boolean"
},
{
"type":"null"
}
],
"default":null,
"description":"Indicates if the part is thought from the model.",
"title":"Thought"
},
"inlineData":{
"anyOf":[
{
"$ref":"#/$defs/Blob"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Inlined bytes data."
},
"codeExecutionResult":{
"anyOf":[
{
"$ref":"#/$defs/CodeExecutionResult"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Result of executing the [ExecutableCode]."
},
"executableCode":{
"anyOf":[
{
"$ref":"#/$defs/ExecutableCode"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Code generated by the model that is meant to be executed."
},
"fileData":{
"anyOf":[
{
"$ref":"#/$defs/FileData"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. URI based data."
},
"functionCall":{
"anyOf":[
{
"$ref":"#/$defs/FunctionCall"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values."
},
"functionResponse":{
"anyOf":[
{
"$ref":"#/$defs/FunctionResponse"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model."
},
"text":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Text part (can be code).",
"title":"Text"
}
},
"title":"Part",
"type":"object"
},
"VideoMetadata":{
"additionalProperties":false,
"description":"Metadata describes the input video content.",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"title":"VideoMetadata",
"type":"object"
}
},
"additionalProperties":false,
"required":[
"parts"
]
}

```


Fields: 
    
  * `parts (list[genai.types.Part])`
  * `role (Literal['user'])`



_field_ parts _:`list`[`Part`]__[Required]_¶ 


_field_ role _:`Literal`[`'user'`]__= 'user'_¶ 


_pydantic model_genai.types.VertexAISearch¶ 
    
Bases: `BaseModel`
Retrieve from Vertex AI Search datastore or engine for grounding.
datastore and engine are mutually exclusive. See https://cloud.google.com/products/agent-builder
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"VertexAISearch",
"description":"Retrieve from Vertex AI Search datastore or engine for grounding.\n\ndatastore and engine are mutually exclusive. See\nhttps://cloud.google.com/products/agent-builder",
"type":"object",
"properties":{
"datastore":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search data store resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`",
"title":"Datastore"
},
"engine":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Fully-qualified Vertex AI Search engine resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}`",
"title":"Engine"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `datastore (str | None)`
  * `engine (str | None)`



_field_ datastore _:`Optional`[`str`]__= None_¶ 
    
Optional. Fully-qualified Vertex AI Search data store resource ID. Format: projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore} 

_field_ engine _:`Optional`[`str`]__= None_¶ 
    
Optional. Fully-qualified Vertex AI Search engine resource ID. Format: projects/{project}/locations/{location}/collections/{collection}/engines/{engine} 

_class_ genai.types.VertexAISearchDict¶ 
    
Bases: `TypedDict`
Retrieve from Vertex AI Search datastore or engine for grounding.
datastore and engine are mutually exclusive. See https://cloud.google.com/products/agent-builder 

datastore _:`Optional`[`str`]_¶ 
    
projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore} 

Type: 
    
Optional. Fully-qualified Vertex AI Search data store resource ID. Format 

engine _:`Optional`[`str`]_¶ 
    
projects/{project}/locations/{location}/collections/{collection}/engines/{engine} 

Type: 
    
Optional. Fully-qualified Vertex AI Search engine resource ID. Format 

_pydantic model_genai.types.VertexRagStore¶ 
    
Bases: `BaseModel`
Retrieve from Vertex RAG Store for grounding.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"VertexRagStore",
"description":"Retrieve from Vertex RAG Store for grounding.",
"type":"object",
"properties":{
"ragCorpora":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Deprecated. Please use rag_resources instead.",
"title":"Ragcorpora"
},
"ragResources":{
"anyOf":[
{
"items":{
"$ref":"#/$defs/VertexRagStoreRagResource"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The representation of the rag source. It can be used to specify corpus only or ragfiles. Currently only support one corpus or multiple files from one corpus. In the future we may open up multiple corpora support.",
"title":"Ragresources"
},
"ragRetrievalConfig":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The retrieval config for the Rag query."
},
"similarityTopK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Number of top k results to return from the selected corpora.",
"title":"Similaritytopk"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only return results with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
}
},
"$defs":{
"RagRetrievalConfig":{
"additionalProperties":false,
"description":"Specifies the context retrieval config.",
"properties":{
"filter":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigFilter"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for filters."
},
"hybridSearch":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigHybridSearch"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Hybrid Search."
},
"ranking":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRanking"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for ranking and reranking."
},
"topK":{
"anyOf":[
{
"type":"integer"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The number of contexts to retrieve.",
"title":"Topk"
}
},
"title":"RagRetrievalConfig",
"type":"object"
},
"RagRetrievalConfigFilter":{
"additionalProperties":false,
"description":"Config for filters.",
"properties":{
"metadataFilter":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. String for metadata filtering.",
"title":"Metadatafilter"
},
"vectorDistanceThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector distance smaller than the threshold.",
"title":"Vectordistancethreshold"
},
"vectorSimilarityThreshold":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Only returns contexts with vector similarity larger than the threshold.",
"title":"Vectorsimilaritythreshold"
}
},
"title":"RagRetrievalConfigFilter",
"type":"object"
},
"RagRetrievalConfigHybridSearch":{
"additionalProperties":false,
"description":"Config for Hybrid Search.",
"properties":{
"alpha":{
"anyOf":[
{
"type":"number"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally.",
"title":"Alpha"
}
},
"title":"RagRetrievalConfigHybridSearch",
"type":"object"
},
"RagRetrievalConfigRanking":{
"additionalProperties":false,
"description":"Config for ranking and reranking.",
"properties":{
"llmRanker":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingLlmRanker"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for LlmRanker."
},
"rankService":{
"anyOf":[
{
"$ref":"#/$defs/RagRetrievalConfigRankingRankService"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. Config for Rank Service."
}
},
"title":"RagRetrievalConfigRanking",
"type":"object"
},
"RagRetrievalConfigRankingLlmRanker":{
"additionalProperties":false,
"description":"Config for LlmRanker.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name used for ranking. Format: `gemini-1.5-pro`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingLlmRanker",
"type":"object"
},
"RagRetrievalConfigRankingRankService":{
"additionalProperties":false,
"description":"Config for Rank Service.",
"properties":{
"modelName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The model name of the rank service. Format: `semantic-ranker-512@latest`",
"title":"Modelname"
}
},
"title":"RagRetrievalConfigRankingRankService",
"type":"object"
},
"VertexRagStoreRagResource":{
"additionalProperties":false,
"description":"The definition of the Rag resource.",
"properties":{
"ragCorpus":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. RagCorpora resource name. Format: `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`",
"title":"Ragcorpus"
},
"ragFileIds":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus field.",
"title":"Ragfileids"
}
},
"title":"VertexRagStoreRagResource",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `rag_corpora (list[str] | None)`
  * `rag_resources (list[genai.types.VertexRagStoreRagResource] | None)`
  * `rag_retrieval_config (genai.types.RagRetrievalConfig | None)`
  * `similarity_top_k (int | None)`
  * `vector_distance_threshold (float | None)`



_field_ rag_corpora _:`Optional`[`list`[`str`]]__= None_ _(alias 'ragCorpora')_¶ 
    
Optional. Deprecated. Please use rag_resources instead. 

_field_ rag_resources _:`Optional`[`list`[`VertexRagStoreRagResource`]]__= None_ _(alias 'ragResources')_¶ 
    
Optional. The representation of the rag source. It can be used to specify corpus only or ragfiles. Currently only support one corpus or multiple files from one corpus. In the future we may open up multiple corpora support. 

_field_ rag_retrieval_config _:`Optional`[`RagRetrievalConfig`]__= None_ _(alias 'ragRetrievalConfig')_¶ 
    
Optional. The retrieval config for the Rag query. 

_field_ similarity_top_k _:`Optional`[`int`]__= None_ _(alias 'similarityTopK')_¶ 
    
Optional. Number of top k results to return from the selected corpora. 

_field_ vector_distance_threshold _:`Optional`[`float`]__= None_ _(alias 'vectorDistanceThreshold')_¶ 
    
Optional. Only return results with vector distance smaller than the threshold. 

_class_ genai.types.VertexRagStoreDict¶ 
    
Bases: `TypedDict`
Retrieve from Vertex RAG Store for grounding. 

rag_corpora _:`Optional`[`list`[`str`]]_¶ 
    
Optional. Deprecated. Please use rag_resources instead. 

rag_resources _:`Optional`[`list`[`VertexRagStoreRagResourceDict`]]_¶ 
    
Optional. The representation of the rag source. It can be used to specify corpus only or ragfiles. Currently only support one corpus or multiple files from one corpus. In the future we may open up multiple corpora support. 

rag_retrieval_config _:`Optional`[`RagRetrievalConfigDict`]_¶ 
    
Optional. The retrieval config for the Rag query. 

similarity_top_k _:`Optional`[`int`]_¶ 
    
Optional. Number of top k results to return from the selected corpora. 

vector_distance_threshold _:`Optional`[`float`]_¶ 
    
Optional. Only return results with vector distance smaller than the threshold. 

_pydantic model_genai.types.VertexRagStoreRagResource¶ 
    
Bases: `BaseModel`
The definition of the Rag resource.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"VertexRagStoreRagResource",
"description":"The definition of the Rag resource.",
"type":"object",
"properties":{
"ragCorpus":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. RagCorpora resource name. Format: `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`",
"title":"Ragcorpus"
},
"ragFileIds":{
"anyOf":[
{
"items":{
"type":"string"
},
"type":"array"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus field.",
"title":"Ragfileids"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `rag_corpus (str | None)`
  * `rag_file_ids (list[str] | None)`



_field_ rag_corpus _:`Optional`[`str`]__= None_ _(alias 'ragCorpus')_¶ 
    
Optional. RagCorpora resource name. Format: projects/{project}/locations/{location}/ragCorpora/{rag_corpus} 

_field_ rag_file_ids _:`Optional`[`list`[`str`]]__= None_ _(alias 'ragFileIds')_¶ 
    
Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus field. 

_class_ genai.types.VertexRagStoreRagResourceDict¶ 
    
Bases: `TypedDict`
The definition of the Rag resource. 

rag_corpus _:`Optional`[`str`]_¶ 
    
projects/{project}/locations/{location}/ragCorpora/{rag_corpus} 

Type: 
    
Optional. RagCorpora resource name. Format 

rag_file_ids _:`Optional`[`list`[`str`]]_¶ 
    
Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus field. 

_pydantic model_genai.types.Video¶ 
    
Bases: `BaseModel`
A generated video.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"Video",
"description":"A generated video.",
"type":"object",
"properties":{
"uri":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Path to another storage.",
"title":"Uri"
},
"videoBytes":{
"anyOf":[
{
"format":"base64url",
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Video bytes.",
"title":"Videobytes"
},
"mimeType":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Video encoding, for example \"video/mp4\".",
"title":"Mimetype"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `mime_type (str | None)`
  * `uri (str | None)`
  * `video_bytes (bytes | None)`



_field_ mime_type _:`Optional`[`str`]__= None_ _(alias 'mimeType')_¶ 
    
Video encoding, for example “video/mp4”. 

_field_ uri _:`Optional`[`str`]__= None_¶ 
    
Path to another storage. 

_field_ video_bytes _:`Optional`[`bytes`]__= None_ _(alias 'videoBytes')_¶ 
    
Video bytes. 

save(_path_)¶ 
    
Saves the video to a file. 

Return type: 
    
`None` 

Parameters: 
    
**path** – Local path where to save the video. 

show()¶ 
    
Shows the video.
If the video has no mime_type, it is assumed to be video/mp4.
This method only works in a notebook environment. 

Return type: 
    
`None` 

_class_ genai.types.VideoDict¶ 
    
Bases: `TypedDict`
A generated video. 

mime_type _:`Optional`[`str`]_¶ 
    
Video encoding, for example “video/mp4”. 

uri _:`Optional`[`str`]_¶ 
    
Path to another storage. 

video_bytes _:`Optional`[`bytes`]_¶ 
    
Video bytes. 

_pydantic model_genai.types.VideoMetadata¶ 
    
Bases: `BaseModel`
Metadata describes the input video content.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"VideoMetadata",
"description":"Metadata describes the input video content.",
"type":"object",
"properties":{
"endOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The end offset of the video.",
"title":"Endoffset"
},
"startOffset":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"Optional. The start offset of the video.",
"title":"Startoffset"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `end_offset (str | None)`
  * `start_offset (str | None)`



_field_ end_offset _:`Optional`[`str`]__= None_ _(alias 'endOffset')_¶ 
    
Optional. The end offset of the video. 

_field_ start_offset _:`Optional`[`str`]__= None_ _(alias 'startOffset')_¶ 
    
Optional. The start offset of the video. 

_class_ genai.types.VideoMetadataDict¶ 
    
Bases: `TypedDict`
Metadata describes the input video content. 

end_offset _:`Optional`[`str`]_¶ 
    
Optional. The end offset of the video. 

start_offset _:`Optional`[`str`]_¶ 
    
Optional. The start offset of the video. 

_pydantic model_genai.types.VoiceConfig¶ 
    
Bases: `BaseModel`
The configuration for the voice to use.
Create a new model by parsing and validating input data from keyword arguments.
Raises [ValidationError][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.
self is explicitly positional-only to allow self as a field name.
Show JSON schema
```
{
"title":"VoiceConfig",
"description":"The configuration for the voice to use.",
"type":"object",
"properties":{
"prebuiltVoiceConfig":{
"anyOf":[
{
"$ref":"#/$defs/PrebuiltVoiceConfig"
},
{
"type":"null"
}
],
"default":null,
"description":"The configuration for the speaker to use.\n      "
}
},
"$defs":{
"PrebuiltVoiceConfig":{
"additionalProperties":false,
"description":"The configuration for the prebuilt speaker to use.",
"properties":{
"voiceName":{
"anyOf":[
{
"type":"string"
},
{
"type":"null"
}
],
"default":null,
"description":"The name of the prebuilt voice to use.\n      ",
"title":"Voicename"
}
},
"title":"PrebuiltVoiceConfig",
"type":"object"
}
},
"additionalProperties":false
}

```


Fields: 
    
  * `prebuilt_voice_config (genai.types.PrebuiltVoiceConfig | None)`



_field_ prebuilt_voice_config _:`Optional`[`PrebuiltVoiceConfig`]__= None_ _(alias 'prebuiltVoiceConfig')_¶ 
    
The configuration for the speaker to use. 

_class_ genai.types.VoiceConfigDict¶ 
    
Bases: `TypedDict`
The configuration for the voice to use. 

prebuilt_voice_config _:`Optional`[`PrebuiltVoiceConfigDict`]_¶ 
    
The configuration for the speaker to use.
Previous
Home
Copyright © 2024, Google 
Made with Sphinx and @pradyunsg's Furo
  *[*]: Keyword-only parameters separator (PEP 3102)
  *[/]: Positional-only parameter separator (PEP 570)


---

# 404
**File not found**
The site configured at this address does not contain the requested file. 
If this is your site, make sure that the filename case matches the URL as well as any file permissions.  
For root URLs (like `http://example.com/`) you must provide an `index.html` file. 
Read the full documentation for more information about using **GitHub Pages**. 
GitHub Status — @githubstatus


---

# 404
**File not found**
The site configured at this address does not contain the requested file. 
If this is your site, make sure that the filename case matches the URL as well as any file permissions.  
For root URLs (like `http://example.com/`) you must provide an `index.html` file. 
Read the full documentation for more information about using **GitHub Pages**. 
GitHub Status — @githubstatus
