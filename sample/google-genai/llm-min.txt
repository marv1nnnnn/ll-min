#META#L:googleapis_github_io_python-genai_#V:1.0#D:2025-05-12T12:42:18Z#
#SCHEMA#A:id;B:typ;C:name;D:purp;E:in;F:out;G:use;H:rel;I:src#IN:a:p;b:t;c:d;d:def;e:ex#OUT:f:f;g:t;h:d#REL:i:id;j:typ#
```json
["feat1","Feat","google-genai library","Provides a Python interface to Google's Generative AI APIs (Gemini, Vertex AI).","[]","[]","pip install google-genai","[]","chunk_0"]
["feat2","Feat","Gemini Developer API","One of the Generative AI APIs supported by the SDK.","[]","[]","","[[\"feat1\",\"Feat\"]]","chunk_0"]
["feat3","Feat","Vertex AI API","One of the Generative AI APIs supported by the SDK.","[]","[]","","[[\"feat1\",\"Feat\"]]","chunk_0"]
["feat4","Feat","API Version Selection","Allows selecting stable or preview API endpoints via http_options.","[[p,t,http_options,null,\"HTTP options including api_version\"]]","[]","","[[\"cfgobj1\",\"CfgObj\"],[\"cfgobj2\",\"CfgObj\"]]","chunk_0"]
["feat5","Feat","Using Type Objects","Parameter types can be specified using Pydantic models from the `types` module or dictionaries.","[]","[]","","[[\"cfgobj3\",\"CfgObj\"]]","chunk_0"]
["feat6","Feat","Contents Argument Structure","Describes the various accepted formats for the `contents` parameter in generation methods (string, list, various Part types).","[[p,t,contents,null,\"Various input types like string, list[str], types.Content, list[types.ContentUnion], types.Part\"]]","[]","","[[\"func1\",\"Func\"],[\"func2\",\"Func\"],[\"cfgobj45\",\"CfgObj\"]]","chunk_0"]
["feat7","Feat","Generation Configuration","Optional settings like temperature, max_output_tokens, system_instruction, etc., to influence model output, including routing and thinking.","[[p,t,config,null,\"Generation configuration object or dict\"]]","[]","","[[\"func1\",\"Func\"],[\"func2\",\"Func\"],[\"cfgobj5\",\"CfgObj\"],[\"cfgobj27\",\"CfgObj\"],[\"cfgobj41\",\"CfgObj\"],[\"cfgobj66\",\"CfgObj\"]]","chunk_1"]
["feat8","Feat","Safety Settings","Configure content safety filtering thresholds for different harm categories.","[[p,t,config,null,\"GenerateContentConfig with safety_settings\"]]","[]","","[[\"func1\",\"Func\"],[\"func2\",\"Func\"],[\"cfgobj5\",\"CfgObj\"],[\"cfgobj6\",\"CfgObj\"]]","chunk_0"]
["feat9","Feat","Function Calling","Allows the model to call external functions provided by the user, including automated code execution.","[[p,t,tools,null,\"List of tool definitions (functions or Tool objects)\"]]","[o,t,FunctionCall,\"Predicted function call from the model\"]","","[[\"func1\",\"Func\"],[\"func2\",\"Func\"],[\"func4\",\"Func\"],[\"cfgobj8\",\"CfgObj\"],[\"cfgobj25\",\"CfgObj\"],[\"cfgobj26\",\"CfgObj\"],[\"cfgobj35\",\"CfgObj\"],[\"cfgobj46\",\"CfgObj\"],[\"cfgobj47\",\"CfgObj\"],[\"cfgobj62\",\"CfgObj\"],[\"cfgobj63\",\"CfgObj\"],[\"cfgobj53\",\"CfgObj\"]]","chunk_1"]
["feat10","Feat","JSON Response Schema","Allows specifying a JSON schema (`types.Schema`) for the model's text output using `application/json` mime type.","[[p,t,config,null,\"Config with response_mime_type and response_schema\"]]","[o,t,str,\"JSON string output\"]","","[[\"func1\",\"Func\"],[\"func2\",\"Func\"],[\"cfgobj5\",\"CfgObj\"],[\"cfgobj9\",\"CfgObj\"]]","chunk_1"]
["feat11","Feat","Enum Response Schema","Allows the model to return a single value from a specified Enum (`types.Schema` derived) using `text/x.enum` mime type.","[[p,t,config,null,\"Config with response_mime_type and response_schema (Enum)\"]]","[o,t,str,\"Plain text enum value\"]","","[[\"func1\",\"Func\"],[\"func2\",\"Func\"],[\"cfgobj5\",\"CfgObj\"],[\"cfgobj9\",\"CfgObj\"],[\"cfgobj48\",\"CfgObj\"]]","chunk_1"]
["feat12","Feat","Async Operations","Provides asynchronous versions of API methods under `client.aio`.","[]","[]","client.aio","[[\"cfgobj1\",\"CfgObj\"],[\"cfgobj12\",\"CfgObj\"]]","chunk_0"]
["feat13","Feat","Imagen (Image Generation & Editing)","Allows generating, upscaling, and editing images (Allowlisted / Vertex AI), using reference images and masks.","[]","[]","","[[\"cfgobj4\",\"CfgObj\"],[\"cfgobj104\",\"CfgObj\"],[\"cfgobj110\",\"CfgObj\"],[\"cfgobj118\",\"CfgObj\"],[\"cfgobj119\",\"CfgObj\"],[\"cfgobj120\",\"CfgObj\"],[\"cfgobj121\",\"CfgObj\"]]","chunk_1"]
["feat14","Feat","Veo (Video Generation)","Allows generating videos from text or images (Allowlisted). Operations API used to poll status.","[]","[]","","[[\"cfgobj4\",\"CfgObj\"],[\"cfgobj111\",\"CfgObj\"],[\"cfgobj105\",\"CfgObj\"],[\"cfgobj13\",\"CfgObj\"]]","chunk_1"]
["feat15","Feat","Chat Sessions","Allows for multi-turn conversations with the model.","[]","[]","","[[\"cfgobj1\",\"CfgObj\"],[\"cfgobj14\",\"CfgObj\"]]","chunk_0"]
["feat16","Feat","File Management","Allows uploading, retrieving, and deleting files (Gemini Developer API only), represented by the `types.File` object.","[]","[]","","[[\"cfgobj1\",\"CfgObj\"],[\"feat2\",\"Feat\"],[\"cfgobj15\",\"CfgObj\"],[\"cfgobj20\",\"CfgObj\"]]","chunk_1"]
["feat17","Feat","Cached Content","Allows caching content to improve latency for repeated queries (control plane APIs), managed via `client.caches` module.","[]","[]","","[[\"cfgobj1\",\"CfgObj\"],[\"cfgobj16\",\"CfgObj\"],[\"cfgobj106\",\"CfgObj\"]]","chunk_1"]
["feat18","Feat","Model Tuning","Supports supervised fine-tuning (SFT) and distillation for models, managed via `client.tunings`.","[]","[]","","[[\"cfgobj1\",\"CfgObj\"],[\"cfgobj17\",\"CfgObj\"],[\"cfgobj92\",\"CfgObj\"],[\"cfgobj98\",\"CfgObj\"],[\"cfgobj100\",\"CfgObj\"]]","chunk_1"]
["feat19","Feat","Batch Prediction","Allows performing predictions on a large dataset (Vertex AI only).","[]","[]","","[[\"cfgobj1\",\"CfgObj\"],[\"feat3\",\"Feat\"],[\"cfgobj18\",\"CfgObj\"]]","chunk_0"]
["feat20","Feat","API Error Handling","Provides a specific exception class (`errors.APIError`) and uses `google.rpc.Status` for handling errors from API calls.","[]","[]","","[[\"cfgobj1\",\"CfgObj\"],[\"cfgobj19\",\"CfgObj\"],[\"cfgobj103\",\"CfgObj\"]]","chunk_1"]
["feat21","Feat","Live API / Bidirectional Streaming","Interact with the model in realtime using a bidirectional stream for conversational AI, supporting continuous input (audio, video, text) and incremental responses.","[]","[]","","[[\"cfgobj1\",\"CfgObj\"],[\"cfgobj49\",\"CfgObj\"],[\"cfgobj57\",\"CfgObj\"]]","chunk_1"]
["feat22","Feat","Code Execution Tool","Enables the model to generate and execute code (`types.ExecutableCode`) and receive the results (`types.CodeExecutionResult`) as part of the function calling flow.","[]","[]","","[[\"cfgobj8\",\"CfgObj\"],[\"cfgobj35\",\"CfgObj\"],[\"cfgobj46\",\"CfgObj\"],[\"cfgobj47\",\"CfgObj\"],[\"feat9\",\"Feat\"]]","chunk_1"]
["feat23","Feat","Retrieval Tools","Allows the model to access external knowledge sources (Vertex AI Search, Vertex RAG Store, Google Search, Google Maps, Enterprise Web Search).","[]","[]","","[[\"cfgobj8\",\"CfgObj\"],[\"cfgobj30\",\"CfgObj\"]]","chunk_1"]
["feat24","Feat","Context Window Compression","Automatically manages chat history length (`types.ContextWindowCompressionConfig`) using methods like sliding windows.","[]","[]","","[[\"feat21\",\"Feat\"],[\"cfgobj54\",\"CfgObj\"],[\"cfgobj52\",\"CfgObj\"],[\"cfgobj38\",\"CfgObj\"]]","chunk_1"]
["feat25","Feat","Session Resumption","Allows resuming previous Live API sessions (`types.SessionResumptionConfig`) using a session handle.","[]","[]","","[[\"feat21\",\"Feat\"],[\"cfgobj54\",\"CfgObj\"],[\"cfgobj52\",\"CfgObj\"],[\"cfgobj37\",\"CfgObj\"],[\"cfgobj60\",\"CfgObj\"]]","chunk_1"]
["feat26","Feat","Realtime Input Configuration","Configure how realtime input (audio, video, text) is processed in Live API using `types.RealtimeInputConfig`, including activity detection.","[]","[]","","[[\"feat21\",\"Feat\"],[\"cfgobj54\",\"CfgObj\"],[\"cfgobj52\",\"CfgObj\"],[\"cfgobj51\",\"CfgObj\"],[\"cfgobj40\",\"CfgObj\"]]","chunk_1"]
["feat27","Feat","Audio Transcription","Transcribe input and output audio streams within the Live API using transcription configurations.","[]","[]","","[[\"feat21\",\"Feat\"],[\"cfgobj54\",\"CfgObj\"],[\"cfgobj52\",\"CfgObj\"],[\"cfgobj79\",\"CfgObj\"]]","chunk_1"]
["feat28","Feat","Speech Synthesis","Generate speech output from the model's text response in the Live API using speech configurations.","[]","[]","","[[\"feat21\",\"Feat\"],[\"cfgobj54\",\"CfgObj\"],[\"cfgobj52\",\"CfgObj\"],[\"cfgobj41\",\"CfgObj\"]]","chunk_1"]
["feat29","Feat","Usage Metadata","Obtain detailed token counts (prompt, response, tool use, cache, thoughts) and traffic type (`types.UsageMetadata`) for API calls.","[]","[]","","[[\"cfgobj73\",\"CfgObj\"]]","chunk_1"]
["feat30","Feat","Log Probability Output","Obtain token log probabilities (`types.LogprobsResult`) from the model response by enabling the logprobs option in generation config.","[]","[]","","[[\"feat7\",\"Feat\"],[\"cfgobj5\",\"CfgObj\"],[\"cfgobj80\",\"CfgObj\"]]","chunk_1"]
["feat31","Feat","Image Editing Reference Configs","Configure reference images (mask, raw, style) and related parameters (`types.MaskReferenceConfig`, etc.) for image editing operations.","[]","[]","","[[\"feat13\",\"Feat\"],[\"cfgobj83\",\"CfgObj\"],[\"cfgobj87\",\"CfgObj\"],[\"cfgobj89\",\"CfgObj\"],[\"cfgobj82\",\"CfgObj\"],[\"cfgobj118\",\"CfgObj\"],[\"cfgobj120\",\"CfgObj\"],[\"cfgobj121\",\"CfgObj\"]]","chunk_1"]
["feat32","Feat","Distillation Tuning","Tune a smaller student model using a larger teacher model via distillation.","[]","[]","","[[\"feat18\",\"Feat\"],[\"cfgobj92\",\"CfgObj\"],[\"cfgobj98\",\"CfgObj\"]]","chunk_1"]
["feat33","Feat","Partner Model Tuning","Supports fine-tuning for partner models.","[]","[]","","[[\"feat18\",\"Feat\"],[\"cfgobj92\",\"CfgObj\"],[\"cfgobj100\",\"CfgObj\"]]","chunk_1"]
["feat34","Feat","Model Update Configuration","Configure updates for tuned models (`types.UpdateModelConfig`), such as display name or description.","[]","[]","","[[\"cfgobj107\",\"CfgObj\"]]","chunk_1"]
["feat35","Feat","Cached Content Update Configuration","Configure updates for cached content TTL using `types.UpdateCachedContentConfig`.","[]","[]","","[[\"feat17\",\"Feat\"],[\"cfgobj106\",\"CfgObj\"]]","chunk_1"]
["feat36","Feat","Upscale Image Configuration","Configure image upscaling parameters (`types.UpscaleImageConfig`) for Imagen upscaling operations.","[]","[]","","[[\"feat13\",\"Feat\"],[\"func14\",\"Func\"],[\"cfgobj109\",\"CfgObj\"],[\"cfgobj108\",\"CfgObj\"]]","chunk_1"]
["howto1","HowTo","Install google-genai","Install the library using pip.","[]","[]","pip install google-genai","[[\"feat1\",\"Feat\"]]", "chunk_0"]
["howto2","HowTo","Import genai modules","Import the main library and types.","[]","[]","from google import genai\nfrom google.genai import types", "[[\"feat1\",\"Feat\"],[\"cfgobj3\",\"CfgObj\"]]", "chunk_0"]
["howto3","HowTo","Create a Gemini Developer API client","Initialize the client using an API key.","[[p,t,api_key,null,\"API key\"]]","[o,t,genai.Client,\"Initialized client object\"]","client = genai.Client(api_key='GEMINI_API_KEY')","[[\"cfgobj1\",\"CfgObj\"],[\"feat2\",\"Feat\"]]", "chunk_0"]
["howto4","HowTo","Create a Vertex AI client","Initialize the client specifying vertexai=True, project, and location.","[[p,t,vertexai,T,\"\"],[p,t,project,null,\"\"],[p,t,location,null,\"\"]]","[o,t,genai.Client,\"Initialized client object\"]","client = genai.Client(\n vertexai=True, project='your-project-id', location='us-central1'\n)","[[\"cfgobj1\",\"CfgObj\"],[\"feat3\",\"Feat\"]]", "chunk_0"]
["howto5","HowTo","Create client using environment variables","Initialize client without explicit args if relevant env vars are set.","[]","[o,t,genai.Client,\"Initialized client object\"]","client = genai.Client()","[[\"cfgobj1\",\"CfgObj\"]]", "chunk_0"]
["howto6","HowTo","Set API version","Configure the API version using `http_options` (`types.HttpOptions`) during client creation.","[[p,t,api_version,null,\"API version string\"]]","[o,t,genai.Client,\"Client with specified API version\"]","client = genai.Client(\n vertexai=True, ...,\n http_options=types.HttpOptions(api_version='v1')\n)","[[\"feat4\",\"Feat\"],[\"cfgobj2\",\"CfgObj\"],[\"cfgobj1\",\"CfgObj\"]]", "chunk_0"]
["howto7","HowTo","Generate text content","Call `client.models.generate_content` with a model and a text string as contents.","[[p,t,model,null,\"\"],[p,t,contents,null,\"Text prompt\"]]","[o,t,GenerateContentResponse,\"Response object\"]","response = client.models.generate_content(\n model='gemini-2.0-flash-001', contents='Why is the sky blue?'\n)","[[\"func1\",\"Func\"]]", "chunk_0"]
["howto8","HowTo","Generate content with uploaded file","Upload a file using `client.files.upload` and include the returned file object (`types.File`) in the `contents` argument for `client.models.generate_content`.","[[p,t,model,null,\"\"],[p,t,contents,null,\"List containing text and file object (\",[\"cfgobj20\",\"CfgObj\"],\")\"]]","[o,t,GenerateContentResponse,\"Response object\"]","file = client.files.upload(file='a11.txt')\nresponse = client.models.generate_content(\n model='gemini-2.0-flash-001',\n contents=['Could you summarize this file?', file]\n)","[[\"func1\",\"Func\"],[\"func6\",\"Func\"],[\"feat16\",\"Feat\"],[\"cfgobj20\",\"CfgObj\"]]","chunk_1"]
["howto9","HowTo","Provide contents as string","Pass a simple text string directly to `contents`. SDK converts to `types.UserContent` (`cfgobj45`).","[[p,t,contents,null,\"Text string\"]]","[o,t,list[types.UserContent],\"Converted content list\"]","contents='Why is the sky blue?'","[[\"feat6\",\"Feat\"],[\"cfgobj45\",\"CfgObj\"]]", "chunk_1"]
["howto10","HowTo","Provide contents as list of strings","Pass a list of text strings. SDK converts each to `types.Part` and wraps in `types.UserContent` (`cfgobj45`).","[[p,t,contents,null,\"List of text strings\"]]","[o,t,list[types.UserContent],\"Converted content list\"]","contents=['Why is the sky blue?', 'Why is the cloud white?']","[[\"feat6\",\"Feat\"],[\"cfgobj45\",\"CfgObj\"]]", "chunk_1"]
["howto11","HowTo","Provide contents as function call part","Pass a `types.Part.from_function_call` (`cfgobj45`) instance. SDK converts to `types.ModelContent`.","[[p,t,contents,null,\"types.Part.from_function_call instance (\",[\"cfgobj45\",\"CfgObj\"],\")\"]]","[o,t,list[types.ModelContent],\"Converted content list\"]","contents = types.Part.from_function_call(\nname='get_weather_by_location', args={'location': 'Boston'}\n)","[[\"feat6\",\"Feat\"],[\"func5\",\"Func\"],[\"cfgobj45\",\"CfgObj\"]]", "chunk_1"]
["howto12","HowTo","Provide contents as non-function call part","Pass a non-function call `types.Part` (`cfgobj45`) instance (e.g., from_uri). SDK converts to `types.UserContent`.","[[p,t,contents,null,\"types.Part instance (\",[\"cfgobj45\",\"CfgObj\"],\"e.g., from_uri)\"]]","[o,t,list[types.UserContent],\"Converted content list\"]","contents = types.Part.from_uri(\nfile_uri: 'gs://...', mime_type: 'image/jpeg'\n)","[[\"feat6\",\"Feat\"],[\"func5\",\"Func\"],[\"cfgobj45\",\"CfgObj\"]]", "chunk_1"]
["howto13","HowTo","Use GenerationConfig object","Pass configuration parameters using a `types.GenerateContentConfig` (`cfgobj5`) instance in the `config` parameter.","[[p,t,config,null,\"types.GenerateContentConfig instance (\",[\"cfgobj5\",\"CfgObj\"],\")\"]]","[o,t,GenerateContentResponse,\"Response object\"]","response = client.models.generate_content(\n model='gemini-2.0-flash-001', contents='high',\n config=types.GenerateContentConfig(\n system_instruction='I say high, you say low',\n max_output_tokens=3, temperature=0.3,\n ),\n)","[[\"feat7\",\"Feat\"],[\"cfgobj5\",\"CfgObj\"]]", "chunk_1"]
["howto14","HowTo","Use Typed Config","Provide API method parameters using Pydantic types from `google.genai.types` (`cfgobj3`), such as `types.GenerateContentConfig` (`cfgobj5`).","[[p,t,config,null,\"Pydantic type instance (\",[\"cfgobj5\",\"CfgObj\"],\" or similar)\"]]","[]","config=types.GenerateContentConfig(\n temperature=0, top_p=0.95, top_k=20, candidate_count=1,\n seed=5, max_output_tokens=100, stop_sequences=['STOP!'],\n presence_penalty=0.0, frequency_penalty=0.0,\n)","[[\"feat5\",\"Feat\"],[\"cfgobj3\",\"CfgObj\"],[\"cfgobj5\",\"CfgObj\"]]", "chunk_1"]
["howto15","HowTo","List available models (sync)","Retrieve a list of available models (`types.Model`, `cfgobj104`) using `client.models.list()`.","[[p,t,config,null,\"Optional config like page_size\"]]","[o,t,Pager[Model],\"Iterable pager object yielding \",[\"cfgobj104\",\"CfgObj\"]]","for model in client.models.list():\n print(model)","[[\"cfgobj4\",\"CfgObj\"],[\"func3\",\"Func\"],[\"cfgobj104\",\"CfgObj\"]]", "chunk_1"]
["howto16","HowTo","Configure safety settings","Pass a list of `types.SafetySetting` (`cfgobj6`) objects in the `config` parameter to generate_content.","[[p,t,config,null,\"GenerateContentConfig (\",[\"cfgobj5\",\"CfgObj\"],\") with list of \",[\"cfgobj6\",\"CfgObj\"],\" instances\"]]","[o,t,GenerateContentResponse,\"Response object\"]","response = client.models.generate_content(\n model='gemini-2.0-flash-001', contents='Say something bad.',\n config=types.GenerateContentConfig(\n safety_settings=[\n types.SafetySetting(\n category='HARM_CATEGORY_HATE_SPEECH',\n threshold='BLOCK_ONLY_HIGH',\n )\n ]\n ),\n)","[[\"feat8\",\"Feat\"],[\"cfgobj5\",\"CfgObj\"],[\"cfgobj6\",\"CfgObj\"]]", "chunk_0"]
["howto17","HowTo","Enable automatic function calling","Pass Python functions directly in the `tools` parameter of `generate_content`. The SDK will automatically execute them.","[[p,t,tools,null,\"List of Python functions\"]]","[o,t,GenerateContentResponse,\"Response object (often contains text result of call)\"]","def get_current_weather(location: str) -> str: ...\nresponse = client.models.generate_content(\n model='gemini-2.0-flash-001',\n contents='What is the weather like in Boston?',\n config=types.GenerateContentConfig(\n tools=[get_current_weather],\n ),\n)","[[\"feat9\",\"Feat\"],[\"func1\",\"Func\"],[\"cfgobj5\",\"CfgObj\"]]", "chunk_0"]
["howto18","HowTo","Disable automatic function calling","Use `automatic_function_calling=types.AutomaticFunctionCallingConfig(disable=True)` (`cfgobj7`) in the config parameter of `generate_content`.","[[p,t,config,null,\"Config with automatic_function_calling disabled (\",[\"cfgobj7\",\"CfgObj\"],\")\"]]","[o,t,GenerateContentResponse,\"Response object with function_calls list\"]","response = client.models.generate_content(\n model='gemini-2.0-flash-001', ...,\n config=types.GenerateContentConfig(\n tools=[get_current_weather],\n automatic_function_calling=types.AutomaticFunctionCallingConfig(\n disable=True\n )\n ),\n)","[[\"feat9\",\"Feat\"],[\"func1\",\"Func\"],[\"cfgobj5\",\"CfgObj\"],[\"cfgobj7\",\"CfgObj\"]]", "chunk_0"]
["howto19","HowTo","Manually declare and invoke a function call","Define `types.FunctionDeclaration` (`func4`), wrap in `types.Tool` (`cfgobj8`), send in generate_content config. Process `response.function_calls` (`cfgobj25`), call function, send result using `types.Part.from_function_response` (`func5`).","[[p,t,function_declarations,null,\"List of \",[\"func4\",\"Func\"],\"\"],[p,t,response.function_calls,null,\"Model prediction (\",[\"cfgobj25\",\"CfgObj\"],\")\"],[p,t,function_response,null,\"Function call result\"]]","[o,t,GenerateContentResponse,\"Response containing function call prediction or model text\"]","function = types.FunctionDeclaration(...)\ntool = types.Tool(function_declarations=[function])\nresponse = client.models.generate_content(config=types.GenerateContentConfig(tools=[tool]), ...)\n# Then call function, get response_part = types.Part.from_function_response(...)\nresponse = client.models.generate_content(contents=[..., function_response_content], ...)","[[\"feat9\",\"Feat\"],[\"func1\",\"Func\"],[\"func4\",\"Func\"],[\"cfgobj8\",\"CfgObj\"],[\"cfgobj5\",\"CfgObj\"],[\"func5\",\"Func\"],[\"cfgobj25\",\"CfgObj\"],[\"cfgobj26\",\"CfgObj\"],[\"cfgobj45\",\"CfgObj\"]]","chunk_1"]
["howto20","HowTo","Get JSON response using Pydantic schema","Provide a Pydantic `BaseModel` subclass as `response_schema` and `application/json` as `response_mime_type` in the generation config (`cfgobj5`).","[[p,t,response_schema,null,\"Pydantic BaseModel class (\",[\"cfgobj10\",\"CfgObj\"],\" subclass)\"]]","[o,t,str,\"JSON string output matching schema\"]","from pydantic import BaseModel\nclass CountryInfo(BaseModel): ...\nresponse = client.models.generate_content(\n model='gemini-2.0-flash-001', contents='...', config=types.GenerateContentConfig(\n response_mime_type='application/json', response_schema=CountryInfo))","[[\"feat10\",\"Feat\"],[\"cfgobj5\",\"CfgObj\"],[\"cfgobj9\",\"CfgObj\"],[\"cfgobj10\",\"CfgObj\"]]", "chunk_1"]
["howto21","HowTo","Get Enum response (text)","Provide an `enum.Enum` (`cfgobj11`) class as `response_schema` and `text/x.enum` as `response_mime_type` in the generation config (`cfgobj5`).","[[p,t,response_schema,null,\"enum.Enum class (\",[\"cfgobj11\",\"CfgObj\"],\")\"]]","[o,t,str,\"Plain text enum value\"]","from enum import Enum\nclass InstrumentEnum(Enum): ...\nresponse = client.models.generate_content(\n model='gemini-2.0-flash-001', contents='...', config={\n 'response_mime_type': 'text/x.enum',\n 'response_schema': InstrumentEnum,\n })", "[[\"feat11\",\"Feat\"],[\"cfgobj5\",\"CfgObj\"],[\"cfgobj11\",\"CfgObj\"]]", "chunk_1"]
["howto22","HowTo","Stream generated content (sync)","Use `client.models.generate_content_stream()` (`func2`) to get model response in chunks.","[[p,t,model,null,\"\"],[p,t,contents,null,\"Input content(s)\"]]","[o,t,Iterator[GenerateContentResponse],\"Iterator yielding response chunks\"]","for chunk in client.models.generate_content_stream(\n model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'\n): print(chunk.text, end='')", "[[\"cfgobj4\",\"CfgObj\"],[\"func2\",\"Func\"]]", "chunk_0"]
["howto23","HowTo","Stream content with image (sync)","Stream content generation using local or GCS image files by creating `types.Part` (`cfgobj45`) objects and including them in the `contents` argument for `client.models.generate_content_stream`.","[[p,t,contents,null,\"List with text and \",[\"cfgobj45\",\"CfgObj\"],\" (from_uri or from_bytes)\"]]","[o,t,Iterator[GenerateContentResponse],\"Iterator yielding response chunks\"]","for chunk in client.models.generate_content_stream(\n model='gemini-2.0-flash-001', contents=[..., types.Part.from_uri(...)])", "[[\"func2\",\"Func\"],[\"cfgobj45\",\"CfgObj\"]]", "chunk_1"]
["howto24","HowTo","Use async generation","Call `client.aio.models.generate_content()` (`func1`) using `await`.","[[p,t,model,null,\"\"],[p,t,contents,null,\"\"]]","[o,t,GenerateContentResponse,\"Response object (awaitable)\"]","response = await client.aio.models.generate_content(\n model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.')", "[[\"feat12\",\"Feat\"],[\"cfgobj12\",\"CfgObj\"],[\"func1\",\"Func\"]]", "chunk_0"]
["howto25","HowTo","Stream content (async)","Use `client.aio.models.generate_content_stream()` (`func2`) with `await` and `async for`.","[[p,t,model,null,\"\"],[p,t,contents,null,\"\"]]","[o,t,AsyncIterator[GenerateContentResponse],\"Async iterator yielding response chunks\"]","async for chunk in await client.aio.models.generate_content_stream(\n model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.')", "[[\"feat12\",\"Feat\"],[\"cfgobj12\",\"CfgObj\"],[\"func2\",\"Func\"]]", "chunk_0"]
["howto26","HowTo","Count tokens","Use `client.models.count_tokens()` (`func10`) to get the total token count (`types.UsageMetadata`, `cfgobj73`) for input content.","[[p,t,model,null,\"\"],[p,t,contents,null,\"\"]]","[o,t,CountTokensResponse,\"Response object with token count (\",[\"cfgobj73\",\"CfgObj\"],\")\"]","response = client.models.count_tokens(\n model='gemini-2.0-flash-001', contents='why is the sky blue?')", "[[\"cfgobj4\",\"CfgObj\"],[\"func10\",\"Func\"],[\"feat29\",\"Feat\"],[\"cfgobj73\",\"CfgObj\"]]","chunk_1"]
["howto27","HowTo","Compute tokens (Vertex AI)","Use `client.models.compute_tokens()` (`func11`) to get token IDs and tokens (`types.UsageMetadata`, `cfgobj73`) (Vertex AI only).","[[p,t,model,null,\"\"],[p,t,contents,null,\"\"]]","[o,t,ComputeTokensResponse,\"Response object with tokens info (\",[\"cfgobj73\",\"CfgObj\"],\")\"]","response = client.models.compute_tokens(\n model='gemini-2.0-flash-001', contents='why is the sky blue?')", "[[\"cfgobj4\",\"CfgObj\"],[\"func11\",\"Func\"],[\"feat3\",\"Feat\"],[\"feat29\",\"Feat\"],[\"cfgobj73\",\"CfgObj\"]]","chunk_1"]
["howto28","HowTo","Embed content","Use `client.models.embed_content()` (`func12`) to generate vector embeddings (`types.UsageMetadata`, `cfgobj73`) for text content.","[[p,t,model,null,\"Embedding model name\"],[p,t,contents,null,\"Text content(s)\"],[p,t,config,null,\"Optional config\"]]","[o,t,EmbedContentResponse,\"Response object with embeddings (\",[\"cfgobj73\",\"CfgObj\"],\")\"]","response = client.models.embed_content(\n model='text-embedding-004', contents='why is the sky blue?')", "[[\"cfgobj4\",\"CfgObj\"],[\"func12\",\"Func\"],[\"feat29\",\"Feat\"],[\"cfgobj73\",\"CfgObj\"]]","chunk_1"]
["howto29","HowTo","Generate images","Use `client.models.generate_images()` (`func13`) with a prompt and optional config (`types.GenerateImagesConfig` - not detailed in chunk).","[[p,t,model,null,\"Image model name\"],[p,t,prompt,null,\"Text description\"],[p,t,config,null,\"Generation config\"]]","[o,t,GenerateImagesResponse,\"Response with generated images\"]","response1 = client.models.generate_images(\n model='imagen-3.0-generate-002', prompt='...', config=types.GenerateImagesConfig(...))", "[[\"feat13\",\"Feat\"],[\"cfgobj4\",\"CfgObj\"],[\"func13\",\"Func\"]]", "chunk_0"]
["howto30","HowTo","Upscale images","Use `client.models.upscale_image()` (`func14`) with an input image object (`types.Image`) and upscale factor, with optional config (`types.UpscaleImageConfig`, `cfgobj109`). Returns `types.UpscaleImageResponse` (`cfgobj110`).","[[p,t,model,null,\"\"],[p,t,image,null,\"Input \",[\"types.Image\",\"CfgObj\"],\" object\"],[p,t,upscale_factor,null,\"Upscale factor string ('x2' or 'x4')\"]]","[o,t,UpscaleImageResponse,\"Response object with upscaled image (\",[\"cfgobj110\",\"CfgObj\"],\")\"]","response2 = client.models.upscale_image(\n model='imagen-3.0-generate-002', image=response1.generated_images[0].image, upscale_factor='x2', ...)", "[[\"feat13\",\"Feat\"],[\"cfgobj4\",\"CfgObj\"],[\"func14\",\"Func\"],[\"feat3\",\"Feat\"],[\"feat36\",\"Feat\"],[\"cfgobj109\",\"CfgObj\"],[\"cfgobj110\",\"CfgObj\"]]", "chunk_1"]
["howto31","HowTo","Edit images","Use `client.models.edit_image()` (`func15`) with a prompt and reference images (`types.RawReferenceImage`, `cfgobj118`, `types.MaskReferenceImage`, `cfgobj119`, `types.StyleReferenceImage`, `cfgobj120`, `types.SubjectReferenceImage`, `cfgobj121`) (Vertex AI only). Returns `EditImageResponse`.","[[p,t,model,null,\"Image editing model\"],[p,t,prompt,null,\"Text description of edit\"],[p,t,reference_images,null,\"List of reference image types (\",[\"cfgobj118\",\"CfgObj\"],\", \",[\"cfgobj119\",\"CfgObj\"],\", \",[\"cfgobj120\",\"CfgObj\"],\", \",[\"cfgobj121\",\"CfgObj\"],\")\"]]","[o,t,EditImageResponse,\"Response object with edited image\"]","from google.genai.types import RawReferenceImage, MaskReferenceImage\nresponse3 = client.models.edit_image(\n model='imagen-3.0-capability-001', prompt='...', reference_images=[...], ...)", "[[\"feat13\",\"Feat\"],[\"cfgobj4\",\"CfgObj\"],[\"func15\",\"Func\"],[\"feat3\",\"Feat\"],[\"feat31\",\"Feat\"],[\"cfgobj118\",\"CfgObj\"],[\"cfgobj119\",\"CfgObj\"],[\"cfgobj120\",\"CfgObj\"],[\"cfgobj121\",\"CfgObj\"]]","chunk_1"]
["howto32","HowTo","Generate videos","Use `client.models.generate_videos()` (`func16`) and poll the returned operation (`types.Operation`, `cfgobj105`) until complete using `client.operations.get` (`func17`). Returns `types.GenerateVideosOperation` (`cfgobj105`).","[[p,t,model,null,\"Video model name\"],[p,t,prompt,null,\"Text prompt\"],[p,t,config,null,\"Generation config\"]]","[o,t,GenerateVideosOperation,\"Operation object (\",[\"cfgobj105\",\"CfgObj\"],\")\"]","operation = client.models.generate_videos(\n model='veo-2.0-generate-001', prompt='...', config=types.GenerateVideosConfig(...))\nwhile not operation.done:\n time.sleep(20)\n operation = client.operations.get(operation)","[[\"feat14\",\"Feat\"],[\"cfgobj4\",\"CfgObj\"],[\"func16\",\"Func\"],[\"cfgobj13\",\"CfgObj\"],[\"func17\",\"Func\"],[\"cfgobj105\",\"CfgObj\"]]","chunk_1"]
["howto33","HowTo","Send message in chat (sync)","Create a chat session using `client.chats.create` and use the `send_message` method.","[[p,t,message,null,\"Message content\"]]","[o,t,GenerateContentResponse,\"Model response\"]","chat = client.chats.create(model='...')\nresponse = chat.send_message('tell me a story')","[[\"feat15\",\"Feat\"],[\"func18\",\"Func\"],[\"func19\",\"Func\"]]", "chunk_0"]
["howto34","HowTo","Stream chat messages (sync)","Use the `send_message_stream` method of a chat session.","[[p,t,message,null,\"Message content\"]]","[o,t,Iterator[GenerateContentResponse],\"Iterator yielding response chunks\"]","chat = client.chats.create(model='...')\nfor chunk in chat.send_message_stream('tell me a story'): print(chunk.text, end='')", "[[\"feat15\",\"Feat\"],[\"func18\",\"Func\"],[\"func20\",\"Func\"]]", "chunk_0"]
["howto35","HowTo","Upload a file","Use `client.files.upload()` (`func6`) with a path or IOBase object (`types.FileData`, `cfgobj21`) to upload a file, returning a `types.File` (`cfgobj20`) object.","[[p,t,file,null,\"Path or IOBase object (\",[\"cfgobj21\",\"CfgObj\"],\")\"]]","[o,t,File,\"File object (\",[\"cfgobj20\",\"CfgObj\"],\") with name and uri\"]","file1 = client.files.upload(file='2312.11805v3.pdf')","[[\"feat16\",\"Feat\"],[\"func6\",\"Func\"],[\"cfgobj20\",\"CfgObj\"],[\"cfgobj21\",\"CfgObj\"]]","chunk_1"]
["howto36","HowTo","Get file information","Use `client.files.get()` (`func7`) with the file name (`types.File.name`) to retrieve its metadata (`types.File`, `cfgobj20`).","[[p,t,name,null,\"File name\"]]","[o,t,File,\"File object (\",[\"cfgobj20\",\"CfgObj\"],\") with metadata\"]","file_info = client.files.get(name=file1.name)", "[[\"feat16\",\"Feat\"],[\"func7\",\"Func\"],[\"howto35\",\"HowTo\"],[\"cfgobj20\",\"CfgObj\"]]","chunk_1"]
["howto37","HowTo","Delete a file","Use `client.files.delete()` (`func8`) with the file name (`types.File.name`) to delete a file.","[[p,t,name,null,\"File name\"]]","[o,t,DeleteFileResponse,\"Response indicating deletion\"]","client.files.delete(name=file3.name)", "[[\"feat16\",\"Feat\"],[\"func8\",\"Func\"]]","chunk_0"]
["howto38","HowTo","Create cached content","Use `client.caches.create()` (`func9`) with content, model, and config (`types.CreateCachedContentConfig` - not detailed in chunk), like display name, ttl.","[[p,t,model,null,\"Model name\"],[p,t,config,null,\"Create config (contents, display_name, ttl)\"]]","[o,t,CachedContent,\"Cached content object\"]","cached_content = client.caches.create(\n model='gemini-2.0-flash-001', config=types.CreateCachedContentConfig(...))", "[[\"feat17\",\"Feat\"],[\"cfgobj16\",\"CfgObj\"],[\"func9\",\"Func\"]]", "chunk_0"]
["howto39","HowTo","Get cached content","Use `client.caches.get()` (`func21`) with the cached content name to retrieve its configuration.","[[p,t,name,null,\"Cached content name\"]]","[o,t,CachedContent,\"Cached content object\"]","cached_content = client.caches.get(name=cached_content.name)", "[[\"feat17\",\"Feat\"],[\"cfgobj16\",\"CfgObj\"],[\"func21\",\"Func\"]]", "chunk_0"]
["howto40","HowTo","Use cached content in generation","Reference the cached content name in the `config` parameter (`types.GenerateContentConfig`, `cfgobj5`) of `generate_content` (`func1`).","[[p,t,config,null,\"GenerateContentConfig (\",[\"cfgobj5\",\"CfgObj\"],\") with cached_content name\"]]","[o,t,GenerateContentResponse,\"Response using cached content\"]","response = client.models.generate_content(\n model='gemini-2.0-flash-001', contents='Summarize the pdfs',\n config=types.GenerateContentConfig(\n cached_content=cached_content.name,\n ),\n)","[[\"feat17\",\"Feat\"],[\"func1\",\"Func\"],[\"cfgobj5\",\"CfgObj\"],[\"cfgobj16\",\"CfgObj\"]]", "chunk_1"]
["howto41","HowTo","Tune a model","Use `client.tunings.tune()` (`func19`) with a base model, training dataset (`types.TuningDataset`), and optional config (`types.CreateTuningJobConfig` - not detailed), returning a `types.TuningJob` (`cfgobj92`).","[[p,t,base_model,null,\"Base model name\"],[p,t,training_dataset,null,\"Dataset (\",[\"types.TuningDataset\",\"CfgObj\"],\" or inline examples)\",[\"cfg116\",\"CfgObj\"],\"\"],[p,t,config,null,\"Tuning config (epoch_count, display_name)\"]]","[o,t,TuningJob,\"Tuning job object (\",[\"cfgobj92\",\"CfgObj\"],\")\"]","tuning_job = client.tunings.tune(\n base_model='gemini-2.0-flash-001', training_dataset=types.TuningDataset(...), config=types.CreateTuningJobConfig(...))", "[[\"feat18\",\"Feat\"],[\"cfgobj17\",\"CfgObj\"],[\"func19\",\"Func\"],[\"cfgobj92\",\"CfgObj\"],[\"cfgobj116\",\"CfgObj\"]]","chunk_1"]
["howto42","HowTo","Get tuning job status","Use `client.tunings.get()` (`func20`) with the tuning job name to retrieve its status and details (`types.TuningJob`, `cfgobj92`).","[[p,t,name,null,\"Tuning job name\"]]","[o,t,TuningJob,\"Tuning job object (\",[\"cfgobj92\",\"CfgObj\"],\")\"]","tuning_job = client.tunings.get(name=tuning_job.name)", "[[\"feat18\",\"Feat\"],[\"cfgobj17\",\"CfgObj\"],[\"func20\",\"Func\"],[\"howto41\",\"HowTo\"],[\"cfgobj92\",\"CfgObj\"]]","chunk_1"]
["howto43","HowTo","Use a tuned model","Reference the tuned model's endpoint name (`types.TunedModel.endpoint`, `cfgobj95`) in the `model` parameter of `generate_content` (`func1`).","[[p,t,model,null,\"Tuned model endpoint name (\",[\"cfgobj95\",\"CfgObj\"],\")\"]]","[o,t,GenerateContentResponse,\"Response from tuned model\"]","response = client.models.generate_content(\n model=tuning_job.tuned_model.endpoint, contents='why is the sky blue?')", "[[\"feat18\",\"Feat\"],[\"func1\",\"Func\"],[\"cfgobj92\",\"CfgObj\"],[\"cfgobj95\",\"CfgObj\"]]","chunk_1"]
["howto44","HowTo","List tuning jobs","Use `client.tunings.list()` (`func22`) to retrieve a list of tuning jobs (`types.TuningJob`, `cfgobj92`).","[[p,t,config,null,\"Optional config like page_size\"]]","[o,t,Pager[TuningJob],\"Iterable pager object yielding \",[\"cfgobj92\",\"CfgObj\"]]","for job in client.tunings.list(config=types.ListTuningJobsConfig(page_size=10)): print(job)", "[[\"feat18\",\"Feat\"],[\"cfgobj17\",\"CfgObj\"],[\"func22\",\"Func\"],[\"cfgobj92\",\"CfgObj\"]]","chunk_1"]
["howto45","HowTo","Create a batch prediction job","Use `client.batches.create()` (`func23`) with a model and data source (GCS or BigQuery URI). Returns `BatchJob`.","[[p,t,model,null,\"Model name\"],[p,t,src,null,\"Source URI\"],[p,t,config,null,\"Optional create config\"]]","[o,t,BatchJob,\"Batch job object\"]","job = client.batches.create(\n model='gemini-2.0-flash-001', src='bq://my-project.my-dataset.my-table')", "[[\"feat19\",\"Feat\"],[\"cfgobj18\",\"CfgObj\"],[\"func23\",\"Func\"],[\"feat3\",\"Feat\"]]", "chunk_0"]
["howto46","HowTo","List batch prediction jobs","Use `client.batches.list()` (`func24`) to retrieve a list of batch jobs (`BatchJob`).","[[p,t,config,null,\"Optional list config\"]]","[o,t,Pager[BatchJob],\"Iterable pager object\"]","for job in client.batches.list(config=types.ListBatchJobsConfig(page_size=10)): print(job)", "[[\"feat19\",\"Feat\"],[\"cfgobj18\",\"CfgObj\"],[\"func24\",\"Func\"],[\"feat3\",\"Feat\"]]", "chunk_0"]
["howto47","HowTo","Delete a batch prediction job","Use `client.batches.delete()` (`func25`) with the job name to delete it. Returns `DeleteResourceJob`.","[[p,t,name,null,\"Batch job name\"]]","[o,t,DeleteResourceJob,\"Object indicating deletion status\"]","delete_job = client.batches.delete(name=job.name)", "[[\"feat19\",\"Feat\"],[\"cfgobj18\",\"CfgObj\"],[\"func25\",\"Func\"],[\"feat3\",\"Feat\"],[\"howto45\",\"HowTo\"]]", "chunk_0"]
["howto48","HowTo","Handle API errors","Use a try-except block to catch `errors.APIError` (`cfgobj19`) and access error details (`code`, `message`, `google.rpc.Status` details (`cfgobj103`)).","[[p,t,e,null,\"APIError exception object (\",[\"cfgobj19\",\"CfgObj\"],\")\"]]","[]","try:\n client.models.generate_content(model=\"invalid-model-name\", ...)\nexcept errors.APIError as e:\n print(e.code)\n print(e.message)", "[[\"feat20\",\"Feat\"],[\"cfgobj19\",\"CfgObj\"],[\"cfgobj103\",\"CfgObj\"]]", "chunk_1"]
["howto49","HowTo","Connect to Live API (sync)","Establish a bidirectional streaming connection to the Live API for real-time interaction.","[[p,t,model,null,\"Model name\"],[p,t,config,null,\"Live connection config (\",[\"cfgobj54\",\"CfgObj\"],\")\"]]","[o,t,LiveConnection,\"Bidirectional stream object\"]","with client.live.connect(model='...') as live_conn:\n ...","[[\"feat21\",\"Feat\"],[\"cfgobj1\",\"CfgObj\"],[\"cfgobj49\",\"CfgObj\"],[\"cfgobj54\",\"CfgObj\"]]","chunk_1"]
["howto50","HowTo","Send Realtime Input (sync)","Send incremental realtime input (audio, video, text) during a Live API session using the connection object.","[[p,t,input,null,\"Realtime input data (\",[\"cfgobj51\",\"CfgObj\"],\")\"]]","[]","live_conn.send_message(realtime_input=types.LiveClientRealtimeInput(text='...'))","[[\"feat21\",\"Feat\"],[\"howto49\",\"HowTo\"],[\"cfgobj51\",\"CfgObj\"],[\"cfgobj49\",\"CfgObj\"]]","chunk_1"]
["howto51","HowTo","Handle Live Server Content (sync)","Process incremental content chunks (`types.LiveServerContent`, `cfgobj58`) received from the model during a Live API session.","[[p,t,chunk,null,\"Server content chunk (\",[\"cfgobj58\",\"CfgObj\"],\")\"]]","[o,t,text,audio,etc,\"Content parts\"]","for chunk in live_conn:\n if chunk.server_content: print(chunk.server_content.text)","[[\"feat21\",\"Feat\"],[\"howto49\",\"HowTo\"],[\"cfgobj57\",\"CfgObj\"],[\"cfgobj58\",\"CfgObj\"]]","chunk_1"]
["howto52","HowTo","Handle Live Tool Calls (sync)","Receive tool call requests (`types.LiveServerToolCall`, `cfgobj62`) from the model in a Live API session and send back responses (`types.LiveClientToolResponse`, `cfgobj53`).","[[p,t,tool_call_msg,null,\"Tool call message (\",[\"cfgobj62\",\"CfgObj\"],\")\"]],[o,t,tool_response_msg,\"Tool response message (\",[\"cfgobj53\",\"CfgObj\"],\")\"]","# Receive a tool call:\nif msg.tool_call:\n # ... process calls ...\n # Send tool response:\n live_conn.send_message(tool_response=...)","[[\"feat21\",\"Feat\"],[\"feat9\",\"Feat\"],[\"howto49\",\"HowTo\"],[\"cfgobj57\",\"CfgObj\"],[\"cfgobj62\",\"CfgObj\"],[\"cfgobj53\",\"CfgObj\"],[\"cfgobj49\",\"CfgObj\"]]","chunk_1"]
["cfgobj1","CfgObj","genai.Client","Represents a client for interacting with the Google Gen AI APIs. Supports Gemini Developer API or Vertex AI, and provides access to models, files, caching, tuning, batch, operations, and live API features.","[[p,t,api_key,null,\"API key string\"],[p,t,vertexai,null,\"Use Vertex AI API\"],[p,t,project,null,\"Google Cloud project ID\"],[p,t,location,null,\"Google Cloud location\"],[p,t,http_options,null,\"HTTP options\"]]","[]","client = genai.Client(api_key='...')","[[\"feat2\",\"Feat\"],[\"feat3\",\"Feat\"],[\"feat15\",\"Feat\"],[\"feat16\",\"Feat\"],[\"feat17\",\"Feat\"],[\"feat18\",\"Feat\"],[\"feat19\",\"Feat\"],[\"feat20\",\"Feat\"],[\"feat12\",\"Feat\"],[\"feat21\",\"Feat\"],[\"cfgobj4\",\"CfgObj\"],[\"cfgobj13\",\"CfgObj\"],[\"cfgobj14\",\"CfgObj\"],[\"cfgobj15\",\"CfgObj\"],[\"cfgobj16\",\"CfgObj\"],[\"cfgobj17\",\"CfgObj\"],[\"cfgobj18\",\"CfgObj\"],[\"cfgobj12\",\"CfgObj\"]]","chunk_1"]
["cfgobj2","CfgObj","types.HttpOptions","Configuration object for HTTP request options, including API version.","[[p,t,api_version,null,\"API version string\"],[p,t,baseUrl,null,\"Base URL\"],[p,t,headers,null,\"Additional headers\"],[p,t,timeout,null,\"Request timeout (ms)\"]]","[]","","[[\"feat4\",\"Feat\"]]","chunk_1"]
["cfgobj3","CfgObj","google.genai.types module","Contains Pydantic model types and TypedDicts for API parameters, request/response bodies, and configuration objects.","[]","[]","from google.genai import types","[[\"feat5\",\"Feat\"],[\"feat7\",\"Feat\"],[\"feat9\",\"Feat\"],[\"feat10\",\"Feat\"],[\"feat11\",\"Feat\"],[\"feat13\",\"Feat\"],[\"feat14\",\"Feat\"],[\"feat16\",\"Feat\"],[\"feat17\",\"Feat\"],[\"feat18\",\"Feat\"],[\"feat19\",\"Feat\"],[\"feat20\",\"Feat\"],[\"feat21\",\"Feat\"],[\"feat22\",\"Feat\"],[\"feat23\",\"Feat\"],[\"feat24\",\"Feat\"],[\"feat25\",\"Feat\"],[\"feat26\",\"Feat\"],[\"feat27\",\"Feat\"],[\"feat28\",\"Feat\"],[\"feat29\",\"Feat\"],[\"feat30\",\"Feat\"],[\"feat31\",\"Feat\"],[\"feat32\",\"Feat\"],[\"feat33\",\"Feat\"],[\"feat34\",\"Feat\"],[\"feat35\",\"Feat\"],[\"feat36\",\"Feat\"],[\"cfgobj5\",\"CfgObj\"],[\"cfgobj6\",\"CfgObj\"],[\"cfgobj7\",\"CfgObj\"],[\"cfgobj8\",\"CfgObj\"],[\"cfgobj9\",\"CfgObj\"],[\"cfgobj20\",\"CfgObj\"],[\"cfgobj21\",\"CfgObj\"],[\"cfgobj22\",\"CfgObj\"],[\"cfgobj23\",\"CfgObj\"],[\"cfgobj24\",\"CfgObj\"],[\"cfgobj25\",\"CfgObj\"],[\"cfgobj26\",\"CfgObj\"],[\"cfgobj27\",\"CfgObj\"],[\"cfgobj28\",\"CfgObj\"],[\"cfgobj29\",\"CfgObj\"],[\"cfgobj30\",\"CfgObj\"],[\"cfgobj31\",\"CfgObj\"],[\"cfgobj32\",\"CfgObj\"],[\"cfgobj33\",\"CfgObj\"],[\"cfgobj34\",\"CfgObj\"],[\"cfgobj35\",\"CfgObj\"],[\"cfgobj36\",\"CfgObj\"],[\"cfgobj37\",\"CfgObj\"],[\"cfgobj38\",\"CfgObj\"],[\"cfgobj39\",\"CfgObj\"],[\"cfgobj40\",\"CfgObj\"],[\"cfgobj41\",\"CfgObj\"],[\"cfgobj42\",\"CfgObj\"],[\"cfgobj43\",\"CfgObj\"],[\"cfgobj44\",\"CfgObj\"],[\"cfgobj45\",\"CfgObj\"],[\"cfgobj46\",\"CfgObj\"],[\"cfgobj47\",\"CfgObj\"],[\"cfgobj48\",\"CfgObj\"],[\"cfgobj49\",\"CfgObj\"],[\"cfgobj50\",\"CfgObj\"],[\"cfgobj51\",\"CfgObj\"],[\"cfgobj52\",\"CfgObj\"],[\"cfgobj53\",\"CfgObj\"],[\"cfgobj54\",\"CfgObj\"],[\"cfgobj55\",\"CfgObj\"],[\"cfgobj56\",\"CfgObj\"],[\"cfgobj57\",\"CfgObj\"],[\"cfgobj58\",\"CfgObj\"],[\"cfgobj59\",\"CfgObj\"],[\"cfgobj60\",\"CfgObj\"],[\"cfgobj61\",\"CfgObj\"],[\"cfgobj62\",\"CfgObj\"],[\"cfgobj63\",\"CfgObj\"],[\"cfgobj64\",\"CfgObj\"],[\"cfgobj65\",\"CfgObj\"],[\"cfgobj66\",\"CfgObj\"],[\"cfgobj67\",\"CfgObj\"],[\"cfgobj68\",\"CfgObj\"],[\"cfgobj69\",\"CfgObj\"],[\"cfgobj70\",\"CfgObj\"],[\"cfgobj71\",\"CfgObj\"],[\"cfgobj72\",\"CfgObj\"],[\"cfgobj73\",\"CfgObj\"],[\"cfgobj74\",\"CfgObj\"],[\"cfgobj75\",\"CfgObj\"],[\"cfgobj76\",\"CfgObj\"],[\"cfgobj77\",\"CfgObj\"],[\"cfgobj78\",\"CfgObj\"],[\"cfgobj79\",\"CfgObj\"],[\"cfgobj80\",\"CfgObj\"],[\"cfgobj81\",\"CfgObj\"],[\"cfgobj82\",\"CfgObj\"],[\"cfgobj83\",\"CfgObj\"],[\"cfgobj84\",\"CfgObj\"],[\"cfgobj85\",\"CfgObj\"],[\"cfgobj86\",\"CfgObj\"],[\"cfgobj87\",\"CfgObj\"],[\"cfgobj88\",\"CfgObj\"],[\"cfgobj89\",\"CfgObj\"],[\"cfgobj90\",\"CfgObj\"],[\"cfgobj91\",\"CfgObj\"],[\"cfgobj92\",\"CfgObj\"],[\"cfgobj93\",\"CfgObj\"],[\"cfgobj94\",\"CfgObj\"],[\"cfgobj95\",\"CfgObj\"],[\"cfgobj96\",\"CfgObj\"],[\"cfgobj97\",\"CfgObj\"],[\"cfgobj98\",\"CfgObj\"],[\"cfgobj99\",\"CfgObj\"],[\"cfgobj100\",\"CfgObj\"],[\"cfgobj101\",\"CfgObj\"],[\"cfgobj102\",\"CfgObj\"],[\"cfgobj103\",\"CfgObj\"],[\"cfgobj104\",\"CfgObj\"],[\"cfgobj105\",\"CfgObj\"],[\"cfgobj106\",\"CfgObj\"],[\"cfgobj107\",\"CfgObj\"],[\"cfgobj108\",\"CfgObj\"],[\"cfgobj109\",\"CfgObj\"],[\"cfgobj110\",\"CfgObj\"],[\"cfgobj111\",\"CfgObj\"],[\"cfgobj112\",\"CfgObj\"],[\"cfgobj113\",\"CfgObj\"],[\"cfgobj114\",\"CfgObj\"],[\"cfgobj115\",\"CfgObj\"],[\"cfgobj116\",\"CfgObj\"],[\"cfgobj117\",\"CfgObj\"],[\"cfgobj118\",\"CfgObj\"],[\"cfgobj119\",\"CfgObj\"],[\"cfgobj120\",\"CfgObj\"],[\"cfgobj121\",\"CfgObj\"]]","chunk_1"]
["cfgobj4","CfgObj","client.models module","Provides interface for model inferencing and getters, including generating text/vision/video content, embedding, counting tokens, listing models.","[]","[]","","[[\"cfgobj1\",\"CfgObj\"],[\"feat13\",\"Feat\"],[\"feat14\",\"Feat\"],[\"cfgobj104\",\"CfgObj\"],[\"cfgobj105\",\"CfgObj\"],[\"cfgobj110\",\"CfgObj\"],[\"cfgobj111\",\"CfgObj\"]]","chunk_1"]
["cfgobj5","CfgObj","types.GenerateContentConfig","Configuration object for generating content, including parameters like temperature, max_output_tokens, system_instruction, tools, safety settings, JSON/Enum response schema, routing config, thinking config, and media resolution.","[[p,t,system_instruction,null,\"\"],[p,t,max_output_tokens,null,\"\"],[p,t,temperature,null,\"\"],[p,t,safety_settings,null,\"\"],[p,t,tools,null,\"\"],[p,t,response_mime_type,null,\"\"],[p,t,response_schema,null,\"\"],[p,T,audioTimestamp,null,\"Include audio timestamp\"],[p,i,candidateCount,null,\"Number of candidates\"],[p,n,frequencyPenalty,null,\"Frequency penalties\"],[p,i,logprobs,null,\"Logit probabilities\"],[p,t,mediaResolution,null,\"Media resolution (\",[\"cfgobj66\",\"CfgObj\"],\")\"],[p,n,presencePenalty,null,\"Presence penalties\"],[p,T,responseLogprobs,null,\"Export logprobs results\"],[p,t,routingConfig,null,\"Routing configuration (\",[\"cfgobj27\",\"CfgObj\"],\")\"],[p,i,seed,null,\"Seed\"],[p,list[str],stopSequences,null,\"Stop sequences\"],[p,n,topK,null,\"Top-k sampling\"],[p,n,topP,null,\"Nucleus sampling\"],[p,t,thinkingConfig,null,\"Thinking features config (\",[\"cfgobj41\",\"CfgObj\"],\")\"]]","[]","","[[\"feat7\",\"Feat\"],[\"feat8\",\"Feat\"],[\"feat9\",\"Feat\"],[\"feat10\",\"Feat\"],[\"feat11\",\"Feat\"],[\"feat30\",\"Feat\"],[\"cfgobj27\",\"CfgObj\"],[\"cfgobj9\",\"CfgObj\"],[\"cfgobj41\",\"CfgObj\"],[\"cfgobj66\",\"CfgObj\"]]","chunk_1"]
["cfgobj6","CfgObj","types.SafetySetting","Configuration object for specifying a safety threshold for a harm category.","[[p,t,category,null,\"Harm category string\"],[p,t,threshold,null,\"Blocking threshold string\"]]","[]","","[[\"feat8\",\"Feat\"]]","chunk_0"]
["cfgobj7","CfgObj","types.AutomaticFunctionCallingConfig","Configuration object for controlling automatic function calling behavior.","[[p,T,disable,F,\"Set to True to disable\"],[p,i,maximum_remote_calls,10,\"Max calls allowed\"],[p,t,ignore_call_history,null,\"Ignore call history in response\"]]","[]","","[[\"howto18\",\"HowTo\"]]","chunk_0"]
["cfgobj8","CfgObj","types.Tool","Container for tool definitions that the model can use, such as function declarations, code execution, or retrieval tools.","[[p,list[types.FunctionDeclaration],function_declarations,null,\"List of function definitions (\",[\"func4\",\"Func\"],\")\"],[p,t,codeExecution,null,\"Code execution tool (\",[\"cfgobj35\",\"CfgObj\"],\")\"],[p,t,retrieval,null,\"Retrieval tool (\",[\"cfgobj30\",\"CfgObj\"],\")\"],[p,t,googleSearch,null,\"Google Search tool (\",[\"cfgobj31\",\"CfgObj\"],\")\"],[p,t,googleMaps,null,\"Google Maps tool (\",[\"cfgobj32\",\"CfgObj\"],\")\"],[p,t,enterpriseWebSearch,null,\"Enterprise Web Search tool (\",[\"cfgobj33\",\"CfgObj\"],\")\"],[p,t,googleSearchRetrieval,null,\"Google Search Retrieval tool (\",[\"cfgobj34\",\"CfgObj\"],\")\"]]","[]","tool = types.Tool(function_declarations=[function])","[[\"feat9\",\"Feat\"],[\"feat22\",\"Feat\"],[\"feat23\",\"Feat\"],[\"func1\",\"Func\"],[\"func2\",\"Func\"],[\"func18\",\"Func\"],[\"cfgobj52\",\"CfgObj\"],[\"cfgobj54\",\"CfgObj\"]]","chunk_1"]
["cfgobj9","CfgObj","types.Schema","Represents a JSON schema for defining data types, used for function parameters, response schemas (JSON/Enum), and nested structures.","[[p,t,type,null,\"Data type (\",[\"cfgobj48\",\"CfgObj\"],\")\"],[p,o,properties,null,\"Object properties schema (\",[\"cfgobj9\",\"CfgObj\"],\")\"],[p,list[str],required,null,\"List of required properties\"],[p,list[str],enum,null,\"Possible enum values\"],[p,n,minimum,null,\"Minimum value (integer/number)\"],[p,n,maximum,null,\"Maximum value (integer/number)\"],[p,i,minLength,null,\"Minimum string length\"],[p,i,maxLength,null,\"Maximum string length\"],[p,t,pattern,null,\"String pattern (regex)\"],[p,i,minItems,null,\"Minimum array items\"],[p,i,maxItems,null,\"Maximum array items\"],[p,list[types.Schema],anyOf,null,\"Matches any of subschemas\"],[p,t,description,null,\"Description\"],[p,t,title,null,\"Title\"],[p,t,format,null,\"Format (e.g., float, int32, email)\"],[p,b,nullable,null,\"Value can be null\"],[p,t,items,null,\"Schema for array items (\",[\"cfgobj9\",\"CfgObj\"],\")\"]","[]","types.Schema(...)","[[\"feat10\",\"Feat\"],[\"feat11\",\"Feat\"],[\"func4\",\"Func\"],[\"cfgobj5\",\"CfgObj\"],[\"cfgobj48\",\"CfgObj\"],[\"cfgobj39\",\"CfgObj\"],[\"cfgobj40\",\"CfgObj\"],[\"cfgobj41\",\"CfgObj\"],[\"cfgobj42\",\"CfgObj\"],[\"cfgobj43\",\"CfgObj\"],[\"cfgobj44\",\"CfgObj\"]]","chunk_1"]
["cfgobj10","CfgObj","pydantic.BaseModel","Base class for Pydantic models, usable as JSON schemas (`cfgobj9`).","[]","[]","from pydantic import BaseModel","[[\"howto20\",\"HowTo\"],[\"cfgobj9\",\"CfgObj\"]]","chunk_1"]
["cfgobj11","CfgObj","enum.Enum","Base class for enumeration types, usable as response schema (`cfgobj9`) for text/x.enum.","[]","[]","from enum import Enum","[[\"feat11\",\"Feat\"],[\"cfgobj9\",\"CfgObj\"]]","chunk_1"]
["cfgobj12","CfgObj","client.aio module","Exposes asynchronous versions of client methods.","[]","[]","client.aio","[[\"feat12\",\"Feat\"],[\"cfgobj1\",\"CfgObj\"]]","chunk_0"]
["cfgobj13","CfgObj","client.operations module","Provides interface for managing long-running operations (`types.Operation`, `cfgobj105`), like video generation.","[]","[]","","[[\"cfgobj1\",\"CfgObj\"],[\"feat14\",\"Feat\"],[\"cfgobj105\",\"CfgObj\"]]","chunk_1"]
["cfgobj14","CfgObj","client.chats module","Provides utilities to create chat sessions.","[]","[]","","[[\"cfgobj1\",\"CfgObj\"],[\"feat15\",\"Feat\"]]","chunk_0"]
["cfgobj15","CfgObj","client.files module","Provides interface for managing files (`types.File`, `cfgobj20`).","[]","[]","","[[\"cfgobj1\",\"CfgObj\"],[\"feat16\",\"Feat\"],[\"cfgobj20\",\"CfgObj\"]]","chunk_1"]
["cfgobj16","CfgObj","client.caches module","Provides control plane APIs for managing cached content, including creation and updates (`types.UpdateCachedContentConfig`, `cfgobj106`).","[]","[]","","[[\"cfgobj1\",\"CfgObj\"],[\"feat17\",\"Feat\"],[\"cfgobj106\",\"CfgObj\"]]","chunk_1"]
["cfgobj17","CfgObj","client.tunings module","Provides APIs for managing tuning jobs (`types.TuningJob`, `cfgobj92`).","[]","[]","","[[\"cfgobj1\",\"CfgObj\"],[\"feat18\",\"Feat\"],[\"cfgobj92\",\"CfgObj\"]]","chunk_1"]
["cfgobj18","CfgObj","client.batches module","Provides APIs for managing batch prediction jobs (Vertex AI only).","[]","[]","","[[\"cfgobj1\",\"CfgObj\"],[\"feat19\",\"Feat\"]]","chunk_0"]
["cfgobj19","CfgObj","errors.APIError","Exception class raised for errors returned by the Gen AI API, containing details like code, message, and `google.rpc.Status` (`cfgobj103`).","[[p,i,code,null,\"HTTP status code\"],[p,t,message,null,\"Error message\"],[p,t,status,null,\"Google RPC Status object (\",[\"cfgobj103\",\"CfgObj\"],\")\"]]","[]","","[[\"feat20\",\"Feat\"],[\"cfgobj103\",\"CfgObj\"]]","chunk_1"]
["cfgobj20","CfgObj","genai.types.File","Represents a file uploaded to the API for use in models. Contains metadata like name, display name, MIME type, size, state, and URI.","[[p,t,name,null,\"File resource name\"],[p,t,displayName,null,\"Human-readable display name\"],[p,t,mimeType,null,\"Output only. MIME type\"],[p,i,sizeBytes,null,\"Output only. Size in bytes\"],[p,t,createTime,null,\"Output only. Creation timestamp\"],[p,t,expirationTime,null,\"Output only. Expiration timestamp\"],[p,t,updateTime,null,\"Output only. Update timestamp\"],[p,t,sha256Hash,null,\"Output only. SHA-256 hash\"],[p,t,uri,null,\"Output only. URI\"],[p,t,downloadUri,null,\"Output only. Download URI\"],[p,t,state,null,\"Output only. Processing state (\",[\"cfgobj23\",\"CfgObj\"],\")\"],[p,t,source,null,\"Output only. File source (\",[\"cfgobj22\",\"CfgObj\"],\")\"],[p,o,videoMetadata,null,\"Output only. Video metadata (\",[\"cfgobj66\",\"CfgObj\"],\")\"],[p,o,error,null,\"Output only. Error status (\",[\"cfgobj24\",\"CfgObj\"],\")\"]]","[]","","[[\"feat16\",\"Feat\"],[\"cfgobj15\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj21","CfgObj","genai.types.FileData","Represents URI-based data, typically referencing an uploaded file.","[[p,t,fileUri,null,\"Required. URI\"],[p,t,mimeType,null,\"Required. MIME type\"]]","[]","","[[\"cfgobj45\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj22","CfgObj","genai.types.FileSource","Enum representing the source of a file: UPLOADED or GENERATED.","[]","[]","","[[\"cfgobj20\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj23","CfgObj","genai.types.FileState","Enum representing the processing state of a file: PROCESSING, ACTIVE, FAILED.","[]","[]","","[[\"cfgobj20\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj24","CfgObj","genai.types.FileStatus","Status of a file processing failure, using a common error model (code, message, details).","[[p,i,code,null,\"Status code\"],[p,t,message,null,\"Error message\"],[p,list[o],details,null,\"List of error details\"]]","[]","","[[\"cfgobj20\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj25","CfgObj","genai.types.FunctionCall","A predicted function call from the model, containing the function name and arguments.","[[p,t,id,null,\"Unique ID for the call\"],[p,o,args,null,\"Required. Function parameters and values (JSON object)\"],[p,t,name,null,\"Required. Name of the function to call\"]]","[]","","[[\"feat9\",\"Feat\"],[\"cfgobj45\",\"CfgObj\"],[\"cfgobj62\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj26","CfgObj","genai.types.FunctionResponse","The result output of a function call executed by the client, to be sent back to the model. Contains the function name, ID, and the result (JSON object).","[[p,t,id,null,\"Required. ID matching the function call\"],[p,t,name,null,\"Required. Name of the function\"],[p,o,response,null,\"Required. Function response (JSON object)\"]]","[]","","[[\"feat9\",\"Feat\"],[\"cfgobj45\",\"CfgObj\"],[\"cfgobj53\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj27","CfgObj","genai.types.GenerationConfigRoutingConfig","Configuration for routing the request to a specific model, including auto or manual modes.","[[p,t,autoMode,null,\"Automated routing config (\",[\"cfgobj28\",\"CfgObj\"],\")\"],[p,t,manualMode,null,\"Manual routing config (\",[\"cfgobj29\",\"CfgObj\"],\")\"]]","[]","","[[\"feat7\",\"Feat\"],[\"cfgobj5\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj28","CfgObj","genai.types.GenerationConfigRoutingConfigAutoRoutingMode","Configuration for automated routing based on a pretrained routing model and user preference.","[[p,t,modelRoutingPreference,null,\"Model routing preference (\",[\"enum:UNKNOWN, PRIORITIZE_QUALITY, BALANCED, PRIORITIZE_COST\",\"Enum\"],\")\"]]","[]","","[[\"cfgobj27\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj29","CfgObj","genai.types.GenerationConfigRoutingConfigManualRoutingMode","Configuration for manual routing, specifying a particular model name.","[[p,t,modelName,null,\"The model name to use (e.g., 'gemini-1.5-pro-001')\"]]","[]","","[[\"cfgobj27\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj30","CfgObj","genai.types.Retrieval","Defines a retrieval tool the model can call to access external knowledge (Vertex AI Search or Vertex RAG Store).","[[p,b,disableAttribution,null,\"Deprecated. Disable attribution.\"],[p,t,vertexAiSearch,null,\"Vertex AI Search tool (\",[\"cfgobj36\",\"CfgObj\"],\")\"],[p,t,vertexRagStore,null,\"Vertex RAG Store tool (\",[\"cfgobj37\",\"CfgObj\"],\")\"]]","[]","","[[\"feat23\",\"Feat\"],[\"cfgobj8\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj31","CfgObj","genai.types.GoogleSearch","Tool to support Google Search for grounding, powered by Google.","[]","[]","","[[\"feat23\",\"Feat\"],[\"cfgobj8\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj32","CfgObj","genai.types.GoogleMaps","Tool to support Google Maps in Model.","[[p,t,authConfig,null,\"Optional. Auth config\"]]","[]","","[[\"feat23\",\"Feat\"],[\"cfgobj8\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj33","CfgObj","genai.types.EnterpriseWebSearch","Tool to search public web data, powered by Vertex AI Search and Sec4 compliance.","[]","[]","","[[\"feat23\",\"Feat\"],[\"cfgobj8\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj34","CfgObj","genai.types.GoogleSearchRetrieval","Tool to retrieve public web data for grounding, powered by Google Search, with dynamic retrieval configuration.","[[p,t,dynamicRetrievalConfig,null,\"Dynamic retrieval config (\",[\"types.DynamicRetrievalConfig\",\"CfgObj\"],\")\"]]","[]","","[[\"feat23\",\"Feat\"],[\"cfgobj8\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj35","CfgObj","genai.types.ToolCodeExecution","Tool that enables the model to execute code it generates, automatically returning the result. Used with the `codeExecution` field in `types.Tool`.","[]","[]","","[[\"feat22\",\"Feat\"],[\"cfgobj8\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj36","CfgObj","genai.types.VertexAISearch","Retrieve from Vertex AI Search datastore or engine for grounding. Mutually exclusive fields for datastore ID or engine ID.","[[p,t,datastore,null,\"Optional. Datastore resource ID\"],[p,t,engine,null,\"Optional. Engine resource ID\"]]","[]","","[[\"feat23\",\"Feat\"],[\"cfgobj30\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj37","CfgObj","genai.types.SessionResumptionConfig","Configuration for session resumption in the Live API, allowing continuation of previous sessions using a handle.","[[p,t,handle,null,\"Session resumption handle\"],[p,T,transparent,null,\"Enable transparent reconnections\"]]","[]","","[[\"feat21\",\"Feat\"],[\"feat25\",\"Feat\"],[\"cfgobj54\",\"CfgObj\"],[\"cfgobj52\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj38","CfgObj","genai.types.ContextWindowCompressionConfig","Enables context window compression in the Live API to manage history length, using methods like sliding windows (`types.SlidingWindow`, `cfgobj39`).","[[p,i,triggerTokens,null,\"Tokens to trigger compression\"],[p,t,slidingWindow,null,\"Sliding window config (\",[\"cfgobj39\",\"CfgObj\"],\")\"]]","[]","","[[\"feat21\",\"Feat\"],[\"feat24\",\"Feat\"],[\"cfgobj54\",\"CfgObj\"],[\"cfgobj52\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj39","CfgObj","genai.types.SlidingWindow","Configuration for the sliding window context compression mechanism, truncating history by keeping the suffix.","[[p,i,targetTokens,null,\"Target tokens to keep\"]]","[]","","[[\"feat24\",\"Feat\"],[\"cfgobj38\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj40","CfgObj","genai.types.AutomaticActivityDetection","Configures automatic detection of user activity (voice, text) for realtime input in the Live API. Can be disabled to require explicit client signals.","[[p,T,disabled,null,\"Disable automatic detection\"],[p,t,startOfSpeechSensitivity,null,\"Start of speech sensitivity (\",[\"cfgobj71\",\"CfgObj\"],\")\"],[p,t,endOfSpeechSensitivity,null,\"End of speech sensitivity (\",[\"cfgobj72\",\"CfgObj\"],\")\"],[p,i,prefixPaddingMs,null,\"Prefix padding (ms)\"],[p,i,silenceDurationMs,null,\"Silence duration (ms)\"]]","[]","","[[\"feat26\",\"Feat\"],[\"cfgobj51\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj41","CfgObj","genai.types.SpeechConfig","Configuration for speech generation (text-to-speech) in the Live API, including voice (`types.VoiceConfig`, `cfgobj112`) and language code.","[[p,t,voiceConfig,null,\"Voice configuration (\",[\"cfgobj112\",\"CfgObj\"],\")\"],[p,t,languageCode,null,\"Language code (e.g., en-US)\"]]","[]","","[[\"feat21\",\"Feat\"],[\"feat28\",\"Feat\"],[\"cfgobj54\",\"CfgObj\"],[\"cfgobj52\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj42","CfgObj","genai.types.PrebuiltVoiceConfig","Configuration for selecting a prebuilt speaker voice for speech synthesis.","[[p,t,voiceName,null,\"Name of the prebuilt voice\"]]","[]","","[[\"feat28\",\"Feat\"],[\"cfgobj41\",\"CfgObj\"],[\"cfgobj112\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj43","CfgObj","genai.types.ThinkingConfig","Configuration for including the model's internal thoughts (`types.Part.thought`) in the response and setting a thinking budget.","[[p,T,includeThoughts,null,\"Include thoughts in response\"],[p,i,thinkingBudget,null,\"Thinking budget in tokens\"]]","[]","","[[\"feat7\",\"Feat\"],[\"cfgobj5\",\"CfgObj\"],[\"cfgobj45\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj44","CfgObj","genai.types.LogprobsResult","Contains log probability information for the model's output, including chosen and top candidates with their scores, tokens, and token IDs.","[[p,list[types.LogprobsResultCandidate],chosenCandidates,null,\"Chosen candidates (\",[\"cfgobj81\",\"CfgObj\"],\")\"],[p,list[types.LogprobsResultTopCandidates],topCandidates,null,\"Top candidates (\",[\"cfgobj82\",\"CfgObj\"],\")\"]]","[]","","[[\"feat30\",\"Feat\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj45","CfgObj","genai.types.Part","A datatype containing media content. Exactly one field (text, inlineData, fileData, functionCall, functionResponse, executableCode, codeExecutionResult, thought, videoMetadata) should be set.","[[p,t,text,null,\"Text part\"],[p,t,inlineData,null,\"Inlined bytes data (\",[\"cfgobj65\",\"CfgObj\"],\")\"],[p,t,fileData,null,\"URI based data (\",[\"cfgobj21\",\"CfgObj\"],\")\"],[p,t,functionCall,null,\"Function call (\",[\"cfgobj25\",\"CfgObj\"],\")\"],[p,t,functionResponse,null,\"Function response (\",[\"cfgobj26\",\"CfgObj\"],\")\"],[p,t,executableCode,null,\"Executable code (\",[\"cfgobj46\",\"CfgObj\"],\")\"],[p,t,codeExecutionResult,null,\"Code execution result (\",[\"cfgobj47\",\"CfgObj\"],\")\"],[p,T,thought,null,\"Model thought indicator\"],[p,o,videoMetadata,null,\"Video metadata (\",[\"cfgobj66\",\"CfgObj\"],\")\"]]","[]","types.Part()","[[\"feat6\",\"Feat\"],[\"feat9\",\"Feat\"],[\"feat22\",\"Feat\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj46","CfgObj","genai.types.ExecutableCode","Code generated by the model that is meant to be executed client-side when using the Code Execution Tool. Contains the code string and language.","[[p,t,code,null,\"Required. Code to be executed\"],[p,t,language,null,\"Required. Programming language (\",[\"cfgobj64\",\"CfgObj\"],\")\"]]","[]","","[[\"feat22\",\"Feat\"],[\"cfgobj35\",\"CfgObj\"],[\"cfgobj45\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj47","CfgObj","genai.types.CodeExecutionResult","Result of executing the generated code (`types.ExecutableCode`), containing the outcome and output (stdout/stderr).","[[p,t,outcome,null,\"Required. Outcome (\",[\"cfgobj115\",\"CfgObj\"],\")\"],[p,t,output,null,\"Optional. Execution output (stdout/stderr)\"]]","[]","","[[\"feat22\",\"Feat\"],[\"cfgobj35\",\"CfgObj\"],[\"cfgobj45\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj48","CfgObj","genai.types.Type","Enum representing the basic data types used in Schema definitions (STRING, NUMBER, INTEGER, BOOLEAN, ARRAY, OBJECT).","[]","[]","","[[\"cfgobj9\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj49","CfgObj","genai.types.LiveClientMessage","Core message type sent by the client in the Live API stream, containing different possible payloads like client content, realtime input, setup, or tool responses.","[[p,t,clientContent,null,\"Incremental content update (\",[\"cfgobj50\",\"CfgObj\"],\")\"],[p,t,realtimeInput,null,\"Realtime input (\",[\"cfgobj51\",\"CfgObj\"],\")\"],[p,t,setup,null,\"Setup message (\",[\"cfgobj52\",\"CfgObj\"],\")\"],[p,t,toolResponse,null,\"Tool response (\",[\"cfgobj53\",\"CfgObj\"],\")\"]]","[]","","[[\"feat21\",\"Feat\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj50","CfgObj","genai.types.LiveClientContent","Incremental content update sent by the client in the Live API, typically appending turns to the conversation history.","[[p,list[types.Content],turns,null,\"Content turns\"],[p,T,turnComplete,null,\"Indicates turn completion\"]]","[]","","[[\"feat21\",\"Feat\"],[\"cfgobj49\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj51","CfgObj","genai.types.LiveClientRealtimeInput","Realtime user input sent in the Live API stream, supporting audio, video, text, and activity signals. Processed incrementally.","[[p,list[types.Blob],mediaChunks,null,\"Inlined media bytes (\",[\"cfgobj65\",\"CfgObj\"],\")\"],[p,t,audio,null,\"Realtime audio stream (\",[\"cfgobj65\",\"CfgObj\"],\")\"],[p,T,audioStreamEnd,null,\"Indicates end of audio stream\"],[p,t,video,null,\"Realtime video stream (\",[\"cfgobj65\",\"CfgObj\"],\")\"],[p,t,text,null,\"Realtime text stream\"],[p,t,activityStart,null,\"Start of user activity (\",[\"cfgobj69\",\"CfgObj\"],\")\"],[p,t,activityEnd,null,\"End of user activity (\",[\"cfgobj70\",\"CfgObj\"],\")\"]]","[]","","[[\"feat21\",\"Feat\"],[\"feat26\",\"Feat\"],[\"cfgobj49\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj52","CfgObj","genai.types.LiveClientSetup","Configuration message sent by the client to set up a Live API streaming session, including model, generation config, system instruction, tools, session resumption, and realtime input config.","[[p,t,model,null,\"Model name\"],[p,t,generationConfig,null,\"Generation config (\",[\"cfgobj54\",\"CfgObj\"],\")\"],[p,list[Union[types.File, types.Part, str]],systemInstruction,null,\"User provided system instructions\"],[p,list[Union[types.Tool, Callable]],tools,null,\"List of tools (\",[\"cfgobj8\",\"CfgObj\"],\")\"],[p,t,sessionResumption,null,\"Session resumption config (\",[\"cfgobj37\",\"CfgObj\"],\")\"],[p,t,contextWindowCompression,null,\"Context window compression config (\",[\"cfgobj38\",\"CfgObj\"],\")\"],[p,t,inputAudioTranscription,null,\"Input audio transcription config\"],[p,t,outputAudioTranscription,null,\"Output audio transcription config\"]]","[]","","[[\"feat21\",\"Feat\"],[\"cfgobj49\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj53","CfgObj","genai.types.LiveClientToolResponse","Message sent by the client in the Live API to provide responses to tool calls (`types.FunctionResponse`, `cfgobj26`) requested by the model.","[[p,list[types.FunctionResponse],functionResponses,null,\"List of function responses (\",[\"cfgobj26\",\"CfgObj\"],\")\"]]","[]","","[[\"feat21\",\"Feat\"],[\"feat9\",\"Feat\"],[\"howto52\",\"HowTo\"],[\"cfgobj49\",\"CfgObj\"],[\"cfgobj26\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj54","CfgObj","genai.types.LiveConnectConfig","Configuration parameters for establishing a Live API connection, including generation config, response modalities, realtime input config, speech config, context compression, and session resumption.","[[p,t,generationConfig,null,\"Generation config (\",[\"cfgobj5\",\"CfgObj\"],\")\"],[p,list[types.Modality],responseModalities,null,\"Requested response modalities (\",[\"cfgobj64\",\"CfgObj\"],\")\"],[p,n,temperature,null,\"Temperature\"],[p,n,topP,null,\"Top-p\"],[p,n,topK,null,\"Top-k\"],[p,i,maxOutputTokens,null,\"Max output tokens\"],[p,t,mediaResolution,null,\"Media resolution (\",[\"cfgobj66\",\"CfgObj\"],\")\"],[p,i,seed,null,\"Seed\"],[p,t,speechConfig,null,\"Speech generation config (\",[\"cfgobj41\",\"CfgObj\"],\")\"],[p,list[Union[types.File, types.Part, str]],systemInstruction,null,\"System instructions\"],[p,list[Union[types.Tool, Callable]],tools,null,\"List of tools (\",[\"cfgobj8\",\"CfgObj\"],\")\"],[p,t,sessionResumption,null,\"Session resumption config (\",[\"cfgobj37\",\"CfgObj\"],\")\"],[p,t,realtimeInputConfig,null,\"Realtime input config (\",[\"types.RealtimeInputConfig\",\"CfgObj\"],\")\"]]","[]","","[[\"feat21\",\"Feat\"],[\"cfgobj55\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj55","CfgObj","genai.types.LiveConnectParameters","Parameters for the `client.live.connect` method, specifying the model and the connection configuration (`types.LiveConnectConfig`, `cfgobj54`).","[[p,t,model,null,\"Model ID\"],[p,t,config,null,\"Optional configuration (\",[\"cfgobj54\",\"CfgObj\"],\")\"]]","[]","","[[\"feat21\",\"Feat\"],[\"howto49\",\"HowTo\"],[\"cfgobj3\",\"CfgObj\"],[\"cfgobj54\",\"CfgObj\"]]","chunk_1"]
["cfgobj56","CfgObj","genai.types.LiveSendRealtimeInputParameters","Parameters for sending realtime input (`types.Blob`, `cfgobj65`, or string) in a Live API session, including activity signals.","[[p,t,media,null,\"Realtime media input (\",[\"cfgobj65\",\"CfgObj\"],\")\"],[p,t,audio,null,\"Realtime audio stream (\",[\"cfgobj65\",\"CfgObj\"],\")\"],[p,T,audioStreamEnd,null,\"End of audio stream\"],[p,t,video,null,\"Realtime video stream (\",[\"cfgobj65\",\"CfgObj\"],\")\"],[p,t,text,null,\"Realtime text stream\"],[p,t,activityStart,null,\"Start of user activity (\",[\"cfgobj69\",\"CfgObj\"],\")\"],[p,t,activityEnd,null,\"End of user activity (\",[\"cfgobj70\",\"CfgObj\"],\")\"]]","[]","","[[\"feat21\",\"Feat\"],[\"howto50\",\"HowTo\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj57","CfgObj","genai.types.LiveServerMessage","Core response message type from the Live API stream, containing server-generated content, tool calls, usage metadata, or session updates.","[[p,t,setupComplete,null,\"Setup complete message (\",[\"cfgobj61\",\"CfgObj\"],\")\"],[p,t,serverContent,null,\"Server generated content (\",[\"cfgobj58\",\"CfgObj\"],\")\"],[p,t,toolCall,null,\"Tool call request (\",[\"cfgobj62\",\"CfgObj\"],\")\"],[p,t,toolCallCancellation,null,\"Tool call cancellation (\",[\"cfgobj63\",\"CfgObj\"],\")\"],[p,t,usageMetadata,null,\"Usage metadata (\",[\"cfgobj73\",\"CfgObj\"],\")\"],[p,t,goAway,null,\"Server disconnect notification (\",[\"cfgobj59\",\"CfgObj\"],\")\"],[p,t,sessionResumptionUpdate,null,\"Session resumption update (\",[\"cfgobj60\",\"CfgObj\"],\")\"]]","[]","","[[\"feat21\",\"Feat\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj58","CfgObj","genai.types.LiveServerContent","Incremental server update generated by the model in the Live API, containing model output (text, audio, etc.), and indicators like turn completion or interruption.","[[p,t,modelTurn,null,\"Model generated content (\",[\"types.Content\",\"CfgObj\"],\")\"],[p,T,turnComplete,null,\"Model done generating for the turn\"],[p,T,interrupted,null,\"Generation was interrupted\"],[p,t,groundingMetadata,null,\"Grounding metadata (\",[\"cfgobj76\",\"CfgObj\"],\")\"],[p,T,generationComplete,null,\"Model finished all generation\"],[p,t,inputTranscription,null,\"Input transcription (\",[\"cfgobj79\",\"CfgObj\"],\")\"],[p,t,outputTranscription,null,\"Output transcription (\",[\"cfgobj79\",\"CfgObj\"],\")\"]]","[]","","[[\"feat21\",\"Feat\"],[\"feat27\",\"Feat\"],[\"feat28\",\"Feat\"],[\"cfgobj57\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj59","CfgObj","genai.types.LiveServerGoAway","Message sent by the server in the Live API indicating it will disconnect soon, providing time left.","[[p,t,timeLeft,null,\"Remaining time before termination\"]]","[]","","[[\"feat21\",\"Feat\"],[\"cfgobj57\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj60","CfgObj","genai.types.LiveServerSessionResumptionUpdate","Message sent by the server in the Live API to update the session resumption state, providing a new handle and resumable status.","[[p,t,newHandle,null,\"New session handle\"],[p,T,resumable,null,\"Session can be resumed\"],[p,i,lastConsumedClientMessageIndex,null,\"Index of last consumed client message\"]]","[]","","[[\"feat21\",\"Feat\"],[\"feat25\",\"Feat\"],[\"cfgobj57\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj61","CfgObj","genai.types.LiveServerSetupComplete","Message sent by the server in the Live API confirming that the client setup message has been processed.","[]","[]","","[[\"feat21\",\"Feat\"],[\"cfgobj57\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj62","CfgObj","genai.types.LiveServerToolCall","Message sent by the server in the Live API requesting the client to execute a list of function calls (`types.FunctionCall`, `cfgobj25`).","[[p,list[types.FunctionCall],functionCalls,null,\"List of function calls (\",[\"cfgobj25\",\"CfgObj\"],\")\"]]","[]","","[[\"feat21\",\"Feat\"],[\"feat9\",\"Feat\"],[\"cfgobj57\",\"CfgObj\"],[\"cfgobj25\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj63","CfgObj","genai.types.LiveServerToolCallCancellation","Message sent by the server in the Live API to cancel previously issued tool calls by their IDs.","[[p,list[str],ids,null,\"IDs of tool calls to cancel\"]]","[]","","[[\"feat21\",\"Feat\"],[\"feat9\",\"Feat\"],[\"cfgobj57\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj64","CfgObj","genai.types.Modality","Enum representing response modalities in the Live API: TEXT, IMAGE, AUDIO.","[]","[]","","[[\"feat21\",\"Feat\"],[\"cfgobj54\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj65","CfgObj","genai.types.Blob","Content blob, typically used for inline binary data with a MIME type.","[[p,t,data,null,\"Required. Raw bytes (base64url encoded)\"],[p,t,mimeType,null,\"Required. IANA standard MIME type\"]]","[]","","[[\"cfgobj45\",\"CfgObj\"],[\"cfgobj51\",\"CfgObj\"],[\"cfgobj56\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj66","CfgObj","genai.types.MediaResolution","Enum representing media resolution options: MEDIA_RESOLUTION_LOW, MEDIA_RESOLUTION_MEDIUM, MEDIA_RESOLUTION_HIGH.","[]","[]","","[[\"feat7\",\"Feat\"],[\"cfgobj5\",\"CfgObj\"],[\"cfgobj54\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj67","CfgObj","genai.types.ActivityHandling","Enum defining how user activity affects generation in the Live API: START_OF_ACTIVITY_INTERRUPTS, NO_INTERRUPTION.","[]","[]","","[[\"feat26\",\"Feat\"],[\"cfgobj51\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj68","CfgObj","genai.types.TurnCoverage","Enum defining which input is included in the user's turn in the Live API: TURN_INCLUDES_ONLY_ACTIVITY, TURN_INCLUDES_ALL_INPUT.","[]","[]","","[[\"feat26\",\"Feat\"],[\"cfgobj51\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj69","CfgObj","genai.types.ActivityStart","Message marking the explicit start of user activity in the Live API, used when automatic detection is disabled.","[]","[]","","[[\"feat26\",\"Feat\"],[\"cfgobj51\",\"CfgObj\"],[\"cfgobj56\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj70","CfgObj","genai.types.ActivityEnd","Message marking the explicit end of user activity in the Live API, used when automatic detection is disabled.","[]","[]","","[[\"feat26\",\"Feat\"],[\"cfgobj51\",\"CfgObj\"],[\"cfgobj56\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj71","CfgObj","genai.types.StartSensitivity","Enum for start of speech sensitivity in AutomaticActivityDetection: START_SENSITIVITY_HIGH, START_SENSITIVITY_LOW.","[]","[]","","[[\"feat26\",\"Feat\"],[\"cfgobj40\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj72","CfgObj","genai.types.EndSensitivity","Enum for end of speech sensitivity in AutomaticActivityDetection: END_SENSITIVITY_HIGH, END_SENSITIVITY_LOW.","[]","[]","","[[\"feat26\",\"Feat\"],[\"cfgobj40\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj73","CfgObj","genai.types.UsageMetadata","Usage metadata about model responses, including detailed token counts (`types.ModalityTokenCount`, `cfgobj74`) for different parts of the prompt and response, and traffic type (`types.TrafficType`, `cfgobj75`).","[[p,i,promptTokenCount,null,\"Tokens in the prompt\"],[p,i,cachedContentTokenCount,null,\"Tokens in cached content\"],[p,i,responseTokenCount,null,\"Tokens in response candidates\"],[p,i,toolUsePromptTokenCount,null,\"Tokens in tool-use prompt\"],[p,i,thoughtsTokenCount,null,\"Tokens in thoughts\"],[p,i,totalTokenCount,null,\"Total token count\"],[p,list[types.ModalityTokenCount],promptTokensDetails,null,\"Prompt token details by modality (\",[\"cfgobj74\",\"CfgObj\"],\")\"],[p,list[types.ModalityTokenCount],cacheTokensDetails,null,\"Cache token details by modality (\",[\"cfgobj74\",\"CfgObj\"],\")\"],[p,list[types.ModalityTokenCount],responseTokensDetails,null,\"Response token details by modality (\",[\"cfgobj74\",\"CfgObj\"],\")\"],[p,list[types.ModalityTokenCount],toolUsePromptTokensDetails,null,\"Tool use prompt token details by modality (\",[\"cfgobj74\",\"CfgObj\"],\")\"],[p,t,trafficType,null,\"Traffic type (\",[\"cfgobj75\",\"CfgObj\"],\")\"]]","[]","","[[\"feat29\",\"Feat\"],[\"func1\",\"Func\"],[\"func2\",\"Func\"],[\"func10\",\"Func\"],[\"func11\",\"Func\"],[\"func12\",\"Func\"],[\"cfgobj57\",\"CfgObj\"],[\"cfgobj74\",\"CfgObj\"],[\"cfgobj75\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj74","CfgObj","genai.types.ModalityTokenCount","Represents token counting information for a single media modality within `types.UsageMetadata`.","[[p,t,modality,null,\"Modality (\",[\"cfgobj65\",\"CfgObj\"],\")\"],[p,i,tokenCount,null,\"Number of tokens\"]]","[]","","[[\"feat29\",\"Feat\"],[\"cfgobj73\",\"CfgObj\"],[\"cfgobj65\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj75","CfgObj","genai.types.TrafficType","Enum indicating the traffic type for a request: ON_DEMAND or PROVISIONED_THROUGHPUT. Used in `types.UsageMetadata`.","[]","[]","","[[\"feat29\",\"Feat\"],[\"cfgobj73\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj76","CfgObj","genai.types.RetrievalMetadata","Metadata related to retrieval in the grounding flow, including Google Search dynamic retrieval score. Used in `types.LiveServerContent`.","[[p,n,googleSearchDynamicRetrievalScore,null,\"Google Search dynamic retrieval score [0, 1]\"]]","[]","","[[\"feat21\",\"Feat\"],[\"cfgobj58\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj77","CfgObj","genai.types.SearchEntryPoint","Google search entry point information, including rendered content and SDK blob. Used in `types.LiveServerContent`.","[[p,t,renderedContent,null,\"Web content snippet\"],[p,bytes,sdkBlob,null,\"Base64 encoded JSON blob\"]]","[]","","[[\"feat21\",\"Feat\"],[\"cfgobj58\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj78","CfgObj","genai.types.Segment","Represents a segment of content within a `types.Part`, including start/end indices, part index, and text. Used in `types.GroundingSupport`.","[[p,i,endIndex,null,\"Output only. End index (bytes)\"],[p,i,partIndex,null,\"Output only. Part index\"],[p,i,startIndex,null,\"Output only. Start index (bytes)\"],[p,t,text,null,\"Output only. Segment text\"]]","[]","","[[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj79","CfgObj","genai.types.Transcription","Audio transcription information, including the transcribed text and a finished indicator. Used in `types.LiveServerContent`.","[[p,t,text,null,\"Transcription text\"],[p,T,finished,null,\"End of transcription indicator\"]]","[]","","[[\"feat21\",\"Feat\"],[\"feat27\",\"Feat\"],[\"cfgobj58\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj80","CfgObj","genai.types.LogprobsResultCandidate","Represents a candidate token within `types.LogprobsResult`, including its log probability, token string, and token ID.","[[p,n,logProbability,null,\"Log probability\"],[p,t,token,null,\"Token string\"],[p,i,tokenId,null,\"Token ID\"]]","[]","","[[\"feat30\",\"Feat\"],[\"cfgobj44\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj81","CfgObj","genai.types.LogprobsResultTopCandidates","Contains a list of `types.LogprobsResultCandidate` (`cfgobj80`) representing the top candidates at a decoding step. Used in `types.LogprobsResult`.","[[p,list[types.LogprobsResultCandidate],candidates,null,\"Sorted list of candidate tokens (\",[\"cfgobj80\",\"CfgObj\"],\")\"]]","[]","","[[\"feat30\",\"Feat\"],[\"cfgobj44\",\"CfgObj\"],[\"cfgobj80\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj82","CfgObj","genai.types.MaskReferenceImage","A mask reference image used in image editing (`func15`), encapsulating a mask image (`types.Image`) and/or configuration (`types.MaskReferenceConfig`, `cfgobj83`) for mask generation.","[[p,t,referenceImage,null,\"Reference image (\",[\"types.Image\",\"CfgObj\"],\")\"],[p,i,referenceId,null,\"Image ID\"],[p,t,referenceType,null,\"Image type (SDK set)\"],[p,t,config,null,\"Mask reference config (\",[\"cfgobj83\",\"CfgObj\"],\")\"]]","[]","","[[\"feat13\",\"Feat\"],[\"feat31\",\"Feat\"],[\"func15\",\"Func\"],[\"cfgobj3\",\"CfgObj\"],[\"cfgobj83\",\"CfgObj\"]]","chunk_1"]
["cfgobj83","CfgObj","genai.types.MaskReferenceConfig","Configuration for a mask reference image (`types.MaskReferenceImage`, `cfgobj82`), controlling mask mode (user-provided, background, foreground, semantic) and dilation.","[[p,t,maskMode,null,\"Mask mode (\",[\"cfgobj85\",\"CfgObj\"],\")\"],[p,list[int],segmentationClasses,null,\"List of segmentation class IDs\"],[p,n,maskDilation,null,\"Mask dilation percentage [0, 1]\"]]","[]","","[[\"feat13\",\"Feat\"],[\"feat31\",\"Feat\"],[\"cfgobj82\",\"CfgObj\"],[\"cfgobj85\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj84","CfgObj","genai.types.RawReferenceImage","A raw reference image (`types.Image`) representing the base image to edit (`func15`). Can be provided optionally with other reference image types.","[[p,t,referenceImage,null,\"Reference image (\",[\"types.Image\",\"CfgObj\"],\")\"],[p,i,referenceId,null,\"Image ID\"],[p,t,referenceType,null,\"Image type (SDK set)\"]]","[]","","[[\"feat13\",\"Feat\"],[\"feat31\",\"Feat\"],[\"func15\",\"Func\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj85","CfgObj","genai.types.MaskReferenceMode","Enum representing mask modes for image editing: MASK_MODE_USER_PROVIDED, MASK_MODE_BACKGROUND, MASK_MODE_FOREGROUND, MASK_MODE_SEMANTIC. Used in `types.MaskReferenceConfig`.","[]","[]","","[[\"feat13\",\"Feat\"],[\"feat31\",\"Feat\"],[\"cfgobj83\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj86","CfgObj","genai.types.StyleReferenceConfig","Configuration for a style reference image (`types.StyleReferenceImage`, `cfgobj120`), including an optional text description of the style.","[[p,t,styleDescription,null,\"Text description of the style\"]]","[]","","[[\"feat13\",\"Feat\"],[\"feat31\",\"Feat\"],[\"cfgobj120\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj87","CfgObj","genai.types.StyleReferenceImage","A style reference image (`types.Image`) used in image editing (`func15`), encapsulating the style image and optional config (`types.StyleReferenceConfig`, `cfgobj86`).","[[p,t,referenceImage,null,\"Reference image (\",[\"types.Image\",\"CfgObj\"],\")\"],[p,i,referenceId,null,\"Image ID\"],[p,t,referenceType,null,\"Image type (SDK set)\"],[p,t,config,null,\"Style reference config (\",[\"cfgobj86\",\"CfgObj\"],\")\"]]","[]","","[[\"feat13\",\"Feat\"],[\"feat31\",\"Feat\"],[\"func15\",\"Func\"],[\"cfgobj3\",\"CfgObj\"],[\"cfgobj86\",\"CfgObj\"]]","chunk_1"]
["cfgobj88","CfgObj","genai.types.JobState","Enum representing the state of a long-running job (`types.TuningJob`, `cfgobj92`): QUEUED, PENDING, RUNNING, SUCCEEDED, FAILED, CANCELLED, etc.","[]","[]","","[[\"feat18\",\"Feat\"],[\"cfgobj92\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj89","CfgObj","genai.types.GoogleRpcStatus","Standard Google RPC Status object used for detailed error information in jobs and responses, including code, message, and a list of details.","[[p,i,code,null,\"Status code\"],[p,t,message,null,\"Error message\"],[p,list[o],details,null,\"List of error details\"]]","[]","","[[\"feat20\",\"Feat\"],[\"cfgobj19\",\"CfgObj\"],[\"cfgobj92\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj90","CfgObj","genai.types.SubjectReferenceImage","A subject reference image (`types.Image`) used in image editing (`func15`), encapsulating the subject image and optional config (`types.SubjectReferenceConfig`, `cfgobj89`).","[[p,t,referenceImage,null,\"Reference image (\",[\"types.Image\",\"CfgObj\"],\")\"],[p,i,referenceId,null,\"Image ID\"],[p,t,referenceType,null,\"Image type (SDK set)\"],[p,t,config,null,\"Subject reference config (\",[\"cfgobj89\",\"CfgObj\"],\")\"]]","[]","","[[\"feat13\",\"Feat\"],[\"feat31\",\"Feat\"],[\"func15\",\"Func\"],[\"cfgobj3\",\"CfgObj\"],[\"cfgobj89\",\"CfgObj\"]]","chunk_1"]
["cfgobj91","CfgObj","genai.types.SubjectReferenceType","Enum representing subject types for image editing: SUBJECT_TYPE_PERSON, SUBJECT_TYPE_ANIMAL, SUBJECT_TYPE_PRODUCT. Used in `types.SubjectReferenceConfig`.","[]","[]","","[[\"feat13\",\"Feat\"],[\"feat31\",\"Feat\"],[\"cfgobj89\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj92","CfgObj","genai.types.TuningJob","Represents a tuning job resource, including its name, state (`cfgobj88`), timestamps, base model, tuned model (`cfgobj95`), tuning specs (`cfgobj93`, `cfgobj98`, `cfgobj100`), data stats (`cfgobj96`), and error details (`cfgobj89`).","[[p,t,name,null,\"Output only. Resource name\"],[p,t,state,null,\"Output only. Job state (\",[\"cfgobj88\",\"CfgObj\"],\")\"],[p,t,createTime,null,\"Output only. Creation time\"],[p,t,startTime,null,\"Output only. Start time\"],[p,t,endTime,null,\"Output only. End time\"],[p,t,updateTime,null,\"Output only. Update time\"],[p,t,error,null,\"Output only. Error status (\",[\"cfgobj89\",\"CfgObj\"],\")\"],[p,t,description,null,\"Optional. Description\"],[p,t,baseModel,null,\"Base model name\"],[p,t,tunedModel,null,\"Output only. Tuned model resource (\",[\"cfgobj95\",\"CfgObj\"],\")\"],[p,t,supervisedTuningSpec,null,\"SFT tuning spec (\",[\"cfgobj93\",\"CfgObj\"],\")\"],[p,t,tuningDataStats,null,\"Output only. Tuning data stats (\",[\"cfgobj96\",\"CfgObj\"],\")\"],[p,t,encryptionSpec,null,\"Encryption key options (\",[\"cfgobj101\",\"CfgObj\"],\")\"],[p,t,partnerModelTuningSpec,null,\"Partner model tuning spec (\",[\"cfgobj100\",\"CfgObj\"],\")\"],[p,t,distillationSpec,null,\"Distillation tuning spec (\",[\"cfgobj98\",\"CfgObj\"],\")\"],[p,t,experiment,null,\"Output only. Experiment name\"],[p,o,labels,null,\"Optional. User-defined labels\"],[p,t,pipelineJob,null,\"Output only. PipelineJob resource name\"],[p,t,tunedModelDisplayName,null,\"Optional. Tuned model display name\"]]","[]","","[[\"feat18\",\"Feat\"],[\"feat32\",\"Feat\"],[\"feat33\",\"Feat\"],[\"cfgobj17\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj93","CfgObj","genai.types.SupervisedTuningSpec","Tuning specification for Supervised Fine-Tuning (SFT) on first-party models, including hyperparameters (`types.SupervisedHyperParameters`, `cfgobj94`) and dataset URIs.","[[p,t,hyperParameters,null,\"Optional. Hyperparameters (\",[\"cfgobj94\",\"CfgObj\"],\")\"],[p,t,trainingDatasetUri,null,\"Required. GCS URI for training dataset\"],[p,t,validationDatasetUri,null,\"Optional. GCS URI for validation dataset\"]]","[]","","[[\"feat18\",\"Feat\"],[\"cfgobj92\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj94","CfgObj","genai.types.SupervisedHyperParameters","Hyperparameters for Supervised Fine-Tuning (SFT), including adapter size, epoch count, and learning rate multiplier.","[[p,t,adapterSize,null,\"Optional. Adapter size (\",[\"types.AdapterSize\",\"CfgObj\"],\")\"],[p,i,epochCount,null,\"Optional. Number of epochs\"],[p,n,learningRateMultiplier,null,\"Optional. Learning rate multiplier\"]]","[]","","[[\"feat18\",\"Feat\"],[\"cfgobj93\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj95","CfgObj","genai.types.TunedModel","Represents a tuned model resource, including its model resource name and endpoint resource name.","[[p,t,model,null,\"Output only. Tuned model resource name\"],[p,t,endpoint,null,\"Output only. Endpoint resource name\"]]","[]","","[[\"feat18\",\"Feat\"],[\"cfgobj92\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj96","CfgObj","genai.types.TuningDataStats","Tuning data statistic values for a `types.TuningJob`, including statistics for supervised tuning (`types.SupervisedTuningDataStats`, `cfgobj97`) and distillation (`types.DistillationDataStats`, `cfgobj55`).","[[p,t,distillationDataStats,null,\"Output only. Stats for distillation (\",[\"cfgobj55\",\"CfgObj\"],\")\"],[p,t,supervisedTuningDataStats,null,\"SFT data stats (\",[\"cfgobj97\",\"CfgObj\"],\")\"]]","[]","","[[\"feat18\",\"Feat\"],[\"feat32\",\"Feat\"],[\"cfgobj92\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj97","CfgObj","genai.types.SupervisedTuningDataStats","Tuning data statistics specifically for Supervised Tuning, including character/token counts, example count, truncated example info, and distributions.","[[p,i,totalBillableCharacterCount,null,\"Output only. Billable character count\"],[p,i,totalBillableTokenCount,null,\"Output only. Billable token count\"],[p,i,totalTruncatedExampleCount,null,\"Truncated example count\"],[p,i,totalTuningCharacterCount,null,\"Output only. Tuning character count\"],[p,list[int],truncatedExampleIndices,null,\"Partial list of truncated example indices\"],[p,i,tuningDatasetExampleCount,null,\"Output only. Example count\"],[p,i,tuningStepCount,null,\"Output only. Tuning step count\"],[p,list[types.Content],userDatasetExamples,null,\"Output only. Sample user examples\"],[p,t,userInputTokenDistribution,null,\"Output only. Input token distribution\"],[p,t,userMessagePerExampleDistribution,null,\"Output only. Messages per example distribution\"],[p,t,userOutputTokenDistribution,null,\"Output only. Output token distribution\"]]","[]","","[[\"feat18\",\"Feat\"],[\"cfgobj96\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj98","CfgObj","genai.types.DistillationSpec","Tuning specification for Distillation, including student/teacher models, hyperparameters (`types.DistillationHyperParameters`, `cfgobj99`), dataset URIs, and a pipeline root directory.","[[p,t,baseTeacherModel,null,\"Base teacher model name\"],[p,t,hyperParameters,null,\"Optional. Hyperparameters (\",[\"cfgobj99\",\"CfgObj\"],\")\"],[p,t,pipelineRootDirectory,null,\"Required. Cloud Storage pipeline root directory\"],[p,t,studentModel,null,\"Student model name\"],[p,t,trainingDatasetUri,null,\"Required. GCS URI for training dataset\"],[p,t,tunedTeacherModelSource,null,\"Tuned teacher model resource name\"],[p,t,validationDatasetUri,null,\"Optional. GCS URI for validation dataset\"]]","[]","","[[\"feat18\",\"Feat\"],[\"feat32\",\"Feat\"],[\"cfgobj92\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj99","CfgObj","genai.types.DistillationHyperParameters","Hyperparameters for Distillation, including adapter size, epoch count, and learning rate multiplier.","[[p,t,adapterSize,null,\"Optional. Adapter size (\",[\"types.AdapterSize\",\"CfgObj\"],\")\"],[p,i,epochCount,null,\"Optional. Number of epochs\"],[p,n,learningRateMultiplier,null,\"Optional. Learning rate multiplier\"]]","[]","","[[\"feat32\",\"Feat\"],[\"cfgobj98\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj100","CfgObj","genai.types.PartnerModelTuningSpec","Tuning specification for partner models, including hyperparameters (arbitrary object) and dataset URIs.","[[p,o,hyperParameters,null,\"Optional. Hyperparameters (dict)\"],[p,t,trainingDatasetUri,null,\"Required. GCS URI for training dataset\"],[p,t,validationDatasetUri,null,\"Optional. GCS URI for validation dataset\"]]","[]","","[[\"feat18\",\"Feat\"],[\"feat33\",\"Feat\"],[\"cfgobj92\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj101","CfgObj","genai.types.EncryptionSpec","Represents a customer-managed encryption key (CMEK) specification for encrypting resources created by a TuningJob.","[[p,t,kmsKeyName,null,\"Required. Cloud KMS resource identifier\"]]","[]","","[[\"feat18\",\"Feat\"],[\"cfgobj92\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj102","CfgObj","genai.types.JobState","Enum representing the detailed state of a long-running job: JOB_STATE_UNSPECIFIED, JOB_STATE_QUEUED, JOB_STATE_PENDING, JOB_STATE_RUNNING, JOB_STATE_SUCCEEDED, JOB_STATE_FAILED, JOB_STATE_CANCELLING, JOB_STATE_CANCELLED, JOB_STATE_PAUSED, JOB_STATE_EXPIRED, JOB_STATE_UPDATING, JOB_STATE_PARTIALLY_SUCCEEDED. Used in `types.TuningJob`.","[]","[]","","[[\"feat18\",\"Feat\"],[\"cfgobj92\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj103","CfgObj","genai.types.GoogleRpcStatus","Detailed status object suitable for different programming environments, including error code, message, and details. Used in `errors.APIError` and `types.TuningJob`.","[[p,i,code,null,\"The status code (google.rpc.Code)\"],[p,t,message,null,\"Developer-facing error message\"],[p,list[o],details,null,\"List of messages with error details\"]]","[]","","[[\"feat20\",\"Feat\"],[\"cfgobj19\",\"CfgObj\"],[\"cfgobj92\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj104","CfgObj","genai.types.Model","Represents a trained machine learning model resource, including name, display name, description, version, endpoints, labels, and token limits.","[[p,t,name,null,\"Resource name\"],[p,t,displayName,null,\"Display name\"],[p,t,description,null,\"Description\"],[p,t,version,null,\"Version ID\"],[p,list[types.Endpoint],endpoints,null,\"List of deployed endpoints\"],[p,o,labels,null,\"User-defined labels\"],[p,t,tunedModelInfo,null,\"Tuned model info (\",[\"types.TunedModelInfo\",\"CfgObj\"],\")\"],[p,i,inputTokenLimit,null,\"Max input tokens\"],[p,i,outputTokenLimit,null,\"Max output tokens\"],[p,list[str],supportedActions,null,\"List of supported actions\"]]","[]","","[[\"cfgobj4\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj105","CfgObj","genai.types.Operation","Represents a long-running operation resource, including its server-assigned name, metadata, status (done), and error details.","[[p,t,name,null,\"Server-assigned name\"],[p,o,metadata,null,\"Service-specific metadata\"],[p,T,done,null,\"Operation completed\"],[p,o,error,null,\"Error result (\",[\"cfgobj103\",\"CfgObj\"],\")\"]]","[]","","[[\"feat14\",\"Feat\"],[\"cfgobj13\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj106","CfgObj","genai.types.UpdateCachedContentConfig","Configuration for updating a cached content resource, primarily to set or update its TTL or expire time.","[[p,t,httpOptions,null,\"HTTP options (\",[\"cfgobj2\",\"CfgObj\"],\")\"],[p,t,ttl,null,\"Duration string (e.g., \\\"3.5s\\\")\"],[p,t,expireTime,null,\"Expiration timestamp (RFC 3339)\"]]","[]","","[[\"feat17\",\"Feat\"],[\"feat35\",\"Feat\"],[\"cfgobj16\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj107","CfgObj","genai.types.UpdateModelConfig","Configuration for updating a tuned model resource (`types.Model`), allowing modification of display name and description.","[[p,t,httpOptions,null,\"HTTP options (\",[\"cfgobj2\",\"CfgObj\"],\")\"],[p,t,displayName,null,\"New display name\"],[p,t,description,null,\"New description\"]]","[]","","[[\"feat34\",\"Feat\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj108","CfgObj","genai.types.UpscaleImageParameters","Parameters for the `client.models.upscale_image` method, including the model, input image (`types.Image`), upscale factor, and optional config (`types.UpscaleImageConfig`, `cfgobj109`).","[[p,t,model,null,\"Model name\"],[p,t,image,null,\"Input image (\",[\"types.Image\",\"CfgObj\"],\")\"],[p,t,upscaleFactor,null,\"Upscale factor ('x2' or 'x4')\"],[p,t,config,null,\"Optional config (\",[\"cfgobj109\",\"CfgObj\"],\")\"]]","[]","","[[\"feat13\",\"Feat\"],[\"feat36\",\"Feat\"],[\"func14\",\"Func\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj109","CfgObj","genai.types.UpscaleImageConfig","Configuration for upscaling an image, including output MIME type, compression quality, and RAI reason inclusion. Used in `types.UpscaleImageParameters`.","[[p,t,httpOptions,null,\"HTTP options (\",[\"cfgobj2\",\"CfgObj\"],\")\"],[p,T,includeRaiReason,null,\"Include RAI reason in response\"],[p,t,outputMimeType,null,\"Output image format\"],[p,i,outputCompressionQuality,null,\"Compression quality (JPEG)\"]]","[]","","[[\"feat13\",\"Feat\"],[\"feat36\",\"Feat\"],[\"cfgobj108\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj110","CfgObj","genai.types.UpscaleImageResponse","Response object for image upscaling operations (`func14`), containing the list of generated images (`types.GeneratedImage`).","[[p,list[types.GeneratedImage],generatedImages,null,\"Generated images (\",[\"types.GeneratedImage\",\"CfgObj\"],\")\"]]","[]","","[[\"feat13\",\"Feat\"],[\"feat36\",\"Feat\"],[\"func14\",\"Func\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj111","CfgObj","genai.types.Video","Represents a generated video, including URI, video bytes, and MIME type.","[[p,t,uri,null,\"Path to another storage\"],[p,bytes,videoBytes,null,\"Video bytes (base64url encoded)\"],[p,t,mimeType,null,\"Video encoding (e.g., video/mp4)\"]]","[]","","[[\"feat14\",\"Feat\"],[\"func16\",\"Func\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
["cfgobj112","CfgObj","genai.types.VoiceConfig","Configuration for the voice to use in speech synthesis, including a prebuilt voice config (`types.PrebuiltVoiceConfig`, `cfgobj42`).","[[p,t,prebuiltVoiceConfig,null,\"Prebuilt voice config (\",[\"cfgobj42\",\"CfgObj\"],\")\"]]","[]","","[[\"feat28\",\"Feat\"],[\"cfgobj41\",\"CfgObj\"],[\"cfgobj42\",\"CfgObj\"],[\"cfgobj3\",\"CfgObj\"]]","chunk_1"]
```