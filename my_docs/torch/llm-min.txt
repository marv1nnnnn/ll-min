S:PyTorch;V:2.7|O:K~deep learning,tensor library;P~Usability over Performance,Simple Over Easy,Python First;O~Autograd mechanics,Broadcasting semantics,CPU threading,TorchScript inference,CUDA semantics,Distributed Data Parallel,Extending PyTorch,Frequently Asked Questions,FSDP Notes,Multiprocessing best practices,Numerical accuracy,Reproducibility,Serialization semantics,Windows FAQ,Community Governance,Contribution Process,Design Philosophy,Governance Mechanics,Maintainer Responsibilities,Pipeline Parallelism Concepts,Tensor Parallelism Concepts,Complex Numbers,Quantization,Sparse Tensors,Distributed RPC Framework,ExecuTorch,TorchData,TorchRec,TorchServe,torchtext,torchvision,TorchXLA,torchao,torchaudio,TorchTune,TorchChat,TorchCodec;F:GPU acceleration,CPU acceleration,Autograd,Mixed Precision,Gradient Scaling,Custom Autograd Functions,Profiling,Anomaly Detection,Autograd Graph Inspection,Gradient Layouts,In-place operations,Forward-mode AD,Functional API,Data Loading,Map-style datasets,Iterable-style datasets,Data Samplers,Automatic batching,Memory Pinning,Multi-process data loading,Checkpointing,Distributed Checkpoint,Asynchronous Saving,Stateful Objects,Storage Interface,Planning Interface,Model State Dict,Optimizer State Dict,Format Conversion,DLPack,C++ API,CUDA,MPS,XPU,MTIA,Backends,cuDNN,cuSPARSELt,MHA,MKL,MKLDNN,NNPACK,OpenMP,opt_einsum,Distributed Communication,Process Groups,DeviceMesh,Point-to-point communication,Collective operations,Distributed Key-Value Store,Third-party backends,Distributed Launch Utility,Spawn utility,Distributed Debugging,DDP Communication Hooks,Gradient Compression,PowerSGD,Zero Redundancy Optimizer,Distributed Optimizer,Pipeline Parallelism,Model Splitting,Pipeline Schedules,Microbatching,Tensor Parallelism,Colwise Parallel,Rowwise Parallel,Sequence Parallel,Loss Parallelism,Complex Numbers,Quantization,Sparse Tensors,Distributed RPC Framework,TunableOp,Stream Sanitizer,GPUDirect Storage,Jiterator,Reproducibility,Numerical Accuracy,Serialization Semantics,Autocasting,Distributed Elastic|I:P~CUDA for GPU build;C~install_cmd;S~FileStore cleanup required after use^;V~profiling,debugging|C:M~Autograd,Distributed,Edge,TorchScript,TorchDynamo,AOT Autograd,Torch FX,DLPack,C++ API,CUDA,MPS,XPU,MTIA,MKL,MKLDNN,NNPACK,OpenMP,opt_einsum,cuSPARSELt,cuBLAS,cuBLASLt,CK,cuSOLVER,MAGMA,AOTriton,DPC++,Ninja,Multi-process loading,Pinned Memory,Checkpointing,Distributed Checkpoint,DDP Communication Hooks,Gradient Compression,PowerSGD,Zero Redundancy Optimizer,Pipeline Parallelism,Tensor Parallelism,Complex Numbers,Quantization,Sparse Tensors,Distributed RPC Framework,TunableOp,Stream Sanitizer,GPUDirect Storage,Jiterator;O~torch.Tensor,Module,Buffer,ExportedProgram,Pipe,PipelineStage,Store,TCPStore,FileStore,HashStore,PrefixStore,GradBucket,TensorDataset,StackDataset,ConcatDataset,ChainDataset,Subset,Sampler,SequentialSampler,RandomSampler,SubsetRandomSampler,WeightedRandomSampler,BatchSampler,DistributedSampler,DeviceMesh,Work,ReduceOp,P2POp,MixedPrecisionPolicy,CPUOffloadPolicy,SDPAParams,AsyncCheckpointerType,StorageReader,StorageWriter,LoadPlanner,SavePlanner,LoadPlan,ReadItem,SavePlan,WriteItem,FileSystemReader,FileSystemWriter,DefaultSavePlanner,DefaultLoadPlanner,Stateful,AsyncStager,BlockingAsyncStager,UnshardHandle,OptimStateKeyType,StateDictSettings,TensorChunkSpec,CommDebugMode,SelectedCheckpointContext,NamedTuple,DataClass,DeviceProperties,EventList,ArrayLike,IO,PathLike,Scalar,Sequential,BaseContext,Generator,WorkerInfo,RemovableHandle,ProcessGroup,GroupMember,StatefulT,Metadata,MetadataIndex,LoadItemType,BytesIO,SavePlan,WriteResult,StorageMeta,STATE_DICT_TYPE,Optimizer,OptimizerStateType,ValueType,Future,OpOverload,PlacementType,TreeSpec,FakeScriptObject,UnflattenedModule,Dim,Constraint,ExportBackwardSignature,ExportGraphSignature,ModuleCallSignature,ModuleCallEntry,CustomDecompTable,InputKind,InputSpec,OutputKind,OutputSpec,SymIntArgument,SymBoolArgument,SymFloatArgument,CustomObjArgument,BlasBackend,ROCmFABackend,LinalgBackend,CPUOffload,StateDictConfig;E~MASTER_PORT,MASTER_ADDR,WORLD_SIZE,RANK,LOCAL_RANK,NCCL_SOCKET_IFNAME,GLOO_SOCKET_IFNAME,NCCL_DEBUG,NCCL_DEBUG_SUBSYS,NCCL_SOCKET_NTHREADS,NCCL_NSOCKS_PERTHREAD,TORCH_CUDA_ARCH_LIST,TORCH_XPU_ARCH_LIST,MAX_JOBS,TORCHELASTIC_RUN_ID,MKL_VERBOSE,DNNL_VERBOSE,USE_DISTRIBUTED,TORCH_BLAS_PREFER_CUBLASLT,TORCH_ROCM_FA_PREFER_CK,TORCH_LINALG_PREFER_CUSOLVER,TORCH_CPP_LOG_LEVEL,TORCH_DISTRIBUTED_DEBUG,TORCH_SHOW_CPP_STACKTRACES
A:torch.amp.autocast_mode#is_autocast_available(device_type~str)>bool;torch#autocast(device_type~str,dtype~torch_dtype=None,enabled~bool=True,cache_enabled~bool=None)();torch.amp#custom_fwd(fwd~Callable,device_type~str,cast_inputs~torch_dtype=None)>Callable;torch.amp#custom_bwd(bwd~Callable,device_type~str)>Callable;torch.cuda.amp#autocast()!D;torch.cuda.amp#custom_fwd()!D;torch.cuda.amp#custom_bwd()!D;torch.cpu.amp#autocast()!D;torch.cuda.amp#GradScaler()!D;torch.cpu.amp#GradScaler()!D;torch.autograd#backward(tensors,gradient,retain_graph,create_graph);torch.autograd#grad(outputs,inputs,grad_outputs,retain_graph,create_graph,allow_unused,is_grads_batched);torch.autograd.forward_ad#dual_level()()!B;torch.autograd.forward_ad#make_dual(value~Tensor,tangent~Tensor)>Tensor!B;torch.autograd.forward_ad#unpack_dual(dual~Tensor)>UnpackedDualTensor!B;torch.autograd.forward_ad#enter_dual_level()>None!B;torch.autograd.forward_ad#exit_dual_level()>None!B;torch.autograd.functional#jacobian()!B;torch.autograd.functional#hessian()!B;torch.autograd.functional#vjp()!B;torch.autograd.functional#jvp()!B;torch.autograd.functional#vhp()!B;torch.autograd.functional#hvp()!B;torch#Tensor(T~grad~Tensor=None,T~requires_grad~bool,T~is_leaf~bool;M~backward(gradient,retain_graph,create_graph);M~detach();M~detach_();M~register_hook(hook~Callable);M~register_post_accumulate_grad_hook(hook~Callable);M~retain_grad());torch.autograd#Function(I();M~forward(ctx,i);M~backward(ctx,grad_output);M~jvp();M~vmap());torch.autograd.function#FunctionCtx(M~mark_dirty(tensors~Tensor);M~mark_non_differentiable(outputs~Tensor);M~save_for_backward(tensors~Tensor);M~set_materialize_grads(value~bool));torch.autograd.function#once_differentiable(fwd,bwd);torch.autograd.function#BackwardCFunction();torch.autograd.function#InplaceFunction();torch.autograd.function#NestedIOFunction();torch.autograd#gradcheck();torch.autograd#gradgradcheck();torch.autograd.profiler#profile(enabled~bool=True,use_cuda~bool=False,use_device~str=None,record_shapes~bool=False,with_flops~bool=False,profile_memory~bool=False,with_stack~bool=False,with_modules~bool=False,use_kineto~bool=False,use_cpu~bool=True,experimental_config~ExperimentalConfig=None,acc_events~bool=False,custom_trace_id_callback~Callable=None)(I();M~export_chrome_trace();M~key_averages()>EventList;T~self_cpu_time_total;M~total_average()>EventList);torch.autograd.profiler#emit_nvtx(enabled~bool=True,record_shapes~bool=False)();torch.autograd.profiler#emit_itt(enabled~bool=True,record_shapes~bool=False)();torch.autograd.profiler#parse_nvprof_trace();torch.autograd.profiler#EnforceUnique();torch.autograd.profiler#KinetoStepTracker();torch.autograd.profiler#record_function(name~str)();torch.autograd#detect_anomaly(check_nan~bool=True)();torch.autograd#set_detect_anomaly(mode~bool,check_nan~bool=True);torch.autograd.grad_mode#set_multithreading_enabled(mode~bool);torch.autograd.graph#Node(T~name~str,T~metadata,T~next_functions;M~register_hook(hook~Callable);M~register_prehook(prehook~Callable));torch.autograd.graph#increment_version(tensor~Tensor)>None;torch.autograd.graph#saved_tensors_hooks(pack_hook~Callable,unpack_hook~Callable)();torch.autograd.graph#save_on_cpu(pin_memory~bool=False,device_type~str='cuda')();torch.autograd.graph#disable_saved_tensors_hooks(error_message~str)();torch.autograd.graph#register_multi_grad_hook(tensors~list,fn~Callable,mode~str='all')>RemovableHandle;torch.autograd.graph#allow_mutation_on_saved_tensors()();torch.autograd.graph#get_gradient_edge(tensor~Tensor)>GradientEdge;torch.accelerator#device_count()>int;torch.accelerator#is_available()>bool;torch.accelerator#current_accelerator();torch.accelerator#set_device_index(device~int)>None;torch.accelerator#set_device_idx(device~int)>None;torch.accelerator#current_device_index()>int;torch.accelerator#current_device_idx()>int;torch.accelerator#set_stream(stream~Stream)>None;torch.accelerator#current_stream(device~int)>Stream;torch.accelerator#synchronize(device~int)>None;torch.cpu#current_device()>int;torch.cpu#current_stream(device~int)>Stream;torch.cpu#is_available()>bool;torch.cpu#synchronize(device~int)>None;torch.cpu#stream(stream~Stream)();torch.cpu#set_device(device~int)>None;torch.cpu#device_count()>int;torch.cuda#can_device_access_peer(device_idx_1~int,device_idx_2~int)>bool;torch.cuda#current_blas_handle();torch.cuda#current_device()>int;torch.cuda#current_stream(device~int)>Stream;torch.cuda#cudart();torch.cuda#default_stream(device~int)>Stream;torch.cuda#device(device~Union[int,device])();torch.cuda#device_count()>int;torch.cuda#device_memory_used(device~Union[int,device])>int;torch.cuda#device_of(obj~Tensor)();torch.cuda#get_arch_list()>list[str];torch.cuda#get_device_capability(device~int)>tuple;torch.cuda#get_device_name(device~int)>str;torch.cuda#get_device_properties(device~Union[int,device])>DeviceProperties;torch.cuda#get_gencode_flags()>list[str];torch.cuda#get_stream_from_external(stream_ptr~int)>Stream;torch.cuda#get_sync_debug_mode()>str;torch.cuda#init()>None;torch.cuda#ipc_collect()>None;torch.cuda#is_available()>bool;torch.cuda#is_initialized()>bool;torch.cuda#is_tf32_supported()>bool;torch.cuda#memory_usage(device~Union[int,device])>float;torch.cuda#set_device(device~Union[int,device])>None;torch.cuda#set_stream(stream~Stream)>None;torch.cuda#set_sync_debug_mode(mode~str)>None;torch.cuda#stream(stream~Stream)();torch.cuda#synchronize(device~Union[int,device])>None;torch.cuda#utilization(device~Union[int,device])>float;torch.cuda#temperature(device~Union[int,device])>float;torch.cuda#power_draw(device~Union[int,device])>float;torch.cuda#clock_rate(device~Union[int,device])>float;torch.cuda.comm#broadcast(tensor~Tensor,device_ids~list[int])>Tensor;torch.cuda.comm#broadcast_coalesced(tensors~list[Tensor],device_ids~list[int],buffer_size~int)>list[Tensor];torch.cuda.comm#reduce_add(inputs~list[Tensor],destination_device~int)>Tensor;torch.cuda.comm#scatter(tensor~Tensor,scatter_list~list[Tensor],device_ids~list[int],chunk_size~int,dim~int,async_op~bool)>Tensor;torch.cuda.comm#gather(tensor~Tensor,gather_list~list[Tensor],device_ids~list[int],dim~int)>list[Tensor];torch.cuda#is_current_stream_capturing()>bool!B;torch.cuda#graph_pool_handle();torch.cuda#graph()()!B;torch.cuda#make_graphed_callables(callables~Iterable)>list!B;torch.cuda#empty_cache()>None;torch.cuda#get_per_process_memory_fraction()>float;torch.cuda#list_gpu_processes(device~Union[int,device])>str;torch.cuda#mem_get_info(device~Union[int,device])>tuple;torch.cuda#memory_stats(device~Union[int,device])>dict;torch.cuda#host_memory_stats(device~Union[int,device])>dict;torch.cuda#memory_summary(device~Union[int,device],abbreviated~bool)>str;torch.cuda#memory_snapshot()>list;torch.cuda#memory_allocated(device~Union[int,device])>int;torch.cuda#max_memory_allocated(device~Union[int,device])>int;torch.cuda#reset_max_memory_allocated(device~Union[int,device])>None;torch.cuda#memory_reserved(device~Union[int,device])>int;torch.cuda#max_memory_reserved(device~Union[int,device])>int;torch.cuda#set_per_process_memory_fraction(fraction~float,device~Union[int,device])>None;torch.cuda#memory_cached()!D;torch.cuda#max_memory_cached()!D;torch.cuda#reset_max_memory_cached()!D;torch.cuda#reset_peak_memory_stats(device~Union[int,device])>None;torch.cuda#reset_peak_host_memory_stats(device~Union[int,device])>None;torch.cuda#caching_allocator_alloc(size~int,device_index~int,stream~Stream)>int;torch.cuda#caching_allocator_delete(ptr~int)>None;torch.cuda#get_allocator_backend()>str;torch.cuda#change_current_allocator(allocator~CUDAPluggableAllocator)>None;torch.cuda#caching_allocator_enable(enabled~bool)>None;torch.cuda#use_mem_pool(pool~MemPool,device~Union[device,int]=None)();torch.cuda.nvtx#mark(msg~str)>None;torch.cuda.nvtx#range_push(msg~str)>int;torch.cuda.nvtx#range_pop()>None;torch.cuda.nvtx#range(msg~str)();torch.cuda.jiterator#_create_jit_fn(kernel_name~str,cpp_source_code~str,cuda_source_code~str,cuda_wrapper_cpp_source_code~str)!B;torch.cuda.jiterator#_create_multi_output_jit_fn(kernel_name~str,cpp_source_code~str,cuda_source_code~str,cuda_wrapper_cpp_source_code~str)!B;torch.cuda.gds#gds_register_buffer(buffer~Tensor)>None!P;torch.cuda.gds#gds_deregister_buffer(buffer~Tensor)>None!P;torch.backends.cpu#get_cpu_capability()>str;torch.backends.cuda#is_built()>bool;torch.backends.cuda#preferred_blas_library(backend~str=None)>BlasBackend!X;torch.backends.cuda#preferred_rocm_fa_library(backend~str=None)>ROCmFABackend!X;torch.backends.cuda#preferred_linalg_library(backend~str=None)>LinalgBackend!X;torch.backends.cuda#flash_sdp_enabled()>bool!B;torch.backends.cuda#enable_mem_efficient_sdp(enabled~bool)>None!B;torch.backends.cuda#mem_efficient_sdp_enabled()>bool!B;torch.backends.cuda#enable_flash_sdp(enabled~bool)>None!B;torch.backends.cuda#math_sdp_enabled()>bool!B;torch.backends.cuda#enable_math_sdp(enabled~bool)>None!B;torch.backends.cuda#fp16_bf16_reduction_math_sdp_allowed()>bool!B;torch.backends.cuda#allow_fp16_bf16_reduction_math_sdp(enabled~bool)>None!B;torch.backends.cuda#cudnn_sdp_enabled()>bool!B;torch.backends.cuda#enable_cudnn_sdp(enabled~bool)>None!B;torch.backends.cuda#is_flash_attention_available()>bool;torch.backends.cuda#can_use_flash_attention(params~SDPAParams,debug~bool=False)>bool;torch.backends.cuda#can_use_efficient_attention(params~SDPAParams,debug~bool=False)>bool;torch.backends.cuda#can_use_cudnn_attention(params~SDPAParams,debug~bool=False)>bool;torch.backends.cuda#sdp_kernel(enable_flash~bool=True,enable_math~bool=True,enable_mem_efficient~bool=True,enable_cudnn~bool=True)()!B;torch.backends.cudnn#version()>int;torch.backends.cudnn#is_available()>bool;torch.backends.mha#get_fastpath_enabled()>bool;torch.backends.mha#set_fastpath_enabled(value~bool)>None;torch.backends.mps#is_available()>bool;torch.backends.mps#is_built()>bool;torch.backends.mkl#is_available()>bool;torch.backends.mkl#verbose(enable~bool)();torch.backends.mkldnn#is_available()>bool;torch.backends.mkldnn#verbose(level~int)();torch.backends.nnpack#is_available()>bool;torch.backends.nnpack#flags(enabled~bool=False)();torch.backends.nnpack#set_flags(enabled~bool)>None;torch.backends.openmp#is_available()>bool;torch.backends.opt_einsum#is_available()>bool;torch.backends.opt_einsum#get_opt_einsum()>Any;torch.backends.opt_einsum#enabled~bool;torch.backends.opt_einsum#strategy~str;torch.utils.benchmark#Timer(stmt~str='pass',setup~str='pass',global_setup~str='',timer~Callable=perf_counter,globals~Optional[dict]=None,label~Optional[str]=None,sub_label~Optional[str]=None,description~Optional[str]=None,env~Optional[str]=None,num_threads~int=1,language~Language=Language.PYTHON)(I();M~adaptive_autorange(threshold~float=0.1,min_run_time~float=0.01,max_run_time~float=10.0,callback~Callable=None)>Measurement;M~blocked_autorange(callback~Callable=None,min_run_time~float=0.2)>Measurement;M~collect_callgrind(number~int,repeats~int=None,collect_baseline~bool,retain_out_file~bool)>CallgrindStats;M~timeit(number~int=1000000)>Measurement);torch.utils.bottleneck# (Module);torch.utils.checkpoint#checkpoint(function~Callable,*args,use_reentrant~bool=None,context_fn~Callable=noop_context_fn,determinism_check~str='default',debug~bool=False,**kwargs)>Any;torch.utils.checkpoint#checkpoint_sequential(functions~Union[Sequential,list],segments~int,input~Tensor,use_reentrant~bool=None,**kwargs)>Any;torch.utils.checkpoint#set_checkpoint_debug_enabled(enabled~bool)>None;torch.utils.checkpoint#create_selective_checkpoint_contexts(policy_fn_or_list~Union[Callable,list],allow_cache_entry_mutation~bool=False)>tuple;torch.utils.cpp_extension#CppExtension(name~str,sources~Union[str,list[str]],*args,**kwargs)>Extension;torch.utils.cpp_extension#CUDAExtension(name~str,sources~Union[str,list[str]],*args,**kwargs)>Extension;torch.utils.cpp_extension#SyclExtension(name~str,sources~Union[str,list[str]],*args,**kwargs)>Extension;torch.utils.cpp_extension#BuildExtension(I());torch.utils.cpp_extension#load(name~str,sources~Union[str,list[str]],extra_cflags~list=None,extra_cuda_cflags~list=None,extra_sycl_cflags~list=None,extra_ldflags~list=None,extra_include_paths~list=None,build_directory~str=None,verbose~bool=False,with_cuda~bool=None,with_sycl~bool=None,is_python_module~bool=True,is_standalone~bool=False,keep_intermediates~bool=True)>Union[Module,str,None];torch.utils.cpp_extension#load_inline(name~str,cpp_sources~Union[str,list[str]],cuda_sources~Union[str,list[str]]=None,sycl_sources~Union[str,list[str]]=None,functions~Union[list[str],dict]=None,extra_cflags~list=None,extra_cuda_cflags~list=None,extra_sycl_cflags~list=None,extra_ldflags~list=None,extra_include_paths~list=None,build_directory~str=None,verbose~bool=False,with_cuda~bool=None,with_sycl~bool=None,is_python_module~bool=True,with_pytorch_error_handling~bool=True,keep_intermediates~bool=True,use_pch~bool=False)>Union[Module,None];torch.utils.cpp_extension#include_paths(device_type~str='cpu')>list[str];torch.utils.cpp_extension#get_compiler_abi_compatibility_and_version(compiler~str)>tuple;torch.utils.cpp_extension#verify_ninja_availability()>None;torch.utils.cpp_extension#is_ninja_available()>bool;torch.utils.data#DataLoader(dataset~Dataset,batch_size~int=1,shuffle~bool=None,sampler~Union[Sampler,Iterable]=None,batch_sampler~Union[Sampler,Iterable]=None,num_workers~int=0,collate_fn~Callable=None,pin_memory~bool=False,drop_last~bool=False,timeout~numeric=0,worker_init_fn~Callable=None,multiprocessing_context~Union[str,BaseContext]=None,generator~Generator=None,prefetch_factor~int=None,persistent_workers~bool=False,pin_memory_device~str='',in_order~bool=True)(I());torch.utils.data#default_collate(batch~list);torch.utils.data#default_convert(data~Any);torch.utils.data#get_worker_info()>Optional[WorkerInfo];torch.utils.data#random_split(dataset~Dataset,lengths~sequence,generator~Generator=None)>list[Subset];torch.utils.data#BatchSampler(sampler~Union[Sampler,Iterable],batch_size~int,drop_last~bool)(I());torch.utils.data.distributed#DistributedSampler(dataset~Dataset,num_replicas~int=None,rank~int=None,shuffle~bool=True,seed~int=0,drop_last~bool=False)(I());torch.utils.dlpack#from_dlpack(ext_tensor~object)>Tensor;torch.utils.dlpack#to_dlpack(tensor~Tensor)>PyCapsule;torch.__config__#show()>str;torch.__config__#parallel_info()>str;torch.distributed#is_available()>bool;torch.distributed#init_process_group(backend~Union[str,Backend]=None,init_method~str=None,timeout~timedelta=None,world_size~int=-1,rank~int=-1,store~Store=None,group_name~str=''!D,pg_options~ProcessGroupOptions=None,device_id~device=None)>None;torch.distributed.device_mesh#init_device_mesh(device_type~str,mesh_shape~tuple,*_,mesh_dim_names~tuple[str]=None)>DeviceMesh;torch.distributed#is_initialized()>bool;torch.distributed#is_mpi_available()>bool;torch.distributed#is_nccl_available()>bool;torch.distributed#is_gloo_available()>bool;torch.distributed.distributed_c10d#is_xccl_available()>bool;torch.distributed#is_torchelastic_launched()>bool;torch.distributed#new_group(ranks~list[int]=None,timeout~timedelta=None,backend~Union[str,Backend]=None,pg_options~ProcessGroupOptions=None,use_local_synchronization~bool=False,group_desc~str=None,device_id~device=None)>Union[ProcessGroup,GroupMember];torch.distributed#get_group_rank(group