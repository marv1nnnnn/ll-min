S:Beautiful Soup;V:4.8.1
O:K~HTML,XML,parsing,web scraping,data extraction,tree traversal,DOM manipulation,encoding detection,parser-agnostic;P~idiomatic API,lenient parsing,memory efficiency|E~KeyError,AttributeError,ImportError,SyntaxError,UnicodeEncodeError,UnicodeDecodeError,HTMLParser.HTMLParseError
I:P~Python 2.7+,Python 3.2+,lxml,html5lib;C~apt-get install python-bs4,apt-get install python3-bs4,easy_install beautifulsoup4,pip install beautifulsoup4,python setup.py install;S~copy bs4 directory;V~diagnose()
C:M~html.parser,lxml,html5lib,lxml-xml,xml,Unicode,Dammit;O~Tag,NavigableString,BeautifulSoup,Comment,CData,ProcessingInstruction,Declaration,Doctype,SoupStrainer,UnicodeDammit,Formatter,HTMLFormatter,XMLFormatter,ResultSet;E~None
A:bs4.element#Tag(I();M~append(element~PageElement)>None,extend(elements~list~PageElement)>None,insert(position~int,element~PageElement)>None,insert_before(element~PageElement)>None,insert_after(element~PageElement)>None,clear()>None,decompose()>None,unwrap()>PageElement,replaceWithChildren()>PageElement!D,smooth()>None,has_attr(name~str)>bool,has_key(name~str)>bool!D,get(key~str,default~any=None)>any,select(selector~str,namespaces~dict=auto)>list~Tag,select_one(selector~str,namespaces~dict=auto)>Tag,find_all(name~filter,attrs~dict,recursive~bool=True,string~filter,limit~int=None,**kwargs~filter)>list~Tag,findAll(name~filter,attrs~dict,recursive~bool=True,string~filter,limit~int=None,**kwargs~filter)>list~Tag!D,find(name~filter,attrs~dict,recursive~bool=True,string~filter,**kwargs~filter)>Tag,findNext(name~filter,attrs~dict,recursive~bool=True,string~filter,**kwargs~filter)>Tag!D,find_parents(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag,findParents(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag!D,find_parent(name~filter,attrs~dict,string~filter,**kwargs~filter)>Tag,findParent(name~filter,attrs~dict,string~filter,**kwargs~filter)>Tag!D,find_next_siblings(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag,findNextSiblings(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag!D,find_next_sibling(name~filter,attrs~dict,string~filter,**kwargs~filter)>Tag,findNextSibling(name~filter,attrs~dict,string~filter,**kwargs~filter)>Tag!D,find_all_next(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag,findAllNext(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag!D,find_next(name~filter,attrs~dict,string~filter,**kwargs~filter)>Tag,findPrevious(name~filter,attrs~dict,string~filter,**kwargs~filter)>Tag!D,find_all_previous(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag,findAllPrevious(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag!D,find_previous(name~filter,attrs~dict,string~filter,**kwargs~filter)>Tag,findPreviousSibling(name~filter,attrs~dict,string~filter,**kwargs~filter)>Tag!D,find_previous_siblings(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag,findPreviousSiblings(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag!D,get_attribute_list(key~str)>list,get_text(separator~str="",strip~bool=False)>str,getText()>str!D,encode(encoding~str=utf-8,formatter~str/Formatter=minimal)>bytes,decode(encoding~str=utf-8,formatter~str/Formatter=minimal)>str,replace_with(element~PageElement)>PageElement,replaceWith(element~PageElement)>PageElement!D,extract()>PageElement,wrap(wrapper~Tag)>Tag,childGenerator()>generator!D,nextGenerator()>generator!D,nextSiblingGenerator()>generator!D,previousGenerator()>generator!D,previousSiblingGenerator()>generator!D,recursiveChildGenerator()>generator!D,parentGenerator()>generator!D);T~name~str,attrs~dict,contents~list~PageElement,children~generator,descendants~generator,string~NavigableString/Tag/None,strings~generator~NavigableString,stripped_strings~generator~str,sourceline~int=None,sourcepos~int=None,is_empty_element~bool,isSelfClosing~bool!D,next~PageElement!D,previous~PageElement!D,parent~PageElement,previous_sibling~PageElement,previousSibling~PageElement!D,next_sibling~PageElement,nextSibling~PageElement!D,previous_elements~generator,next_elements~generator,parents~generator);bs4.element#NavigableString(I(obj~str);M~replace_with(element~PageElement)>PageElement,extract()>PageElement,wrap(wrapper~Tag)>Tag,getText()>str!D;T~parent~PageElement,previous_sibling~PageElement,previousSibling~PageElement!D,next_sibling~PageElement,nextSibling~PageElement!D,previous_elements~generator,previousGenerator()>generator!D,next_elements~generator,nextGenerator()>generator!D,parents~generator,parentGenerator()>generator!D,string~NavigableString/Tag/None);bs4.element#Comment(I(obj~str));bs4.element#CData(I(obj~str));bs4.element#ProcessingInstruction(I());bs4.element#Declaration(I());bs4.element#Doctype(I());bs4#BeautifulSoup(I(markup~str/filehandle,parser~str=best,parse_only~SoupStrainer=None,parseOnlyThese~SoupStrainer=None!D,from_encoding~str=auto,fromEncoding~str=auto!D,exclude_encodings~list=auto,multi_valued_attributes~dict=auto,store_line_numbers~bool=auto,isHTML~bool!D,markupMassage~callable!D);M~prettify()>str,encode(encoding~str=utf-8,formatter~str/Formatter=minimal)>bytes,decode(encoding~str=utf-8,formatter~str/Formatter=minimal)>str,get_text(separator~str="",strip~bool=False)>str,getText()>str!D,select(selector~str,namespaces~dict=auto)>list~Tag,select_one(selector~str,namespaces~dict=auto)>Tag,find_all(name~filter,attrs~dict,recursive~bool=True,string~filter,limit~int=None,**kwargs~filter)>list~Tag,findAll(name~filter,attrs~dict,recursive~bool=True,string~filter,limit~int=None,**kwargs~filter)>list~Tag!D,find(name~filter,attrs~dict,recursive~bool=True,string~filter,**kwargs~filter)>Tag,findNext(name~filter,attrs~dict,recursive~bool=True,string~filter,**kwargs~filter)>Tag!D,find_parents(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag,findParents(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag!D,find_parent(name~filter,attrs~dict,string~filter,**kwargs~filter)>Tag,findParent(name~filter,attrs~dict,string~filter,**kwargs~filter)>Tag!D,find_next_siblings(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag,findNextSiblings(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag!D,find_next_sibling(name~filter,attrs~dict,string~filter,**kwargs~filter)>Tag,findNextSibling(name~filter,attrs~dict,string~filter,**kwargs~filter)>Tag!D,find_all_next(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag,findAllNext(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag!D,find_next(name~filter,attrs~dict,string~filter,**kwargs~filter)>Tag,findPrevious(name~filter,attrs~dict,string~filter,**kwargs~filter)>Tag!D,find_all_previous(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag,findAllPrevious(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag!D,find_previous(name~filter,attrs~dict,string~filter,**kwargs~filter)>Tag,findPreviousSibling(name~filter,attrs~dict,string~filter,**kwargs~filter)>Tag!D,find_previous_siblings(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag,findPreviousSiblings(name~filter,attrs~dict,string~filter,limit~int=None,**kwargs~filter)>list~Tag!D,new_tag(name~str,namespace~str=None,soup~BeautifulSoup=None,**kwargs~attr)>Tag,childGenerator()>generator!D,nextGenerator()>generator!D,nextSiblingGenerator()>generator!D,previousGenerator()>generator!D,previousSiblingGenerator()>generator!D,recursiveChildGenerator()>generator!D,parentGenerator()>generator!D,renderContents()>bytes!D);T~name~str='[document]',attrs~dict,contents~list~PageElement,children~generator,descendants~generator,string~NavigableString/Tag/None,strings~generator~NavigableString,stripped_strings~generator~str,original_encoding~str,parent~None););bs4#SoupStrainer(I(name~filter=None,attrs~dict=None,string~filter=None,**kwargs~filter));bs4#UnicodeDammit(I(markup~bytes/str,encodings~list=auto,is_html~bool=False,smart_quotes_to~str=unicode,smartQuotesTo~str=unicode!D,exclude_encodings~list=None,override_encodings~list=None,convertEntities~str!D);M~detwingle(markup~bytes)>bytes;T~unicode_markup~str,unicode~str!D,original_encoding~str,contains_replacement_characters~bool);bs4.formatter#Formatter(M~formatter(value~str)>str,attributes(tag~Tag)>list~tuple~str/any);bs4.formatter#HTMLFormatter(I(entity_substitution~callable=None));bs4.formatter#XMLFormatter(I(entity_substitution~callable=None));bs4.diagnose#diagnose(data~str/bytes)>None;bs4.builder#builder_registry(M~lookup(parser~str)>Builder);bs4.builder#Builder(T~DEFAULT_CDATA_LIST_ATTRIBUTES~dict);bs4.element#ResultSet(T~list~PageElement);
F:HTML parsing,XML parsing,tree navigation,tree searching,tree modification,output formatting,encoding detection,troubleshooting,CSS selectors,performance tuning,BS3 compatibility
X:pip,easy_install,apt-get,setup.py,source distribution,application packaging,Python 2,Python 3
Z:^Ifrom bs4 import BeautifulSoup
soup = BeautifulSoup(html_doc, 'html.parser')
print(soup.prettify())^;^Esoup.title
soup.title.name
soup.title.string
soup.title.parent.name
soup.p
soup.p['class']
soup.a
soup.find_all('a')
soup.find(id="link3")^;^Efor link in soup.find_all('a'):
  print(link.get('href'))^;^Eprint(soup.get_text())^;^Esoup.find_all('b')^;^Eimport re
soup.find_all(re.compile("^b"))^;^Esoup.find_all(["a", "b"])^;^Edef has_class_but_no_id(tag):
  return tag.has_attr('class') and not tag.has_attr('id')
soup.find_all(has_class_but_no_id)^;^Esoup.find_all(id=True)^;^Esoup.find_all(href=re.compile("elsie"), id='link1')^;^Edata_soup = BeautifulSoup('<div data-foo="value">foo!</div>')
data_soup.find_all(attrs={"data-foo": "value"})^;^Esoup.find_all("a", class_="sister")^;^Esoup.find_all(class_=re.compile("itl"))^;^Esoup.find_all(string="Elsie")^;^Esoup.find_all("a", limit=2)^;^Esoup.html.find_all("title", recursive=False)^;^Esoup("a")^;^Esoup.find('title')^;^Ea_string = soup.find(string="Lacie")
a_string.find_parents("a")
a_string.find_parent("p")^;^Efirst_link = soup.a
first_link.find_next_siblings("a")^;^Elast_link = soup.find("a", id="link3")
last_link.find_previous_siblings("a")^;^Efirst_link = soup.a
first_link.find_all_next(string=True)^;^Efirst_link = soup.a
first_link.find_all_previous("p")^;^Esoup.select("title")
soup.select("p:nth-of-type(3)")
soup.select("body a")
soup.select("head > title")
soup.select("#link1 ~ .sister")
soup.select(".sister")
soup.select("#link1")
soup.select('a[href]')
soup.select('a[href*=".com/el"]')^;^Esoup.select_one(".sister")^;^Esoup = BeautifulSoup('<b class="boldest">Extremely bold</b>')
tag = soup.b
tag.name = "blockquote"
tag['class'] = 'verybold'
tag['id'] = 1
del tag['class']^;^Etag.string = "New link text."^;^Esoup = BeautifulSoup("<a>Foo</a>")
soup.a.append("Bar")^;^Esoup = BeautifulSoup("<a>Soup</a>")
soup.a.extend(["'s", " ", "on"])^;^Esoup = BeautifulSoup("<b></b>")
tag = soup.b
new_string = NavigableString(" there")
tag.append(new_string)
new_comment = Comment("Nice to see you.")
tag.append(new_comment)^;^Esoup = BeautifulSoup("<b></b>")
original_tag = soup.b
new_tag = soup.new_tag("a", href="http://www.example.com")
original_tag.append(new_tag)^;^Esoup = BeautifulSoup('<a href="http://example.com/">I linked to <i>example.com</i></a>')
tag = soup.a
tag.insert(1, "but did not endorse ")^;^Esoup = BeautifulSoup("<b>stop</b>")
tag = soup.new_tag("i")
tag.string = "Don't"
soup.b.string.insert_before(tag)^;^Ediv = soup.new_tag('div')
div.string = 'ever'
soup.b.i.insert_after(" you ", div)^;^Esoup = BeautifulSoup('<a href="http://example.com/">I linked to <i>example.com</i></a>')
tag = soup.a
tag.clear()^;^Esoup = BeautifulSoup('<a href="http://example.com/">I linked to <i>example.com</i></a>')
i_tag = soup.i.extract()^;^Esoup = BeautifulSoup('<a href="http://example.com/">I linked to <i>example.com</i></a>')
soup.i.decompose()^;^Esoup = BeautifulSoup('<a href="http://example.com/">I linked to <i>example.com</i></a>')
new_tag = soup.new_tag("b")
new_tag.string = "example.net"
soup.i.replace_with(new_tag)^;^Esoup = BeautifulSoup("<p>I wish I was bold.</p>")
soup.p.string.wrap(soup.new_tag("b"))^;^Esoup = BeautifulSoup('<a href="http://example.com/">I linked to <i>example.com</i></a>')
a_tag = soup.a
a_tag.i.unwrap()^;^Esoup = BeautifulSoup("<p>A one</p>")
soup.p.append(", a two")
soup.smooth()^;^Esoup = BeautifulSoup(markup)
print(soup.prettify())^;^Estr(soup)
unicode(soup.a)^;^Esoup = BeautifulSoup("&ldquo;Dammit!&rdquo; he said.")
str(soup)^;^Efrench = "<p>Il a dit &lt;&lt;Sacr&eacute; bleu!&gt;&gt;</p>"
soup = BeautifulSoup(french)
print(soup.prettify(formatter="minimal"))^;^Esoup = BeautifulSoup("<br>")
print(soup.encode(formatter="html5"))^;^Elink_soup = BeautifulSoup('<a href="http://example.com/?foo=val1&bar=val2">A link</a>')
print(link_soup.a.encode(formatter=None))^;^Efrom bs4.formatter import HTMLFormatter
def uppercase(str):
  return str.upper()
formatter = HTMLFormatter(uppercase)
print(soup.prettify(formatter=formatter))^;^Eattr_soup = BeautifulSoup(b'<p z="1" m="2" a="3"></p>')
class UnsortedAttributes(HTMLFormatter):
  def attributes(self, tag):
    for k, v in tag.attrs.items():
      if k == 'm':
	     continue
       yield k, v
print(attr_soup.p.encode(formatter=UnsortedAttributes()))^;^Esoup = BeautifulSoup(markup)
soup.get_text("|", strip=True)^;^Esoup = BeautifulSoup(markup, 'html.parser')
for tag in soup.find_all('p'):
  print(tag.sourceline, tag.sourcepos, tag.string)^;^Eimport copy
p_copy = copy.copy(soup.p)^;^Efrom bs4 import SoupStrainer
only_a_tags = SoupStrainer("a")
only_tags_with_id_link2 = SoupStrainer(id="link2")
def is_short_string(string):
  return len(string) < 10
only_short_strings = SoupStrainer(string=is_short_string)
print(BeautifulSoup(html_doc, "html.parser", parse_only=only_a_tags).prettify())^;^Efrom bs4.diagnose import diagnose
with open("bad.html") as fp:
  data = fp.read()
diagnose(data)^;^Esoup = BeautifulSoup(markup, "xml")^;^Edammit = UnicodeDammit("Sacr\xc3\xa9 bleu!")
print(dammit.unicode_markup)
dammit.original_encoding^;^Edammit = UnicodeDammit("Sacr\xe9 bleu!", ["latin-1", "iso-8859-1"])^;^Emarkup = b"<p>I just \x93love\x94 Microsoft Word\x92s smart quotes</p>"
UnicodeDammit(markup, ["windows-1252"], smart_quotes_to="html").unicode_markup^;^Esnowmen = (u"\N{SNOWMAN}" * 3)
quote = (u"\N{LEFT DOUBLE QUOTATION MARK}I like snowmen!\N{RIGHT DOUBLE QUOTATION MARK}")
doc = snowmen.encode("utf8") + quote.encode("windows_1252")
new_doc = UnicodeDammit.detwingle(doc)
print(new_doc.decode("utf8"))^;^Efrom BeautifulSoup import BeautifulSoup # BS3 import
from bs4 import BeautifulSoup # BS4 import^